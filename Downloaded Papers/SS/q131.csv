Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
0,"M. Careem, A. Dutta, Ngwe Thawdar","On Equivalence of Neural Network Receivers",2021,"","","","",1,"2022-07-13 10:07:35","","10.1109/ICC42927.2021.9500703","","",,,,,0,0.00,0,3,1,"Neural Network (NN) based receivers have seen limited adoption in practical systems due to a lack of explainability and performance guarantees, despite their efficacy as a data-driven tool for physical layer signal processing. In order to bridge this gap in explainability, we present an equivalent NN-based receiver that performs the same optimizations used by classical receivers for symbol detection. Achieving equivalence is crucial to explaining how a NN-based receiver classifies symbols in high-dimensional channels and determining its structure that is robust to the underlying channel with minimum training. We realize this by deriving the risk function that guarantees equivalence, which also provides a measure of the disparity between NN-based and classical receivers. Consequently, this information allows us to derive mathematically tight data-dependent bounds on the bit error rate of NN-based receivers, and empirically determine its structure that achieves minimum error rate. Extensive simulation results show the efficacy of the derived bounds and structure of NN-based receivers for single and multi-antenna systems over a variety of channels.","",""
1,"J. Hyatt, Michael Lee","Requirements for Developing Robust Neural Networks",2019,"","","","",2,"2022-07-13 10:07:35","","","","",,,,,1,0.33,1,2,3,"Validation accuracy is a necessary, but not sufficient, measure of a neural network classifier's quality. High validation accuracy during development does not guarantee that a model is free of serious flaws, such as vulnerability to adversarial attacks or a tendency to misclassify (with high confidence) data it was not trained on. The model may also be incomprehensible to a human or base its decisions on unreasonable criteria. These problems, which are not unique to classifiers, have been the focus of a substantial amount of recent research. However, they are not prioritized during model development, which almost always optimizes on validation accuracy to the exclusion of everything else. The product of this approach is likely to fail in unexpected ways outside of the training environment. We believe that, in addition to validation accuracy, the model development process must give added weight to other performance metrics such as explainability, resistance to adversarial attacks, and overconfidence on out-of-distribution data.","",""
7,"Laura Rieger, L. K. Hansen","Aggregating explanation methods for stable and robust explainability.",2019,"","","","",3,"2022-07-13 10:07:35","","","","",,,,,7,2.33,4,2,3,"Despite a growing literature on explaining neural networks, no consensus has been reached on how to explain a neural network decision or how to evaluate an explanation. Our contributions in this paper are twofold. First, we investigate schemes to combine explanation methods and reduce model uncertainty to obtain a single aggregated explanation. We provide evidence that the aggregation is better at identifying important features, than on individual methods. Adversarial attacks on explanations is a recent active research topic. As our second contribution, we present evidence that aggregate explanations are much more robust to attacks than individual explanation methods.","",""
7,"Laura Rieger, L. K. Hansen","Aggregating explainability methods for neural networks stabilizes explanations",2019,"","","","",4,"2022-07-13 10:07:35","","","","",,,,,7,2.33,4,2,3,"Despite a growing literature on explaining neural networks, no consensus has been reached on how to explain a neural network decision or how to evaluate an explanation. In fact, most works rely on manually assessing the explanation to evaluate the quality of a method. This injects uncertainty in the explanation process along several dimensions: Which explanation method to apply? Who should we ask to evaluate it and which criteria should be used for the evaluation? Our contributions in this paper are twofold. First, we investigate schemes to combine explanation methods and reduce model uncertainty to obtain a single aggregated explanation. Our findings show that the aggregation is more robust, well-aligned with human explanations and can attribute relevance to a broader set of features (completeness). Second, we propose a novel way of evaluating explanation methods that circumvents the need for manual evaluation and is not reliant on the alignment of neural networks and humans decision processes.","",""
0,"Kudzai Sauka, Gunkwon Shin, Dong-Wook Kim, Myung-Mook Han","Adversarial Robust and Explainable Network Intrusion Detection Systems Based on Deep Learning",2022,"","","","",5,"2022-07-13 10:07:35","","10.3390/app12136451","","",,,,,0,0.00,0,4,1,"The ever-evolving cybersecurity environment has given rise to sophisticated adversaries who constantly explore new ways to attack cyberinfrastructure. Recently, the use of deep learning-based intrusion detection systems has been on the rise. This rise is due to deep neural networks (DNN) complexity and efficiency in making anomaly detection activities more accurate. However, the complexity of these models makes them black-box models, as they lack explainability and interpretability. Not only is the DNN perceived as a black-box model, but recent research evidence has also shown that they are vulnerable to adversarial attacks. This paper developed an adversarial robust and explainable network intrusion detection system based on deep learning by applying adversarial training and implementing explainable AI techniques. In our experiments with the NSL-KDD dataset, the PGD adversarial-trained model was a more robust model than DeepFool adversarial-trained and FGSM adversarial-trained models, with a ROC-AUC of 0.87. The FGSM attack did not affect the PGD adversarial-trained model’s ROC-AUC, while the DeepFool attack caused a minimal 9.20% reduction in PGD adversarial-trained model’s ROC-AUC. PGD attack caused a 15.12% reduction in the DeepFool adversarial-trained model’s ROC-AUC and a 12.79% reduction in FGSM trained model’s ROC-AUC.","",""
1,"Anubhab Ghosh, Antoine Honor'e, Dong Liu, G. Henter, S. Chatterjee","Normalizing Flow based Hidden Markov Models for Classification of Speech Phones with Explainability",2021,"","","","",6,"2022-07-13 10:07:35","","","","",,,,,1,1.00,0,5,1,"In pursuit of explainability, we develop generative models for sequential data. The proposed models provide state-of-the-art classification results and robust performance for speech phone classification. We combine modern neural networks (normalizing flows) and traditional generative models (hidden Markov models HMMs). Normalizing flow-based mixture models (NMMs) are used to model the conditional probability distribution given the hidden state in the HMMs. Model parameters are learned through judicious combinations of time-tested Bayesian learning methods and contemporary neural network learning methods. We mainly combine expectation-maximization (EM) and mini-batch gradient descent. The proposed generative models can compute likelihood of a data and hence directly suitable for maximum-likelihood (ML) classification approach. Due to structural flexibility of HMMs, we can use different normalizing flow models. This leads to different types of HMMs providing diversity in data modeling capacity. The diversity provides an opportunity for easy decision fusion from different models. For a standard speech phone classification setup involving 39 phones (classes) and the TIMIT dataset, we show that the use of standard features called mel-frequency-cepstral-coeffcients (MFCCs), the proposed generative models, and the decision fusion together can achieve 86.6% accuracy by generative training only. This result is close to state-of-the-art results, for examples, 86.2% accuracy of PyTorch-Kaldi toolkit [1], and 85.1% accuracy using light gated recurrent units [2]. We do not use any discriminative learning approach and related sophisticated features in this article.","",""
13,"R. Shafik, A. Wheeldon, A. Yakovlev","Explainability and Dependability Analysis of Learning Automata based AI Hardware",2020,"","","","",7,"2022-07-13 10:07:35","","10.1109/iolts50870.2020.9159725","","",,,,,13,6.50,4,3,2,"Explainability remains the holy grail in designing the next-generation pervasive artificial intelligence (AI) systems. Current neural network based AI design methods do not naturally lend themselves to reasoning for a decision making process from the input data. A primary reason for this is the overwhelming arithmetic complexity.Built on the foundations of propositional logic and game theory, the principles of learning automata are increasingly gaining momentum for AI hardware design. The lean logic based processing has been demonstrated with significant advantages of energy efficiency and performance. The hierarchical logic underpinning can also potentially provide opportunities for by-design explainable and dependable AI hardware. In this paper, we study explainability and dependability using reachability analysis in two simulation environments. Firstly, we use a behavioral SystemC model to analyze the different state transitions. Secondly, we carry out illustrative fault injection campaigns in a low-level SystemC environment to study how reachability is affected in the presence of hardware stuck-at 1 faults. Our analysis provides the first insights into explainable decision models and demonstrates dependability advantages of learning automata driven AI hardware design.","",""
23,"Xinyang Zhang, Lina Yao, Manqing Dong, Zhe Liu, Yu Zhang, Yong Li","Adversarial Representation Learning for Robust Patient-Independent Epileptic Seizure Detection",2019,"","","","",8,"2022-07-13 10:07:35","","10.1109/JBHI.2020.2971610","","",,,,,23,7.67,4,6,3,"Epilepsy is a chronic neurological disorder characterized by the occurrence of spontaneous seizures, which affects about one percent of the worlds population. Most of the current seizure detection approaches strongly rely on patient history records and thus fail in the patient-independent situation of detecting the new patients. To overcome such limitation, we propose a robust and explainable epileptic seizure detection model that effectively learns from seizure states while eliminates the inter-patient noises. A complex deep neural network model is proposed to learn the pure seizure-specific representation from the raw non-invasive electroencephalography (EEG) signals through adversarial training. Furthermore, to enhance the explainability, we develop an attention mechanism to automatically learn the importance of each EEG channels in the seizure diagnosis procedure. The proposed approach is evaluated over the Temple University Hospital EEG (TUH EEG) database. The experimental results illustrate that our model outperforms the competitive state-of-the-art baselines with low latency. Moreover, the designed attention mechanism is demonstrated ables to provide fine-grained information for pathological analysis. We propose an effective and efficient patient-independent diagnosis approach of epileptic seizure based on raw EEG signals without manually feature engineering, which is a step toward the development of large-scale deployment for real-life use.","",""
0,"Yao Qiang, Supriya Tumkur Suresh Kumar, Marco Brocanelli, D. Zhu","Adversarially Robust and Explainable Model Compression with On-Device Personalization for Text Classification",2021,"","","","",9,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,4,1,"On-device Deep Neural Networks (DNNs) have recently gained more attention due to the increasing computing power of the mobile devices and the number of applications in Computer Vision (CV), Natural Language Processing (NLP), and Internet of Things (IoTs). Unfortunately, the existing efficient convolutional neural network (CNN) architectures designed for CV tasks are not directly applicable to NLP tasks and the tiny Recurrent Neural Network (RNN) architectures have been designed primarily for IoT applications. In NLP applications, although model compression has seen initial success in on-device text classification, there are at least three major challenges yet to be addressed: adversarial robustness, explainability, and personalization. Here we attempt to tackle these challenges by designing a new training scheme for model compression and adversarial robustness, including the optimization of an explainable feature mapping objective, a knowledge distillation objective, and an adversarially robustness objective. The resulting compressed model is personalized using on-device private training data via fine-tuning. We perform extensive experiments to compare our approach with both compact RNN (e.g., FastGRNN) and compressed RNN (e.g., PRADO) architectures in both natural and adversarial NLP test settings.","",""
0,"Yao Qiang, Supriya Tumkur Suresh Kumar, Marco Brocanelli, D. Zhu","Adversarially robust and explainable model compression with on-device personalization for NLP applications",2021,"","","","",10,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,4,1,"On-device Deep Neural Networks (DNNs) have recently gained more attention due to the increasing computing power of the mobile devices and the number of applications in Computer Vision (CV), Natural Language Processing (NLP), and Internet of Things (IoTs). Unfortunately, the existing efficient convolutional neural network (CNN) architectures designed for CV tasks are not directly applicable to NLP tasks and the tiny Recurrent Neural Network (RNN) architectures have been designed primarily for IoT applications. In NLP applications, although model compression has seen initial success in on-device text classification, there are at least three major challenges yet to be addressed: adversarial robustness, explainability, and personalization. Here we attempt to tackle these challenges by designing a new training scheme for model compression and adversarial robustness, including the optimization of an explainable feature mapping objective, a knowledge distillation objective, and an adversarially robustness objective. The resulting compressed model is personalized using on-device private training data via fine-tuning. We perform extensive experiments to compare our approach with both compact RNN (e.g., FastGRNN) and compressed RNN (e.g., PRADO) architectures in both natural and adversarial NLP test settings.","",""
0,"Junhee Lee, Hyeonseong Cho, Yun Jang Pyun, Suk‐Ju Kang, H. Nam","Heatmap Assisted Accuracy Score Evaluation Method for Machine-Centric Explainable Deep Neural Networks",2022,"","","","",11,"2022-07-13 10:07:35","","10.1109/access.2022.3184453","","",,,,,0,0.00,0,5,1,"There have existed many studies about the explainable artificial intelligence (XAI) that explains the logic behind the complex deep neural network called a black box. At the same time, researchers have tried to evaluate the explainability performance of various XAIs. However, most previous evaluation methods are human-centric, that is, subjective, where they rely on how much the results of explanation are similar to what people’s decision is based on rather than what features actually affect the decision in the model. Their XAI selections are also dependent of datasets. Furthermore, they are focusing only on the output variation of a target class. On the other hand, this paper proposes a robust heatmap assisted accuracy score (HAAS) scheme over datasets that helps selecting machine-centric explanation algorithms to show what actually leads to the decision of a given classification network. The proposed method modifies the input image with the heatmap scores obtained by a given explanation algorithm and then puts the resultant heatmap assisted (HA) images into the network to estimate the accuracy change. The resultant metric (<inline-formula> <tex-math notation=""LaTeX"">$HAAS$ </tex-math></inline-formula>) is computed as a ratio of accuracies of the given network over HA and original images. The proposed evaluation scheme is verified in the image classification models of LeNet-5 for MNIST and VGG-16 for CIFAR-10, STL-10, and ILSVRC2012 over totally 11 XAI algorithms of saliency map, deconvolution, and 9 layer-wise relevance propagation (LRP) configurations. Consequently, for LRP1 and LRP3, MINST showed largest <inline-formula> <tex-math notation=""LaTeX"">$HAAS$ </tex-math></inline-formula> values of 1.0088 and 1.0079, CIFAR-10 achieved 1.1160 and 1.1254, STL-10 had 1.0906 and 1.0918, and ILSVRC2012 got 1.3207 and 1.3469. While LRP1 consists of <inline-formula> <tex-math notation=""LaTeX"">$\epsilon $ </tex-math></inline-formula>-rules for input, convolutional, and fully-connected layers, LRP3 adopts a bounded-rule for an input layer and the same <inline-formula> <tex-math notation=""LaTeX"">$\epsilon $ </tex-math></inline-formula>-rules for other layers as LRP1. The consistency of evaluation results of HAAS and AOPC has been compared by means of Kullback-Leibler divergence, ensuring that HAAS is the more robust evaluation method than AOPC independently of datasets since HAAS has much lower average divergence of 0.0251 than AOPC of 0.3048. In addition, the validity of the proposed HAAS scheme is further investigated through the inverted HA test that employs inverted HA images made up with inverted heatmap scores and estimates the accuracy degradation caused by applying them to the network. The XAI algorithms with largest <inline-formula> <tex-math notation=""LaTeX"">$HAAS$ </tex-math></inline-formula> results experience biggest accuracy degradation in the inverted HA test.","",""
1,"André Ferreira, S. Madeira, M. Gromicho, M. Carvalho, S. Vinga, Alexandra M. Carvalho","Predictive Medicine Using Interpretable Recurrent Neural Networks",2020,"","","","",12,"2022-07-13 10:07:35","","10.1007/978-3-030-68763-2_14","","",,,,,1,0.50,0,6,2,"","",""
2,"Z. Wang, D. Guo, Zhangren Tu, Yihui Huang, Yirong Zhou, Jian Wang, Liubin Feng, Donghai Lin, Yongfu You, T. Agback, V. Orekhov, X. Qu","A Sparse Model-Inspired Deep Thresholding Network for Exponential Signal Reconstruction--Application in Fast Biological Spectroscopy.",2020,"","","","",13,"2022-07-13 10:07:35","","10.1109/TNNLS.2022.3144580","","",,,,,2,1.00,0,12,2,"The nonuniform sampling (NUS) is a powerful approach to enable fast acquisition but requires sophisticated reconstruction algorithms. Faithful reconstruction from partially sampled exponentials is highly expected in general signal processing and many applications. Deep learning (DL) has shown astonishing potential in this field, but many existing problems, such as lack of robustness and explainability, greatly limit its applications. In this work, by combining the merits of the sparse model-based optimization method and data-driven DL, we propose a DL architecture for spectra reconstruction from undersampled data, called MoDern. It follows the iterative reconstruction in solving a sparse model to build the neural network, and we elaborately design a learnable soft-thresholding to adaptively eliminate the spectrum artifacts introduced by undersampling. Extensive results on both synthetic and biological data show that MoDern enables more robust, high-fidelity, and ultrafast reconstruction than the state-of-the-art methods. Remarkably, MoDern has a small number of network parameters and is trained on solely synthetic data while generalizing well to biological data in various scenarios. Furthermore, we extend it to an open-access and easy-to-use cloud computing platform (XCloud-MoDern), contributing a promising strategy for further development of biological applications.","",""
51,"A. Garcez, L. Lamb","Neurosymbolic AI: The 3rd Wave",2020,"","","","",14,"2022-07-13 10:07:35","","","","",,,,,51,25.50,26,2,2,"Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.","",""
5,"A. Aßmann, Brian Stewart, A. Wallace","Deep Learning for LiDAR Waveforms with Multiple Returns",2020,"","","","",15,"2022-07-13 10:07:35","","10.23919/Eusipco47968.2020.9287545","","",,,,,5,2.50,2,3,2,"We present LiDARNet, a novel data driven approach to LiDAR waveform processing utilising convolutional neural networks to extract depth information. To effectively leverage deep learning, an efficient LiDAR toolchain was developed, which can generate realistic waveform datasets based on either specific experimental parameters or synthetic scenes at scale. This enables us to generate a large volume of waveforms in varying conditions with meaningful underlying data. To validate our simulation approach, we model a super resolution benchmark and cross-validate the network with real unseen data. We demonstrate the ability to resolve peaks in close proximity, as well as to extract multiple returns from waveforms with low signal-to-noise ratio simultaneously with over 99% accuracy. This approach is fast, flexible and highly parallelizable for arrayed imagers. We provide explainability in the deep learning process by matching intermediate outputs to a robust underlying signal model.","",""
0,"A. Leventi-Peetz, T. Östreich","Deep Learning Reproducibility and Explainable AI (XAI)",2022,"","","","",16,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,2,1,"The nondeterminism of Deep Learning (DL) training algorithms and its influence on the explainability of neural network (NN) models are investigated in this work with the help of image classification examples. To discuss the issue, two convolutional neural networks (CNN) have been trained and their results compared. The comparison serves the exploration of the feasibility of creating deterministic, robust DL models and deterministic explainable artificial intelligence (XAI) in practice. Successes and limitation of all here carried out efforts are described in detail. The source code of the attained deterministic models has been listed in this work. Reproducibility is indexed as a development-phase-component of the Model Governance Framework, proposed by the EU within their excellence in AI approach. Furthermore, reproducibility is a requirement for establishing causality for the interpretation of model results and building of trust towards the overwhelming expansion of AI systems applications. Problems that have to be solved on the way to reproducibility and ways to deal with some of them, are examined in this work.","",""
9,"J. Stember, Hrithwik Shalu","Deep reinforcement learning to detect brain lesions on MRI: a proof-of-concept application of reinforcement learning to medical images",2020,"","","","",17,"2022-07-13 10:07:35","","","","",,,,,9,4.50,5,2,2,"Purpose: AI in radiology is hindered chiefly by: 1) Requiring large annotated data sets. 2) Non-generalizability that limits deployment to new scanners / institutions. And 3) Inadequate explainability and interpretability. We believe that reinforcement learning can address all three shortcomings, with robust and intuitive algorithms trainable on small datasets. To the best of our knowledge, reinforcement learning has not been directly applied to computer vision tasks for radiological images. In this proof-of-principle work, we train a deep reinforcement learning network to predict brain tumor location.  Materials and Methods: Using the BraTS brain tumor imaging database, we trained a deep Q network on 70 post-contrast T1-weighted 2D image slices. We did so in concert with image exploration, with rewards and punishments designed to localize lesions. To compare with supervised deep learning, we trained a keypoint detection convolutional neural network on the same 70 images. We applied both approaches to a separate 30 image testing set.  Results: Reinforcement learning predictions consistently improved during training, whereas those of supervised deep learning quickly diverged. Reinforcement learning predicted testing set lesion locations with 85% accuracy, compared to roughly 7% accuracy for the supervised deep network.  Conclusion: Reinforcement learning predicted lesions with high accuracy, which is unprecedented for such a small training set. We believe that reinforcement learning can propel radiology AI well past the inherent limitations of supervised deep learning, with more clinician-driven research and finally toward true clinical applicability.","",""
2,"A. Garcez, L. Lamb","A I ] 1 0 D ec 2 02 0 Neurosymbolic AI : The 3 rd Wave",2020,"","","","",18,"2022-07-13 10:07:35","","","","",,,,,2,1.00,1,2,2,"Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.","",""
11,"Daniel Harborne, C. Willis, Richard J. Tomsett, A. Preece","Integrating learning and reasoning services for explainable information fusion",2018,"","","","",19,"2022-07-13 10:07:35","","","","",,,,,11,2.75,3,4,4,"—We present a distributed information fusion system  able to integrate heterogeneous information processing services  based on machine learning and reasoning approaches. We focus  on higher (semantic) levels of information fusion, and highlight  the requirement for the component services, and the system as  a whole, to generate explanations of its outputs. Using a case  study approach in the domain of traffic monitoring, we introduce  component services based on (i) deep neural network approaches  and (ii) heuristic-based reasoning. We examine methods for  explanation generation in each case, including both transparency  (e.g, saliency maps, reasoning traces) and post-hoc methods  (e.g, explanation in terms of similar examples, identification of  relevant semantic objects). We consider trade-offs in terms of  the classification performance of the services and the kinds of  available explanations, and show how service integration offers  more robust performance and explainability.","",""
22,"Hantao Huang, Jingye Zhou, Qingxun Di, Jiawei Zhou, Jiawang Li","Robust neural network–based tracking control and stabilization of a wheeled mobile robot with input saturation",2018,"","","","",20,"2022-07-13 10:07:35","","10.1002/rnc.4396","","",,,,,22,5.50,4,5,4,"This paper presents a robust neural network–based control scheme to deal with the problem of tracking and stabilization simultaneously for a wheeled mobile robot subject to parametric uncertainties, external disturbances, and input saturation. At first, a new error‐state transformation scheme is designed by introducing some auxiliary variables as an additional virtual control signals to reduce the adverse effect caused by the underactuation. These variables can change their structures for different desired trajectories to be tracked. Then, a robust control law is proposed combining with a kinematic controller and a dynamic controller, while a three‐layer neural network system is applied to approximate model uncertainties. Stability analysis via the Lyapunov theory shows that the proposed controller can make tracking errors converge to bounded neighborhoods of the origin. Finally, some simulation results are illustrated to verify the effectiveness of the proposed control strategy.","",""
3,"Ian E. Nielsen, Dimah Dera, G. Rasool, N. Bouaynaya, R. Ramachandran","Robust Explainability: A tutorial on gradient-based attribution methods for deep neural networks",2021,"","","","",21,"2022-07-13 10:07:35","","10.1109/MSP.2022.3142719","","",,,,,3,3.00,1,5,1,"The rise in deep neural networks (DNNs) has led to increased interest in explaining their predictions. While many methods for this exist, there is currently no consensus on how to evaluate them. On the other hand, robustness is a popular topic for deep learning (DL) research; however, it has been hardly talked about in explainability until very recently.","",""
33,"Zebin Yang, Aijun Zhang, A. Sudjianto","Enhancing Explainability of Neural Networks Through Architecture Constraints",2019,"","","","",22,"2022-07-13 10:07:35","","10.1109/TNNLS.2020.3007259","","",,,,,33,11.00,11,3,3,"Prediction accuracy and model explainability are the two most important objectives when developing machine learning algorithms to solve real-world problems. Neural networks are known to possess good prediction performance but suffer from a lack of model interpretability. In this article, we propose to enhance the explainability of neural networks through the following architecture constraints: 1) sparse additive subnetworks; 2) projection pursuit with orthogonality constraint; and 3) smooth function approximation. It leads to an enhanced explainable neural network (ExNN) with a superior balance between prediction performance and model interpretability. We derive sufficient identifiability conditions for the proposed ExNN model. The multiple parameters are simultaneously estimated by a modified minibatch gradient descent method based on the backpropagation algorithm for calculating the derivatives and the Cayley transform for preserving the projection orthogonality. Through simulation study under six different scenarios, we compare the proposed method to several benchmarks, including least absolute shrinkage and selection operator, support vector machine, random forest, extreme learning machine, and multilayer perceptron. It is shown that the proposed ExNN model keeps the flexibility of pursuing high prediction accuracy while attaining improved interpretability. Finally, a real data example is employed as a showcase application.","",""
0,"Yipeng Du, Jian Liu","IENet: a robust convolutional neural network for EEG based brain-computer interfaces",2022,"","","","",23,"2022-07-13 10:07:35","","10.1088/1741-2552/ac7257","","",,,,,0,0.00,0,2,1,"Objective. Brain-computer interfaces (BCIs) based on electroencephalogram (EEG) develop into novel application areas with more complex scenarios, which put forward higher requirements for the robustness of EEG signal processing algorithms. Deep learning can automatically extract discriminative features and potential dependencies via deep structures, demonstrating strong analytical capabilities in numerous domains such as computer vision and natural language processing. Making full use of deep learning technology to design a robust algorithm that is capable of analyzing EEG across BCI paradigms is our main work in this paper. Approach. Inspired by InceptionV4 and InceptionTime architecture, we introduce a neural network ensemble named InceptionEEG-Net (IENet), where multi-scale convolutional layer and convolution of length 1 enable model to extract rich high-dimensional features with limited parameters. In addition, we propose the average receptive field (RF) gain for convolutional neural networks (CNNs), which optimizes IENet to detect long patterns at a smaller cost. We compare with the current state-of-the-art methods across five EEG-BCI paradigms: steady-state visual evoked potentials (VEPs), epilepsy EEG, overt attention P300 VEPs, covert attention P300 visual-EPs and movement-related cortical potentials. Main results. The classification results show that the generalizability of IENet is on par with the state-of-the-art paradigm-agnostic models on test datasets. Furthermore, the feature explainability analysis of IENet illustrates its capability to extract neurophysiologically interpretable features for different BCI paradigms, ensuring the reliability of algorithm. Significance. It can be seen from our results that IENet can generalize to different BCI paradigms. And it is essential for deep CNNs to increase the RF size using average RF gain.","",""
11,"Zhengshi Yang, X. Zhuang, K. Sreenivasan, V. Mishra, D. Cordes","Robust Motion Regression of Resting-State Data Using a Convolutional Neural Network Model",2019,"","","","",24,"2022-07-13 10:07:35","","10.3389/fnins.2019.00169","","",,,,,11,3.67,2,5,3,"Resting-state functional magnetic resonance imaging (rs-fMRI) based on the blood-oxygen-level-dependent (BOLD) signal has been widely used in healthy individuals and patients to investigate brain functions when the subjects are in a resting or task-negative state. Head motion considerably confounds the interpretation of rs-fMRI data. Nuisance regression is commonly used to reduce motion-related artifacts with six motion parameters estimated from rigid-body realignment as regressors. To further compensate for the effect of head movement, the first-order temporal derivatives of motion parameters and squared motion parameters were proposed previously as possible motion regressors. However, these additional regressors may not be sufficient to model the impact of head motion because of the complexity of motion artifacts. In addition, while using more motion-related regressors could explain more variance in the data, the neural signal may also be removed with increasing number of motion regressors. To better model how in-scanner motion affects rs-fMRI data, a robust and automated convolutional neural network (CNN) model is developed in this study to obtain optimal motion regressors. The CNN network consists of two temporal convolutional layers and the output from the network are the derived motion regressors used in the following nuisance regression. The temporal convolutional layer in the network can non-parametrically model the prolonged effect of head motion. The set of regressors derived from the neural network is compared with the same number of regressors used in a traditional nuisance regression approach. It is demonstrated that the CNN-derived regressors can more effectively reduce motion-related artifacts.","",""
6,"Kaveri A. Thakoor, Sharath C. Koorathota, D. Hood, P. Sajda","Robust and Interpretable Convolutional Neural Networks to Detect Glaucoma in Optical Coherence Tomography Images",2020,"","","","",25,"2022-07-13 10:07:35","","10.1109/tbme.2020.3043215","","",,,,,6,3.00,2,4,2,"Recent studies suggest that deep learning systems can now achieve performance on par with medical experts in diagnosis of disease. A prime example is in the field of ophthalmology, where convolutional neural networks (CNNs) have been used to detect retinal and ocular diseases. However, this type of artificial intelligence (AI) has yet to be adopted clinically due to questions regarding robustness of the algorithms to datasets collected at new clinical sites and a lack of explainability of AI-based predictions, especially relative to those of human expert counterparts. In this work, we develop CNN architectures that demonstrate robust detection of glaucoma in optical coherence tomography (OCT) images and test with concept activation vectors (TCAVs) to infer what image concepts CNNs use to generate predictions. Furthermore, we compare TCAV results to eye fixations of clinicians, to identify common decision-making features used by both AI and human experts. We find that employing fine-tuned transfer learning and CNN ensemble learning create end-to-end deep learning models with superior robustness compared to previously reported hybrid deep-learning/machine-learning models, and TCAV/eye-fixation comparison suggests the importance of three OCT report sub-images that are consistent with areas of interest fixated upon by OCT experts to detect glaucoma. The pipeline described here for evaluating CNN robustness and validating interpretable image concepts used by CNNs with eye movements of experts has the potential to help standardize the acceptance of new AI tools for use in the clinic.","",""
28,"U. Oparaji, R. Sheu, M. Bankhead, J. Austin, E. Patelli","Robust artificial neural network for reliability and sensitivity analyses of complex non-linear systems",2017,"","","","",26,"2022-07-13 10:07:35","","10.1016/j.neunet.2017.09.003","","",,,,,28,5.60,6,5,5,"","",""
1,"Y. Lu, Ilgiz Murzakhanov, Spyros Chatzivasileiadis","Neural network interpretability for forecasting of aggregated renewable generation",2021,"","","","",27,"2022-07-13 10:07:35","","10.1109/SmartGridComm51999.2021.9631993","","",,,,,1,1.00,0,3,1,"With the rapid growth of renewable energy, lots of small photovoltaic (PV) prosumers emerge. Due to the uncertainty of solar power generation, there is a need for aggregated prosumers to predict solar power generation and whether solar power generation will be larger than load. This paper presents two interpretable neural networks to solve the problem: one binary classification neural network and one regression neural network. The neural networks are built using TensorFlow. The global feature importance and local feature contributions are examined by three gradient-based methods: Integrated Gradients, Expected Gradients, and DeepLIFT. Moreover, we detect abnormal cases when predictions might fail by estimating the prediction uncertainty using Bayesian neural networks. Neural networks, which are interpreted by the gradient-based methods and complemented with uncertainty estimation, provide robust and explainable forecasting for decision-makers.","",""
0,"Mauro J. Sanchirico, Xun Jiao, C. Nataraj","AMITE: A Novel Polynomial Expansion for Analyzing Neural Network Nonlinearities.",2020,"","","","",28,"2022-07-13 10:07:35","","10.1109/TNNLS.2021.3130904","","",,,,,0,0.00,0,3,2,"Polynomial expansions are important in the analysis of neural network nonlinearities. They have been applied thereto addressing well-known difficulties in verification, explainability, and security. Existing approaches span classical Taylor and Chebyshev methods, asymptotics, and many numerical approaches. We find that, while these have useful properties individually, such as exact error formulas, adjustable domain, and robustness to undefined derivatives, there are no approaches that provide a consistent method, yielding an expansion with all these properties. To address this, we develop an analytically modified integral transform expansion (AMITE), a novel expansion via integral transforms modified using derived criteria for convergence. We show the general expansion and then demonstrate an application for two popular activation functions: hyperbolic tangent and rectified linear units. Compared with existing expansions (i.e., Chebyshev, Taylor, and numerical) employed to this end, AMITE is the first to provide six previously mutually exclusive desired expansion properties, such as exact formulas for the coefficients and exact expansion errors. We demonstrate the effectiveness of AMITE in two case studies. First, a multivariate polynomial form is efficiently extracted from a single hidden layer black-box multilayer perceptron (MLP) to facilitate equivalence testing from noisy stimulus-response pairs. Second, a variety of feedforward neural network (FFNN) architectures having between three and seven layers are range bounded using Taylor models improved by the AMITE polynomials and error formulas. AMITE presents a new dimension of expansion methods suitable for the analysis/approximation of nonlinearities in neural networks, opening new directions and opportunities for the theoretical analysis and systematic testing of neural networks.","",""
0,"Qiwei Shen, Zonghua Liu","Remote firing propagation in the neural network of C. elegans.",2021,"","","","",29,"2022-07-13 10:07:35","","10.1103/PhysRevE.103.052414","","",,,,,0,0.00,0,2,1,"Understanding the mechanisms of firing propagation in brain networks has been a long-standing problem in the fields of nonlinear dynamics and network science. In general, it is believed that a specific firing in a brain network may be gradually propagated from a source node to its neighbors and then to the neighbors' neighbors and so on. Here, we explore firing propagation in the neural network of Caenorhabditis elegans and surprisingly find an abnormal phenomenon, i.e., remote firing propagation between two distant and indirectly connected nodes with the intermediate nodes being inactivated. This finding is robust to source nodes but depends on the topology of network such as the unidirectional couplings and heterogeneity of network. Further, a brief theoretical analysis is provided to explain its mechanism and a principle for remote firing propagation is figured out. This finding provides insights for us to understand how those cognitive subnetworks emerge in a brain network.","",""
0,"Zi-JiangYANG, KiyoshiWADA","An Experimental Study on Adaptive Robust PCA Neural Network",2017,"","","","",30,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,2,5,"In this paper, we show the experimental study on adaptive robust neural network Principal Component Analysis (PCA) b出 edon a reconstruction error model . Firstly we explain the traditional batch PCA method which is based on eigenvalue decomposition and discuss its problems of computational complexity and poor robustness. To overcome such problems, the adaptive robust neural network Principal Component Analysis wil b巴 introduced.This adaptive robust approach is based on the structure of single-layer neural network with modification of the reconstruction error model. From the experト ments, it can be seen that this method can reduce the efect of outliers existing in the training sample set.","",""
11,"Wenzhe Guo, M. Fouda, A. Eltawil, K. Salama","Neural Coding in Spiking Neural Networks: A Comparative Study for Robust Neuromorphic Systems",2021,"","","","",31,"2022-07-13 10:07:35","","10.3389/fnins.2021.638474","","",,,,,11,11.00,3,4,1,"Various hypotheses of information representation in brain, referred to as neural codes, have been proposed to explain the information transmission between neurons. Neural coding plays an essential role in enabling the brain-inspired spiking neural networks (SNNs) to perform different tasks. To search for the best coding scheme, we performed an extensive comparative study on the impact and performance of four important neural coding schemes, namely, rate coding, time-to-first spike (TTFS) coding, phase coding, and burst coding. The comparative study was carried out using a biological 2-layer SNN trained with an unsupervised spike-timing-dependent plasticity (STDP) algorithm. Various aspects of network performance were considered, including classification accuracy, processing latency, synaptic operations (SOPs), hardware implementation, network compression efficacy, input and synaptic noise resilience, and synaptic fault tolerance. The classification tasks on Modified National Institute of Standards and Technology (MNIST) and Fashion-MNIST datasets were applied in our study. For hardware implementation, area and power consumption were estimated for these coding schemes, and the network compression efficacy was analyzed using pruning and quantization techniques. Different types of input noise and noise variations in the datasets were considered and applied. Furthermore, the robustness of each coding scheme to the non-ideality-induced synaptic noise and fault in analog neuromorphic systems was studied and compared. Our results show that TTFS coding is the best choice in achieving the highest computational performance with very low hardware implementation overhead. TTFS coding requires 4x/7.5x lower processing latency and 3.5x/6.5x fewer SOPs than rate coding during the training/inference process. Phase coding is the most resilient scheme to input noise. Burst coding offers the highest network compression efficacy and the best overall robustness to hardware non-idealities for both training and inference processes. The study presented in this paper reveals the design space created by the choice of each coding scheme, allowing designers to frame each scheme in terms of its strength and weakness given a designs’ constraints and considerations in neuromorphic systems.","",""
0,"Ingrid Fadelli","A memory-augmented, artificial neural network-based architecture",2021,"","","","",32,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,1,1,"ions that can be applied to future tasks. ""This abstraction mechanism and evolutionary training enable the learning of robust and scalable algorithmic solutions,"" the researchers explained in their paper. The team at Technische Universität Darmstadt evaluated the NHC by using it to train and run 11 different algorithms. They then tested the performance of these algorithms, along with their generalization and abstraction capabilities. The researchers found that the NHC could reliably run all 11 algorithms, while also allowing them to perform well on tasks that were more complex than those they were originally trained to complete. ""On a diverse set of 11 algorithms with varying complexities, we show that the NHC reliably learns","",""
6,"Joel Dapello, J. Feather, Hang Le, Tiago Marques, D. Cox, Josh H. McDermott, J. DiCarlo, SueYeon Chung","Neural Population Geometry Reveals the Role of Stochasticity in Robust Perception",2021,"","","","",33,"2022-07-13 10:07:35","","","","",,,,,6,6.00,1,8,1,"Adversarial examples are often cited by neuroscientists and machine learning researchers as an example of how computational models diverge from biological sensory systems. Recent work has proposed adding biologically-inspired components to visual neural networks as a way to improve their adversarial robustness. One surprisingly effective component for reducing adversarial vulnerability is response stochasticity, like that exhibited by biological neurons. Here, using recently developed geometrical techniques from computational neuroscience, we investigate how adversarial perturbations influence the internal representations of standard, adversarially trained, and biologically-inspired stochastic networks. We find distinct geometric signatures for each type of network, revealing different mechanisms for achieving robust representations. Next, we generalize these results to the auditory domain, showing that neural stochasticity also makes auditory models more robust to adversarial perturbations. Geometric analysis of the stochastic networks reveals overlap between representations of clean and adversarially perturbed stimuli, and quantitatively demonstrates that competing geometric effects of stochasticity mediate a tradeoff between adversarial and clean performance. Our results shed light on the strategies of robust perception utilized by adversarially trained and stochastic networks, and help explain how stochasticity may be beneficial to machine and biological computation.1","",""
1,"N. M. Thoiyab, P. Muruganantham, N. Gunasekaran","Global Robust Stability Analysis for Hybrid BAM Neural Networks",2021,"","","","",34,"2022-07-13 10:07:35","","10.1109/CMI50323.2021.9362980","","",,,,,1,1.00,0,3,1,"In this paper, we study some new sufficient criteria on global stability analysis for the hybrid bidirectional associative memory (BAM) neural networks with multiple time delays. The ultimate focus of this paper is to derive some new generalized sufficient criteria for the global asymptotic robust stability (GARS) of equilibrium point of the time-delayed BAM neural networks. The obtained sufficient conditions are always independent on the delay of system parameters of hybrid BAM neural networks. Finally, numerical example has been given to explain the effectiveness of our results in terms of network parameters.","",""
2,"Christian Fiedler, M. Fornasier, T. Klock, Michael Rauchensteiner","Stable Recovery of Entangled Weights: Towards Robust Identification of Deep Neural Networks from Minimal Samples",2021,"","","","",35,"2022-07-13 10:07:35","","","","",,,,,2,2.00,1,4,1,"In this paper we approach the problem of unique and stable identifiability of generic deep artificial neural networks with pyramidal shape and smooth activation functions from a finite number of input-output samples. More specifically we introduce the so-called entangled weights, which compose weights of successive layers intertwined with suitable diagonal and invertible matrices depending on the activation functions and their shifts. We prove that entangled weights are completely and stably approximated by an efficient and robust algorithm as soon as O(D ×m) nonadaptive input-output samples of the network are collected, where D is the input dimension and m is the number of neurons of the network. Moreover, we empirically observe that the approach applies to networks with up to O(D × mL) neurons, wheremL is the number of output neurons at layer L. Provided knowledge of layer assignments of entangled weights and of remaining scaling and shift parameters, which may be further heuristically obtained by least squares, the entangled weights identify the network completely and uniquely. To highlight the relevance of the theoretical result of stable recovery of entangled weights, we present numerical experiments, which demonstrate that multilayered networks with generic weights can be robustly identified and therefore uniformly approximated by the presented algorithmic pipeline. In contrast backpropagation cannot generalize stably very well in this setting, being always limited by relatively large uniform error. In terms of practical impact, our study shows that we can relate input-output information uniquely and stably to network parameters, providing a form of explainability. Moreover, our method paves the way for compression of overparametrized networks and for the training of minimal complexity networks.","",""
22,"Masaki Kobayashi","Noise Robust Projection Rule for Hyperbolic Hopfield Neural Networks",2020,"","","","",36,"2022-07-13 10:07:35","","10.1109/TNNLS.2019.2899914","","",,,,,22,11.00,22,1,2,"A complex-valued Hopfield neural network (CHNN) is a multistate Hopfield model. Low noise tolerance is the main disadvantage of CHNNs. The hyperbolic Hopfield neural network (HHNN) is a noise robust multistate Hopfield model. In HHNNs employing the projection rule, noise tolerance rapidly worsened as the number of training patterns increased. This result was caused by the self-loops. The projection rule for CHNNs improves noise tolerance by removing the self-loops, however, that for HHNNs cannot remove them. In this brief, we extended the stability condition for the self-loops of HHNNs and modified the projection rule. Thus, the HHNNs had improved noise tolerance.","",""
0,"Zhuotong Chen, Qianxiao Li, Zheng Zhang","Self-Healing Robust Neural Networks via Closed-Loop Control",2022,"","","","",37,"2022-07-13 10:07:35","","10.48550/arXiv.2206.12963","","",,,,,0,0.00,0,3,1,"Despite the wide applications of neural networks, there have been increasing concerns about their vulnerability issue. While numerous attack and defense techniques have been developed, this work investigates the robustness issue from a new angle: can we design a self-healing neural network that can automatically detect and ﬁx the vulnerability issue by itself? A typical self-healing mechanism is the immune system of a human body. This biology-inspired idea has been used in many engineering designs, but is rarely investigated in deep learning. This paper considers the post-training self-healing of a neural network, and proposes a closed-loop control formulation to automatically detect and ﬁx the errors caused by various attacks or perturbations. We provide a margin-based analysis to explain how this formulation can improve the robustness of a classiﬁer. To speed up the inference of the proposed self-healing network, we solve the control problem via improving the Pontryagin’s Maximum Principle-based solver. Lastly, we present an error estimation of the proposed framework for neural networks with nonlinear activation functions. We validate the performance on several network architectures against various perturbations. Since the self-healing method does not need a-priori information about data perturbations/attacks, it can handle a broad class of unforeseen perturbations. 1 .","",""
2,"Gurpreet Singh, Soumyajit Gupta, Matt Lease, Clint N. Dawson","TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes",2020,"","","","",38,"2022-07-13 10:07:35","","","","",,,,,2,1.00,1,4,2,"Partial Differential Equations are infinite dimensional encoded representations of physical processes. However, imbibing multiple observation data towards a coupled representation presents significant challenges. We present a fully convolutional architecture that captures the invariant structure of the domain to reconstruct the observable system. The proposed architecture is significantly low-weight compared to other networks for such problems. Our intent is to learn coupled dynamic processes interpreted as deviations from true kernels representing isolated processes for model-adaptivity. Experimental analysis shows that our architecture is robust and transparent in capturing process kernels and system anomalies. We also show that high weights representation is not only redundant but also impacts network interpretability. Our design is guided by domain knowledge, with isolated process representations serving as ground truths for verification. These allow us to identify redundant kernels and their manifestations in activation maps to guide better designs that are both interpretable and explainable unlike traditional deep-nets.","",""
8,"S. Pontes-Filho, M. Liwicki","Bidirectional Learning for Robust Neural Networks",2018,"","","","",39,"2022-07-13 10:07:35","","10.1109/IJCNN.2019.8852120","","",,,,,8,2.00,4,2,4,"A multilayer perceptron can behave as a generative classifier by applying bidirectional learning (BL). It consists of training an undirected neural network to map input to output and vice-versa; therefore it can produce a classifier in one direction, and a generator in the opposite direction for the same data. The learning process of BL tries to reproduce the neuroplasticity stated in Hebbian theory using only backward propagation of errors. In this paper, two learning techniques are independently introduced which use BL for improving robustness to white noise static and adversarial examples. The first method is bidirectional propagation of errors, which the error propagation occurs in backward and forward directions. Motivated by the fact that its generative model receives as input a constant vector per class, we introduce as a second method the novel hybrid adversarial networks (HAN). Its generative model receives a random vector as input and its training is based on generative adversarial networks (GAN). To assess the performance of BL, we perform experiments using several architectures with fully and convolutional layers, with and without bias. Experimental results show that both methods improve robustness to white noise static and adversarial examples, and even increase accuracy, but have different behavior depending on the architecture and task, being more beneficial to use the one or the other. Nevertheless, HAN using a convolutional architecture with batch normalization presents outstanding robustness, reaching state-of-the-art accuracy on adversarial examples of hand-written digits.","",""
3,"Thomas Fel, Mélanie Ducoffe, David Vigouroux, Remi Cadene, Mikael Capelle, C. Nicodeme, Thomas Serre","Don't Lie to Me! Robust and Efficient Explainability with Verified Perturbation Analysis",2022,"","","","",40,"2022-07-13 10:07:35","","","","",,,,,3,3.00,0,7,1,"A variety of methods have been proposed to try to explain how deep neural networks make their decisions. Key to those approaches is the need to sample the pixel space efficiently in order to derive importance maps. However, it has been shown that the sampling methods used to date introduce biases and other artifacts, leading to inaccurate estimates of the importance of individual pixels and severely limit the reliability of current explainability methods. Unfortunately, the alternative – to exhaustively sample the image space is computationally prohibitive. In this paper, we introduce EVA (Explaining using Verified perturbation Analysis) – the first explainability method guarantee to have an exhaustive exploration of a perturbation space. Specifically, we leverage the beneficial properties of verified perturbation analysis – time efficiency, tractability and guaranteed complete coverage of a manifold – to efficiently characterize the input variables that are most likely to drive the model decision. We evaluate the approach systematically and demonstrate state-of-the-art results on multiple benchmarks.","",""
64,"H. C. Liaw, B. Shirinzadeh, Julian Smith","Robust Neural Network Motion Tracking Control of Piezoelectric Actuation Systems for Micro/Nanomanipulation",2009,"","","","",41,"2022-07-13 10:07:35","","10.1109/TNN.2008.2004406","","",,,,,64,4.92,21,3,13,"This paper presents a robust neural network motion tracking control methodology for piezoelectric actuation systems employed in micro/nanomanipulation. This control methodology is proposed for tracking of desired motion trajectories in the presence of unknown system parameters, nonlinearities including the hysteresis effect and external disturbances in the control systems. In this paper, the related control issues are investigated, and a control methodology is established including the neural networks and a sliding control scheme. In particular, the radial basis function (RBF) neural networks are chosen for function approximations. The stability of the closed-loop system, as well as the convergence of the position and velocity tracking errors to zero, is assured by the control methodology in the presence of the aforementioned conditions. An offline learning procedure is also proposed for the improvement of the motion tracking performance. Precise tracking results of the proposed control methodology for a desired motion trajectory are demonstrated in the experimental study. With such a motion tracking capability, the proposed control methodology promises the realization of high-performance piezoelectric actuated micro/nanomanipulation systems.","",""
0,"Jenn-Bing Ong, W. Ng, C.-C. Jay Kuo","Convolutional Neural Networks with Transformed Input based on Robust Tensor Network Decomposition",2018,"","","","",42,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,3,4,"Tensor network decomposition, originated from quantum physics to model entangled many-particle quantum systems, turns out to be a promising mathematical technique to efficiently represent and process big data in parsimonious manner. In this study, we show that tensor networks can systematically partition structured data, e.g. color images, for distributed storage and communication in privacy-preserving manner. Leveraging the sea of big data and metadata privacy, empirical results show that neighbouring subtensors with implicit information stored in tensor network formats cannot be identified for data reconstruction. This technique complements the existing encryption and randomization techniques which store explicit data representation at one place and highly susceptible to adversarial attacks such as side-channel attacks and de-anonymization. Furthermore, we propose a theory for adversarial examples that mislead convolutional neural networks to misclassification using subspace analysis based on singular value decomposition (SVD). The theory is extended to analyze higher-order tensors using tensor-train SVD (TT-SVD); it helps to explain the level of susceptibility of different datasets to adversarial attacks, the structural similarity of different adversarial attacks including global and localized attacks, and the efficacy of different adversarial defenses based on input transformation. An efficient and adaptive algorithm based on robust TT-SVD is then developed to detect strong and static adversarial attacks.","",""
6,"P. Konar, Vishal S. Ngairangbam, M. Spannowsky","Energy-weighted message passing: an infra-red and collinear safe graph neural network algorithm",2021,"","","","",43,"2022-07-13 10:07:35","","10.1007/JHEP02(2022)060","","",,,,,6,6.00,2,3,1,"","",""
22,"Adam Kortylewski, Qing Liu, Angtian Wang, Yihong Sun, A. Yuille","Compositional Convolutional Neural Networks: A Robust and Interpretable Model for Object Recognition under Occlusion",2020,"","","","",44,"2022-07-13 10:07:35","","10.1007/s11263-020-01401-3","","",,,,,22,11.00,4,5,2,"","",""
22,"Walt Woods, Jack H Chen, C. Teuscher","Adversarial explanations for understanding image classification decisions and improved neural network robustness",2019,"","","","",45,"2022-07-13 10:07:35","","10.1038/s42256-019-0104-6","","",,,,,22,7.33,7,3,3,"","",""
24,"Ç. Aladag, E. Egrioglu, U. Yolcu","Robust multilayer neural network based on median neuron model",2014,"","","","",46,"2022-07-13 10:07:35","","10.1007/s00521-012-1315-5","","",,,,,24,3.00,8,3,8,"","",""
31,"Q. Song, J. Spall, Y. Soh, Jie-ke Ni","Robust Neural Network Tracking Controller Using Simultaneous Perturbation Stochastic Approximation",2008,"","","","",47,"2022-07-13 10:07:35","","10.1109/TNN.2007.912315","","",,,,,31,2.21,8,4,14,"This paper considers the design of robust neural network tracking controllers for nonlinear systems. The neural network is used in the closed-loop system to estimate the nonlinear system function. We introduce the conic sector theory to establish a robust neural control system, with guaranteed boundedness for both the input/output (I/O) signals and the weights of the neural network. The neural network is trained by the simultaneous perturbation stochastic approximation (SPSA) method instead of the standard backpropagation (BP) algorithm. The proposed neural control system guarantees closed-loop stability of the estimation system, and a good tracking performance. The performance improvement of the proposed system over existing systems can be quantified in terms of preventing weight shifts, fast convergence, and robustness against system disturbance.","",""
0,"Hanxiao Tan, Helena Kotthaus","Explainability-Aware One Point Attack for Point Cloud Neural Networks",2021,"","","","",48,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,2,1,"With the proposition of neural networks for point clouds, deep learning has started to shine in the field of 3D object recognition while researchers have shown an increased interest to investigate the reliability of point cloud networks by fooling them with perturbed instances. However, most studies focus on the imperceptibility or surface consistency, with humans perceiving no perturbations on the adversarial examples. This work proposes two new attack methods: one-point attack (OPA) and critical traverse attack (CTA), which go in the opposite direction: we restrict the perturbation dimensions to a human cognizable range with the help of explainability methods, which enables the working principle or decision boundary of the models to be comprehensible through the observable perturbation magnitude. Our results show that the popular point cloud networks can be deceived with almost 100% success rate by shifting only one point from the input instance. In addition, we attempt to provide a more persuasive viewpoint of comparing the robustness of point cloud models against adversarial attacks. We also show the interesting impact of different point attribution distributions on the adversarial robustness of point cloud networks. Finally, we discuss how our approaches facilitate the explainability study for point cloud networks. To the best of our knowledge, this is the first point-cloud-based adversarial approach concerning explainability. Our code is available at https://github.com/Explain3D/ Exp-One-Point-Atk-PC. Figure 1: One point attack for point cloud networks. With the saliency map provided by the explainability method, only one point needs to be perturbed in the point set of the original instance to fool the most popular point cloud networks.","",""
4,"Anis Hamza, N. B. Yahia","Intelligent Neural Network Control for Active Heavy Truck Suspension",2018,"","","","",49,"2022-07-13 10:07:35","","10.1007/978-3-030-19781-0_2","","",,,,,4,1.00,2,2,4,"","",""
94,"C. Kwan, F. Lewis, D. Dawson","Robust neural-network control of rigid-link electrically driven robots",1998,"","","","",50,"2022-07-13 10:07:35","","10.1109/72.701172","","",,,,,94,3.92,31,3,24,"A robust neural-network (NN) controller is proposed for the motion control of rigid-link electrically driven (RLED) robots. Two-layer NN's are used to approximate two very complicated nonlinear functions. The main advantage of our approach is that the NN weights are tuned on-line, with no off-line learning phase required. Most importantly, we can guarantee the uniformly ultimately bounded (UUB) stability of tracking errors and NN weights. When compared with standard adaptive robot controllers, we do not require lengthy and tedious preliminary analysis to determine a regression matrix. The controller can be regarded as a universal reusable controller because the same controller can be applied to any type of RLED robots without any modifications.","",""
62,"M. Kohlbrenner, Alexander Bauer, Shinichi Nakajima, Alexander Binder, W. Samek, S. Lapuschkin","Towards Best Practice in Explaining Neural Network Decisions with LRP",2019,"","","","",51,"2022-07-13 10:07:35","","10.1109/IJCNN48605.2020.9206975","","",,,,,62,20.67,10,6,3,"Within the last decade, neural network based predictors have demonstrated impressive — and at times superhuman — capabilities. This performance is often paid for with an intransparent prediction process and thus has sparked numerous contributions in the novel field of explainable artificial intelligence (XAI). In this paper, we focus on a popular and widely used method of XAI, the Layer-wise Relevance Propagation (LRP). Since its initial proposition LRP has evolved as a method, and a best practice for applying the method has tacitly emerged, based however on humanly observed evidence alone. In this paper we investigate — and for the first time quantify — the effect of this current best practice on feedforward neural networks in a visual object detection setting. The results verify that the layer-dependent approach to LRP applied in recent literature better represents the model’s reasoning, and at the same time increases the object localization and class discriminativity of LRP.","",""
22,"Hongwei Hu, Bo Ma, Jianbing Shen, Hanqiu Sun, L. Shao, F. Porikli","Robust Object Tracking Using Manifold Regularized Convolutional Neural Networks",2019,"","","","",52,"2022-07-13 10:07:35","","10.1109/TMM.2018.2859831","","",,,,,22,7.33,4,6,3,"In visual tracking, usually only a small number of samples are labeled, and most existing deep learning based trackers ignore abundant unlabeled samples that could provide additional information for deep trackers to boost their tracking performance. An intuitive way to explain unlabeled data is to incorporate manifold regularization into the common classification loss functions, but the high computational cost may prohibit those deep trackers from practical applications. To overcome this issue, we propose a two-stage approach to a deep tracker that takes into account both labeled and unlabeled samples. The annotation of unlabeled samples is propagated from its labeled neighbors first by exploring the manifold space that these samples are assumed to lie in. Then, we refine it by training a deep convolutional neural network using both labeled and unlabeled data in a supervised manner. Online visual tracking is further carried out under the framework of particle filters with the presented manifold regularized deep model being updated every few frames. Experimental results on different tracking datasets demonstrate that our tracker outperforms most existing tracking approaches. The source code and results are available at: https://github.com/shenjianbing/MRCNNTracking.","",""
144,"Tong Yang, Ning Sun, He Chen, Yongchun Fang","Neural Network-Based Adaptive Antiswing Control of an Underactuated Ship-Mounted Crane With Roll Motions and Input Dead Zones",2020,"","","","",53,"2022-07-13 10:07:35","","10.1109/TNNLS.2019.2910580","","",,,,,144,72.00,36,4,2,"As a type of indispensable oceanic transportation tools, ship-mounted crane systems are widely employed to transport cargoes and containers on vessels due to their extraordinary flexibility. However, various working requirements and the oceanic environment may cause some uncertain and unfavorable factors for ship-mounted crane control. In particular, to accomplish different control tasks, some plant parameters (e.g., boom lengths, payload masses, and so on) frequently change; hence, most existing model-based controllers cannot ensure satisfactory control performance any longer. For example, inaccurate gravity compensation may result in positioning errors. Additionally, due to ship roll motions caused by sea waves, residual payload swing generally exists, which may result in safety risks in practice. To solve the above-mentioned issues, this paper designs a neural network-based adaptive control method that can provide effective control for both actuated and unactuated state variables based on the original nonlinear ship-mounted crane dynamics without any linearizing operations. In particular, the proposed update law availably compensates parameter/structure uncertainties for ship-mounted crane systems. Based on a 2-D sliding surface, the boom and rope can arrive at their preset positions in finite time, and the payload swing can be completely suppressed. Furthermore, the problem of nonlinear input dead zones is also taken into account. The stability of the equilibrium point of all state variables in ship-mounted crane systems is theoretically proven by a rigorous Lyapunov-based analysis. The hardware experimental results verify the practicability and robustness of the presented control approach.","",""
7,"Chen-Yi Lin, Xuefei Song, Lunhao Li, Yinwei Li, Mengda Jiang, Rou Sun, Huifang Zhou, Xianqun Fan","Detection of active and inactive phases of thyroid-associated ophthalmopathy using deep convolutional neural network",2021,"","","","",54,"2022-07-13 10:07:35","","10.1186/s12886-020-01783-5","","",,,,,7,7.00,1,8,1,"","",""
6,"Yashas B L Samaga, Shampa Raghunathan, U. D. Priyakumar","SCONES: Self-Consistent Neural Network for Protein Stability Prediction Upon Mutation.",2021,"","","","",55,"2022-07-13 10:07:35","","10.26434/CHEMRXIV.14729445.V1","","",,,,,6,6.00,2,3,1,"Engineering proteins to have desired properties by mutating amino acids at specific sites is commonplace. Such engineered proteins must be stable to function. Experimental methods used to determine stability at throughputs required to scan the protein sequence space thoroughly are laborious. To this end, many machine learning based methods have been developed to predict thermodynamic stability changes upon mutation. These methods have been evaluated for symmetric consistency by testing with hypothetical reverse mutations. In this work, we propose transitive data augmentation, evaluating transitive consistency with our new Stransitive data set, and a new machine learning based method, the first of its kind, that incorporates both symmetric and transitive properties into the architecture. Our method, called SCONES, is an interpretable neural network that predicts small relative protein stability changes for missense mutations that do not significantly alter the structure. It estimates a residue's contributions toward protein stability (ΔG) in its local structural environment, and the difference between independently predicted contributions of the reference and mutant residues is reported as ΔΔG. We show that this self-consistent machine learning architecture is immune to many common biases in data sets, relies less on data than existing methods, is robust to overfitting, and can explain a substantial portion of the variance in experimental data.","",""
15,"F. Ham, Sungjin Park","A robust neural network classifier for infrasound events using multiple array data",2002,"","","","",56,"2022-07-13 10:07:35","","10.1109/IJCNN.2002.1007556","","",,,,,15,0.75,8,2,20,"An integral part of the Comprehensive Nuclear-Test-Ban Treaty International Monitoring System is an infrasound monitoring network. This network has the capability to detect and verify infrasonic signals-of-interest, e.g., nuclear explosions, from other unwanted infrasound noise sources. The paper presents classification results of infrasonic events using a robust neural network.","",""
1,"Pragnyaban Mishra, P. Srinivas","Facial emotion recognition using deep convolutional neural network and smoothing, mixture filters applied during preprocessing stage",2021,"","","","",57,"2022-07-13 10:07:35","","10.11591/ijai.v10.i4.pp889-900","","",,,,,1,1.00,1,2,1,"The facial emotion recognition by the machine is a challenging task. From decades, researchers applied different methods to classify facial emotion into the different classes. The expansion of artificial intelligence in a form of deep convolutional neural network (CNN) changed the direction of the research. The facial emotion recognition using deep CNN is powerful in terms of taking bulk input images for processing and classify with high accuracy. It has been noticed in a few cases the classification model does not judge the facial images into appropriate classes due to the influence of noises. So, it is highly recommended to apply a noiseless image to the facial emotion recognition model for classification. We adopted a mechanism and proposed a model for classifying facial image into one of the seven classes with high accuracy. The images are smoothed before applying to the model by different smoothing process as part of image preprocessing. We claim facial emotion recognition with image smoothing by different filters or a mixture of filter are more robust than without preprocessing. The detail is explained in the subsequent sections.","",""
2,"B. Hamdaoui, Abdurrahman Elmaghbub, Siefeddine Mejri","Deep Neural Network Feature Designs for RF Data-Driven Wireless Device Classification",2021,"","","","",58,"2022-07-13 10:07:35","","10.1109/MNET.011.2000492","","",,,,,2,2.00,1,3,1,"Most prior works on deep learning-based wireless device classification using radio frequency (RF) data apply off-the-shelf deep neural network (DNN) models, which were matured mainly for domains like vision and language. However, wireless RF data possesses unique characteristics that differentiate it from these other domains. For instance, RF data encompasses intermingled time and frequency features that are dictated by the underlying hardware and protocol configurations. In addition, wireless RF communication signals exhibit cyclostationarity due to repeated patterns (PHY pilots, frame prefixes, and so on) that these signals inherently contain. In this article, we begin by explaining and showing the unsuitability as well as limitations of existing DNN feature design approaches currently proposed to be used for wireless device classification. We then present novel feature design approaches that exploit the distinct structures of RF communication signals and the spectrum emissions caused by transmitter hardware impairments to custom-make DNN models suitable for classifying wireless devices using RF signal data. Our proposed DNN feature designs substantially improve classification robustness in terms of scalability, accuracy, signature anti-cloning, and insensitivity to environment perturbations. We end the article by presenting other feature design strategies that have great potential for providing further performance improvements of the DNN-based wireless device classification, and discuss the open research challenges related to these proposed strategies.","",""
356,"M. Mirman, Timon Gehr, Martin T. Vechev","Differentiable Abstract Interpretation for Provably Robust Neural Networks",2018,"","","","",59,"2022-07-13 10:07:35","","","","",,,,,356,89.00,119,3,4,"We introduce a scalable method for training robust neural networks based on abstract interpretation. We present several abstract transformers which balance efficiency with precision and show these can be used to train large neural networks that are certifiably robust to adversarial perturbations.","",""
619,"Mou Chen, S. Ge, B. How","Robust Adaptive Neural Network Control for a Class of Uncertain MIMO Nonlinear Systems With Input Nonlinearities",2010,"","","","",60,"2022-07-13 10:07:35","","10.1109/TNN.2010.2042611","","",,,,,619,51.58,206,3,12,"In this paper, robust adaptive neural network (NN) control is investigated for a general class of uncertain multiple-input-multiple-output (MIMO) nonlinear systems with unknown control coefficient matrices and input nonlinearities. For nonsymmetric input nonlinearities of saturation and deadzone, variable structure control (VSC) in combination with backstepping and Lyapunov synthesis is proposed for adaptive NN control design with guaranteed stability. In the proposed adaptive NN control, the usual assumption on nonsingularity of NN approximation for unknown control coefficient matrices and boundary assumption between NN approximation error and control input have been eliminated. Command filters are presented to implement physical constraints on the virtual control laws, then the tedious analytic computations of time derivatives of virtual control laws are canceled. It is proved that the proposed robust backstepping control is able to guarantee semiglobal uniform ultimate boundedness of all signals in the closed-loop system. Finally, simulation results are presented to illustrate the effectiveness of the proposed adaptive NN control.","",""
5,"Boyuan Feng, Yuke Wang, Z. Wang, Yufei Ding","Uncertainty-aware Attention Graph Neural Network for Defending Adversarial Attacks",2020,"","","","",61,"2022-07-13 10:07:35","","","","",,,,,5,2.50,1,4,2,"With the increasing popularity of graph-based learning, graph neural networks (GNNs) emerge as the essential tool for gaining insights from graphs. However, unlike the conventional CNNs that have been extensively explored and exhaustively tested, people are still worrying about the GNNs' robustness under the critical settings, such as financial services. The main reason is that existing GNNs usually serve as a black-box in predicting and do not provide the uncertainty on the predictions. On the other side, the recent advancement of Bayesian deep learning on CNNs has demonstrated its success of quantifying and explaining such uncertainties to fortify CNN models. Motivated by these observations, we propose UAG, the first systematic solution to defend adversarial attacks on GNNs through identifying and exploiting hierarchical uncertainties in GNNs. UAG develops a Bayesian Uncertainty Technique (BUT) to explicitly capture uncertainties in GNNs and further employs an Uncertainty-aware Attention Technique (UAT) to defend adversarial attacks on GNNs. Intensive experiments show that our proposed defense approach outperforms the state-of-the-art solutions by a significant margin.","",""
1,"Camilo A. Garcia Trillos, Nicolás García Trillos","On the regularized risk of distributionally robust learning over deep neural networks",2021,"","","","",62,"2022-07-13 10:07:35","","","","",,,,,1,1.00,1,2,1,". In this paper we explore the relation between distributionally robust learning and diﬀerent forms of regularization to enforce robustness of deep neural networks. In particular, starting from a concrete min-max distributionally robust problem, and using tools from optimal transport theory, we derive ﬁrst order and second order approximations to the distributionally robust problem in terms of appropriate regularized risk minimization problems. In the context of deep ResNet models, we identify the structure of the resulting regularization problems as mean-ﬁeld optimal control problems where the number and dimension of state variables is within a dimension-free factor of the dimension of the original unrobust problem. Using the Pontryagin maximum principles associated to these problems we motivate a family of scalable algorithms for the training of robust neural networks. Our analysis recovers some results and algorithms known in the literature (in settings explained throughout the paper) and provides many other theoretical and algorithmic insights that to our knowledge are novel. In our analysis we employ tools that we deem useful for a future analysis of more general adversarial learning problems.","",""
17,"Kyle D. Julian, Ritchie Lee, Mykel J. Kochenderfer","Validation of Image-Based Neural Network Controllers through Adaptive Stress Testing",2020,"","","","",63,"2022-07-13 10:07:35","","10.1109/ITSC45102.2020.9294549","","",,,,,17,8.50,6,3,2,"Neural networks have become state-of-the-art for computer vision problems because of their ability to efficiently model complex functions from large amounts of data. While neural networks can be shown to perform well empirically for a variety of tasks, their performance is difficult to guarantee. Neural network verification tools have been developed that can certify robustness with respect to a given input image; however, for neural network systems used in closed-loop controllers, robustness with respect to individual images does not address multi-step properties of the neural network controller and its environment. Furthermore, neural network systems interacting in the physical world and using natural images are operating in a black-box environment, making formal verification intractable. This work combines the adaptive stress testing (AST) framework with neural network verification tools to search for the most likely sequence of image disturbances that cause the neural network controlled system to reach a failure. An autonomous aircraft taxi application is presented, and results show that the AST method finds failures with more likely image disturbances than baseline methods. Further analysis of AST results revealed an explainable cause of the failure, giving insight into the problematic scenarios that should be addressed.","",""
15,"S. Mahdavifar, A. Ghorbani","DeNNeS: deep embedded neural network expert system for detecting cyber attacks",2020,"","","","",64,"2022-07-13 10:07:35","","10.1007/s00521-020-04830-w","","",,,,,15,7.50,8,2,2,"","",""
1,"","RECURRENT NEURAL NETWORK ARCHITECTURE",2020,"","","","",65,"2022-07-13 10:07:35","","","","",,,,,1,0.50,0,0,2,"While dynamic systems can be modeled as sequence-to-sequence tasks by deep learning using different network architectures like DNN, CNN, RNNs or neural ODEs, the resulting models often provide poor understanding of the underlying system properties. We propose a new recurrent network architecture, the Dynamic Recurrent Network (DYRNN), where the computation function is based on the discrete difference equations of basic linear system transfer functions known from dynamic system identification. This results in a more explainable model, since the learnt weights can provide insight on a system’s time dependent behaviour. It also introduces the sequences’ sampling rate as an additional model parameter, which can be leveraged, for example, for time series data augmentation and model robustness checks. The network is trained using traditional gradient descent optimization and can be used in combination with other state of the art neural network layers. We show that our new layer type yields results comparable to or better than other recurrent layer types on several system identification tasks.","",""
6,"Gang Liu, Jing Wang","A Polynomial Neural Network with Controllable Precision and Human-Readable Topology for Prediction and System Identification",2020,"","","","",66,"2022-07-13 10:07:35","","","","",,,,,6,3.00,3,2,2,"Although artificial neural networks (ANNs) are successful, there is still a concern among many over their ""black box"" nature. Why do they work? Could we design a ""transparent"" network? This paper presents a controllable and readable polynomial neural network (CR-PNN) for approximation, prediction, and system identification. CR-PNN is simple enough to be described as one ""small"" formula, so that we can control the approximation precision and explain the internal structure of the network. CR-PNN, in fact, essentially is the fascinating Taylor expansion in the form of network. The number of layers represents precision. Derivatives in Taylor expansion are exactly imitated by error back-propagation algorithm. Firstly, we demonstrated that CR-PNN shows excellent analysis performance to the ""black box"" system through ten synthetic data with noise. Also, the results were compared with synthetic data to substantiate its search easily towards the global optimum. Secondly, it was verified, by ten real-world applications, that CR-PNN brought better generalization capability relative to the typical ANNs that approximate depended on the nonlinear activation function. Finally, 200,000 repeated experiments, with 4898 samples, demonstrated that CR-PNN is five times more efficient than typical ANN for one epoch and ten times more efficient than typical ANN for one forward-propagation. In short, compared with the traditional neural networks, the novelties and advantages of CR-PNN include readability of the internal structure, easy to find global optimal solution, lower computational complexity, and likely better robustness to real-world approximation. (We're strong believers in Open Source, and provide CR-PNN code for others. GitHub: this https URL)","",""
64,"Andras Rozsa, Manuel Günther, T. Boult","Towards Robust Deep Neural Networks with BANG",2016,"","","","",67,"2022-07-13 10:07:35","","10.1109/WACV.2018.00093","","",,,,,64,10.67,21,3,6,"Machine learning models, including state-of-the-art deep neural networks, are vulnerable to small perturbations that cause unexpected classification errors. This unexpected lack of robustness raises fundamental questions about their generalization properties and poses a serious concern for practical deployments. As such perturbations can remain imperceptible – the formed adversarial examples demonstrate an inherent inconsistency between vulnerable machine learning models and human perception – some prior work casts this problem as a security issue. Despite the significance of the discovered instabilities and ensuing research, their cause is not well understood and no effective method has been developed to address the problem. In this paper, we present a novel theory to explain why this unpleasant phenomenon exists in deep neural networks. Based on that theory, we introduce a simple, efficient, and effective training approach, Batch Adjusted Network Gradients (BANG), which significantly improves the robustness of machine learning models. While the BANG technique does not rely on any form of data augmentation or the utilization of adversarial images for training, the resultant classifiers are more resistant to adversarial perturbations while maintaining or even enhancing the overall classification performance.","",""
12,"H. Ninomiya","An Improved Online quasi-Newton method for robust training and its application to microwave neural network models",2010,"","","","",68,"2022-07-13 10:07:35","","10.1109/IJCNN.2010.5596655","","",,,,,12,1.00,12,1,12,"This paper describes a new technique for robust training of feedforward neural networks. The proposed algorithm is employed for the robust neural network training purpose. The quasi-Newton method was studied as one of the most efficient optimization algorithms based on the gradient descent and used as the batch training method of neural networks. On the other hand, the stochastic (online) quasi-Newton method was developed as an algorithm for the machine learning. In this paper the stochastic quasi-Newton training algorithm is improved for robust neural network training. Neural network training for some benchmark problems is presented to demonstrate the proposed algorithm. Furthermore, neural network training for microwave circuit modeling, such as the waveguide and the microstrip examples is presented, demonstrating that the proposed algorithm achieves more accurate models than both the batch and the stochastic quasi-Newton methods.","",""
1,"H. Bouzari, M. Srámek, G. Mistelbauer, E. Bouzari","Robust Adaptive Wavelet Neural Network Control of Buck Converters",2011,"","","","",69,"2022-07-13 10:07:35","","10.5772/16843","","",,,,,1,0.09,0,4,11,"Robustness is of crucial importance in control system design because the real engineering systems are vulnerable to external disturbance and measurement noise and there are always differences between mathematical models used for design and the actual system. Typically, it is required to design a controller that will stabilize a plant, if it is not stable originally, and to satisfy certain performance levels in the presence of disturbance signals, noise interference, unmodelled plant dynamics and plant-parameter variations. These design objectives are best realized via the feedback control mechanism (Fig. 1), although it introduces in the issues of high cost (the use of sensors), system complexity (implementation and safety) and more concerns on stability (thus internal stability and stabilizing controllers) (Gu, Petkov, & Konstantinov, 2005). In abstract, a control system is robust if it remains stable and achieves certain performance criteria in the presence of possible uncertainties. The robust design is to find a controller, for a given system, such that the closed-loop system is robust. In this chapter, the basic concepts and representations of a robust adaptive wavelet neural network control for the case study of buck converters will be discussed. The remainder of the chapter is organized as follows: In section 2 the advantages of neural network controllers over conventional ones will be discussed, considering the efficiency of introduction of wavelet theory in identifying unknown dependencies. Section 3 presents an overview of the buck converter models. In section 4, a detailed overview of WNN methods is presented. Robust control is introduced in section 5 to increase the robustness against noise by implementing the error minimization. Section 6 explains the stability analysis which is based on adaptive bound estimation. The implementation procedure and results of AWNN controller are explained in section 7. The results show the effectiveness of the proposed method in comparison to other previous works. The final section concludes the chapter.","",""
27,"P. Babakhani, J. Bridge, R. Doong, T. Phenrat","Parameterization and prediction of nanoparticle transport in porous media: A reanalysis using artificial neural network",2017,"","","","",70,"2022-07-13 10:07:35","","10.1002/2016WR020358","","",,,,,27,5.40,7,4,5,"The continuing rapid expansion of industrial and consumer processes based on nanoparticles (NP) necessitates a robust model for delineating their fate and transport in groundwater. An ability to reliably specify the full parameter set for prediction of NP transport using continuum models is crucial. In this paper we report the reanalysis of a data set of 493 published column experiment outcomes together with their continuum modeling results. Experimental properties were parameterized into 20 factors which are commonly available. They were then used to predict five key continuum model parameters as well as the effluent concentration via artificial neural network (ANN)‐based correlations. The Partial Derivatives (PaD) technique and Monte Carlo method were used for the analysis of sensitivities and model‐produced uncertainties, respectively. The outcomes shed light on several controversial relationships between the parameters, e.g., it was revealed that the trend of Katt with average pore water velocity was positive. The resulting correlations, despite being developed based on a “black‐box” technique (ANN), were able to explain the effects of theoretical parameters such as critical deposition concentration (CDC), even though these parameters were not explicitly considered in the model. Porous media heterogeneity was considered as a parameter for the first time and showed sensitivities higher than those of dispersivity. The model performance was validated well against subsets of the experimental data and was compared with current models. The robustness of the correlation matrices was not completely satisfactory, since they failed to predict the experimental breakthrough curves (BTCs) at extreme values of ionic strengths.","",""
18,"E. Egrioglu, U. Yolcu, E. Bas, Ali Z. Dalar","Median-Pi artificial neural network for forecasting",2019,"","","","",71,"2022-07-13 10:07:35","","10.1007/s00521-017-3002-z","","",,,,,18,6.00,5,4,3,"","",""
1,"Enyan Dai, Tianxiang Zhao, Huaisheng Zhu, Jun Xu, Zhimeng Guo, Hui Liu, Jiliang Tang, Suhang Wang","A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability",2022,"","","","",72,"2022-07-13 10:07:35","","10.48550/arXiv.2204.08570","","",,,,,1,1.00,0,8,1,"Graph Neural Networks (GNNs) have made rapid developments in the recent years. Due to their great ability in modeling graph-structured data, GNNs are vastly used in various applications, including high-stakes scenarios such as financial analysis, traffic predictions, and drug discovery. Despite their great potential in benefiting humans in the real world, recent study shows that GNNs can leak private information, are vulnerable to adversarial attacks, can inherit and magnify societal bias from training data and lack interpretability, which have risk of causing unintentional harm to the users and society. For example, existing works demonstrate that attackers can fool the GNNs to give the outcome they desire with unnoticeable perturbation on training graph. GNNs trained on social networks may embed the discrimination in their decision process, strengthening the undesirable societal bias. Consequently, trustworthy GNNs in various aspects are emerging to prevent the harm from GNN models and increase the users’ trust in GNNs. In this paper, we give a comprehensive survey of GNNs in the computational aspects of privacy, robustness, fairness, and explainability. For each aspect, we give the taxonomy of the related methods and formulate the general frameworks for the multiple categories of trustworthy GNNs. We also discuss the future research directions of each aspect and connections between these aspects to help achieve trustworthiness. Neural Networks:","",""
14,"Hongwei Hu, Jianbing Shen, Hanqiu Sun, L. Shao, F. Porikli","Robust Tracking using Manifold Convolutional Neural Networks with Laplacian Regularization",2018,"","","","",73,"2022-07-13 10:07:35","","10.1109/tmm.2018.2859831","","",,,,,14,3.50,3,5,4,"In visual tracking, usually only a small number of samples are labeled, and most existing deep learning based trackers ignore abundant unlabeled samples that could provide additional information for deep trackers to boost their tracking performance. An intuitive way to explain unlabeled data is to incorporate manifold regularization into the common classification loss functions, but the high computational cost may prohibit those deep trackers from practical applications. To overcome this issue, we propose a two-stage approach to a deep tracker that takes into account both labeled and unlabeled samples. The annotation of unlabeled samples is propagated from its labeled neighbors first by exploring the manifold space that these samples are assumed to lie in. Then, we refine it by training a deep convolutional neural network (CNN) using both labeled and unlabeled data in a supervised manner. Online visual tracking is further carried out under the framework of particle filters with the presented manifold regularized deep model being updated every few frames. Experimental results on different public tracking datasets demonstrate that our tracker outperforms most existing visual tracking approaches.","",""
5,"Minshuo Chen, Hao Liu, Wenjing Liao, T. Zhao","Doubly Robust Off-Policy Learning on Low-Dimensional Manifolds by Deep Neural Networks",2020,"","","","",74,"2022-07-13 10:07:35","","","","",,,,,5,2.50,1,4,2,"Causal inference explores the causation between actions and the consequent rewards on a covariate set. Recently deep learning has achieved a remarkable performance in causal inference, but existing statistical theories cannot well explain such an empirical success, especially when the covariates are high-dimensional. Most theoretical results in causal inference are asymptotic, suffer from the curse of dimensionality, and only work for the finite-action scenario. To bridge such a gap between theory and practice, this paper studies doubly robust off-policy learning by deep neural networks. When the covariates lie on a low-dimensional manifold, we prove nonasymptotic regret bounds, which converge at a fast rate depending on the intrinsic dimension of the manifold. Our results cover both the finite- and continuous-action scenarios. Our theory shows that deep neural networks are adaptive to the low-dimensional geometric structures of the covariates, and partially explains the success of deep learning for causal inference.","",""
2,"J. Kalina, P. Vidnerová","On Robust Training of Regression Neural Networks",2020,"","","","",75,"2022-07-13 10:07:35","","10.1007/978-3-030-47756-1_20","","",,,,,2,1.00,1,2,2,"","",""
0,"F. Palmieri, Mario Baldi, A. Buonanno, Giovanni Di Gennaro, Francesco Ospedale","Probing a Deep Neural Network",2020,"","","","",76,"2022-07-13 10:07:35","","10.1007/978-981-13-8950-4_19","","",,,,,0,0.00,0,5,2,"","",""
30,"Yangming Li, Shuai Li, B. Hannaford","A Model-Based Recurrent Neural Network With Randomness for Efficient Control With Applications",2019,"","","","",77,"2022-07-13 10:07:35","","10.1109/TII.2018.2869588","","",,,,,30,10.00,10,3,3,"Recently, recurrent neural network (RNN) control schemes for redundant manipulators have been extensively studied. These control schemes demonstrate superior computational efficiency, control precision, and control robustness. However, they lack planning completeness. This paper explains why RNN control schemes suffer from the problem. Based on the analysis, this work presents a new random RNN control scheme, which 1) introduces randomness into RNN to address the planning completeness problem, 2) improves control precision with a new optimization target, and 3) improves planning efficiency through learning from exploration. Theoretical analyses are used to prove the global stability, the planning completeness, and the computational complexity of the proposed method. Software simulation is provided to demonstrate the improved robustness against noise, the planning completeness and the improved planning efficiency of the proposed method over benchmark RNN control schemes. Real-world experiments are presented to demonstrate the application of the proposed method.","",""
0,"Justin A. Goodwin, Olivia M. Brown, Victoria Helus","Fast Training of Deep Neural Networks Robust to Adversarial Perturbations",2020,"","","","",78,"2022-07-13 10:07:35","","10.1109/HPEC43674.2020.9286256","","",,,,,0,0.00,0,3,2,"Despite their promising performance, deep neural networks have shown sensitivities to perturbations of their inputs (e.g., adversarial examples) and their learned feature representations are often difficult to interpret, raising concerns about their true capability and trustworthiness. Recent work in adversarial training, a form of robust optimization in which the model is optimized against adversarial examples, demonstrates the ability to improve performance sensitivities to perturbations and yield feature representations that are more interpretable. Adversarial training, however, comes with an increased computational cost over that of standard (i.e., nonrobust) training, rendering it impractical for use in large-scale problems. Recent work suggests that a fast approximation to adversarial training shows promise for reducing training time and maintaining robustness in the presence of perturbations bounded by the infinity norm. In this work, we demonstrate that this approach extends to the Euclidean norm and preserves the human-aligned feature representations that are common for robust models. Additionally, we show that using a distributed training scheme can further reduce the time to train robust deep networks. Fast adversarial training is a promising approach that will provide increased security and explainability in machine learning applications for which robust optimization was previously thought to be impractical.","",""
0,"Xinyue Wang, Jianhao Liang, Haitao Sun","The Network of Tumor Microtubes: An Improperly Reactivated Neural Cell Network With Stemness Feature for Resistance and Recurrence in Gliomas",2022,"","","","",79,"2022-07-13 10:07:35","","10.3389/fonc.2022.921975","","",,,,,0,0.00,0,3,1,"Gliomas are known as an incurable brain tumor for the poor prognosis and robust recurrence. In recent years, a cellular subpopulation with tumor microtubes (TMs) was identified in brain tumors, which may provide a new angle to explain the invasion, resistance, recurrence, and heterogeneity of gliomas. Recently, it was demonstrated that the cell subpopulation also expresses neural stem cell markers and shares a lot of features with both immature neurons and cancer stem cells and may be seen as an improperly reactivated neural cell network with a stemness feature at later time points of life. TMs may also provide a new angle to understand the resistance and recurrence mechanisms of glioma stem cells. In this review, we innovatively focus on the common features between TMs and sprouting axons in morphology, formation, and function. Additionally, we summarized the recent progress in the resistance and recurrence mechanisms of gliomas with TMs and explained the incurability and heterogeneity in gliomas with TMs. Moreover, we discussed the recently discovered overlap between cancer stem cells and TM-positive glioma cells, which may contribute to the understanding of resistant glioma cell subpopulation and the exploration of the new potential therapeutic target for gliomas.","",""
37,"Maximilian Augustin, Alexander Meinke, Matthias Hein","Adversarial Robustness on In- and Out-Distribution Improves Explainability",2020,"","","","",80,"2022-07-13 10:07:35","","10.1007/978-3-030-58574-7_14","","",,,,,37,18.50,12,3,2,"","",""
90,"Chandan Singh, W. James Murdoch, Bin Yu","Hierarchical interpretations for neural network predictions",2018,"","","","",81,"2022-07-13 10:07:35","","","","",,,,,90,22.50,30,3,4,"Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method, agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. Using examples from Stanford Sentiment Treebank and ImageNet, we show that ACD is effective at diagnosing incorrect predictions and identifying dataset bias. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.","",""
45,"Gil Fidel, Ron Bitton, A. Shabtai","When Explainability Meets Adversarial Learning: Detecting Adversarial Examples using SHAP Signatures",2019,"","","","",82,"2022-07-13 10:07:35","","10.1109/IJCNN48605.2020.9207637","","",,,,,45,15.00,15,3,3,"State-of-the-art deep neural networks (DNNs) are highly effective in solving many complex real-world problems. However, these models are vulnerable to adversarial perturbation attacks, and despite the plethora of research in this domain, to this day, adversaries still have the upper hand in the cat and mouse game of adversarial example generation methods vs. detection and prevention methods. In this research, we present a novel detection method that uses Shapley Additive Explanations (SHAP) values computed for the internal layers of a DNN classifier to discriminate between normal and adversarial inputs. We evaluate our method by building an extensive dataset of adversarial examples over the popular CIFAR-10 and MNIST datasets, and training a neural network-based detector to distinguish between normal and adversarial inputs. We evaluate our detector against adversarial examples generated by diverse state-of-the-art attacks and demonstrate its high detection accuracy and strong generalization ability to adversarial inputs generated with different attack methods.","",""
5,"Austin Talbot, D. Dunson, K. Dzirasa, David Edwin Carlson","Supervised Autoencoders Learn Robust Joint Factor Models of Neural Activity",2020,"","","","",83,"2022-07-13 10:07:35","","","","",,,,,5,2.50,1,4,2,"Factor models are routinely used for dimensionality reduction in modeling of correlated, high-dimensional data. We are particularly motivated by neuroscience applications collecting high-dimensional `predictors' corresponding to brain activity in different regions along with behavioral outcomes. Joint factor models for the predictors and outcomes are natural, but maximum likelihood estimates of these models can struggle in practice when there is model misspecification. We propose an alternative inference strategy based on supervised autoencoders; rather than placing a probability distribution on the latent factors, we define them as an unknown function of the high-dimensional predictors. This mapping function, along with the loadings, can be optimized to explain variance in brain activity while simultaneously being predictive of behavior. In practice, the mapping function can range in complexity from linear to more complex forms, such as splines or neural networks, with the usual tradeoff between bias and variance. This approach yields distinct solutions from a maximum likelihood inference strategy, as we demonstrate by deriving analytic solutions for a linear Gaussian factor model. Using synthetic data, we show that this function-based approach is robust against multiple types of misspecification. We then apply this technique to a neuroscience application resulting in substantial gains in predicting behavioral tasks from electrophysiological measurements in multiple factor models.","",""
1,"Peter Kok-Yiu Wong, Han Luo, Mingzhu Wang, Jack C. P. Cheng","Enriched and discriminative convolutional neural network features for pedestrian re‐identification and trajectory modeling",2021,"","","","",84,"2022-07-13 10:07:35","","10.1111/mice.12750","","",,,,,1,1.00,0,4,1,"Understanding pedestrian flow patterns in urban areas could support the decision‐making for infrastructure planning. By incorporating computer vision techniques into surveillance video processing, human walking trajectories in a wide area could be identified by pedestrian re‐identification (ReID) across multiple cameras. Recent ReID methods mostly use convolutional neural networks equipped with deep learning techniques to extract discriminative human features from images for identity matching. However, they still suffer from realistic challenges such as occlusion and appearance variation. This paper develops a ReID‐based framework for pedestrian trajectory recognition across multiple cameras. Specifically, a generic approach of explainable model design is presented, which intuitively analyzes existing baseline models based on feature visualization. Hence, a new model named OSNet + BDB is developed that extracts discriminative‐and‐distributed features. Additionally, an incremental feature aggregation strategy is designed for more robust identity matching. Our ReID method notably outperforms its baselines by 4% identification F1 accuracy in public benchmarks. Practically, pedestrian flow statistics in a real building are extracted for behavioral modeling. Simulations of several what‐if layouts are then conducted for facility performance evaluation.","",""
1,"Shuncheng Jia, Ruichen Zuo, Tielin Zhang, Hongxing Liu, Bo Xu","Motif-topology and Reward-learning improved Spiking Neural Network for Efficient Multi-sensory Integration",2022,"","","","",85,"2022-07-13 10:07:35","","10.1109/icassp43922.2022.9746157","","",,,,,1,1.00,0,5,1,"Network architectures and learning principles are key in forming complex functions in artificial neural networks (ANNs) and spiking neural networks (SNNs). SNNs are considered the new-generation artificial networks by incorporating more biological features than ANNs, including dynamic spiking neurons, functionally specified architectures, and efficient learning paradigms. In this paper, we propose a Motiftopology and Reward-learning improved SNN (MR-SNN) for efficient multi-sensory integration. MR-SNN contains 13 types of 3-node Motif topologies which are first extracted from independent single-sensory learning paradigms and then integrated for multi-sensory classification. The experimental results showed higher accuracy and stronger robustness of the proposed MR-SNN than other conventional SNNs without using Motifs. Furthermore, the proposed reward learning paradigm was biologically plausible and can better explain the cognitive McGurk effect caused by incongruent visual and auditory sensory signals.","",""
3,"Jeremy Bernstein, I. Dasgupta, D. Rolnick, H. Sompolinsky","Markov Transitions between Attractor States in a Recurrent Neural Network",2017,"","","","",86,"2022-07-13 10:07:35","","","","",,,,,3,0.60,1,4,5,"Stochasticity is an essential part of explaining the world. Increasingly, neuroscientists and cognitive scientists are identifying mechanisms whereby the brain uses probabilistic reasoning in representational, predictive, and generative settings. But stochasticity is not always useful: robust perception and memory retrieval require representations that are immune to corruption by stochastic noise. In an effort to combine these robust representations with stochastic computation, we present an architecture that generalizes traditional recurrent attractor networks to follow probabilistic Markov dynamics between stable and noise-resistant fixed points.","",""
2,"Sulaiman Khan, Hazrat Ali, Z. Ullah, N. Minallah, S. Maqsood, Abdul Hafeez","Higher Accurate Recognition of Handwritten Pashto Letters through Zoning Feature by using K-Nearest Neighbour and Artificial Neural Network",2019,"","","","",87,"2022-07-13 10:07:35","","10.14569/IJACSA.2018.091070","","",,,,,2,0.67,0,6,3,"This paper presents a recognition system for handwritten Pashto letters. However, handwritten character recognition is a challenging task. These letters not only differ in shape and style but also vary among individuals. The recognition becomes further daunting due to the lack of standard datasets for inscribed Pashto letters. In this work, we have designed a database of moderate size, which encompasses a total of 4488 images, stemming from 102 distinguishing samples for each of the 44 letters in Pashto. The recognition framework uses zoning feature extractor followed by K-Nearest Neighbour (KNN) and Neural Network (NN) classifiers for classifying individual letter. Based on the evaluation of the proposed system, an overall classification accuracy of approximately 70.05% is achieved by using KNN while 72% is achieved by using NN. Keywords—KNN, deep neural network, OCR, zoning technique, Pashto, character recognition, classification sectionIntroduction In this modern technological and digital age, optical character recognition (OCR) systems play a vital role in machine learning and automatic recognition problems. OCR is a section of software tool that converts printed text and images to machine readable form and enables the machine to recognize images or text like humans. OCR systems are commercially available for isolated languages, which include Chinese, English, Japanese, and others. However, few OCR systems are available for cursive languages such as Persian and Arabic and are not highly robust. To the best of our knowledge, there is no such commercial OCR system available for carved Pashto letters recognition; however, such systems exist in research labs. Handwritten letters recognition is a daunting task mainly because of variations in writing styles of different users. Handwritten letters recognition can be done either offline or online. Online character recognition is simpler and easier to implement due to the temporal based information such as velocity, time, number of strokes, and direction for writing. In addition, the trace of the pen is a few pixels wide so this does not require thinning techniques for classification. On the other hand, offline character recognition system implementation is even laborious due to high variations in writing and font styles of every user. In our paper, we present inscribed of handwritten Pashto letters. Pashto is a major language of Pashtun tribe in Pakistan and the official language of Afghanistan. In censes 2007 2009, it was estimated that about 40 60 millions of people around the world are native speakers of this language. Pashto letters can be shaped into six different formats, which make the recognition process challenging. Furthermore, the count of character dots and occurrence of these dots that varies from letter to letter make the problem challenging. In order to address these problems, research shows the use of high level features based on the structural information of letters. An OCR based system using deep learning network model that incorporates Biand Multi-dimensional long short term memory for printed Pashto text recognition has been suggested [1]. A web-based survey shows that Pashto script contains a huge number of unique ligature [2]. Such ligature makes the implementation of OCR system for carved Pashto challenging. As printed letters contain a constant shape/style and font size; thus, the said technique fails in our case due to higher higher variations in style and font in case of inscribed letters. Riaz et al. [3] has presented the development of an OCR system for cursive Pashto script using scale invariant feature transform and principle component analysis. In order to address this issue, we present a system for handwritten Pashto letters recognition, which has the following key contributions: • As there is no standard handwritten Pashto letters database for testing an algorithm; thus, one of the contribution of this work is to develop and present a medium-sized database of 4488 (102 samples for each letter) for further research work. • The second contribution of this research work is to provide a base result as a benchmark for Pashto language. For this purpose, the performance results of the state-of-the-art classifiers−KNN and deep Neural Network are used based on zoning features. • Our proposed handwritten Pashto letters recognition system is efficient, simple, and cost-effective. • We provide comprehensive results for analyzing the proposed system for handwritten Pashto letters recognition, which may help the researchers to further explore this area. This paper is divided in seven sections: Section I explains the related work. Section II captures the background informawww.ijacsa.thesai.org 1 | P a g e ar X iv :1 90 4. 03 39 1v 1 [ cs .C V ] 6 A pr 2 01 9 (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 9, No. 10, 2018 tion about the classifiers and feature extraction algorithm used in this research work. Section III delineates the methodology. Section IV discusses about the feature extraction, which is very important in the area of pattern recognition and machine learning while section V demonstrates the experimental results followed by the conclusions and future work in Section VI.","",""
2,"S. Meister, Mahdieu A. M. Wermes, J. Stüve, R. Groves","Explainability of deep learning classifier decisions for optical detection of manufacturing defects in the automated fiber placement process",2021,"","","","",88,"2022-07-13 10:07:35","","10.1117/12.2592584","","",,,,,2,2.00,1,4,1,"Automated fibre layup techniques are commonly used composite manufacturing processes in the aviation sector and require a manual visual inspection. Neural Network classification of defects has the potential to automate this visual inspection, however, the machine decision-making processes are hard to verify. Thus, we present an approach for visualising Convolutional Neural Network (CNN) based classifications of manufacturing defects and quantifying its robustness suitably. Our investigations have shown that especially Smoothed Integrated Gradients and DeepSHAP are particularly well suited for the visualisation of CNN classifications. The Smoothed Integrated Gradients technique also reveals advantages in robustness when evaluating degraded input images.","",""
1,"Riccardo De Feo, E. Hämäläinen, Eppu Manninen, R. Immonen, Juan Miguel Valverde, X. Ndode-Ekane, O. Gröhn, A. Pitkänen, Jussi Tohka","Convolutional Neural Networks Enable Robust Automatic Segmentation of the Rat Hippocampus in MRI After Traumatic Brain Injury",2022,"","","","",89,"2022-07-13 10:07:35","","10.3389/fneur.2022.820267","","",,,,,1,1.00,0,9,1,"Registration-based methods are commonly used in the automatic segmentation of magnetic resonance (MR) brain images. However, these methods are not robust to the presence of gross pathologies that can alter the brain anatomy and affect the alignment of the atlas image with the target image. In this work, we develop a robust algorithm, MU-Net-R, for automatic segmentation of the normal and injured rat hippocampus based on an ensemble of U-net-like Convolutional Neural Networks (CNNs). MU-Net-R was trained on manually segmented MR images of sham-operated rats and rats with traumatic brain injury (TBI) by lateral fluid percussion. The performance of MU-Net-R was quantitatively compared with methods based on single and multi-atlas registration using MR images from two large preclinical cohorts. Automatic segmentations using MU-Net-R and multi-atlas registration were of excellent quality, achieving cross-validated Dice scores above 0.90 despite the presence of brain lesions, atrophy, and ventricular enlargement. In contrast, the performance of single-atlas segmentation was unsatisfactory (cross-validated Dice scores below 0.85). Interestingly, the registration-based methods were better at segmenting the contralateral than the ipsilateral hippocampus, whereas MU-Net-R segmented the contralateral and ipsilateral hippocampus equally well. We assessed the progression of hippocampal damage after TBI by using our automatic segmentation tool. Our data show that the presence of TBI, time after TBI, and whether the hippocampus was ipsilateral or contralateral to the injury were the parameters that explained hippocampal volume.","",""
0,"R. Barati, R. Safabakhsh, M. Rahmati","An Analytic Framework for Robust Training of Artificial Neural Networks",2022,"","","","",90,"2022-07-13 10:07:35","","10.48550/arXiv.2205.13502","","",,,,,0,0.00,0,3,1,"The reliability of a learning model is key to the successful deployment of machine learning in various industries. Creating a robust model, particularly one unaffected by adversarial attacks, requires a comprehensive understanding of the adversarial examples phenomenon. However, it is difﬁcult to describe the phenomenon due to the complicated nature of the problems in machine learning. Consequently, many studies investigate the phenomenon by proposing a simpliﬁed model of how adversarial examples occur and validate it by predicting some aspect of the phenomenon. While these studies cover many different characteristics of the adversarial examples, they have not reached a holistic approach to the geometric and analytic modeling of the phenomenon. This paper propose a formal framework to study the phenomenon in learning theory and make use of complex analysis and holomorphicity to offer a robust learning rule for artiﬁcial neural networks. With the help of complex analysis, we can effortlessly move between geometric and analytic perspectives of the phenomenon and offer further insights on the phenomenon by revealing its connection with harmonic functions. Using our model, we can explain some of the most intriguing characteristics of adversarial examples, including transferability of adversarial examples, and pave the way for novel approaches to mitigate the effects of the phenomenon.","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",91,"2022-07-13 10:07:35","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
13,"L. Wandera, K. Mallick, G. Kiely, O. Roupsard, M. Peichl, V. Magliulo","Upscaling instantaneous to daily evapotranspiration using modelled daily shortwave radiation for remote sensing applications: an artificial neural network approach",2016,"","","","",92,"2022-07-13 10:07:35","","10.5194/HESS-21-197-2017","","",,,,,13,2.17,2,6,6,"Abstract. Upscaling instantaneous evapotranspiration retrieved at any specific time-of-day (ETi) to daily evapotranspiration (ETd) is a key challenge in mapping regional ET using polar orbiting sensors. Various studies have unanimously cited the shortwave incoming radiation (RS) to be the most robust reference variable explaining the ratio between ETd and ETi. This study aims to contribute in ETi upscaling for global studies using the ratio between daily and instantaneous incoming shortwave radiation (RSd ∕ RSi) as a factor for converting ETi to ETd. This paper proposes an artificial neural network (ANN) machine-learning algorithm first to predict RSd from RSi followed by using the RSd ∕ RSi ratio to convert ETi to ETd across different terrestrial ecosystems. Using RSi and RSd observations from multiple sub-networks of the FLUXNET database spread across different climates and biomes (to represent inputs that would typically be obtainable from remote sensors during the overpass time) in conjunction with some astronomical variables (e.g. solar zenith angle, day length, exoatmospheric shortwave radiation), we developed the ANN model for reproducing RSd and further used it to upscale ETi to ETd. The efficiency of the ANN is evaluated for different morning and afternoon times of day, under varying sky conditions, and also at different geographic locations. RS-based upscaled ETd produced a significant linear relation (R2 =  0.65 to 0.69), low bias (−0.31 to −0.56 MJ m−2 d−1; approx. 4 %), and good agreement (RMSE 1.55 to 1.86 MJ m−2 d−1; approx. 10 %) with the observed ETd, although a systematic overestimation of ETd was also noted under persistent cloudy sky conditions. Inclusion of soil moisture and rainfall information in ANN training reduced the systematic overestimation tendency in predominantly overcast days. An intercomparison with existing upscaling method at daily, 8-day, monthly, and yearly temporal resolution revealed a robust performance of the ANN-driven RS-based ETi upscaling method and was found to produce lowest RMSE under cloudy conditions. Sensitivity analysis revealed variable sensitivity of the method to biome selection and high ETd prediction errors in forest ecosystems are primarily associated with greater rainfall and cloudiness. The overall methodology appears to be promising and has substantial potential for upscaling ETi to ETd for field and regional-scale evapotranspiration mapping studies using polar orbiting satellites.","",""
158,"C. Hua, X. Guan, P. Shi","Robust Output Feedback Tracking Control for Time-Delay Nonlinear Systems Using Neural Network",2007,"","","","",93,"2022-07-13 10:07:35","","10.1109/TNN.2006.888368","","",,,,,158,10.53,53,3,15,"In this paper, the problem of robust output tracking control for a class of time-delay nonlinear systems is considered. The systems are in the form of triangular structure with unmodeled dynamics. First, we construct an observer whose gain matrix is scheduled via linear matrix inequality approach. For the case that the information of uncertainties bounds is not completely available, we design an observer-based neural network (NN) controller by employing the backstepping method. The resulting closed-loop system is ensured to be stable in the sense of semiglobal boundedness with the help of changing supplying function idea. The observer and the controller designed are both independent of the time delays. Finally, numerical simulations are conducted to verify the effectiveness of the main theoretic results obtained","",""
405,"David Alvarez-Melis, T. Jaakkola","Towards Robust Interpretability with Self-Explaining Neural Networks",2018,"","","","",94,"2022-07-13 10:07:35","","","","",,,,,405,101.25,203,2,4,"Most recent work on interpretability of complex machine learning models has focused on estimating a posteriori explanations for previously trained models around specific predictions. Self-explaining models where interpretability plays a key role already during learning have received much less attention. We propose three desiderata for explanations in general – explicitness, faithfulness, and stability – and show that existing methods do not satisfy them. In response, we design self-explaining models in stages, progressively generalizing linear classifiers to complex yet architecturally explicit models. Faithfulness and stability are enforced via regularization specifically tailored to such models. Experimental results across various benchmark datasets show that our framework offers a promising direction for reconciling model complexity and interpretability.","",""
0,"R. Sathish, Debdoot Sheet","Unit Impulse Response as an Explainer of Redundancy in a Deep Convolutional Neural Network",2019,"","","","",95,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,2,3,"Convolutional neural networks (CNN) are generally designed with a heuristic initialization of network architecture and trained for a certain task. This often leads to overparametrization after learning and induces redundancy in the information flow paths within the network. This robustness and reliability is at the increased cost of redundant computations. Several methods have been proposed which leverage metrics that quantify the redundancy in each layer. However, layer-wise evaluation in these methods disregards the long-range redundancy which exists across depth on account of the distributed nature of the features learned by the model. In this paper, we propose (i) a mechanism to empirically demonstrate the robustness in performance of a CNN on account of redundancy across its depth, (ii) a method to identify the systemic redundancy in response of a CNN across depth using the understanding of unit impulse response, we subsequently demonstrate use of these methods to interpret redundancy in few networks as example. These techniques provide better insights into the internal dynamics of a CNN","",""
125,"Jie Hou, B. Adhikari, Jianlin Cheng","DeepSF: deep convolutional neural network for mapping protein sequences to folds",2017,"","","","",96,"2022-07-13 10:07:35","","10.1093/bioinformatics/btx780","","",,,,,125,25.00,42,3,5,"Motivation Protein fold recognition is an important problem in structural bioinformatics. Almost all traditional fold recognition methods use sequence (homology) comparison to indirectly predict the fold of a target protein based on the fold of a template protein with known structure, which cannot explain the relationship between sequence and fold. Only a few methods had been developed to classify protein sequences into a small number of folds due to methodological limitations, which are not generally useful in practice. Results We develop a deep 1D‐convolution neural network (DeepSF) to directly classify any protein sequence into one of 1195 known folds, which is useful for both fold recognition and the study of sequence‐structure relationship. Different from traditional sequence alignment (comparison) based methods, our method automatically extracts fold‐related features from a protein sequence of any length and maps it to the fold space. We train and test our method on the datasets curated from SCOP1.75, yielding an average classification accuracy of 75.3%. On the independent testing dataset curated from SCOP2.06, the classification accuracy is 73.0%. We compare our method with a top profile‐profile alignment method—HHSearch on hard template‐based and template‐free modeling targets of CASP9‐12 in terms of fold recognition accuracy. The accuracy of our method is 12.63‐26.32% higher than HHSearch on template‐free modeling targets and 3.39‐17.09% higher on hard template‐based modeling targets for top 1, 5 and 10 predicted folds. The hidden features extracted from sequence by our method is robust against sequence mutation, insertion, deletion and truncation, and can be used for other protein pattern recognition problems such as protein clustering, comparison and ranking. Availability and implementation The DeepSF server is publicly available at: http://iris.rnet.missouri.edu/DeepSF/. Supplementary information Supplementary data are available at Bioinformatics online.","",""
1,"Charles B. Delahunt, Pedro D. Maia, J. Kutz","Built to Last: Functional and Structural Mechanisms in the Moth Olfactory Network Mitigate Effects of Neural Injury",2018,"","","","",97,"2022-07-13 10:07:35","","10.3390/brainsci11040462","","",,,,,1,0.25,0,3,4,"Most organisms suffer neuronal damage throughout their lives, which can impair performance of core behaviors. Their neural circuits need to maintain function despite injury, which in particular requires preserving key system outputs. In this work, we explore whether and how certain structural and functional neuronal network motifs act as injury mitigation mechanisms. Specifically, we examine how (i) Hebbian learning, (ii) high levels of noise, and (iii) parallel inhibitory and excitatory connections contribute to the robustness of the olfactory system in the Manduca sexta moth. We simulate injuries on a detailed computational model of the moth olfactory network calibrated to data. The injuries are modeled on focal axonal swellings, a ubiquitous form of axonal pathology observed in traumatic brain injuries and other brain disorders. Axonal swellings effectively compromise spike train propagation along the axon, reducing the effective neural firing rate delivered to downstream neurons. All three of the network motifs examined significantly mitigate the effects of injury on readout neurons, either by reducing injury’s impact on readout neuron responses or by restoring these responses to pre-injury levels. These motifs may thus be partially explained by their value as adaptive mechanisms to minimize the functional effects of neural injury. More generally, robustness to injury is a vital design principle to consider when analyzing neural systems.","",""
2,"Kuntal Ghosh","A neural network based model of M and P LGN cells",2016,"","","","",98,"2022-07-13 10:07:35","","10.1109/BSB.2016.7552165","","",,,,,2,0.33,2,1,6,"A new excitatory-inhibitory neural network model for the extended classical receptive field (ECRF) of Parvo (P), and Magno (M) cells in the lateral geniculate nucleus (LGN) is proposed. The model is based upon various well-known findings in neurophysiology, anatomy and psychophysics. The top-down linking of the proposed model to the feed-forward pathways, that is able to explain the simple, yet intriguing problem of brightness perception, may have implication in developing robust visual capturing and display systems, as well as in overall accurate representation of images as has been demonstrated in recent works.","",""
692,"W. Samek, Alexander Binder, G. Montavon, S. Lapuschkin, K. Müller","Evaluating the Visualization of What a Deep Neural Network Has Learned",2015,"","","","",99,"2022-07-13 10:07:35","","10.1109/TNNLS.2016.2599820","","",,,,,692,98.86,138,5,7,"Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the “importance” of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.","",""
38,"G. Lai, Zhi Liu, Yun Zhang, C. L. Chen","Adaptive Position/Attitude Tracking Control of Aerial Robot With Unknown Inertial Matrix Based on a New Robust Neural Identifier",2016,"","","","",100,"2022-07-13 10:07:35","","10.1109/TNNLS.2015.2406812","","",,,,,38,6.33,10,4,6,"This paper presents a novel adaptive controller for controlling an autonomous helicopter with unknown inertial matrix to asymptotically track the desired trajectory. To identify the unknown inertial matrix included in the attitude dynamic model, this paper proposes a new structural identifier that differs from those previously proposed in that it additionally contains a neural networks (NNs) mechanism and a robust adaptive mechanism, respectively. Using the NNs to compensate the unknown aerodynamic forces online and the robust adaptive mechanism to cancel the combination of the overlarge NNs compensation error and the external disturbances, the new robust neural identifier exhibits a better identification performance in the complex flight environment. Moreover, an optimized algorithm is included in the NNs mechanism to alleviate the burdensome online computation. By the strict Lyapunov argument, the asymptotic convergence of the inertial matrix identification error, position tracking error, and attitude tracking error to arbitrarily small neighborhood of the origin is proved. The simulation and implementation results are provided to evaluate the performance of the proposed controller.","",""
140,"R. Wai, Rajkumar Muthusamy","Fuzzy-Neural-Network Inherited Sliding-Mode Control for Robot Manipulator Including Actuator Dynamics",2013,"","","","",101,"2022-07-13 10:07:35","","10.1109/TNNLS.2012.2228230","","",,,,,140,15.56,70,2,9,"This paper presents the design and analysis of an intelligent control system that inherits the robust properties of sliding-mode control (SMC) for an n-link robot manipulator, including actuator dynamics in order to achieve a high-precision position tracking with a firm robustness. First, the coupled higher order dynamic model of an n-link robot manipulator is briefy introduced. Then, a conventional SMC scheme is developed for the joint position tracking of robot manipulators. Moreover, a fuzzy-neural-network inherited SMC (FNNISMC) scheme is proposed to relax the requirement of detailed system information and deal with chattering control efforts in the SMC system. In the FNNISMC strategy, the FNN framework is designed to mimic the SMC law, and adaptive tuning algorithms for network parameters are derived in the sense of projection algorithm and Lyapunov stability theorem to ensure the network convergence as well as stable control performance. Numerical simulations and experimental results of a two-link robot manipulator actuated by DC servo motors are provided to justify the claims of the proposed FNNISMC system, and the superiority of the proposed FNNISMC scheme is also evaluated by quantitative comparison with previous intelligent control schemes.","",""
39,"G. Dziugaite, Alexandre Drouin, Brady Neal, Nitarshan Rajkumar, Ethan Caballero, Linbo Wang, Ioannis Mitliagkas, Daniel M. Roy","In Search of Robust Measures of Generalization",2020,"","","","",102,"2022-07-13 10:07:35","","","","",,,,,39,19.50,5,8,2,"One of the principal scientific challenges in deep learning is explaining generalization, i.e., why the particular way the community now trains networks to achieve small training error also leads to small error on held-out data from the same population. It is widely appreciated that some worst-case theories -- such as those based on the VC dimension of the class of predictors induced by modern neural network architectures -- are unable to explain empirical performance. A large volume of work aims to close this gap, primarily by developing bounds on generalization error, optimization error, and excess risk. When evaluated empirically, however, most of these bounds are numerically vacuous. Focusing on generalization bounds, this work addresses the question of how to evaluate such bounds empirically. Jiang et al. (2020) recently described a large-scale empirical study aimed at uncovering potential causal relationships between bounds/measures and generalization. Building on their study, we highlight where their proposed methods can obscure failures and successes of generalization measures in explaining generalization. We argue that generalization measures should instead be evaluated within the framework of distributional robustness.","",""
0,"Minh Le","Robust Deep Neural Networks Inspired by Fuzzy Logic",2019,"","","","",103,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,1,3,"Deep neural networks have achieved impressive performance and become the de-facto standard in many tasks. However, troubling phenomena such as adversarial and fooling examples suggest that the generalization they make is flawed. I argue that among the roots of the phenomena are two geometric properties of common deep learning architectures: their distributed nature and the connectedness of their decision regions. As a remedy, I propose new architectures inspired by fuzzy logic that combine several alternative design elements. Through experiments on MNIST and CIFAR-10, the new models are shown to be more local, better at rejecting noise samples, and more robust against adversarial examples. Ablation analyses reveal behaviors on adversarial examples that cannot be explained by the linearity hypothesis but are consistent with the hypothesis that logic-inspired traits create more robust models.","",""
41,"M. Matsugu, Katsuhiko Mori, Mie Ishii, Y. Mitarai","Convolutional spiking neural network model for robust face detection",2002,"","","","",104,"2022-07-13 10:07:35","","10.1109/ICONIP.2002.1198140","","",,,,,41,2.05,10,4,20,"We propose a convolutional spiking neural network (CSNN) model with population coding for robust face detection. The basic structure of the network includes hierarchically alternating layers for feature detection and feature pooling. The proposed model implements hierarchical template matching by temporal integration of structured pulse packet. The packet signal represents some intermediate or complex visual feature (e.g., a pair of line segments, corners, eye, nose, etc.) that constitutes a face model. The output pulse of a feature pooling neuron represents some local feature (e.g., line segments). Introducing a population coding scheme in the CSNN architecture, we show how the biologically inspired model attains invariance to changes in size and position of face and ensures the efficiency of face detection.","",""
158,"A. Vemuri, M. Polycarpou","Neural-network-based robust fault diagnosis in robotic systems",1997,"","","","",105,"2022-07-13 10:07:35","","10.1109/72.641464","","",,,,,158,6.32,79,2,25,"Fault diagnosis plays an important role in the operation of modern robotic systems. A number of researchers have proposed fault diagnosis architectures for robotic manipulators using the model-based analytical redundancy approach. One of the key issues in the design of such fault diagnosis schemes is the effect of modeling uncertainties on their performance. This paper investigates the problem of fault diagnosis in rigid-link robotic manipulators with modeling uncertainties. A learning architecture with sigmoidal neural networks is used to monitor the robotic system for any off-nominal behavior due to faults. The robustness and stability properties of the fault diagnosis scheme are rigorously established. Simulation examples are presented to illustrate the ability of the neural-network-based robust fault diagnosis scheme to detect and accommodate faults in a two-link robotic manipulator.","",""
4,"Mohammad Shorfuzzaman, M. S. Hossain, A. El Saddik","An Explainable Deep Learning Ensemble Model for Robust Diagnosis of Diabetic Retinopathy Grading",2021,"","","","",106,"2022-07-13 10:07:35","","10.1145/3469841","","",,,,,4,4.00,1,3,1,"Diabetic retinopathy (DR) is one of the most common causes of vision loss in people who have diabetes for a prolonged period. Convolutional neural networks (CNNs) have become increasingly popular for computer-aided DR diagnosis using retinal fundus images. While these CNNs are highly reliable, their lack of sufficient explainability prevents them from being widely used in medical practice. In this article, we propose a novel explainable deep learning ensemble model where weights from different models are fused into a single model to extract salient features from various retinal lesions found on fundus images. The extracted features are then fed to a custom classifier for the final diagnosis of DR severity level. The model is trained on an APTOS dataset containing retinal fundus images of various DR grades using a cyclical learning rates strategy with an automatic learning rate finder for decaying the learning rate to improve model accuracy. We develop an explainability approach by leveraging gradient-weighted class activation mapping and shapely adaptive explanations to highlight the areas of fundus images that are most indicative of different DR stages. This allows ophthalmologists to view our model's decision in a way that they can understand. Evaluation results using three different datasets (APTOS, MESSIDOR, IDRiD) show the effectiveness of our model, achieving superior classification rates with a high degree of precision (0.970), sensitivity (0.980), and AUC (0.978). We believe that the proposed model, which jointly offers state-of-the-art diagnosis performance and explainability, will address the black-box nature of deep CNN models in robust detection of DR grading.","",""
149,"Songwu Lu, T. Başar","Robust nonlinear system identification using neural-network models",1998,"","","","",107,"2022-07-13 10:07:35","","10.1109/72.668883","","",,,,,149,6.21,75,2,24,"We study the problem of identification for nonlinear systems in the presence of unknown driving noise, using both feedforward multilayer neural network and radial basis function network models. Our objective is to resolve the difficulty associated with the persistency of excitation condition inherent to the standard schemes in the neural identification literature. This difficulty is circumvented here by a novel formulation and by using a new class of identification algorithms recently obtained by Didinsky et al. We show how these algorithms can be exploited to successfully identify the nonlinearity in the system using neural-network models. By embedding the original problem in one with noise-perturbed state measurements, we present a class of identifiers (under L1 and L2 cost criteria) which secure a good approximant for the system nonlinearity provided that some global optimization technique is used. In this respect, many available learning algorithms in the current neural-network literature, e.g., the backpropagation scheme and the genetic algorithms-based scheme, with slight modifications, can ensure the identification of the system nonlinearity. Subsequently, we address the same problem under a third, worst case L(infinity) criterion for an RBF modeling. We present a neural-network version of an H(infinity)-based identification algorithm from Didinsky et al and show how, along with an appropriate choice of control input to enhance excitation, under both full-state-derivative information (FSDI) and noise-perturbed full-state-information (NPFSI), it leads to satisfaction of a relevant persistency of excitation condition, and thereby to robust identification of the nonlinearity. Results from several simulation studies have been included to demonstrate the effectiveness of these algorithms.","",""
490,"M. Matsugu, Katsuhiko Mori, Y. Mitari, Yuji Kaneda","Subject independent facial expression recognition with robust face detection using a convolutional neural network",2003,"","","","",108,"2022-07-13 10:07:35","","10.1016/S0893-6080(03)00115-1","","",,,,,490,25.79,123,4,19,"","",""
147,"K. Liano","Robust error measure for supervised neural network learning with outliers",1996,"","","","",109,"2022-07-13 10:07:35","","10.1109/72.478411","","",,,,,147,5.65,147,1,26,"Most supervised neural networks (NNs) are trained by minimizing the mean squared error (MSE) of the training set. In the presence of outliers, the resulting NN model can differ significantly from the underlying system that generates the data. Two different approaches are used to study the mechanism by which outliers affect the resulting models: influence function and maximum likelihood. The mean log squared error (MLSE) is proposed as the error criteria that can be easily adapted by most supervised learning algorithms. Simulation results indicate that the proposed method is robust against outliers.","",""
11,"Alexander Hartl, Maximilian Bachl, J. Fabini, T. Zseby","Explainability and Adversarial Robustness for RNNs",2019,"","","","",110,"2022-07-13 10:07:35","","10.1109/BigDataService49289.2020.00030","","",,,,,11,3.67,3,4,3,"Recurrent Neural Networks (RNNs) yield attractive properties for constructing Intrusion Detection Systems (IDSs) for network data. With the rise of ubiquitous Machine Learning (ML) systems, malicious actors have been catching up quickly to find new ways to exploit ML vulnerabilities for profit. Recently developed adversarial ML techniques focus on computer vision and their applicability to network traffic is not straightforward: Network packets expose fewer features than an image, are sequential and impose several constraints on their features. We show that despite these completely different characteristics, adversarial samples can be generated reliably for RNNs. To understand a classifier's potential for misclassification, we extend existing explainability techniques and propose new ones, suitable particularly for sequential data. Applying them shows that already the first packets of a communication flow are of crucial importance and are likely to be targeted by attackers. Feature importance methods show that even relatively unimportant features can be effectively abused to generate adversarial samples. We thus introduce the concept of feature sensitivity which quantifies how much potential a feature has to cause misclassification. Since traditional evaluation metrics such as accuracy are not sufficient for quantifying the adversarial threat, we propose the Adversarial Robustness Score (ARS) for comparing IDSs and show that an adversarial training procedure can significantly and successfully reduce the attack surface.","",""
1,"Anna-Kathrin Kopetzki, Stephan Günnemann","Reachable Sets of Classifiers & Regression Models: (Non-)Robustness Analysis and Robust Training",2020,"","","","",111,"2022-07-13 10:07:35","","10.1007/S10994-021-05973-0","","",,,,,1,0.50,1,2,2,"","",""
1,"Eduardo Ulises Moya-Sánchez, S. Xambó-Descamps, Abraham Sánchez Pérez, Sebastián Salazar-Colores, Ulises Cort'es","A Trainable Monogenic ConvNet Layer Robust in Front of Large Contrast Changes in Image Classification",2021,"","","","",112,"2022-07-13 10:07:35","","10.1109/access.2021.3128552","","",,,,,1,1.00,0,5,1,"At present, Convolutional Neural Networks (ConvNets) achieve remarkable performance in image classification tasks. However, current ConvNets cannot guarantee the capabilities of mammalian visual systems such as invariance to contrast and illumination changes. Some ideas for overcoming the illumination and contrast variations must usually be tuned manually and tend to fail when tested with other types of data degradation. In this context, a new bio-inspired entry layer is presented in this work, M6, which detects low-level geometric features (lines, edges, and orientations) similar to those patterns detected by the V1 visual cortex. This new trainable layer is capable of dealing with image classification tasks even with large contrast variations. The explanation for this behavior is due to the use of monogenic signal geometry, which represents each pixel value in a 3D space using quaternions, a fact that confers a degree of explainability to the networks. The M6 was compared to conventional convolutional layer (C) and a deterministic quaternion local phase layer (Q9). The experimental setup is designed to evaluate the robustness of this M6 enriched ConvNet model and includes three architectures, four datasets, and three types of contrast degradation (including non-uniform haze degradations). The numerical results reveal that the models with M6 are the most robust in front of any kind of contrast variations. This amounts to a significant enhancement of the C models, which usually have reasonably good performance only when the same training and test degradation are used, except for the case of maximum degradation. Moreover, the Structural Similarity Index Measure (SSIM) and Peak Signal to Noise Ratio (PSNR) are used to analyze and explain the robustness effect of the M6 feature maps under any kind of contrast degradations.","",""
75,"Vu Thi Yen, Yaonan Wang, C. Pham","Recurrent fuzzy wavelet neural networks based on robust adaptive sliding mode control for industrial robot manipulators",2019,"","","","",113,"2022-07-13 10:07:35","","10.1007/s00521-018-3520-3","","",,,,,75,25.00,25,3,3,"","",""
4,"Jay Roberts, Theodoros Tsiligkaridis","Controllably Sparse Perturbations of Robust Classifiers for Explaining Predictions and Probing Learned Concepts",2021,"","","","",114,"2022-07-13 10:07:35","","","","",,,,,4,4.00,2,2,1,"Explaining the predictions of a deep neural network (DNN) in image classification is an active area of research. Many methods focus on localizing pixels, or groups of pixels, which maximize a relevance metric for the prediction. Others aim at creating local ""proxy"" explainers which aim to account for an individual prediction of a model. We aim to explore ""why"" a model made a prediction by perturbing inputs to robust classifiers and interpreting the semantically meaningful results. For such an explanation to be useful for humans it is desirable for it to be sparse; however, generating sparse perturbations can computationally expensive and infeasible on high resolution data. Here we introduce controllably sparse explanations that can be efficiently generated on higher resolution data to provide improved counter-factual explanations. Further we use these controllably sparse explanations to probe what the robust classifier has learned. These explanations could provide insight for model developers as well as assist in detecting dataset bias. CCS Concepts • Computing methodologies → Machine learning; Artificial intelligence;","",""
112,"Zheng Yan, Jun Wang","Robust Model Predictive Control of Nonlinear Systems With Unmodeled Dynamics and Bounded Uncertainties Based on Neural Networks",2014,"","","","",115,"2022-07-13 10:07:35","","10.1109/TNNLS.2013.2275948","","",,,,,112,14.00,56,2,8,"This paper presents a neural network approach to robust model predictive control (MPC) for constrained discrete-time nonlinear systems with unmodeled dynamics affected by bounded uncertainties. The exact nonlinear model of underlying process is not precisely known, but a partially known nominal model is available. This partially known nonlinear model is first decomposed to an affine term plus an unknown high-order term via Jacobian linearization. The linearization residue combined with unmodeled dynamics is then modeled using an extreme learning machine via supervised learning. The minimax methodology is exploited to deal with bounded uncertainties. The minimax optimization problem is reformulated as a convex minimization problem and is iteratively solved by a two-layer recurrent neural network. The proposed neurodynamic approach to nonlinear MPC improves the computational efficiency and sheds a light for real-time implementability of MPC technology. Simulation results are provided to substantiate the effectiveness and characteristics of the proposed approach.","",""
2,"Zhiming Zhang, Yongming Liu","Robust Data-Driven Discovery of Partial Differential Equations under Uncertainties",2021,"","","","",116,"2022-07-13 10:07:35","","","","",,,,,2,2.00,1,2,1,"Robust physics (e.g., governing equations and laws) discovery is of great interest for many engineering fields and explainable machine learning. A critical challenge compared with general training is that the term and format of governing equations is not known as a prior. In addition, significant measurement noise and complex algorithm hyperparameter tuning usually reduces the robustness of existing methods. A robust data-driven method is proposed in this study for identifying the governing Partial Differential Equations (PDEs) of a given system from noisy data. The proposed method is based on the concept of Progressive Sparse Identification of PDEs (PSI-PDE or ψ-PDE). Special focus is on the handling of data with huge uncertainties (e.g., 50% noise level). Neural Network modeling and fast Fourier transform (FFT) are implemented to reduce the influence of noise in sparse regression. Following this, candidate terms from the prescribed library are progressively selected and added to the learned PDEs, which automatically promotes parsimony with respect to the number of terms in PDEs as well as their complexity. Next, the significance of each learned terms is further evaluated and the coefficients of PDE terms are optimized by minimizing the L2 residuals. Results of numerical case studies indicate that the governing PDEs of many canonical dynamical systems can be correctly identified using the proposed ψ-PDE method with highly noisy data. One great benifit of proposed algorithm is that it avoids complex algorithm modification and hyperparameter tuning in most existing methods. Limitations of the proposed method and major findings are presented.","",""
8,"Shahd Safarani, Arne Nix, K. Willeke, Santiago A. Cadena, K. Restivo, George H. Denfield, A. Tolias, Fabian H Sinz","Towards robust vision by multi-task learning on monkey visual cortex",2021,"","","","",117,"2022-07-13 10:07:35","","","","",,,,,8,8.00,1,8,1,"Deep neural networks set the state-of-the-art across many tasks in computer vision, but their generalization ability to simple image distortions is surprisingly fragile. In contrast, the mammalian visual system is robust to a wide range of perturbations. Recent work suggests that this generalization ability can be explained by useful inductive biases encoded in the representations of visual stimuli throughout the visual cortex. Here, we successfully leveraged these inductive biases with a multitask learning approach: we jointly trained a deep network to perform image classification and to predict neural activity in macaque primary visual cortex (V1) in response to the same natural stimuli. We measured the out-of-distribution generalization abilities of our resulting network by testing its robustness to common image distortions. We found that co-training on monkey V1 data indeed leads to increased robustness despite the absence of those distortions during training. Additionally, we showed that our network’s robustness is often very close to that of an Oracle network where parts of the architecture are directly trained on noisy images. Our results also demonstrated that the network’s representations become more brain-like as their robustness improves. Using a novel constrained reconstruction analysis, we investigated what makes our brain-regularized network more robust. We found that our monkey co-trained network is more sensitive to content than noise when compared to a Baseline network that we trained for image classification alone. Using DeepGaze-predicted saliency maps for ImageNet images, we found that the monkey co-trained network tends to be more sensitive to salient regions in a scene, reminiscent of existing theories on the role of V1 in the detection of object borders and bottom-up saliency. Overall, our work expands the promising research avenue of transferring inductive biases from biological to artificial neural networks on the representational level, and provides a novel analysis of the effects of our transfer.","",""
3,"Mauro Rodrigo Larrat Frota e Silva, Glaucio H. S. Carvalho, D. Monteiro, L. S. Machado","Distributed Target Location in Wireless Sensors Network: An Approach Using FPGA and Artificial Neural Network",2015,"","","","",118,"2022-07-13 10:07:35","","10.4236/WSN.2015.75005","","",,,,,3,0.43,1,4,7,"This paper analyzes the implementation of an algorithm into a FPGA embedded and distributed target location method using the Received Signal Strength Indicator (RSSI). The objective is to show a method in which an embedded feedforward Artificial Neural Network (ANN) can estimate target location in a distributed fashion against anchor failure. We discuss the lack of FPGA implementation of equivalent methods and the benefits of using a robust platform. We introduce the description of the implementation and we explain the operation of the proposed method, followed by the calculated errors due to inherent Elliott function approximation and the discretization of decimal values used as free parameters in ANN. Furthermore, we show some target location estimation points in function of different numbers of anchor failures. Our contribution is to show that an FPGA embedded ANN implementation, with a few layers, can rapidly estimate target location in a distributed fashion and in presence of failures of anchor nodes considering accuracy, precision and execution time.","",""
0,"Véronique M. Gomes, P. Melo-Pinto","Towards robust Machine Learning models for grape ripeness assessment",2021,"","","","",119,"2022-07-13 10:07:35","","10.1109/JCSSE53117.2021.9493822","","",,,,,0,0.00,0,2,1,"Artificial intelligence methods need to be more transparent for wider acceptance by the industry. In particular deep neural networks (DNN) are not explainable, due to the complex processes the input undergo. The present work addresses model explainability for wine grapes quality assessment through 1D-CNN, using regression activation maps (RAM) to show the contribution score of each wavelength for the prediction of sugar content. This way we identify the relevant regions related to this enological parameter. The results obtained indicate that the proposed approach can successfully highlight important spectral regions related to sugars absorption, improving the current state of the art, and opening way to dimensionality reduction methods and further model interpretation.","",""
0,"A. Agogino, Ritchie Lee, D. Giannakopoulou","Machine Learning Explainability and Transferability for Path Navigation",2020,"","","","",120,"2022-07-13 10:07:35","","10.2514/6.2021-1885","","",,,,,0,0.00,0,3,2,"Deep neural networks are powerful tools for machine perception. Unfortunately their decisions are difficult to explain due to the complexity and size of the networks. Previously we have alleviated this issue by using the representational portion of a deep neural network and combining it with a :-nearest neighbor (KNN) classifier. Through inspection of the decisions made by the KNN, we can directly see the training data responsible for the decisions, allowing us to determine the quality of the overall decision and the quality of the representational layer of the deep NN. While the technique worked well, it requires tens of thousands of latent vectors to be stored for classification. In addition, it lacks the ability to show how parts of an image influence the classification decision. Here we address these issues by 1) Using a radial basis function network (RBFN) in place of the KNN allowing far fewer images to be used in deployment and 2) Using an autoencoder network for explainability. In addition to these techniques, we examine the effects of transfer learning to determine that results are robust. All results are tested on a domain where an unmanned aerial vehicle (UAV) navigates a forest trail through a single camera.","",""
19,"Yangming Li, Shuai Li, B. Hannaford","A Novel Recurrent Neural Network for Improving Redundant Manipulator Motion Planning Completeness",2018,"","","","",121,"2022-07-13 10:07:35","","10.1109/ICRA.2018.8461204","","",,,,,19,4.75,6,3,4,"Recurrent Neural Networks (RNNs) demonstrated advantages on control precision, system robustness and computational efficiency, and have been widely applied to redundant manipulator control optimization. Existing RNN control schemes locally optimize trajectories and are efficient and reliable on obstacle avoidance. However, for motion planning, they suffer from local minimum and do not have planning completeness. This work explained the cause of the planning incompleteness and addressed the problem with a novel RNN control scheme. The paper presented the proposed method in detail and analyzed the global stability and the planning completeness in theory. The proposed method was compared with other three control schemes on the precision, the robustness and the planning completeness in software simulation and the results shows the proposed method has improved precision and robustness, and planning completeness.","",""
7,"Thorben Funke, Megha Khosla, Avishek Anand","Zorro: Valid, Sparse, and Stable Explanations in Graph Neural Networks",2021,"","","","",122,"2022-07-13 10:07:35","","","","",,,,,7,7.00,2,3,1,"With the ever-increasing popularity and applications of graph neural networks, several proposals have been made to explain and understand the decisions of a graph neural network. Explanations for graph neural networks differ in principle from other input settings. It is important to attribute the decision to input features and other related instances connected by the graph structure. We find that the previous explanation generation approaches that maximize the mutual information between the label distribution produced by the model and the explanation to be restrictive. Specifically, existing approaches do not enforce explanations to be valid, sparse, or robust to input perturbations. In this paper, we lay down some of the fundamental principles that an explanation method for graph neural networks should follow and introduce a metric RDT-Fidelity as a measure of the explanation’s effectiveness. We propose a novel approach Zorro based on the principles from rate-distortion theory that uses a simple combinatorial procedure to optimize for RDT-Fidelity. Extensive experiments on real and synthetic datasets reveal that Zorro produces sparser, stable, and more faithful explanations than existing graph neural network explanation approaches.","",""
80,"Q. Song, Qinqin Yu, Zhenjiang Zhao, Yurong Liu, F. Alsaadi","Boundedness and global robust stability analysis of delayed complex-valued neural networks with interval parameter uncertainties",2018,"","","","",123,"2022-07-13 10:07:35","","10.1016/j.neunet.2018.03.008","","",,,,,80,20.00,16,5,4,"","",""
5,"Kshitij Dwivedi, Radoslaw Martin Cichy, G. Roig","Unraveling Representations in Scene-selective Brain Regions Using Scene-Parsing Deep Neural Networks",2020,"","","","",124,"2022-07-13 10:07:35","","10.1162/jocn_a_01624","","",,,,,5,2.50,2,3,2,"Abstract Visual scene perception is mediated by a set of cortical regions that respond preferentially to images of scenes, including the occipital place area (OPA) and parahippocampal place area (PPA). However, the differential contribution of OPA and PPA to scene perception remains an open research question. In this study, we take a deep neural network (DNN)-based computational approach to investigate the differences in OPA and PPA function. In a first step, we search for a computational model that predicts fMRI responses to scenes in OPA and PPA well. We find that DNNs trained to predict scene components (e.g., wall, ceiling, floor) explain higher variance uniquely in OPA and PPA than a DNN trained to predict scene category (e.g., bathroom, kitchen, office). This result is robust across several DNN architectures. On this basis, we then determine whether particular scene components predicted by DNNs differentially account for unique variance in OPA and PPA. We find that variance in OPA responses uniquely explained by the navigation-related floor component is higher compared to the variance explained by the wall and ceiling components. In contrast, PPA responses are better explained by the combination of wall and floor, that is, scene components that together contain the structure and texture of the scene. This differential sensitivity to scene components suggests differential functions of OPA and PPA in scene processing. Moreover, our results further highlight the potential of the proposed computational approach as a general tool in the investigation of the neural basis of human scene perception.","",""
130,"David Sussillo, P. Nuyujukian, Joline M. Fan, J. Kao, S. Stavisky, S. Ryu, K. Shenoy","A recurrent neural network for closed-loop intracortical brain-machine interface decoders.",2012,"","","","",125,"2022-07-13 10:07:35","","10.1088/1741-2560/9/2/026027","","",,,,,130,13.00,19,7,10,"Recurrent neural networks (RNNs) are useful tools for learning nonlinear relationships in time series data with complex temporal dependences. In this paper, we explore the ability of a simplified type of RNN, one with limited modifications to the internal weights called an echostate network (ESN), to effectively and continuously decode monkey reaches during a standard center-out reach task using a cortical brain-machine interface (BMI) in a closed loop. We demonstrate that the RNN, an ESN implementation termed a FORCE decoder (from first order reduced and controlled error learning), learns the task quickly and significantly outperforms the current state-of-the-art method, the velocity Kalman filter (VKF), using the measure of target acquire time. We also demonstrate that the FORCE decoder generalizes to a more difficult task by successfully operating the BMI in a randomized point-to-point task. The FORCE decoder is also robust as measured by the success rate over extended sessions. Finally, we show that decoded cursor dynamics are more like naturalistic hand movements than those of the VKF. Taken together, these results suggest that RNNs in general, and the FORCE decoder in particular, are powerful tools for BMI decoder applications.","",""
35,"Ning Ma, José A. González, Guy J. Brown","Robust Binaural Localization of a Target Sound Source by Combining Spectral Source Models and Deep Neural Networks",2018,"","","","",126,"2022-07-13 10:07:35","","10.1109/TASLP.2018.2855960","","",,,,,35,8.75,12,3,4,"Despite there being a clear evidence for top–down (e.g., attentional) effects in biological spatial hearing, relatively few machine hearing systems exploit the top–down model-based knowledge in sound localization. This paper addresses this issue by proposing a novel framework for the binaural sound localization that combines the model-based information about the spectral characteristics of sound sources and deep neural networks (DNNs). A target source model and a background source model are first estimated during a training phase using spectral features extracted from sound signals in isolation. When the identity of the background source is not available, a universal background model can be used. During testing, the source models are used jointly to explain the mixed observations and improve the localization process by selectively weighting source azimuth posteriors output by a DNN-based localization system. To address the possible mismatch between the training and testing, a model adaptation process is further employed the on-the-fly during testing, which adapts the background model parameters directly from the noisy observations in an iterative manner. The proposed system, therefore, combines the model-based and data-driven information flow within a single computational framework. The evaluation task involved localization of a target speech source in the presence of an interfering source and room reverberation. Our experiments show that by exploiting the model-based information in this way, the sound localization performance can be improved substantially under various noisy and reverberant conditions.","",""
2,"Yingying Yan, Daguang Yang","A Stock Trend Forecast Algorithm Based on Deep Neural Networks",2021,"","","","",127,"2022-07-13 10:07:35","","10.1155/2021/7510641","","",,,,,2,2.00,1,2,1,"As a recognized complex dynamic system, the stock market has many influencing factors, such as nonstationarity, nonlinearity, high noise, and long memory. It is difficult to explain it simply through mathematical models. Therefore, the analysis and prediction of the stock market have been a very challenging job since long time. Therefore, this paper adopts an encoder-decoder model of attention mechanism, adding attention mechanism from two aspects of feature and time. Both encoder and decoder use LSTM neural network. This method solves two problems in time series prediction; the first problem is that multiple input features have different degrees of influence on the target sequence, the feature attention mechanism is used to deal with this problem, and the weights of different input features can be obtained. A more robust feature association relationship is obtained; the second problem is that the data before and after the sequence have a strong time correlation. The time attention mechanism is used to deal with this problem, and the weights at different time points can be obtained to obtain more robustness and good timing dependencies. The simulation and experimental results show that the introduction of the attention mechanism can obtain lower forecast errors, which proves the effectiveness of the model in dealing with stock forecasting problems.","",""
3,"Nurit Sternberg, R. Luria, G. Sheppes","For whom is social-network usage associated with anxiety? The moderating role of neural working-memory filtering of Facebook information",2018,"","","","",128,"2022-07-13 10:07:35","","10.3758/s13415-018-0627-z","","",,,,,3,0.75,1,3,4,"","",""
181,"Yuwei Cui, Chetan Surpur, Subutai Ahmad, J. Hawkins","Continuous Online Sequence Learning with an Unsupervised Neural Network Model",2015,"","","","",129,"2022-07-13 10:07:35","","10.1162/NECO_a_00893","","",,,,,181,25.86,45,4,7,"Abstract The ability to recognize and predict temporal sequences of sensory inputs is vital for survival in natural environments. Based on many known properties of cortical neurons, hierarchical temporal memory (HTM) sequence memory recently has been proposed as a theoretical framework for sequence learning in the cortex. In this letter, we analyze properties of HTM sequence memory and apply it to sequence learning and prediction problems with streaming data. We show the model is able to continuously learn a large number of variable order temporal sequences using an unsupervised Hebbian-like learning rule. The sparse temporal codes formed by the model can robustly handle branching temporal sequences by maintaining multiple predictions until there is sufficient disambiguating evidence. We compare the HTM sequence memory with other sequence learning algorithms, including statistical methods—autoregressive integrated moving average; feedforward neural networks—time delay neural network and online sequential extreme learning machine; and recurrent neural networks—long short-term memory and echo-state networks on sequence prediction problems with both artificial and real-world data. The HTM model achieves comparable accuracy to other state-of-the-art algorithms. The model also exhibits properties that are critical for sequence learning, including continuous online learning, the ability to handle multiple predictions and branching sequences with high-order statistics, robustness to sensor noise and fault tolerance, and good performance without task-specific hyperparameter tuning. Therefore, the HTM sequence memory not only advances our understanding of how the brain may solve the sequence learning problem but is also applicable to real-world sequence learning problems from continuous data streams.","",""
0,"Katsuhiro Honda, Satoshi Hyakutake, S. Ubukata, A. Notsu","A Hybrid Robust ANFIS Based on Noise Fuzzy Clustering",2021,"","","","",130,"2022-07-13 10:07:35","","10.1109/ICIEVicIVPR52578.2021.9564173","","",,,,,0,0.00,0,4,1,"Adaptive Network-based Fuzzy Inference System (ANFIS) is a promising model of explainable neural networks but rejection of illegal noise effects is an important issue in real application. In this paper, a novel approach for introducing noise clustering concepts into fuzzy $c$-means-based ANFIS is proposed for robust modeling. In the premise part, noise fuzzy clustering is performed in the input data space for estimating fuzzy membership functions removing noise inputs. Then, in the consequence part, rule-wise robust regression models are estimated by removing noise outputs. As a result, the proposed hybrid robust ANFIS model simultaneously considers two types of noise generation schemes of the input-level and the output-level. The characteristics of the proposed method are demonstrated through numerical experiments such that input-level noise are rejected by degrading premise fuzzy memberships of noise objects so that their ANFIS outputs have small absolute values while output-level noise observations are rejected through robust regression.","",""
23,"Yangming Li, Shuai Li, David E. Caballero, Muneaki Miyasaka, Andrew Lewis, B. Hannaford","Improving control precision and motion adaptiveness for surgical robot with recurrent neural network",2017,"","","","",131,"2022-07-13 10:07:35","","10.1109/IROS.2017.8206197","","",,,,,23,4.60,4,6,5,"Surgical robot research is driven by the desire of improving surgical outcomes. This paper proposed a Recurrent Neural Network based controller to address two problems: 1) improving control precision, 2) increasing adaptiveness for robot motion (explained in Section I). RNN was adopted in this work mainly because 1) the problem formulation naturally matches RNN structure, 2) RNN has advantages as an biologically inspired method. The proposed method was explained in detail and analysis shows that the proposed method is able to dynamically regulate outputs to increase the adaptiveness and the control precision. This paper uses Raven II surgical robot as an example to show the application of the proposed method, and the numeral simulation results from the proposed method and three other controllers show that the proposed method has improved precision, improved high robustness against noise and increased movement smoothness, and it keeps the manipulator links as far away as possible from physical boundaries, which potentially increases surgical safety and leads to improved surgical outcomes.","",""
0,"Marek Sarvaš","Interpretation of Deep Neural Networks in Speech Classification",2021,"","","","",132,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,1,1,"The growing problem of the popularity of using deep neural networks is their black box representation. The lack of transparency is raising questions about their reliability, credibility, or vulnerability to adversarial attacks. This caused rising demand for neural network explainability. The goal of this paper is to replicate existing experiments on a gender classification model and extend these experiments to analyze and uncover vulnerabilities of a network trained for gender classification on audio signal spectrograms. The easiest way to explain something is through visualization. For this, a layer-wise relevance propagation technique was chosen in this work because it produces easy-to-understand heatmaps of features relevant to a neural network. The heatmaps are produced by back-propagating relevances through a network from the output to the input layer. Two neural network models with AlexNet and ResNet architecture were used. Experiments with AlexNet model show that the network’s predictions are highly dependent on a small number of time-frequency (TF) bins. By augmenting the training data using obtained relevance maps, I managed to lower the dependency on these bins. As a result, the prediction accuracy, when these bins were not present, was increased by 15%. The proposed approach can potentially lead to increased robustness of models, preventing or reducing the impact of adversarial attacks. Interpretation of ResNet model showed dependencies on lower frequencies and time. Producing interpretable heatmaps of the ResNet model required the implementation of more robust LRP rules.","",""
0,"Guoxuan Xia, Sangwon Ha, Tiago Azevedo, Partha P. Maji","An Underexplored Dilemma between Confidence and Calibration in Quantized Neural Networks",2021,"","","","",133,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,4,1,"Modern convolutional neural networks (CNNs) are known to be overconﬁdent in terms of their calibration on unseen input data. That is to say, they are more conﬁdent than they are accurate. This is undesirable if the probabilities predicted are to be used for downstream decision making. When considering accuracy, CNNs are also surprisingly robust to compression techniques, such as quantization, which aim to reduce computational and memory costs. We show that this robustness can be partially explained by the calibration behavior of modern CNNs, and may be improved with overconﬁdence. This is due to an intuitive result: low conﬁdence predictions are more likely to change post-quantization, whilst being less accurate. High conﬁdence predictions will be more accurate, but more difﬁcult to change. Thus, a minimal drop in post-quantization accuracy is incurred. This presents a potential conﬂict in neural network design: worse calibration from overconﬁdence may lead to better robustness to quantization. We perform experiments applying post-training quantization to a variety of CNNs, on the CIFAR-100 and ImageNet datasets, and make our code publicly available. 1","",""
0,"Rémi Bernhard, Pierre-Alain Moëllic, J. Dutertre","Luring Transferable Adversarial Perturbations for Deep Neural Networks",2021,"","","","",134,"2022-07-13 10:07:35","","10.1109/IJCNN52387.2021.9534397","","",,,,,0,0.00,0,3,1,"The growing interest for adversarial examples, i.e. maliciously modified examples which fool a classifier, has resulted in many defenses intended to detect them, render them inoffensive or make the model more robust against them. In this paper, we pave the way towards a new approach to improve the robustness of a model against black-box transfer attacks. A removable additional neural network is included in the target model, and is designed to induce the luring effect, which tricks the adversary into choosing false directions to fool the target model. Training the additional model is achieved thanks to a loss function acting on the logits sequence order. Our deception-based method only needs to have access to the predictions of the target model and does not require a labeled data set. We explain the luring effect thanks to the notion of robust and non-robust useful features and perform experiments on MNIST, SVHN and CIFAR10 to characterize and evaluate this phenomenon. Additionally, we scale the luring effect to ImageNet, experiment practical use of it and discuss its complementarity with other defense schemes.","",""
2,"A. A. Abello, R. Hirata, Zhangyang Wang","Dissecting the High-Frequency Bias in Convolutional Neural Networks",2021,"","","","",135,"2022-07-13 10:07:35","","10.1109/CVPRW53098.2021.00096","","",,,,,2,2.00,1,3,1,"For convolutional neural networks (CNNs), a common hypothesis that explains both their generalization capability and their characteristic brittleness is that these models are implicitly regularized to rely on imperceptible high-frequency patterns, more than humans would do. This hypothesis has seen some empirical validation, but most works do not rigorously divide the image frequency spectrum. We present a model to divide the spectrum in disjointed discs based on the distribution of energy and apply simple feature importance procedures to test whether high-frequencies are more important than lower ones. We find evidence that mid or high-level frequencies are disproportionately important for CNNs. The evidence is robust across different datasets and networks. Moreover, we find the diverse effects of the network’s attributes, such as architecture and depth, on frequency bias and robustness in general. Code for reproducing our experiments is available at: https://github.com/Abello966/FrequencyBiasExperiments","",""
1,"S. Matveev, I. Oseledets, E. Ponomarev, A. Chertkov","Overview of Visualization Methods for Artificial Neural Networks",2021,"","","","",136,"2022-07-13 10:07:35","","10.1134/S0965542521050134","","",,,,,1,1.00,0,4,1,"","",""
11,"Xu Cheng, Shengyong Chen, Chen Diao, Liu Mengna, Guoyuan Li, Houxiang Zhang","Simplifying Neural Network Based Model for Ship Motion Prediction: A Comparative Study of Sensitivity Analysis",2017,"","","","",137,"2022-07-13 10:07:35","","10.1115/OMAE2017-61474","","",,,,,11,2.20,2,6,5,"This paper presents a comparative study of sensitivity analysis (SA) and simplification on artificial neural network (ANN) based model used for ship motion prediction. Considering traditional structural complexity of ANN usually results in slow convergence, SA, as an efficient tool for correlation analysis, can help to reconstruct the ANN model for ship motion prediction. An ANN-Garson method and an ANN-EFAST method are proposed, both of which utilize the ANN for modeling but select the input parameters in a local and a global fashion, respectively. Through the benchmark tests, ANN-EFAST exhibits superior performance in both linear and nonlinear systems. Further test on ANN-EFAST via a case study of ship heading prediction shows its cost-effective and timely in compacting the ANN based prediction model. INTRODUCTION With the development and prosperity of the world’s shipping industry, the maritime transportation has become more and more busy. In order to ensure the safety of navigation, great concern has been put toward the ship motion prediction. Furthermore, some special operations, such as submarine cable laying, marine survey, etc., need more accurate ship motion prediction and control precisely. Therefore, how to establish an efficient ship motion prediction model has great theoretical and practical value in the maritime applications. However, mathematical model based ship motion prediction is challenging due to the nonlinear and ∗Corresponding author, Email: guoyuan.li@ntnu.no. Xu Cheng and Guoyuan Li have equal contribution to this paper. time-varying dynamical model of ship, as well as complex dynamic nature of sea [1, 2]. Our partner in Norway therefore started to collect on-board ship sensor data long time ago and intended to create robust predictive models for ship maneuvering technologies. There would be a possibility to combine those ship sensor data with modeling methods to design and implement ship motion prediction model. To date, a variety of novel intelligent approximation-based techniques and algorithms like fuzzy logic, Kalman filtering, Bayesian network, regression analysis and ANN have been applied to create predictive models [3–6]. Those methods have their own pros and cons at specific aspects. For example, regression analysis is not suitable for complex, high dimensional and non-linear system; Fuzzy logic relies more on mathematical model; Kalman filtering works only for Gaussian noise process; The performance of Bayesian network in high dimensional data set is poor. None of them except ANN are suitable for modeling the ship motion, as situations in which lack precise mathematical model and only input-output sample data are available. Indeed, an ANN is a “black box” and has the ability to explicitly identify possible causal relationships from the inputoutput sample data. However, there is no standard to construct a compact ANN for prediction purposes. Input parameters and hidden units are the main factors to obtain an optimized model [7]. If there are too few inputs, the network cannot represent the input-output mapping of system with sufficient accuracy. If there are too many inputs, the network dimension will increase, which in turn aggravates computational complexity. Both cases will deteriorate the generalization capability of the network. Therefore, selection of input parameters is a key issue when applying ANN 1 Copyright c © 2017 by ASME to ship motion prediction. SA investigates how the variation in the output of a numerical model can be attributed to variations of its input factors, and it plays an important role in prediction model construction and simplification, and thus the generalization ability of prediction model. The main purpose of SA is to estimate the contribution of each model input, either main or interaction contribution, on the model output and to identify the main contributors to the output. SA has been widely used in areas such as engineering, economics, and sociology [8]. Taking advantages of SA’s characteristics, it is possible to use it to select the input parameters of an ANN based model used for ship motion prediction. The rest of the paper is organized as follows. The related work section is a brief recall of some of the existing methods in ANN and SA. In the next section, we describe the input selection procedure and the case ship, then the methods we used in this paper is introduced and the calculation of local sensitivity analysis (LSA) and global sensitivity analysis (GSA) are explained. After that, the proposed algorithm is tested using two analytical models and a case study of SA on heading of ship motion prediction model is described in detail. The results are shown and the calculated first order sensitivity index are compared with analytical results. A comparison of the performance of the LSA and GSA is also presented in this section. Finally conclusions are given. RELATED WORK Artificial Neural Network Inspired by biological neural network, ANN could build up the mathematical relationship between the input parameters and the output parameters, with the advantage that it can be modeled without prior knowledge. An ANN facilitates the ability to learn complex nonlinear relationships between input and output parameters. Thanks to the powerful potential (massive parallelism, generalization capacity and fault-tolerance), ANN has been widely used in fields like pattern recognition, reliability analysis, classification, ship motion control and prediction. The basic architecture of ANN consists of single input, hidden and output layer, with each layer containing one or more neurons, in addition to bias neurons connected to the hidden and output layers. The back-propagation (BP) algorithm is the most widely used learning algorithm for ANN, which is a self-adapted learning procedure that minimizes the error between the desired and the predicted outputs. The learning process consists of two parts: feed-forward and backward pass. The output of ANN is calculated in the process of feed-forward pass, with the output error propagated backward to adjust the weights and bias of the ANN. The number of hidden layer nodes and the maximum iteration number should be carefully chosen to overcome the over-fitting and under-fitting problems. Over-fitting means that a trained ANN has weak capability of generalization. An over-fitted ANN usually has a good prediction capability over train samples, but has a bad prediction capability over test samples. Under-fitting means that a trained ANN is too simple to be capable of representing the relationship between input parameters and output targets. An under-fitted ANN usually has bad prediction capabilities over both training and testing samples. Sensitivity Analysis SA could be implemented in either local or global manner. The LSA explore the response of the model output to a small change of the parameter from its nominal value. Garson algorithm is one of the popular LSA algorithms [9]. This method has shown to be computational efficient and conceptually simple when quantifying the relative importance of input parameters. It has been used in some ship motion prediction applications, such as the work in [5, 6, 10]. Local sensitivity index is calculated at the nominal point or a fixed point, which is not representative for all inputs in the whole parameter space. In addition, the LSA do not explore the interactions between input parameters. In contrast, a GSA estimates the effect of input parameters across the whole input parameter space. GSA is generally divided into four categories: Traditional methods, Analysis of Variance methods (ANOVA) methods, Derivative-Based Methods and Surrogate-Based Methods. ANOVA methods are also called variance-based methods, which makes ANOVA decomposition of model response variances into the contributions from individual parameters and their interactions. Cukier, et al. presented Fourier Amplitude Sensitivity Test (FAST) [11]. Later, Salteli et al. introduces a global, quantitative, model independent SA method for calculating both main effect and total effect indices based on the FAST — extended FAST (EFAST) [12]. EFAST is model independent, which can be used in ANN based prediction. Currently, most of the study only focuses on studying either LSA or GSA in ANN based ship prediction model. There is not a systematic comparison between them. In this study, efforts are made to combine the ANN with the Garson algorithm and the EFAST algorithm respectively, aiming to find out which one is preferable for nonlinear ship motion prediction. SIMPLIFICATION OF ANN MODEL VIA SENSITIVITY ANALYSIS System Structure This paper aims to construct a compact ANN model for ship motion prediction using the SA approach. The main idea is to use the SA method to evaluate the importance of each input and select the inputs according to their importance. The input selection procedure consists of four components: data cleaning, surrogate model, SA and result visualization. Data cleaning is to minimize the affection of noisy, redundant information of sensor data on further analysis and modeling. In general, it is difficult to estimate the contribution of each input parameter and the interaction 2 Copyright c © 2017 by ASME","",""
1,"Refik Soyak, Ebru Navruz, Eda Ozgu Ersoy, G. Cruz, C. Prieto, A. King, D. Unay, I. Oksuz","Channel Attention Networks for Robust MR Fingerprint Matching",2020,"","","","",138,"2022-07-13 10:07:35","","10.1109/TBME.2021.3116877","","",,,,,1,0.50,0,8,2,"Objective: Magnetic Resonance Fingerprinting (MRF) enables simultaneous mapping of multiple tissue parameters such as T1 and T2 relaxation times. The working principle of MRF relies on varying acquisition parameters pseudo-randomly, so that each tissue generates its unique signal evolution during scanning. Even though MRF provides faster scanning, it has disadvantages such as erroneous and slow generation of the corresponding parametric maps, which needs to be improved. Moreover, there is a need for explainable architectures for understanding the guiding signals to generate accurate parametric maps. Methods: In this paper, we addressed both of these shortcomings by proposing a novel neural network architecture (CONV-ICA) consisting of a channel-wise attention module and a fully convolutional network. Another contribution of this study is a new channel selection method: attention-based channel selection. Furthermore, the effect of patch size and temporal frames of MRF signal on channel reduction are analyzed by employing a channel-wise attention. Results: The proposed approach, evaluated over 3 simulated MRF signals, reduces error in the reconstruction of tissue parameters by 8.88% for T1 and 75.44% for T2 with respect to state-of-the-art methods. Conclusion: It is demonstrated that channel attention mechanism helps to focus on informative channels and fully convolutional network extracts spatial information achieve the best reconstruction performance. Significance: As a consequence of improvement in fast and accurate manner, presented work can contribute to make MRF appropriate for clinical use.","",""
4,"S. Yu, Yulei Niu, Shuohang Wang, Jing Jiang, Qianru Sun","Counterfactual Variable Control for Robust and Interpretable Question Answering",2020,"","","","",139,"2022-07-13 10:07:35","","","","",,,,,4,2.00,1,5,2,"Deep neural network based question answering (QA) models are neither robust nor explainable in many cases. For example, a multiple-choice QA model, tested without any input of question, is surprisingly ""capable"" to predict the most of correct options. In this paper, we inspect such spurious ""capability"" of QA models using causal inference. We find the crux is the shortcut correlation, e.g., unrobust word alignment between passage and options learned by the models. We propose a novel approach called Counterfactual Variable Control (CVC) that explicitly mitigates any shortcut correlation and preserves the comprehensive reasoning for robust QA. Specifically, we leverage multi-branch architecture that allows us to disentangle robust and shortcut correlations in the training process of QA. We then conduct two novel CVC inference methods (on trained models) to capture the effect of comprehensive reasoning as the final prediction. For evaluation, we conduct extensive experiments using two BERT backbones on both multi-choice and span-extraction QA benchmarks. The results show that our CVC achieves high robustness against a variety of adversarial attacks in QA while maintaining good interpretation ability.","",""
6,"Kei Nakagawa, Masaya Abe, Junpei Komiyama","RIC-NN: A Robust Transferable Deep Learning Framework for Cross-sectional Investment Strategy",2019,"","","","",140,"2022-07-13 10:07:35","","10.1109/DSAA49011.2020.00051","","",,,,,6,2.00,2,3,3,"Stock return predictability is an important research theme as it reflects our economic and social organization, and significant efforts are made to explain the dynamism therein. Statistics of strong explanative power, called ""factor"", have been proposed to summarize the essence of predictive stock returns. The challenge here is to make a multi-factor investment strategy that is consistent over a reasonably long period based on supervised machine learning. Although machine learning methods are increasingly popular in stock return prediction, an inference of the stock return is highly elusive, and naive use of complex machine learning methods easily overfits the current data and results in poor performance on future data. We propose a principled stock return prediction framework that we call Ranked Information Coefficient Neural Network (RIC-NN) that alleviates the overfitting. RIC-NN addresses the difficulty that arises in nonconvex machine learning: Namely, initialization and the stopping of the training model and the transfer among several different tasks (markets). RIC-NN is a deep learning approach and includes the following three novel ideas: (1) nonlinear multi-factor approach, (2) stopping criteria with ranked information coefficient (rank IC), and (3) deep transfer learning among multiple regions. Experimental comparison with the stocks in the Morgan Stanley Capital International indices shows that RIC-NN outperforms not only off-the-shelf machine learning methods but also the average return of major equity investment funds in the last fourteen years.","",""
0,"Mehdi Nourelahi, Lars Kotthoff, Peijie Chen, Anh M Nguyen","How explainable are adversarially-robust CNNs?",2022,"","","","",141,"2022-07-13 10:07:35","","10.48550/arXiv.2205.13042","","",,,,,0,0.00,0,4,1,"Three important criteria of existing convolutional neural networks (CNNs) are (1) test-set accuracy; (2) out-of-distribution accuracy; and (3) explainability. While these criteria have been studied independently, their relationship is unknown. For example, do CNNs that have a stronger out-of-distribution performance have also stronger explainability? Furthermore, most prior feature-importance studies only evaluate methods on 2-3 common vanilla ImageNet-trained CNNs, leaving it unknown how these methods generalize to CNNs of other architectures and training algorithms. Here, we perform the ﬁrst, large-scale evaluation of the relations of the three criteria using 9 feature-importance methods and 12 ImageNet-trained CNNs that are of 3 training algorithms and 5 CNN architectures. We ﬁnd several important insights and recommendations for ML practitioners. First, adversarially robust CNNs have a higher explainability score on gradient-based attribution methods (but not CAM-based or perturbation-based methods). Second, AdvProp models, despite being highly accurate more than both vanilla and robust models alone, are not superior in explainability. Third, among 9 feature attribution methods tested, GradCAM and RISE are consistently the best methods. Fourth, Insertion and Deletion are biased towards vanilla and robust models respectively, due to their strong correlation with the conﬁdence score distributions of a CNN. Fifth, we did not ﬁnd a single CNN to be the best in all three criteria, which interestingly suggests that CNNs are harder to interpret as they become more accurate.","",""
0,"Alexandru-Răzvan Florea, M. Roman","Artificial neural networks applied for predicting and explaining the education level of Twitter users",2021,"","","","",142,"2022-07-13 10:07:35","","10.1007/s13278-021-00832-1","","",,,,,0,0.00,0,2,1,"","",""
8,"Seyed Iman Mirzadeh, Arslan Chaudhry, Huiyi Hu, Razvan Pascanu, Dilan Gorur, Mehrdad Farajtabar","Wide Neural Networks Forget Less Catastrophically",2021,"","","","",143,"2022-07-13 10:07:35","","","","",,,,,8,8.00,1,6,1,"A growing body of research in continual learning is devoted to overcoming the “Catastrophic Forgetting” of neural networks by designing new algorithms that are more robust to the distribution shifts. While the recent progress in continual learning literature is encouraging, our understanding of what properties of neural networks contribute to catastrophic forgetting is still limited. To address this, instead of focusing on continual learning algorithms, in this work, we focus on the model itself and study the impact of “width” of the neural network architecture on catastrophic forgetting, and show that width has a surprisingly significant effect on forgetting. To explain this effect, we study the learning dynamics of the network from various perspectives such as gradient norm and sparsity, orthogonalization, and lazy training regime. We provide potential explanations that are consistent with the empirical results across different architectures and continual learning benchmarks.","",""
19,"B. Pandey, Tarun Jain, V. Kothari, Tarush Grover, Tata Consultancy, Services Limited","Evolutionary Modular Neural Network Approach for Breast Cancer Diagnosis",2012,"","","","",144,"2022-07-13 10:07:35","","","","",,,,,19,1.90,3,6,10,"Knowledge Discovery paradigms especially Soft Computing techniques like Artificial Neural Networks have been at the fore front of research aimed at solving the problem areas involved in many diverse fields of application. Automated diagnosis of deadly diseases is one of such fields that have seen much effort from researchers in the last few years. One area where this effort has been most felt is the diagnosis of breast cancer in women. However, development of a computationally efficient, detection-wise effective and robust framework for the diagnosis of breast cancer has still not materialized. The major problem here is the presence of a number of decision variables involved that makes this problem of diagnosis much more complex and intricate. This makes it difficult to be tackled by traditional computing paradigms efficiently. In this paper, we explain how the paradigms of modularity and optimization using evolutionary technique could be used to solve the aforesaid problem with significant success. Here, to take benefit of modularity, we make of use modular neural network instead of the traditional monolithic neural network for the recognition of input vectors implying breast cancer. Also, to make the architecture more optimal, we make use of genetic algorithms to achieve optimal connections (weights) among the neurons in each of the individual experts of the modular neural network. Experimental results show that the proposed approach has been significantly successful in dealing with aforesaid problem of breast cancer diagnosis with a training accuracy of 95.97% and testing accuracy of 96.5%. That is well above what shown by traditional approaches as described later on.","",""
18,"Ruoxia Li, Jinde Cao","Finite-Time and Fixed-Time Stabilization Control of Delayed Memristive Neural Networks: Robust Analysis Technique",2018,"","","","",145,"2022-07-13 10:07:35","","10.1007/s11063-017-9689-0","","",,,,,18,4.50,9,2,4,"","",""
10,"Zhao Ren, Qiuqiang Kong, Jing Han, Mark D. Plumbley, Björn Schuller","CAA-Net: Conditional Atrous CNNs With Attention for Explainable Device-Robust Acoustic Scene Classification",2020,"","","","",146,"2022-07-13 10:07:35","","10.1109/TMM.2020.3037534","","",,,,,10,5.00,2,5,2,"Acoustic Scene Classification (ASC) aims to classify the environment in which the audio signals are recorded. Recently, Convolutional Neural Networks (CNNs) have been successfully applied to ASC. However, the data distributions of the audio signals recorded with multiple devices are different. There has been little research on the training of robust neural networks on acoustic scene datasets recorded with multiple devices, and on explaining the operation of the internal layers of the neural networks. In this article, we focus on training and explaining device-robust CNNs on multi-device acoustic scene data. We propose conditional atrous CNNs with attention for multi-device ASC. Our proposed system contains an ASC branch and a device classification branch, both modelled by CNNs. We visualise and analyse the intermediate layers of the atrous CNNs. A time-frequency attention mechanism is employed to analyse the contribution of each time-frequency bin of the feature maps in the CNNs. On the Detection and Classification of Acoustic Scenes and Events (DCASE) 2018 ASC dataset, recorded with three devices, our proposed model performs significantly better than CNNs trained on single-device data.","",""
45,"A. Rădulescu","Neural Network Spectral Robustness under Perturbations of the Underlying Graph",2016,"","","","",147,"2022-07-13 10:07:35","","10.1162/NECO_a_00798","","",,,,,45,7.50,45,1,6,"Recent studies have been using graph-theoretical approaches to model complex networks (such as social, infrastructural, or biological networks) and how their hardwired circuitry relates to their dynamic evolution in time. Understanding how configuration reflects on the coupled behavior in a system of dynamic nodes can be of great importance, for example, in the context of how the brain connectome is affecting brain function. However, the effect of connectivity patterns on network dynamics is far from being fully understood. We study the connections between edge configuration and dynamics in a simple oriented network composed of two interconnected cliques (representative of brain feedback regulatory circuitry). In this article our main goal is to study the spectra of the graph adjacency and Laplacian matrices, with a focus on three aspects in particular: (1) the sensitivity and robustness of the spectrum in response to varying the intra- and intermodular edge density, (2) the effects on the spectrum of perturbing the edge configuration while keeping the densities fixed, and (3) the effects of increasing the network size. We study some tractable aspects analytically, then simulate more general results numerically, thus aiming to motivate and explain our further work on the effect of these patterns on the network temporal dynamics and phase transitions. We discuss the implications of such results to modeling brain connectomics. We suggest potential applications to understanding synaptic restructuring in learning networks and the effects of network configuration on function of regulatory neural circuits.","",""
19,"M. Azad","Predicting mobile banking adoption in Bangladesh: a neural network approach",2016,"","","","",148,"2022-07-13 10:07:35","","10.1080/19186444.2016.1233726","","",,,,,19,3.17,19,1,6,"Abstract Rapid development in technology amplifies the need of examining technology adoption. Financial sectors, nowadays, are providing a long list of both financial and nonfinancial services to attract their potential customers using mobile banking (m-banking). Thus, m-banking is becoming a part of modern life style. This paper critically predicts the key factors of m-banking adoption in Bangladesh from the user perspective. A three layer neural network is used with 10-fold cross validation as a prediction model. For robustness, factor analysis is run using principal component analysis and verimax rotation technique. After pilot study, a structured questionnaire was used and a total of 314 respondents successfully returned their filled survey questionnaire. The results revealed that Perceived Ease of Use is the most influencing factor. One significant finding is that gender has no significance on m-banking adoption in Bangladesh explaining both men and women are flexible in technology adoption. Policy makers can find significant results in this paper for implementing future service design. Limitations and future research scope are also discussed.","",""
5,"Matthew Holden, M. Pereyra, K. Zygalakis","Bayesian Imaging With Data-Driven Priors Encoded by Neural Networks: Theory, Methods, and Algorithms",2021,"","","","",149,"2022-07-13 10:07:35","","10.1137/21m1406313","","",,,,,5,5.00,2,3,1,"This paper proposes a new methodology for performing Bayesian inference in imaging inverse problems where the prior knowledge is available in the form of training data. Following the manifold hypothesis and adopting a generative modelling approach, we construct a data-driven prior that is supported on a sub-manifold of the ambient space, which we can learn from the training data by using a variational autoencoder or a generative adversarial network. We establish the existence and well-posedness of the associated posterior distribution and posterior moments under easily verifiable conditions, providing a rigorous underpinning for Bayesian estimators and uncertainty quantification analyses. Bayesian computation is performed by using a parallel tempered version of the preconditioned Crank-Nicolson algorithm on the manifold, which is shown to be ergodic and robust to the non-convex nature of these data-driven models. In addition to point estimators and uncertainty quantification analyses, we derive a model misspecification test to automatically detect situations where the data-driven prior is unreliable, and explain how to identify the dimension of the latent space directly from the training data. The proposed approach is illustrated with a range of experiments with the MNIST dataset, where it outperforms alternative image reconstruction approaches from the state of the art. A model accuracy analysis suggests that the Bayesian probabilities reported by the data-driven models are also remarkably accurate under a frequentist definition of probability.","",""
2,"Vedant Nanda, Till Speicher, John P. Dickerson, K. Gummadi, M. B. Zafar","Unifying Model Explainability and Robustness via Machine-Checkable Concepts",2020,"","","","",150,"2022-07-13 10:07:35","","","","",,,,,2,1.00,0,5,2,"As deep neural networks (DNNs) get adopted in an ever-increasing number of applications, explainability has emerged as a crucial desideratum for these models. In many real-world tasks, one of the principal reasons for requiring explainability is to in turn assess prediction robustness, where predictions (i.e., class labels) that do not conform to their respective explanations (e.g., presence or absence of a concept in the input) are deemed to be unreliable. However, most, if not all, prior methods for checking explanation-conformity (e.g., LIME, TCAV, saliency maps) require significant manual intervention, which hinders their large-scale deployability. In this paper, we propose a robustness-assessment framework, at the core of which is the idea of using machine-checkable concepts. Our framework defines a large number of concepts that the DNN explanations could be based on and performs the explanation-conformity check at test time to assess prediction robustness. Both steps are executed in an automated manner without requiring any human intervention and are easily scaled to datasets with a very large number of classes. Experiments on real-world datasets and human surveys show that our framework is able to enhance prediction robustness significantly: the predictions marked to be robust by our framework have significantly higher accuracy and are more robust to adversarial perturbations.","",""
0,"Mark H. Meng, Guangdong Bai, S. Teo, Zhe Hou, Yan Xiao, Yun Lin, Jin Song Dong","Adversarial Robustness of Deep Neural Networks: A Survey from a Formal Verification Perspective",2022,"","","","",151,"2022-07-13 10:07:35","","10.1109/TDSC.2022.3179131","","",,,,,0,0.00,0,7,1,"—Neural networks have been widely applied in security applications such as spam and phishing detection, intrusion prevention, and malware detection. This black-box method, however, often has uncertainty and poor explainability in applications. Furthermore, neural networks themselves are often vulnerable to adversarial attacks. For those reasons, there is a high demand for trustworthy and rigorous methods to verify the robustness of neural network models. Adversarial robustness, which concerns the reliability of a neural network when dealing with maliciously manipulated inputs, is one of the hottest topics in security and machine learning. In this work, we survey existing literature in adversarial robustness veriﬁcation for neural networks and collect 39 diversiﬁed research works across machine learning, security, and software engineering domains. We systematically analyze their approaches, including how robustness is formulated, what veriﬁcation techniques are used, and the strengths and limitations of each technique. We provide a taxonomy from a formal veriﬁcation perspective for a comprehensive understanding of this topic. We classify the existing techniques based on property speciﬁcation, problem reduction, and reasoning strategies. We also demonstrate representative techniques that have been applied in existing studies with a sample model. Finally, we discuss open questions for future research.","",""
0,"A. Nande, V. Dubinkina, Riccardo Ravasio, Grace H. Zhang, Gordon J. Berman","Bottlenecks, Modularity, and the Neural Control of Behavior",2022,"","","","",152,"2022-07-13 10:07:35","","10.3389/fnbeh.2022.835753","","",,,,,0,0.00,0,5,1,"In almost all animals, the transfer of information from the brain to the motor circuitry is facilitated by a relatively small number of neurons, leading to a constraint on the amount of information that can be transmitted. Our knowledge of how animals encode information through this pathway, and the consequences of this encoding, however, is limited. In this study, we use a simple feed-forward neural network to investigate the consequences of having such a bottleneck and identify aspects of the network architecture that enable robust information transfer. We are able to explain some recently observed properties of descending neurons—that they exhibit a modular pattern of connectivity and that their excitation leads to consistent alterations in behavior that are often dependent upon the desired behavioral state of the animal. Our model predicts that in the presence of an information bottleneck, such a modular structure is needed to increase the efficiency of the network and to make it more robust to perturbations. However, it does so at the cost of an increase in state-dependent effects. Despite its simplicity, our model is able to provide intuition for the trade-offs faced by the nervous system in the presence of an information processing constraint and makes predictions for future experiments.","",""
4,"M. O'Brien, W. Goble, G. Hager, J. Bukowski","Dependable Neural Networks for Safety Critical Tasks",2019,"","","","",153,"2022-07-13 10:07:35","","10.1007/978-3-030-62144-5_10","","",,,,,4,1.33,1,4,3,"","",""
0,"Vedant Nanda, Junaid Ali, K. Gummadi","Unifying model explainability and robustness via reasoning labels",2019,"","","","",154,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,3,3,"Explainability in deep learning has emerged as an important topic in recent years, with several works exploring various notions and mechanisms of explainability for deep neural networks (DNNs). In this paper, we draw upon the insight that in many situations model explainability is a means to assess another related yet distinct criterion model robustness. In order to render the link between explainability and robustness more explicit, we propose to use human-understandable reasoning labels during the training process of DNNs. The reasoning labels are jointly learned with the traditional classification labels. This joint training enables the model to predict a set of reasoning labels with every predicted class label. Then, we tie model explainability and robustness by introducing a notion of prediction consistency, whereby the model predictions are accepted—or considered robust—only when the predicted class and the predicted reasoning labels follow a certain pre-specified mapping. We show that by adopting such a framework, one can improve the classification accuracy of the state-of-the-art models (on consistent samples). We further show that using this notion of consistency makes the model more robust to adversarial perturbations.","",""
241,"Decai Li, Min Han, Jun Wang","Chaotic Time Series Prediction Based on a Novel Robust Echo State Network",2012,"","","","",155,"2022-07-13 10:07:35","","10.1109/TNNLS.2012.2188414","","",,,,,241,24.10,80,3,10,"In this paper, a robust recurrent neural network is presented in a Bayesian framework based on echo state mechanisms. Since the new model is capable of handling outliers in the training data set, it is termed as a robust echo state network (RESN). The RESN inherits the basic idea of ESN learning in a Bayesian framework, but replaces the commonly used Gaussian distribution with a Laplace one, which is more robust to outliers, as the likelihood function of the model output. Moreover, the training of the RESN is facilitated by employing a bound optimization algorithm, based on which, a proper surrogate function is derived and the Laplace likelihood function is approximated by a Gaussian one, while remaining robust to outliers. It leads to an efficient method for estimating model parameters, which can be solved by using a Bayesian evidence procedure in a fully autonomous way. Experimental results show that the proposed method is robust in the presence of outliers and is superior to existing methods.","",""
35,"Simran Kaur, Jeremy M. Cohen, Zachary Chase Lipton","Are Perceptually-Aligned Gradients a General Property of Robust Classifiers?",2019,"","","","",156,"2022-07-13 10:07:35","","","","",,,,,35,11.67,12,3,3,"For a standard convolutional neural network, optimizing over the input pixels to maximize the score of some target class will generally produce a grainy-looking version of the original image. However, Santurkar et al. (2019) demonstrated that for adversarially-trained neural networks, this optimization produces images that uncannily resemble the target class. In this paper, we show that these ""perceptually-aligned gradients"" also occur under randomized smoothing, an alternative means of constructing adversarially-robust classifiers. Our finding supports the hypothesis that perceptually-aligned gradients may be a general property of robust classifiers. We hope that our results will inspire research aimed at explaining this link between perceptually-aligned gradients and adversarial robustness.","",""
38,"T. Guo, Lianping Wu, Cunjun Wang, Zili Xu","Damage detection in a novel deep-learning framework: a robust method for feature extraction",2020,"","","","",157,"2022-07-13 10:07:35","","10.1177/1475921719846051","","",,,,,38,19.00,10,4,2,"Extracting damage features precisely while overcoming the adverse interferences of measurement noise and incomplete data is a problem demanding prompt solution in structural health monitoring (SHM). In this article, we present a deep-learning-based method that can extract the damage features from mode shapes without utilizing any hand-engineered feature or prior knowledge. To meet various requirements of the damage scenarios, we use convolutional neural network (CNN) algorithm and design a new network architecture: a multi-scale module, which helps in extracting features at various scales that can reduce the interference of contaminated data; stacked residual learning modules, which help in accelerating the network convergence; and a global average pooling layer, which helps in reducing the consumption of computing resources and obtaining a regression performance. An extensive evaluation of the proposed method is conducted by using datasets based on numerical simulations, along with two datasets based on laboratory measurements. The transferring parameter methodology is introduced to reduce retraining requirement without any decreases in precision. Furthermore, we plot the feature vectors of each layer to discuss the damage features learned at these layers and additionally provide the basis for explaining the working principle of the neural network. The results show that our proposed method has accuracy improvements of at least 10% over other network architectures.","",""
55,"Sayak Paul, Pin-Yu Chen","Vision Transformers are Robust Learners",2021,"","","","",158,"2022-07-13 10:07:35","","10.1609/aaai.v36i2.20103","","",,,,,55,55.00,28,2,1,"Transformers, composed of multiple self-attention layers, hold strong promises toward a generic learning primitive applicable to different data modalities, including the recent breakthroughs in computer vision achieving state-of-the-art (SOTA) standard accuracy. What remains largely unexplored is their robustness evaluation and attribution. In this work, we study the robustness of the Vision Transformer (ViT) (Dosovitskiy et al. 2021) against common corruptions and perturbations, distribution shifts, and natural adversarial examples. We use six different diverse ImageNet datasets concerning robust classification to conduct a comprehensive performance comparison of ViT(Dosovitskiy et al. 2021) models and SOTA convolutional neural networks (CNNs), Big-Transfer (Kolesnikov et al. 2020). Through a series of six systematically designed experiments, we then present analyses that provide both quantitative andqualitative indications to explain why ViTs are indeed more robust learners. For example, with fewer parameters and similar dataset and pre-training combinations, ViT gives a top-1accuracy of 28.10% on ImageNet-A which is 4.3x higher than a comparable variant of BiT. Our analyses on image masking, Fourier spectrum sensitivity, and spread on discrete cosine energy spectrum reveal intriguing properties of ViT attributing to improved robustness. Code for reproducing our experiments is available at https://git.io/J3VO0.","",""
4,"M. Hamdi, C. Aloui, S. Nanda","Comparing Functional Link Artificial Neural Network And Multilayer Feedforward Neural Network Model To Forecast Crude Oil Prices",2016,"","","","",159,"2022-07-13 10:07:35","","","","",,,,,4,0.67,1,3,6,"In this paper a trigonometric functional link artificial neural network (FLANN) model using backpropagation rule is applied to predict the next day's spot price of US crude oil. The daily observations of these variables: US dollar index, S&P 500 stock price index, gold spot price, heating oil spot price and US crude oil spot price are employed as inputs of the proposed model. By comparing with multilayer backpropagation feedforward neural network (FNN), more accurate predictions were shown by applying the FLANN model. In fact, several performance criteria are used to assess the forecasting power of the proposed model such as the Root Mean Squared Error (RMSE), the Mean Absolute Error (MAE) and the hit rate. For checking the forecasting robustness of the proposed model, in addition to the other input variables, the US crude oil and biofuels production are also used to predict the next month's spot price of crude oil. Comparatively, similar conclusion was deduced and the FLANN model performs better than the standard FNN. These findings can be explained by the simplicity of FLANN structure since it consists of a single layer with only one neuron at the output thus a lower computational load on the network.","",""
18,"Francesco Donnarumma, R. Prevete, F. Chersi, G. Pezzulo","A Programmer-Interpreter Neural Network Architecture for Prefrontal Cognitive Control",2015,"","","","",160,"2022-07-13 10:07:35","","10.1142/S0129065715500173","","",,,,,18,2.57,5,4,7,"There is wide consensus that the prefrontal cortex (PFC) is able to exert cognitive control on behavior by biasing processing toward task-relevant information and by modulating response selection. This idea is typically framed in terms of top-down influences within a cortical control hierarchy, where prefrontal-basal ganglia loops gate multiple input-output channels, which in turn can activate or sequence motor primitives expressed in (pre-)motor cortices. Here we advance a new hypothesis, based on the notion of programmability and an interpreter-programmer computational scheme, on how the PFC can flexibly bias the selection of sensorimotor patterns depending on internal goal and task contexts. In this approach, multiple elementary behaviors representing motor primitives are expressed by a single multi-purpose neural network, which is seen as a reusable area of ""recycled"" neurons (interpreter). The PFC thus acts as a ""programmer"" that, without modifying the network connectivity, feeds the interpreter networks with specific input parameters encoding the programs (corresponding to network structures) to be interpreted by the (pre-)motor areas. Our architecture is validated in a standard test for executive function: the 1-2-AX task. Our results show that this computational framework provides a robust, scalable and flexible scheme that can be iterated at different hierarchical layers, supporting the realization of multiple goals. We discuss the plausibility of the ""programmer-interpreter"" scheme to explain the functioning of prefrontal-(pre)motor cortical hierarchies.","",""
1,"Kshitij Dwivedi, Radoslaw Martin Cichy, G. Roig","Unravelling Representations in Scene-selective Brain Regions Using Scene Parsing Deep Neural Networks",2020,"","","","",161,"2022-07-13 10:07:35","","10.1101/2020.03.10.985309","","",,,,,1,0.50,0,3,2,"Visual scene perception is mediated by a set of cortical regions that respond preferentially to images of scenes, including the occipital place area (OPA) and parahippocampal place area (PPA). However, the differential contribution of OPA and PPA to scene perception remains an open research question. In this study, we take a deep neural network (DNN)-based computational approach to investigate the differences in OPA and PPA function. In a first step we search for a computational model that predicts fMRI responses to scenes in OPA and PPA well. We find that DNNs trained to predict scene components (e.g., wall, ceiling, floor) explain higher variance uniquely in OPA and PPA than a DNN trained to predict scene category (e.g., bathroom, kitchen, office). This result is robust across several DNN architectures. On this basis, we then determine whether particular scene components predicted by DNNs differentially account for unique variance in OPA and PPA. We find that variance in OPA responses uniquely explained by the navigation-related floor component is higher compared to the variance explained by the wall and ceiling components. In contrast, PPA responses are better explained by the combination of wall and floor, that is scene components that together contain the structure and texture of the scene. This differential sensitivity to scene components suggests differential functions of OPA and PPA in scene processing. Moreover, our results further highlight the potential of the proposed computational approach as a general tool in the investigation of the neural basis of human scene perception.","",""
1,"Zhen Gao, Xiaohui Wei, Han Zhang, Wenshuo Li, Guangjun Ge, Yu Wang, P. Reviriego","Reliability Evaluation of Pruned Neural Networks against Errors on Parameters",2020,"","","","",162,"2022-07-13 10:07:35","","10.1109/DFT50435.2020.9250812","","",,,,,1,0.50,0,7,2,"Convolutional Neural Networks (CNNs) are widely used in image classification tasks. To fit the application of CNNs on resource-limited embedded systems, pruning is a popular technique to reduce the complexity of the network. In this paper, the robustness of the pruned network against errors on the network parameters is examined with VGG16 as a case study. The effects of errors on the weights, bias, and batch normalization (BN) parameters are evaluated for the network with different pruning rates based on error injection experiments. The results show that in general networks with more weights pruned are more robust for a given error rate. The effect of multiple errors on bias or BN parameters is almost the same for the networks with different pruning rates that are lower than 90%. Further experiments are performed to explain the bimodal phenomenon of the network performance with errors on the parameters, to find that only errors on 6% of the parameter bits will cause large degradation of the neural network performance.","",""
0,"Rub'en Ballester, Xavier Arnal Clemente, C. Casacuberta, M. Madadi, C. Corneanu, S. Escalera","Towards explaining the generalization gap in neural networks using topological data analysis",2022,"","","","",163,"2022-07-13 10:07:35","","10.48550/arXiv.2203.12330","","",,,,,0,0.00,0,6,1,"Understanding how neural networks generalize on unseen data is crucial for designing more robust and reliable models. In this paper, we study the generalization gap of neural networks using methods from topological data analysis. For this purpose, we compute homological persistence diagrams of weighted graphs constructed from neuron activation correlations after a training phase, aiming to capture patterns that are linked to the generalization capacity of the network. We compare the usefulness of different numerical summaries from persistence diagrams and show that a combination of some of them can accurately predict and partially explain the generalization gap without the need of a test set. Evaluation on two computer vision recognition tasks (CIFAR10 and SVHN) shows competitive generalization gap prediction when compared against state-of-the-art methods.","",""
1,"M. Quade, Thomas Isele, Markus Abel","Explainable Machine Learning Control - robust control and stability analysis",2020,"","","","",164,"2022-07-13 10:07:35","","","","",,,,,1,0.50,0,3,2,"Recently, the term explainable AI became known as an approach to produce models from artificial intelligence which allow interpretation. Since a long time, there are models of symbolic regression in use that are perfectly explainable and mathematically tractable: in this contribution we demonstrate how to use symbolic regression methods to infer the optimal control of a dynamical system given one or several optimization criteria, or cost functions. In previous publications, network control was achieved by automatized machine learning control using genetic programming. Here, we focus on the subsequent analysis of the analytical expressions which result from the machine learning. In particular, we use AUTO to analyze the stability properties of the controlled oscillator system which served as our model. As a result, we show that there is a considerable advantage of explainable models over less accessible neural networks.","",""
179,"Hwanjun Song, Minseok Kim, Dongmin Park, Jae-Gil Lee","Learning from Noisy Labels with Deep Neural Networks: A Survey",2020,"","","","",165,"2022-07-13 10:07:35","","10.1109/TNNLS.2022.3152527","","",,,,,179,89.50,45,4,2,"Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies.","",""
62,"Minho Lee, Hyeung-Sik Choi","A robust neural controller for underwater robot manipulators",2000,"","","","",166,"2022-07-13 10:07:35","","10.1109/72.883478","","",,,,,62,2.82,31,2,22,"This paper presents a robust control scheme using a multilayer neural network with the error backpropagation learning algorithm. The multilayer neural network acts as a compensator of the conventional sliding mode controller to improve the control performance when initial assumptions of uncertainty bounds of system parameters are not valid. The proposed controller is applied to control a robot manipulator operating under the sea which has large uncertainties such as the buoyancy, the drag force, wave effects, currents, and the added mass/moment of inertia. Computer simulation results show that the proposed control scheme gives an effective path way to cope with those unexpected large uncertainties.","",""
5,"Zakaria Senousy, M. Abdelsamea, Mona Mostafa Mohamed, M. Gaber","3E-Net: Entropy-Based Elastic Ensemble of Deep Convolutional Neural Networks for Grading of Invasive Breast Carcinoma Histopathological Microscopic Images",2021,"","","","",167,"2022-07-13 10:07:35","","10.3390/e23050620","","",,,,,5,5.00,1,4,1,"Automated grading systems using deep convolution neural networks (DCNNs) have proven their capability and potential to distinguish between different breast cancer grades using digitized histopathological images. In digital breast pathology, it is vital to measure how confident a DCNN is in grading using a machine-confidence metric, especially with the presence of major computer vision challenging problems such as the high visual variability of the images. Such a quantitative metric can be employed not only to improve the robustness of automated systems, but also to assist medical professionals in identifying complex cases. In this paper, we propose Entropy-based Elastic Ensemble of DCNN models (3E-Net) for grading invasive breast carcinoma microscopy images which provides an initial stage of explainability (using an uncertainty-aware mechanism adopting entropy). Our proposed model has been designed in a way to (1) exclude images that are less sensitive and highly uncertain to our ensemble model and (2) dynamically grade the non-excluded images using the certain models in the ensemble architecture. We evaluated two variations of 3E-Net on an invasive breast carcinoma dataset and we achieved grading accuracy of 96.15% and 99.50%.","",""
39,"Yi Lu, Hong Guo, L. Feldkamp","Robust neural learning from unbalanced data samples",1998,"","","","",168,"2022-07-13 10:07:35","","10.1109/IJCNN.1998.687133","","",,,,,39,1.63,13,3,24,"This paper describes the result of our study on neural learning to solve the classification problem in which the data is unbalanced and noisy. Our study was conducted on three different neural network architectures, multilayered back propagation, radial basis function, and fuzzy ARTMAP with training methods including duplicating minority class samples and the Snowball technique. Three major issues are addressed: neural learning from unbalanced data samples, neural learning from noise data, and making intentional biased decisions. The application considered in this study is classifying good(pass)/bad(fail) vehicles. Experiments are conducted on data samples downloaded directly from test sites of automobile assembly.","",""
2,"N. M. Thoiyab, P. Muruganantham, G. Rajchakit, N. Gunasekaran, B. Unyong, U. Humphries, P. Kaewmesri, C. P. Lim","Global Stability Analysis of Neural Networks with Constant Time Delay via Frobenius Norm",2020,"","","","",169,"2022-07-13 10:07:35","","10.1155/2020/4321312","","",,,,,2,1.00,0,8,2,"This paper deals with the global asymptotic robust stability (GARS) of neural networks (NNs) with constant time delay via Frobenius norm. The Frobenius norm result has been utilized to find a new sufficient condition for the existence, uniqueness, and GARS of equilibrium point of the NNs. Some suitable Lyapunov functional and the slope bounded functions have been employed to find the new sufficient condition for GARS of NNs. Finally, we give some comparative study of numerical examples for explaining the advantageous of the proposed result along with the existing GARS results in terms of network parameters.","",""
9,"R. Blything, Valerio Biscione, Ivan I. Vankov, Casimir J H Ludwig, J. Bowers","The human visual system and CNNs can both support robust online translation tolerance following extreme displacements",2020,"","","","",170,"2022-07-13 10:07:35","","10.1167/jov.21.2.9","","",,,,,9,4.50,2,5,2,"Visual translation tolerance refers to our capacity to recognize objects over a wide range of different retinal locations. Although translation is perhaps the simplest spatial transform that the visual system needs to cope with, the extent to which the human visual system can identify objects at previously unseen locations is unclear, with some studies reporting near complete invariance over 10 degrees and other reporting zero invariance at 4 degrees of visual angle. Similarly, there is confusion regarding the extent of translation tolerance in computational models of vision, as well as the degree of match between human and model performance. Here, we report a series of eye-tracking studies (total N = 70) demonstrating that novel objects trained at one retinal location can be recognized at high accuracy rates following translations up to 18 degrees. We also show that standard deep convolutional neural networks (DCNNs) support our findings when pretrained to classify another set of stimuli across a range of locations, or when a global average pooling (GAP) layer is added to produce larger receptive fields. Our findings provide a strong constraint for theories of human vision and help explain inconsistent findings previously reported with convolutional neural networks (CNNs).","",""
8,"F. List, N. Rodd, G. Lewis","Dim but not entirely dark: Extracting the Galactic Center Excess' source-count distribution with neural nets",2021,"","","","",171,"2022-07-13 10:07:35","","10.1103/PhysRevD.104.123022","","",,,,,8,8.00,3,3,1,"The two leading hypotheses for the Galactic Center Excess (GCE) in the Fermi data are an unresolved population of faint millisecond pulsars (MSPs) and dark-matter (DM) annihilation. The dichotomy between these explanations is typically reflected by modeling them as two separate emission components. However, point-sources (PSs) such as MSPs become statistically degenerate with smooth Poisson emission in the ultra-faint limit (formally where each source is expected to contribute much less than one photon on average), leading to an ambiguity that can render questions such as whether the emission is PS-like or Poissonian in nature ill-defined. We present a conceptually new approach that describes the PS and Poisson emission in a unified manner and only afterwards derives constraints on the Poissonian component from the so obtained results. For the implementation of this approach, we leverage deep learning techniques, centered around a neural network-based method for histogram regression that expresses uncertainties in terms of quantiles. We demonstrate that our method is robust against a number of systematics that have plagued previous approaches, in particular DM / PS misattribution. In the Fermi data, we find a faint GCE described by a median source-count distribution (SCD) peaked at a flux of ∼ 4 × 10−11 counts cm−2 s−1 (corresponding to ∼ 3− 4 expected counts per PS), which would require N ∼ O(10) sources to explain the entire excess (median value N = 29,300 across the sky). Although faint, this SCD allows us to derive the constraint ηP ≤ 66% for the Poissonian fraction of the GCE flux ηP at 95% confidence, suggesting that a substantial amount of the GCE flux is due to PSs.","",""
38,"Hassan Ismail Fawaz, G. Forestier, J. Weber, L. Idoumghar, Pierre-Alain Muller","Accurate and interpretable evaluation of surgical skills from kinematic data using fully convolutional neural networks",2019,"","","","",172,"2022-07-13 10:07:35","","10.1007/s11548-019-02039-4","","",,,,,38,12.67,8,5,3,"","",""
20,"T. DeWolf, P. Jaworski, C. Eliasmith","Nengo and Low-Power AI Hardware for Robust, Embedded Neurorobotics",2020,"","","","",173,"2022-07-13 10:07:35","","10.3389/fnbot.2020.568359","","",,,,,20,10.00,7,3,2,"In this paper we demonstrate how the Nengo neural modeling and simulation libraries enable users to quickly develop robotic perception and action neural networks for simulation on neuromorphic hardware using tools they are already familiar with, such as Keras and Python. We identify four primary challenges in building robust, embedded neurorobotic systems, including: (1) developing infrastructure for interfacing with the environment and sensors; (2) processing task specific sensory signals; (3) generating robust, explainable control signals; and (4) compiling neural networks to run on target hardware. Nengo helps to address these challenges by: (1) providing the NengoInterfaces library, which defines a simple but powerful API for users to interact with simulations and hardware; (2) providing the NengoDL library, which lets users use the Keras and TensorFlow API to develop Nengo models; (3) implementing the Neural Engineering Framework, which provides white-box methods for implementing known functions and circuits; and (4) providing multiple backend libraries, such as NengoLoihi, that enable users to compile the same model to different hardware. We present two examples using Nengo to develop neural networks that run on CPUs and GPUs as well as Intel's neuromorphic chip, Loihi, to demonstrate two variations on this workflow. The first example is an implementation of an end-to-end spiking neural network in Nengo that controls a rover simulated in Mujoco. The network integrates a deep convolutional network that processes visual input from cameras mounted on the rover to track a target, and a control system implementing steering and drive functions in connection weights to guide the rover to the target. The second example uses Nengo as a smaller component in a system that has addressed some but not all of those challenges. Specifically it is used to augment a force-based operational space controller with neural adaptive control to improve performance during a reaching task using a real-world Kinova Jaco2 robotic arm. The code and implementation details are provided1, with the intent of enabling other researchers to build and run their own neurorobotic systems.","",""
5,"Haichao Huang, Jingya Chen, Xinting Huo, Yufei Qiao, Lei Ma","Effect of Multi-Scale Decomposition on Performance of Neural Networks in Short-Term Traffic Flow Prediction",2021,"","","","",174,"2022-07-13 10:07:35","","10.1109/ACCESS.2021.3068652","","",,,,,5,5.00,1,5,1,"Numerous studies employ multi-scale decomposition to improve the prediction performance of neural networks, but the grounds for selecting the decomposition algorithm are not explained, and the effects of decomposition algorithms on other performance of neural networks are also lacking further study. This paper studies the influence of commonly used multi-scale decomposition algorithms including EMD (Empirical Mode Decomposition), EEMD(Ensemble Empirical Mode Decomposition), CEEMDAN (Complete Ensemble Empirical Mode Decomposition with Adaptive Noise), VMD (Variational Mode Decomposition), WD (Wavelet Decomposition), and WPD (Wavelet Packet Decomposition) on the performance of Neural Networks. Decomposition algorithms are adopted to decompose traffic flow data into component signals, and then K-means is used to cluster component signals into volatility components, periodic components, and residual components. A Bi-directional LSTM (BiLSTM) neural network is adopted as the standard model for training and forecasting. Finally, three metrics, including prediction performance, robustness, and generalization performance are proposed to evaluate the influence of the multi-scale decomposition algorithm for neural networks comprehensively. By comparing the evaluation results of different hybrid models, this study provides some useful suggestions on proper multi-scale decomposition algorithm selection in short-time traffic flow prediction.","",""
5,"Anis Hamza, N. B. Yahia","Heavy trucks with intelligent control of active suspension based on artificial neural networks",2020,"","","","",175,"2022-07-13 10:07:35","","10.1177/0959651820958516","","",,,,,5,2.50,3,2,2,"The active control of a suspension system is meant to provide an isolated behavior of the system spring-mass (for example, increased comfort and performance). During this article, we are going to explain the importance of developing an intelligent control approach for active truck suspensions based on the artificial neural network. From where the main objective of this article is to obtain a mathematical model for active suspension systems then build a hydraulic model for active suspension control for trucks using an artificial neural network. In this article, a corresponding artificial neural network nonlinear active suspension controller has been designed and optimized for approximate road profiles, using simulation according to International Organization for Standardization 2631-5 and International Organization for Standardization 8608 standardizations. The model developed with MATLAB Toolbox, estimated and validated from data collected during tests carried out with a truck in other research work. To model the system, the laws of physics are used to describe the system and experimental data or information supplied about the system to determine the parameters of the system. The statement of the problem of this research is to develop a robust artificial neural network controller for the nonlinear active suspension system of the heavy truck that can improve the performances and its verifications using graphical and simulation output. The results of the simulation show that the methodology offers excellent performance. In addition, the robustness of the artificial neural network hydraulic controller is demonstrated for a variety of road profiles that increase the capabilities of the proposed methodology and prove its effectiveness.","",""
2,"Masaki Kobayashi","Quaternion-Valued Twin-Multistate Hopfield Neural Networks With Dual Connections",2020,"","","","",176,"2022-07-13 10:07:35","","10.1109/TNNLS.2020.2979904","","",,,,,2,1.00,2,1,2,"Dual connections (DCs) utilize the noncommutativity of quaternions and improve the noise tolerance of quaternion Hopfield neural networks (QHNNs). In this article, we introduce DCs to twin-multistate QHNNs. We conduct computer simulations to investigate the noise tolerance. The QHNNs with DCs were weak against an increase in the number of training patterns, but they were robust against increased resolution factor. The simulation results can be explained from the standpoints of storage capacities and rotational invariance.","",""
1,"Benjamin Filtjens, P. Ginis, A. Nieuwboer, M. R. Afzal, J. Spildooren, B. Vanrumste, P. Slaets","Modelling and identification of characteristic kinematic features preceding freezing of gait with convolutional neural networks and layer-wise relevance propagation",2021,"","","","",177,"2022-07-13 10:07:35","","10.1186/s12911-021-01699-0","","",,,,,1,1.00,0,7,1,"","",""
356,"Travis A. Jarrell, Yi Wang, Adam Bloniarz, C. Brittin, Meng Xu, J. N. Thomson, D. Albertson, D. Hall, S. W. Emmons","The Connectome of a Decision-Making Neural Network",2012,"","","","",178,"2022-07-13 10:07:35","","10.1126/science.1221762","","",,,,,356,35.60,40,9,10,"The Male Wiring Diagram The function of the nervous system is thought to represent an emergent property of its network connectivity. However, there are few complete descriptions of all the physical connections between neurons within a real nervous system. Working in nematodes, Jarrell et al. (p. 437; see the Perspective by Chklovskii and Bargmann) identified the complete connectome—every single chemical and gap junction synapse—of the tail ganglia, which govern mating behavior. The complete wiring structure of the synaptic network governing mating behavior of male nematodes is revealed. In order to understand the nervous system, it is necessary to know the synaptic connections between the neurons, yet to date, only the wiring diagram of the adult hermaphrodite of the nematode Caenorhabditis elegans has been determined. Here, we present the wiring diagram of the posterior nervous system of the C. elegans adult male, reconstructed from serial electron micrograph sections. This region of the male nervous system contains the sexually dimorphic circuits for mating. The synaptic connections, both chemical and gap junctional, form a neural network with four striking features: multiple, parallel, short synaptic pathways directly connecting sensory neurons to end organs; recurrent and reciprocal connectivity among sensory neurons; modular substructure; and interneurons acting in feedforward loops. These features help to explain how the network robustly and rapidly selects and executes the steps of a behavioral program on the basis of the inputs from multiple sensory neurons.","",""
1,"Lei Zhu, Qi She, Duo Li, Yanye Lu, Xuejing Kang, Jie Hu, Changhu Wang","Unifying Nonlocal Blocks for Neural Networks",2021,"","","","",179,"2022-07-13 10:07:35","","10.1109/ICCV48922.2021.01207","","",,,,,1,1.00,0,7,1,"The nonlocal-based blocks are designed for capturing long-range spatial-temporal dependencies in computer vision tasks. Although having shown excellent performance, they still lack the mechanism to encode the rich, structured information among elements in an image or video. In this paper, to theoretically analyze the property of these nonlocal-based blocks, we provide a new perspective to interpret them, where we view them as a set of graph filters generated on a fully-connected graph. Specifically, when choosing the Chebyshev graph filter, a unified formulation can be derived for explaining and analyzing the existing nonlocal-based blocks (e.g., nonlocal block, nonlocal stage, double attention block). Furthermore, by concerning the property of spectral, we propose an efficient and robust spectral nonlocal block, which can be more robust and flexible to catch long-range dependencies when inserted into deep neural networks than the existing nonlocal blocks. Experimental results demonstrate the clear-cut improvements and practical applicabilities of our method on image classification, action recognition, semantic segmentation, and person re-identification tasks. Code are available at https://github.com/zh460045050/SNL_ICCV2021.","",""
1,"Oussama Abdul Hay, Mohamad Chehadeh, Abdulla Ayyad, Mohamad Wahbah, M. Humais, Y. Zweiri","Unified Identification and Tuning Approach Using Deep Neural Networks For Visual Servoing Applications",2021,"","","","",180,"2022-07-13 10:07:35","","","","",,,,,1,1.00,0,6,1,"Vision based control of Unmanned Aerial Vehicles (UAVs) has been adopted by a wide range of applications due to the availability of low-cost on-board sensors and computers. Tuning such systems to work properly requires extensive domain specific experience which limits the growth of emerging applications. Moreover, obtaining performance limits of UAV based visual servoing with the current state-of-the-art is not possible due to the complexity of the models used. In this paper, we present a systematic approach for real-time identification and tuning of visual servoing systems based on a novel robustified version of the recent deep neural networks with the modified relay feedback test (DNN-MRFT) approach. The proposed robust DNN-MRFT algorithm can be used with a multitude of vision sensors and estimation algorithms despite the high levels of sensor’s noise. Sensitivity of MRFT to perturbations is investigated and its effect on identification and tuning performance is analyzed. DNNMRFT was able to detect performance changes due to the use of slower vision sensors, or due to the integration of accelerometer measurements. Experimental identification results were closely matching simulation results, which can be used to explain system behaviour and anticipate the closed loop performance limits given a certain hardware and software setup. Finally, we demonstrate the capability of the DNN-MRFT tuned visual servoing systems to reject external disturbances. Some advantages of the suggested robust identification approach compared to existing visual servoing design approaches are presented.","",""
430,"Amirata Ghorbani, Abubakar Abid, James Y. Zou","Interpretation of Neural Networks is Fragile",2017,"","","","",181,"2022-07-13 10:07:35","","10.1609/aaai.v33i01.33013681","","",,,,,430,86.00,143,3,5,"In order for machine learning to be trusted in many applications, it is critical to be able to reliably explain why the machine learning algorithm makes certain predictions. For this reason, a variety of methods have been developed recently to interpret neural network predictions by providing, for example, feature importance maps. For both scientific robustness and security reasons, it is important to know to what extent can the interpretations be altered by small systematic perturbations to the input data, which might be generated by adversaries or by measurement biases. In this paper, we demonstrate how to generate adversarial perturbations that produce perceptively indistinguishable inputs that are assigned the same predicted label, yet have very different interpretations. We systematically characterize the robustness of interpretations generated by several widely-used feature importance interpretation methods (feature importance maps, integrated gradients, and DeepLIFT) on ImageNet and CIFAR-10. In all cases, our experiments show that systematic perturbations can lead to dramatically different interpretations without changing the label. We extend these results to show that interpretations based on exemplars (e.g. influence functions) are similarly susceptible to adversarial attack. Our analysis of the geometry of the Hessian matrix gives insight on why robustness is a general challenge to current interpretation approaches.","",""
77,"S. Arik","An improved robust stability result for uncertain neural networks with multiple time delays",2014,"","","","",182,"2022-07-13 10:07:35","","10.1016/j.neunet.2014.02.008","","",,,,,77,9.63,77,1,8,"","",""
1,"Vezha Boboeva, Alberto Pezzotta, C. Clopath","Free recall scaling laws and short-term memory effects in a latching attractor network",2020,"","","","",183,"2022-07-13 10:07:35","","10.1101/2020.12.19.423464","","",,,,,1,0.50,0,3,2,"Significance The ability to store and retrieve information is a crucial function of memory in the brain. One well-established paradigm in which this is tested is free recall, in which a number of robust features and biases characterize the statistics of recall. Although these laws are consistently reproduced, the neuronal basis of how they emerge is not clear. In this manuscript, we propose a neural network model with a plausible learning rule that expresses these laws that may provide a mechanistic insight into memory function. In particular, our model reproduces power laws governing the recall capacity, as well as the biases that human subjects use to guide recall, such as the use of temporal and semantic cues. Despite the complexity of human memory, paradigms like free recall have revealed robust qualitative and quantitative characteristics, such as power laws governing recall capacity. Although abstract random matrix models could explain such laws, the possibility of their implementation in large networks of interacting neurons has so far remained underexplored. We study an attractor network model of long-term memory endowed with firing rate adaptation and global inhibition. Under appropriate conditions, the transitioning behavior of the network from memory to memory is constrained by limit cycles that prevent the network from recalling all memories, with scaling similar to what has been found in experiments. When the model is supplemented with a heteroassociative learning rule, complementing the standard autoassociative learning rule, as well as short-term synaptic facilitation, our model reproduces other key findings in the free recall literature, namely, serial position effects, contiguity and forward asymmetry effects, and the semantic effects found to guide memory recall. The model is consistent with a broad series of manipulations aimed at gaining a better understanding of the variables that affect recall, such as the role of rehearsal, presentation rates, and continuous and/or end-of-list distractor conditions. We predict that recall capacity may be increased with the addition of small amounts of noise, for example, in the form of weak random stimuli during recall. Finally, we predict that, although the statistics of the encoded memories has a strong effect on the recall capacity, the power laws governing recall capacity may still be expected to hold.","",""
3,"R. Visser, J. Bathelt, H. Scholte, M. Kindt","Robust BOLD Responses to Faces But Not to Conditioned Threat: Challenging the Amygdala's Reputation in Human Fear and Extinction Learning",2021,"","","","",184,"2022-07-13 10:07:35","","10.1523/JNEUROSCI.0857-21.2021","","",,,,,3,3.00,1,4,1,"Most of our knowledge about human emotional memory comes from animal research. Based on this work, the amygdala is often labeled the brain's “fear center”, but it is unclear to what degree neural circuitries underlying fear and extinction learning are conserved across species. Neuroimaging studies in humans yield conflicting findings, with many studies failing to show amygdala activation in response to learned threat. Such null findings are often treated as resulting from MRI-specific problems related to measuring deep brain structures. Here we test this assumption in a mega-analysis of three studies on fear acquisition (n = 98; 68 female) and extinction learning (n = 79; 53 female). The conditioning procedure involved the presentation of two pictures of faces and two pictures of houses: one of each pair was followed by an electric shock [a conditioned stimulus (CS+)], the other one was never followed by a shock (CS–), and participants were instructed to learn these contingencies. Results revealed widespread responses to the CS+ compared with the CS– in the fear network, including anterior insula, midcingulate cortex, thalamus, and bed nucleus of the stria terminalis, but not the amygdala, which actually responded stronger to the CS–. Results were independent of spatial smoothing, and of individual differences in trait anxiety and conditioned pupil responses. In contrast, robust amygdala activation distinguished faces from houses, refuting the idea that a poor signal could account for the absence of effects. Moving forward, we suggest that, apart from imaging larger samples at higher resolution, alternative statistical approaches may be used to identify cross-species similarities in fear and extinction learning. SIGNIFICANCE STATEMENT The science of emotional memory provides the foundation of numerous theories on psychopathology, including stress and anxiety disorders. This field relies heavily on animal research, which suggests a central role of the amygdala in fear learning and memory. However, this finding is not strongly corroborated by neuroimaging evidence in humans, and null findings are too easily explained away by methodological limitations inherent to imaging deep brain structures. In a large nonclinical sample, we find widespread BOLD activation in response to learned fear, but not in the amygdala. A poor signal could not account for the absence of effects. While these findings do not disprove the involvement of the amygdala in human fear learning, they challenge its typical portrayals and illustrate the complexities of translational science.","",""
16,"Zifan Wang, Haofan Wang, Shakul Ramkumar, Matt Fredrikson, Piotr Mardziel, Anupam Datta","Smoothed Geometry for Robust Attribution",2020,"","","","",185,"2022-07-13 10:07:35","","","","",,,,,16,8.00,3,6,2,"Feature attributions are a popular tool for explaining the behavior of Deep Neural Networks (DNNs), but have recently been shown to be vulnerable to attacks that produce divergent explanations for nearby inputs. This lack of robustness is especially problematic in high-stakes applications where adversarially-manipulated explanations could impair safety and trustworthiness. Building on a geometric understanding of these attacks presented in recent work, we identify Lipschitz continuity conditions on models' gradient that lead to robust gradient-based attributions, and observe that smoothness may also be related to the ability of an attack to transfer across multiple attribution methods. To mitigate these attacks in practice, we propose an inexpensive regularization method that promotes these conditions in DNNs, as well as a stochastic smoothing technique that does not require re-training. Our experiments on a range of image models demonstrate that both of these mitigations consistently improve attribution robustness, and confirm the role that smooth geometry plays in these attacks on real, large-scale models.","",""
17,"Saima Sharmin, P. Panda, Syed Shakib Sarwar, Chankyu Lee, Wachirawit Ponghiran, K. Roy","A Comprehensive Analysis on Adversarial Robustness of Spiking Neural Networks",2019,"","","","",186,"2022-07-13 10:07:35","","10.1109/IJCNN.2019.8851732","","",,,,,17,5.67,3,6,3,"In this era of machine learning models, their functionality is being threatened by adversarial attacks. In the face of this struggle for making artificial neural networks robust, finding a model, resilient to these attacks, is very important. In this work, we present, for the first time, a comprehensive analysis of the behavior of more bio-plausible networks, namely Spiking Neural Network (SNN) under state-of-the-art adversarial tests. We perform a comparative study of the accuracy degradation between conventional VGG-9 Artificial Neural Network (ANN) and equivalent spiking network with CIFAR-10 dataset in both whitebox and blackbox setting for different types of single-step and multi-step FGSM (Fast Gradient Sign Method) attacks. We demonstrate that SNNs tend to show more resiliency compared to ANN under blackbox attack scenario. Additionally, we find that SNN robustness is largely dependent on the corresponding training mechanism. We observe that SNNs trained by spike-based backpropagation are more adversarially robust than the ones obtained by ANN-to-SNN conversion rules in several whitebox and blackbox scenarios. Finally, we also propose a simple, yet, effective framework for crafting adversarial attacks from SNNs. Our results suggest that attacks crafted from SNNs following our proposed method are much stronger than those crafted from ANNs.","",""
30,"Guillermo Ortiz-Jiménez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, P. Frossard","Hold me tight! Influence of discriminative features on deep network boundaries",2020,"","","","",187,"2022-07-13 10:07:35","","","","",,,,,30,15.00,8,4,2,"Important insights towards the explainability of neural networks reside in the characteristics of their decision boundaries. In this work, we borrow tools from the field of adversarial robustness, and propose a new perspective that relates dataset features to the distance of samples to the decision boundary. This enables us to carefully tweak the position of the training samples and measure the induced changes on the boundaries of CNNs trained on large-scale vision datasets. We use this framework to reveal some intriguing properties of CNNs. Specifically, we rigorously confirm that neural networks exhibit a high invariance to non-discriminative features, and show that the decision boundaries of a DNN can only exist as long as the classifier is trained with some features that hold them together. Finally, we show that the construction of the decision boundary is extremely sensitive to small perturbations of the training samples, and that changes in certain directions can lead to sudden invariances in the orthogonal ones. This is precisely the mechanism that adversarial training uses to achieve robustness.","",""
0,"Kelei Cao, Mengchen Liu, Hang Su, Jing Wu, Jun Zhu, Shixia Liu","Analyzing the Noise Robustness of Deep Neural Networks",2020,"","","","",188,"2022-07-13 10:07:35","","10.1109/TVCG.2020.2969185","","",,,,,0,0.00,0,6,2,"Adversarial examples, generated by adding small but intentionally imperceptible perturbations to normal examples, can mislead deep neural networks (DNNs) to make incorrect predictions. Although much work has been done on both adversarial attack and defense, a fine-grained understanding of adversarial examples is still lacking. To address this issue, we present a visual analysis method to explain why adversarial examples are misclassified. The key is to compare and analyze the datapaths of both the adversarial and normal examples. A datapath is a group of critical neurons along with their connections. We formulate the datapath extraction as a subset selection problem and solve it by constructing and training a neural network. A multi-level visualization consisting of a network-level visualization of data flows, a layer-level visualization of feature maps, and a neuron-level visualization of learned features, has been designed to help investigate how datapaths of adversarial and normal examples diverge and merge in the prediction process. A quantitative evaluation and a case study were conducted to demonstrate the promise of our method to explain the misclassification of adversarial examples.","",""
0,"A. Saadallah, K. Morik","Meta-Adversarial Training of Neural Networks for Binary Classification",2021,"","","","",189,"2022-07-13 10:07:35","","10.1109/IJCNN52387.2021.9534247","","",,,,,0,0.00,0,2,1,"We propose a novel framework for classification using neural networks via an adversarial training procedure, in which we simultaneously train a main classifier—a neural network that solves the original classification task, i.e classifying instances into two main categories—and two meta-classifiers which act as discriminators and aim to detect false positives and negatives predicted by the original classifier. Our framework operates in two stages: In a first stage, both main and meta classifiers are pre-trained using the cross-entropy loss. The second stage consists of an adversarial training stage in which both main and meta classifiers are placed in a min-max game. Therefore, we switch to our new loss function so that the goal for the main classifier becomes to maximize the probability of failure of the adversarial meta-classifiers. Our training procedure can be explained by the fact that the meta-classifiers are more accurate when the main classifier is weak i.e., instances misclassified by the main classifier are naturally easy to separate and assign to the correct class membership. Opposingly, if the main classifier is robust enough, then the meta-classifiers are supposed to distinguish between instances that are naturally hard to classify, making thus more mistakes. In this work, both main and meta-classifiers are defined by Multi-Layer Perceptrons (MLP) and the entire training system is performed using backpropagation with gradient descent optimization. Experiments demonstrate the potential of our framework in outperforming the traditional learning scheme in improving the classification accuracy.","",""
0,"Yunzhe Xue, Meiyan Xie, Zhibo Yang, Usman Roshan","Defending against black-box adversarial attacks with gradient-free trained sign activation neural networks",2021,"","","","",190,"2022-07-13 10:07:35","","","","",,,,,0,0.00,0,4,1,"While machine learning models today can achieve high accuracies on classification tasks, they can be deceived by minor imperceptible distortions to the data. These are known as adversarial attacks and can be lethal in the black-box setting which does not require knowledge of the target model type or its parameters. Binary neural networks that have sign activation and are trained with gradient descent have been shown to be harder to attack than conventional sigmoid activation networks but their improvements are marginal. We instead train sign activation networks with a novel gradient-free stochastic coordinate descent algorithm and propose an ensemble of such networks as a defense model. We evaluate the robustness of our model (a hard problem in itself) on image, text, and medical ECG data and find it to be more robust than ensembles of binary, full precision, and convolutional neural networks, and than random forests while attaining comparable clean test accuracy. In order to explain our model's robustness we show that an adversary targeting a single network in our ensemble fails to attack (and thus non-transferable to) other networks in the ensemble. Thus a datapoint requires a large distortion to fool the majority of networks in our ensemble and is likely to be detected in advance. This property of non-transferability arises naturally from the non-convexity of sign activation networks and randomization in our gradient-free training algorithm without any adversarial defense effort.","",""
36,"E. Magosso, Cristiano Cuppini, M. Ursino","A Neural Network Model of Ventriloquism Effect and Aftereffect",2012,"","","","",191,"2022-07-13 10:07:35","","10.1371/journal.pone.0042503","","",,,,,36,3.60,12,3,10,"Presenting simultaneous but spatially discrepant visual and auditory stimuli induces a perceptual translocation of the sound towards the visual input, the ventriloquism effect. General explanation is that vision tends to dominate over audition because of its higher spatial reliability. The underlying neural mechanisms remain unclear. We address this question via a biologically inspired neural network. The model contains two layers of unimodal visual and auditory neurons, with visual neurons having higher spatial resolution than auditory ones. Neurons within each layer communicate via lateral intra-layer synapses; neurons across layers are connected via inter-layer connections. The network accounts for the ventriloquism effect, ascribing it to a positive feedback between the visual and auditory neurons, triggered by residual auditory activity at the position of the visual stimulus. Main results are: i) the less localized stimulus is strongly biased toward the most localized stimulus and not vice versa; ii) amount of the ventriloquism effect changes with visual-auditory spatial disparity; iii) ventriloquism is a robust behavior of the network with respect to parameter value changes. Moreover, the model implements Hebbian rules for potentiation and depression of lateral synapses, to explain ventriloquism aftereffect (that is, the enduring sound shift after exposure to spatially disparate audio-visual stimuli). By adaptively changing the weights of lateral synapses during cross-modal stimulation, the model produces post-adaptive shifts of auditory localization that agree with in-vivo observations. The model demonstrates that two unimodal layers reciprocally interconnected may explain ventriloquism effect and aftereffect, even without the presence of any convergent multimodal area. The proposed study may provide advancement in understanding neural architecture and mechanisms at the basis of visual-auditory integration in the spatial realm.","",""
7,"Lorenz Kuhn, Clare Lyle, Aidan N. Gomez, Jonas Rothfuss, Y. Gal","Robustness to Pruning Predicts Generalization in Deep Neural Networks",2021,"","","","",192,"2022-07-13 10:07:35","","","","",,,,,7,7.00,1,5,1,"Existing generalization measures that aim to capture a model’s simplicity based on parameter counts or norms fail to explain generalization in overparameterized deep neural networks. In this paper, we introduce a new, theoretically motivated measure of a network’s simplicity which we call prunability: the smallest fraction of the network’s parameters that can be kept while pruning without adversely affecting its training loss. We show that this measure is highly predictive of a model’s generalization performance across a large set of convolutional networks trained on CIFAR10, does not grow with network size unlike existing pruning-based measures, and exhibits high correlation with test set loss even in a particularly challenging double descent setting. Lastly, we show that the success of prunability cannot be explained by its relation to known complexity measures based on models’ margin, flatness of minima and optimization speed, finding that our new measure is similar to – but more predictive than – existing flatness-based measures, and that its predictions exhibit low mutual information with those of other baselines.","",""
22,"Derrick W Shaughnessy, R. L. Hyson, R. Bertram, Wei Wu, F. Johnson","Female zebra finches do not sing yet share neural pathways necessary for singing in males",2018,"","","","",193,"2022-07-13 10:07:35","","10.1002/cne.24569","","",,,,,22,5.50,4,5,4,"Adult female zebra finches (Taeniopygia guttata), which do not produce learned songs, have long been thought to possess only vestiges of the forebrain network that supports learned song in males. This view ostensibly explains why females do not sing—many of the neural populations and pathways that make up the male song control network appear rudimentary or even missing in females. For example, classic studies of vocal‐premotor cortex (HVC, acronym is name) in male zebra finches identified prominent efferent pathways from HVC to vocal‐motor cortex (RA, robust nucleus of the arcopallium) and from HVC to the avian basal ganglia (Area X). In females, by comparison, the efferent targets of HVC were thought to be only partially innervated by HVC axons (RA) or absent (Area X). Here, using a novel visually guided surgical approach to target tracer injections with precision, we mapped the extrinsic connectivity of the adult female HVC. We find that female HVC shows a mostly male‐typical pattern of afferent and efferent connectivity, including robust HVC innervation of RA and Area X. As noted by earlier investigators, we find large sex differences in the volume of many regions that control male singing (male > female). However, sex differences in volume were diminished in regions that convey ascending afferent input to HVC. Our findings do not support a vestigial interpretation of the song control network in females. Instead, our findings support the emerging view that the song control network may have an altogether different function in nonsinging females.","",""
5,"Cory Shain, I. Blank, Evelina Fedorenko, E. Gibson, William Schuler","Robust effects of working memory demand during naturalistic language comprehension in language-selective cortex",2021,"","","","",194,"2022-07-13 10:07:35","","10.1101/2021.09.18.460917","","",,,,,5,5.00,1,5,1,"A standard view of human language processing is that comprehenders build richly structured mental representations of natural language utterances, word by word, using computationally costly memory operations supported by domain-general working memory resources. However, three core claims of this view have been questioned, with some prior work arguing that (1) rich word-by-word structure building is not a core function of the language comprehension system, (2) apparent working memory costs are underlyingly driven by word predictability (surprisal), and/or (3) language comprehension relies primarily on domain-general rather than domain-specific working memory resources. In this work, we simultaneously evaluate all three of these claims using naturalistic comprehension in fMRI. In each participant, we functionally localize (a) a language-selective network and (b) a ‘multiple-demand’ network that supports working memory across domains, and we analyze the responses in these two networks of interest during naturalistic story listening with respect to a range of theory-driven predictors of working memory demand under rigorous surprisal controls. Results show robust surprisal-independent effects of word-by-word memory demand in the language network and no effect of working memory demand in the multiple demand network. Our findings thus support the view that language comprehension (1) entails word-by-word structure building using (2) computationally intensive memory operations that are not explained by surprisal. However, these results challenge (3) the domain-generality of the resources that support these operations, instead indicating that working memory operations for language comprehension are carried out by the same neural resources that store linguistic knowledge. Significance Statement This study uses fMRI to investigate signatures of working memory (WM) demand during naturalistic story listening, using a broad range of theoretically motivated estimates of WM demand. Results support a strong effect of WM demand in language-selective brain regions but no effect of WM demand in “multiple demand” regions that have previously been associated with WM in non-linguistic domains. We further show evidence that WM effects in language regions are distinct from effects of word predictability. Our findings support a core role for WM in incremental language processing, using WM resources that are specialized for language.","",""
2,"Saurav Mishra","Malaria Parasite Detection using Efficient Neural Ensembles",2021,"","","","",195,"2022-07-13 10:07:35","","10.35882/jeeemi.v3.i3.2","","",,,,,2,2.00,2,1,1,"Caused by the bite of the Anopheles mosquito infected with the parasite of genus Plasmodium, malaria has remained a major burden towards healthcare for years with an approximate 400,000 deaths reported globally every year. The traditional diagnosis process for malaria involves an examination of the blood smear slide under the microscope. This process is not only time consuming but also requires pathologists to be highly skilled in their work. Timely diagnosis and availability of robust diagnostic facilities and skilled laboratory technicians are very much vital to reduce the mortality rate. This study aims to build a robust system by applying deep learning techniques such as transfer learning and snapshot ensembling to automate the detection of the parasite in the thin blood smear images. All the models were evaluated against the following metrics - F1 score, Accuracy, Precision, Recall, Mathews Correlation Coefficient (MCC), Area Under the Receiver Operating Characteristics (AUC-ROC) and the Area under the Precision Recall curve (AUC-PR). The snapshot ensembling model created by combining the snapshots of the EfficientNet-B0 pre-trained model outperformed every other model achieving a f1 score - 99.37%, precision - 99.52% and recall - 99.23%. The results show the potential of  model ensembles which combine the predictive power of multiple weal models to create a single efficient model that is better equipped to handle the real world data. The GradCAM experiment displayed the gradient activation maps of the last convolution layer to visually explicate where and what a model sees in an image to classify them into a particular class. The models in this study correctly activate the stained parasitic region of interest in the thin blood smear images. Such visuals make the model more transparent, explainable, and trustworthy which are very much essential for deploying AI based models in the healthcare network.","",""
6,"Chandra Mohan Dasari, Raju Bhukya","Explainable deep neural networks for novel viral genome prediction",2021,"","","","",196,"2022-07-13 10:07:35","","10.1007/s10489-021-02572-3","","",,,,,6,6.00,3,2,1,"","",""
290,"L. Cheng, Z. Hou, M. Tan, Yingzi Lin, W. Zhang","Neural-Network-Based Adaptive Leader-Following Control for Multiagent Systems With Uncertainties",2010,"","","","",197,"2022-07-13 10:07:35","","10.1109/TNN.2010.2050601","","",,,,,290,24.17,58,5,12,"A neural-network-based adaptive approach is proposed for the leader-following control of multiagent systems. The neural network is used to approximate the agent's uncertain dynamics, and the approximation error and external disturbances are counteracted by employing the robust signal. When there is no control input constraint, it can be proved that all the following agents can track the leader's time-varying state with the tracking error as small as desired. Compared with the related work in the literature, the uncertainty in the agent's dynamics is taken into account; the leader's state could be time-varying; and the proposed algorithm for each following agent is only dependent on the information of its neighbor agents. Finally, the satisfactory performance of the proposed method is illustrated by simulation examples.","",""
19,"Hande Dong, Jiawei Chen, Fuli Feng, Xiangnan He, Shuxian Bi, Zhaolin Ding, Peng Cui","On the Equivalence of Decoupled Graph Convolution Network and Label Propagation",2020,"","","","",198,"2022-07-13 10:07:35","","10.1145/3442381.3449927","","",,,,,19,9.50,3,7,2,"The original design of Graph Convolution Network (GCN) couples feature transformation and neighborhood aggregation for node representation learning. Recently, some work shows that coupling is inferior to decoupling, which supports deep graph propagation better and has become the latest paradigm of GCN (e.g., APPNP [16] and SGCN [32]). Despite effectiveness, the working mechanisms of the decoupled GCN are not well understood. In this paper, we explore the decoupled GCN for semi-supervised node classification from a novel and fundamental perspective — label propagation. We conduct thorough theoretical analyses, proving that the decoupled GCN is essentially the same as the two-step label propagation: first, propagating the known labels along the graph to generate pseudo-labels for the unlabeled nodes, and second, training normal neural network classifiers on the augmented pseudo-labeled data. More interestingly, we reveal the effectiveness of decoupled GCN: going beyond the conventional label propagation, it could automatically assign structure- and model- aware weights to the pseudo-label data. This explains why the decoupled GCN is relatively robust to the structure noise and over-smoothing, but sensitive to the label noise and model initialization. Based on this insight, we propose a new label propagation method named Propagation then Training Adaptively (PTA), which overcomes the flaws of the decoupled GCN with a dynamic and adaptive weighting strategy. Our PTA is simple yet more effective and robust than decoupled GCN. We empirically validate our findings on four benchmark datasets, demonstrating the advantages of our method. The code is available at https://github.com/DongHande/PT_propagation_then_training.","",""
58,"Y. Kao, Changhong Wang, Lin Zhang","Delay-Dependent Robust Exponential Stability of Impulsive Markovian Jumping Reaction-Diffusion Cohen-Grossberg Neural Networks",2013,"","","","",199,"2022-07-13 10:07:35","","10.1007/s11063-012-9269-2","","",,,,,58,6.44,19,3,9,"","",""
2,"D. Vos, S. Verwer","Robust Optimal Classification Trees Against Adversarial Examples",2021,"","","","",200,"2022-07-13 10:07:35","","10.1609/aaai.v36i8.20829","","",,,,,2,2.00,1,2,1,"Decision trees are a popular choice of explainable model, but just like neural networks, they suffer from adversarial examples. Existing algorithms for fitting decision trees robust against adversarial examples are greedy heuristics and lack approximation guarantees. In this paper we propose ROCT, a collection of methods to train decision trees that are optimally robust against user-specified attack models. We show that the min-max optimization problem that arises in adversarial learning can be solved using a single minimization formulation for decision trees with 0-1 loss. We propose such formulations in Mixed-Integer Linear Programming and Maximum Satisfiability, which widely available solvers can optimize. We also present a method that determines the upper bound on adversarial accuracy for any model using bipartite matching. Our experimental results demonstrate that the existing heuristics achieve close to optimal scores while ROCT achieves state-of-the-art scores.","",""
