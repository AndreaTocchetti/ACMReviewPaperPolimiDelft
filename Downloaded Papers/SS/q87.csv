Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",1,"2022-07-13 09:33:13","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
3,"Yongyue Wang, Chunhe Xia, Chengxiang Si, Beitong Yao, Tianbo Wang","Robust Reasoning Over Heterogeneous Textual Information for Fact Verification",2020,"","","","",2,"2022-07-13 09:33:13","","10.1109/ACCESS.2020.3019586","","",,,,,3,1.50,1,5,2,"Automatic fact verification (FV) based on artificial intelligence is considered as a promising approach which can be used to identify misinformation distributed on the web. Even though previous FV using deep learning have made great achievements in single dataset (e.g., FEVER), the trained systems are unlikely to be capable of extracting evidence from heterogeneous web-sources and validating claims in accordance with evidence found on the Internet. Nevertheless, the heterogeneity covers abundant semantic information, which will help FV system identify misinformation in a more accurate way. The current work is the first attempt to make the combination of knowledge graph (KG) and graph neural network (GNN) to enhance the robustness of FV systems for heterogeneous information. As a result, it can be generalized to multi-domain datasets after training on a sufficient single one. To make information update and aggregate well on the collaborative graph, the present study proposes a double graph attention network (DGAT) framework which recursively propagates the embeddings from a node’s neighbors to refine the node’s embedding as well as applies an attention mechanism to classify the importance of the neighbors. We train and evaluate our system on FEVER, a single and benchmark dataset for FV, and then re-evaluate our system on UKP Snopes Corpus, a new richly annotated corpus for FV tasks on the basis of heterogeneous web sources. According to experimental results, although DGAT has no excellent advantages in a single dataset, it shows outstanding performance in more realistic and multi-domain datasets. Moreover, the current study also provides a feasible method for deep learning to have the ability to infer heterogeneous information robustly.","",""
3,"Zhengxiang Shi, Qiang Zhang, Aldo Lipani","StepGame: A New Benchmark for Robust Multi-Hop Spatial Reasoning in Texts",2022,"","","","",3,"2022-07-13 09:33:13","","10.48550/arXiv.2204.08292","","",,,,,3,3.00,1,3,1,"Inferring spatial relations in natural language is a crucial ability an intelligent system should possess. The bAbI dataset tries to capture tasks relevant to this domain (task 17 and 19). However, these tasks have several limitations. Most importantly, they are limited to fixed expressions, they are limited in the number of reasoning steps required to solve them, and they fail to test the robustness of models to input that contains irrelevant or redundant information. In this paper, we present a new Question-Answering dataset called StepGame for robust multi-step spatial reasoning in texts. Our experiments demonstrate that state-of-the-art models on the bAbI dataset struggle on the StepGame dataset. Moreover, we propose a Tensor-Product based Memory-Augmented Neural Network (TP-MANN) specialized for spatial reasoning tasks. Experimental results on both datasets show that our model outperforms all the baselines with superior generalization and robustness performance.","",""
4,"Stuart J. Russell","Artificial Intelligence and the Problem of Control",2021,"","","","",4,"2022-07-13 09:33:13","","10.1007/978-3-030-86144-5_3","","",,,,,4,4.00,4,1,1,"","",""
0,"Alexander Williams, C. S. Bangun","Artificial Intelligence System Framework in Improving The Competence of Indonesian Human Resources",2022,"","","","",5,"2022-07-13 09:33:13","","10.34306/ijcitsm.v2i1.91","","",,,,,0,0.00,0,2,1,"In this rapidly evolving period, notably the digital era, technology is critical. The globe is presently living in the technological era, sometimes known as the ""Industrial Revolution 4.0."" This state is characterized by the widespread use of digital machines and the internet, which has resulted in quick and substantial changes in many aspects of human existence, making it simpler for humans to perform numerous tasks. The digital transformation age is part of a more robust technology, which is a shift in how digital technology is applied to many elements of life in society. Artificial intelligence is a field of study that looks at ways to make computers behave like humans. In order to advance science, technology, and art in Indonesia, an artificial intelligence system framework is required. The goal of this research is to explain the Case-Based Reasoning (CBR) paradigm in the context of artificial intelligence development. This framework is intended to serve as a model for implementing intelligence systems in Indonesia.","",""
6,"","Dutch Artificial Intelligence Manifesto",2018,"","","","",6,"2022-07-13 09:33:13","","","","",,,,,6,1.50,0,0,4,"Artificial Intelligence (AI), the science and engineering that studies and creates intelligent systems, has become a disruptive force revolutionizing fields as diverse as health care, finance, law, insurance, HR, communication, education, energy, transportation, manufacturing, agriculture, and defense.2 Driven by the increased availability of compute power, access to massive amounts of data3, and advanced sensor technology, AI techniques such as reasoning, imaging processing and machine learning algorithms have become powerful enablers of automation, predictive analytics, and human-machine interaction. AI has already changed online interactions in the retail sector (e.g., recommender systems and chatbots) but also enable sophisticated AI-enabled user experiences (e.g., AI assistants) that profoundly affect how people live, work, and play.4 To ensure these developments are beneficial for all, we should invest in making AI highly robust, and include all stakeholders in their development.5 The Netherlands is well positioned to benefit from these developments as strong enablers are in place including strong digital absorption and economic innovation. AI research and education is also strong, but to avoid a brain drain, investments are needed in human talent.6 In the meantime, a technology race has started with the US taking a leading role, China closely following and heavily investing in AI7, and Europe still in the process of formulating its AI strategy at EU as well as national levels.8 We urgently need a national agenda for AI that provides a national strategy that is supported by academy, industry, and government. The Netherlands must make substantial investments in high-quality Dutch AI research and innovation if it is to compete at all.","",""
0,"Juveriya Afreen","A Survey on Artificial Intelligence Techniques to Prevent Cyber Crime",2018,"","","","",7,"2022-07-13 09:33:13","","10.23956/IJARCSSE.V8I5.669","","",,,,,0,0.00,0,1,4,"Abstract-- With increase in complexity of data, security, it is difficult for the individuals to prevent the offence. Thus, by using any automation or software it’s not possible by only using huge fixed algorithms to overcome this. Thus, we need to look for something which is robust and feasible enough. Hence AI plays an epitome role to defense such violations. In this paper we basically look how human reasoning along with AI can be applied to uplift cyber security.","",""
0,"Shashank Agnihotri, Anshul Agarwal","Ambient Artificial Intelligence",2017,"","","","",8,"2022-07-13 09:33:13","","10.5120/IJCA2017914886","","",,,,,0,0.00,0,2,5,"The paper presents an integrated, automated and wireless system concept for the human intelligence environment domain based on the technique called ambient artificial intelligence (AAI). Ambient Intelligence system is that which is embedded in an environment, enhancing complex and manual life to simple and automatic life. This technology in an environment is challenging to various algorithm that are being used with respect to human behavior and human life. Development of such intelligent and smart environment is dependent on the adaptive nature, flexibility, robust parameters of such intelligent system which are mainly forecasted on certain factors like reasoning, decision making and acting. The details of new emerging technology, ambient artificial intelligence, its working, architecture and various technologies used to build such efficient system.[1]","",""
15,"M. Klincewicz","Artificial Intelligence as a Means to Moral Enhancement",2016,"","","","",9,"2022-07-13 09:33:13","","10.1515/SLGR-2016-0061","","",,,,,15,2.50,15,1,6,"Abstract This paper critically assesses the possibility of moral enhancement with ambient intelligence technologies and artificial intelligence presented in Savulescu and Maslen (2015). The main problem with their proposal is that it is not robust enough to play a normative role in users’ behavior. A more promising approach, and the one presented in the paper, relies on an artificial moral reasoning engine, which is designed to present its users with moral arguments grounded in first-order normative theories, such as Kantianism or utilitarianism, that reason-responsive people can be persuaded by. This proposal can play a normative role and it is also a more promising avenue towards moral enhancement. It is more promising because such a system can be designed to take advantage of the sometimes undue trust that people put in automated technologies. We could therefore expect a well-designed moral reasoner system to be able to persuade people that may not be persuaded by similar arguments from other people. So, all things considered, there is hope in artificial intelligence for moral enhancement, but not in artificial intelligence that relies solely on ambient intelligence technologies.","",""
24,"Sebastian Bader, P. Hitzler, Steffen Hölldobler","The Integration of Connectionism and First-Order Knowledge Representation and Reasoning as a Challenge for Artificial Intelligence",2004,"","","","",10,"2022-07-13 09:33:13","","","","",,,,,24,1.33,8,3,18,"Intelligent systems based on first-order logic on the one hand, and on artificial neural networks (also called connectionist systems) on the other, differ substantially. It would be very desirable to combine the robust neural networking machinery with symbolic knowledge representation and reasoning paradigms like logic programming in such a way that the strengths of either paradigm will be retained. Current state-of-the-art research, however, fails by far to achieve this ultimate goal. As one of the main obstacles to be overcome we perceive the question how symbolic knowledge can be encoded by means of connectionist systems: Satisfactory answers to this will naturally lead the way to knowledge extraction algorithms and to integrated neural-symbolic systems.","",""
138,"A. Garcez, M. Gori, L. Lamb, L. Serafini, Michael Spranger, S. Tran","Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning",2019,"","","","",11,"2022-07-13 09:33:13","","","","",,,,,138,46.00,23,6,3,"Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.","",""
0,"K. Manikandan, K. Yogeswari, M. Vishnupriya, S. Priya","A Milestone in Artificial Intelligence & Neural Science Cyborg",2015,"","","","",12,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,4,7,"Neural interfacing is a powerful means, which can develop a robust bridge between humans and machines. In this paper we emphasize on neural interfacing as an evolving trend in wireless communications by taking into account one of its important application i.e. cyborgs. In the next half of the paper we discuss the operational features of cyborgs. In an attempt to promote greater interaction between humans and computers, companies that develop cybernetic technologies participate in a variety of seductive strategies that embody the cyborg discourse. Some of these strategies persuade individuals to concede to particular philosophies, such as the argument that technical artifacts and instrumental reasoning are necessary for effective social development. With the experiments conducted and proposed to be conducted in future, and in the process given a brief description of the advantages and disadvantages of this technology.","",""
0,"L. Valiant","How to Augment Learning with Reasoning?",2021,"","","","",13,"2022-07-13 09:33:13","","10.1145/3486622.0000001","","",,,,,0,0.00,0,1,1,"Learning is a cognitive phenomenon that has proved amenable both to theoretical analysis and exploitation as a technology. However, not all of cognition can be accounted for directly by learning. The question we ask here is whether one can build on the success of machine learning to address the broader goals of artificial intelligence. We regard reasoning as the major component of cognition that needs to be added. We suggest that the central challenge therefore is to unify the formulation of these two phenomena, learning and reasoning, into a single framework with a common semantics. In such a framework one would aim to learn rules with the same success that predicates can be learned by means of machine learning, and, at the same time, to reason with the rules with guarantees analogous to those of standard logic. We discuss how Robust Logic fulfils the role of such a theoretical framework. We also discuss the challenges of testing this experimentally on a significant scale, for tasks where one hopes to exceed the performance offered by learning alone.","",""
0,"Ruben Branco, A. Branco, J. Silva, J. Rodrigues","Commonsense Reasoning: \protect \@normalcr how do Neuro-Symbolic and Neuro-only approaches compare?",2021,"","","","",14,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,4,1,"The representation of knowledge is a central task in Artificial Intelligence and has been an active topic of research since the beginnings of the field. Intensive research and labor has been put into producing resources which encode knowledge regarding different topics, structured in suitable formats so as to allow robust, automated reasoning over them. In Natural Language Processing, deep learning models are commonly given unstructured data and seek to learn the necessary knowledge and abstractions required to represent and understand the underlying mechanisms that govern the target language processing tasks. A popular method to address this issue is to expand the training process to include more tasks and data. Yet, it remains one of the challenges of deep learning. In this respect, a promising research path is to combine the rich knowledge encoded in structured resources with deep learning methods, enhancing them with the necessary means to more effectively learn the complexities of the target tasks. In this paper we set out to compare a Neuro-Symbolic model with mainstream Neuro-only models when they are tasked with solving commonsense reasoning problems, which heavily rely on appropriately represented knowledge: commonsense reasoning is an essential part of the human experience, encompassing human values and needs, and by resorting to it, we can organize sensible arguments and decide on effective actions. The results obtained indicate that there is no clear advantage to either approach, with the Neuro-Symbolic model being competitive amongst the Neuro-only models, but not superior.","",""
0,"Ruben Branco, A. Branco, João Silva, J. Rodrigues","Commonsense Reasoning: How do Neuro-Symbolic and Neuro-only Approaches Compare?",2021,"","","","",15,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,4,1,"The representation of knowledge is a central task in Artificial Intelligence and has been an active topic of research since the beginnings of the field. Intensive research and labor has been put into producing resources which encode knowledge regarding different topics, structured in suitable formats so as to allow robust, automated reasoning over them. In Natural Language Processing, deep learning models are commonly given unstructured data and seek to learn the necessary knowledge and abstractions required to represent and understand the underlying mechanisms that govern the target language processing tasks. A popular method to address this issue is to expand the training process to include more tasks and data. Yet, it remains one of the challenges of deep learning. In this respect, a promising research path is to combine the rich knowledge encoded in structured resources with deep learning methods, enhancing them with the necessary means to more effectively learn the complexities of the target tasks. In this paper we set out to compare a Neuro-Symbolic model with mainstream Neuro-only models when they are tasked with solving commonsense reasoning problems, which heavily rely on appropriately represented knowledge: commonsense reasoning is an essential part of the human experience, encompassing human values and needs, and by resorting to it, we can organize sensible arguments and decide on effective actions. The results obtained indicate that there is no clear advantage to either approach, with the Neuro-Symbolic model being competitive amongst the Neuro-only models, but not superior.","",""
0,"Kaiyu Yang","1 Machine Learning for Reasoning",2021,"","","","",16,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,1,"Reasoning is a core component of human intelligence that machines still struggle with. I do research in the field of artificial intelligence, with the long-term goal of building machines that reason precisely, systematically, in ways that are interpretable and robust to ambiguity in real-world environments. My research advances towards this goal by attempting to combine the complementary strengths of machine learning and symbolic reasoning. My graduate research has focused on developing machine learning models that represent reasoning via symbolic proofs. They show the promise of new learning paradigms that I envision to be more robust, interpretable, and trustworthy for deployment in real-world high-stake applications. Symbolic reasoning is precise and generalizes systematically to unseen scenarios. But it has been restricted to domains amenable to rigid formalization. In contrast, machine learning has the flexibility to handle noisy and ambiguous domains that are hard to formalize. But predominant machine learning models, such as deep neural networks, are notoriously uninterpretable, data-hungry, and incapable of generalizing outside the training data distribution. Integrating the strengths of both approaches is essential for building flexible reasoning machines with precise and systematic generalization. However, due to the discrete nature of symbolic reasoning, such integration may require a radical departure from the predominant paradigm of gradient-based learning. And my research tries to answer what that alternative form of learning might look like.","",""
2,"B. Dorr, Lucian Galescu, E. Golob, K. Venable, Y. Wilks","Companion-Based Ambient Robust Intelligence (CARING)",2015,"","","","",17,"2022-07-13 09:33:13","","","","",,,,,2,0.29,0,5,7,"We present a Companion-based Ambient Robust INtelliGence (CARING) system, for communication with, and support of, clients with Traumatic brain injury (TBI) or Amyotrophic Lateral Sclerosis (ALS). A central component of this system is an artificial companion, combined with a range of elements for ambient intelligence. The companion acts as a personalized intermediary for multi-party communication between the client, the environment (e.g. a Smart Home), caregivers and health professionals. CARING is based on tightly coupled systems drawing from natural language processing, speech recognition and adaptation, deep language understanding and constraintbased knowledge representation and reasoning. A major innovation of the system is its ability to adapt and accommodate different interfaces associated with different client capabilities and needs. The system will use, as a proxy, different interaction requirements of clients (e.g., Brain-Computer Interfaces) at different stages of ALS progression and with different types of TBI impairments. Ultimately, this technology is expected to improve the quality of life for clients through conversation with a computer.","",""
4,"Ao Luo, F. Yang, Kunming Luo, Xin Li, Haoqiang Fan, Shuaicheng Liu","Learning Optical Flow with Adaptive Graph Reasoning",2022,"","","","",18,"2022-07-13 09:33:13","","10.1609/aaai.v36i2.20083","","",,,,,4,4.00,1,6,1,"Estimating per-pixel motion between video frames, known as optical flow, is a long-standing problem in video understanding and analysis. Most contemporary optical flow techniques largely focus on addressing the cross-image matching with feature similarity, with few methods considering how to explicitly reason over the given scene for achieving a holistic motion understanding. In this work, taking a fresh perspective, we introduce a novel graph-based approach, called adaptive graph reasoning for optical flow (AGFlow), to emphasize the value of scene/context information in optical flow. Our key idea is to decouple the context reasoning from the matching procedure, and exploit scene information to effectively assist motion estimation by learning to reason over the adaptive graph. The proposed AGFlow can effectively exploit the context information and incorporate it within the matching procedure, producing more robust and accurate results. On both Sintel clean and final passes, our AGFlow achieves the best accuracy with EPE of 1.43 and 2.47 pixels, outperforming state-of-the-art approaches by 11.2% and 13.6%, respectively. Code is publicly available at https://github.com/megvii-research/AGFlow.","",""
11,"L. Eliot","An Ontological AI-and-Law Framework for the Autonomous Levels of AI Legal Reasoning",2020,"","","","",19,"2022-07-13 09:33:13","","","","",,,,,11,5.50,11,1,2,"A framework is proposed that seeks to identify and establish a set of robust autonomous levels articulating the realm of Artificial Intelligence and Legal Reasoning (AILR). Doing so provides a sound and parsimonious basis for being able to assess progress in the application of AI to the law, and can be utilized by scholars in academic pursuits of AI legal reasoning, along with being used by law practitioners and legal professionals in gauging how advances in AI are aiding the practice of law and the realization of aspirational versus achieved results. A set of seven levels of autonomy for AI and Legal Reasoning are meticulously proffered and mindfully discussed.","",""
9,"R. Das, Ameya Godbole, S. Dhuliawala, M. Zaheer, A. McCallum","A Simple Approach to Case-Based Reasoning in Knowledge Bases",2020,"","","","",20,"2022-07-13 09:33:13","","10.24432/C52S3K","","",,,,,9,4.50,2,5,2,"We present a surprisingly simple yet accurate approach to reasoning in knowledge graphs (KGs) that requires \emph{no training}, and is reminiscent of case-based reasoning in classical artificial intelligence (AI).  Consider the task of finding a target entity given a source entity and a binary relation.  Our approach finds multiple \textit{graph path patterns} that connect similar source entities through the given relation, and looks for pattern matches starting from the query source.  Using our method, we obtain new state-of-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122.  We also demonstrate that our model is robust in low data settings, outperforming recently proposed meta-learning approaches.","",""
2,"C. Lim, C. Abeynayake, M. Sato-Ilic, L. Jain","Special issue: Computational intelligence models for image processing and information reasoning",2013,"","","","",21,"2022-07-13 09:33:13","","10.3233/IFS-2012-0546","","",,,,,2,0.22,1,4,9,"Computational Intelligence CI models comprise robust computing methodologies with a high level of machine learning quotient. CI models, in general, are useful for designing computerized intelligent systems/machines that possess useful characteristics mimicking human behaviors and capabilities in solving complex tasks, e.g., learning, adaptation, and evolution. Examples of some popular CI models include fuzzy systems, artificial neural networks, evolutionary algorithms, multi-agent systems, decision trees, rough set theory, knowledge-based systems, and hybrid of these models. This special issue highlights how different computational intelligence models, coupled with other complementary techniques, can be used to handle problems encountered in image processing and information reasoning.","",""
4,"M. Gates, Mukesh Ambani","Non-Parametric Reasoning on Knowledge Bases",2020,"","","","",22,"2022-07-13 09:33:13","","","","",,,,,4,2.00,2,2,2,"We present a surprisingly simple yet accurate approach to reasoning in knowledge graphs (KGs) that requires no training, and is reminiscent of case-based reasoning in classical artificial intelligence (AI). Consider the task of finding a target entity given a source entity and a binary relation. Our approach finds multiple graph path patterns that connect similar source entities through the given relation, and looks for pattern matches starting from the query source. Using our method, we obtain new state-of-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122. We also demonstrate that our model is robust in low data settings, outperforming recently proposed meta-learning approaches.","",""
39,"Kecheng Zheng, Zhengjun Zha, Wei Wei","Abstract Reasoning with Distracting Features",2019,"","","","",23,"2022-07-13 09:33:13","","","","",,,,,39,13.00,13,3,3,"Abstraction reasoning is a long-standing challenge in artificial intelligence. Recent studies suggest that many of the deep architectures that have triumphed over other domains failed to work well in abstract reasoning. In this paper, we first illustrate that one of the main challenges in such a reasoning task is the presence of distracting features, which requires the learning algorithm to leverage counter-evidence and to reject any of false hypothesis in order to learn the true patterns. We later show that carefully designed learning trajectory over different categories of training data can effectively boost learning performance by mitigating the impacts of distracting features. Inspired this fact, we propose feature robust abstract reasoning (FRAR) model, which consists of a reinforcement learning based teacher network to determine the sequence of training and a student network for predictions. Experimental results demonstrated strong improvements over baseline algorithms and we are able to beat the state-of-the-art models by 18.7\% in RAVEN dataset and 13.3\% in the PGM dataset.","",""
0,"Gasmi Safa, Djebbar Akila, Merouani Hayet Farida","A Survey on Hybrid Case-Based Reasoning and Deep Learning Systems for Medical Data Classification",2022,"","","","",24,"2022-07-13 09:33:13","","10.4018/978-1-7998-9016-4.ch006","","",,,,,0,0.00,0,3,1,"Several artificial intelligence approaches, particularly case-based reasoning (CBR), which is analogous to the context of human reasoning for problem resolution, have demonstrated their efficiency and reliability in the medical field. In recent years, deep learning represents the latest iteration of an advance in artificial intelligence technologies in medicine to aid in data classification, diagnosis of new diseases, and complex decision-making. Although these two independent approaches have good results in the medical field, the latter is still a complex field. This chapter reviews the available literature on CBR systems, deep learning systems, and CBR deep learning systems in medicine. The methods used and results obtained are discussed, and key findings are highlighted. Further, in the light of this review, some directions for future research are given. This chapter presents the proposed approach, which helps to make the retrieval phase of the CBR cycle more reliable and robust.","",""
1,"F. Fabiano","Towards a Complete Characterization of Epistemic Reasoning: the Notion of Trust",2020,"","","","",25,"2022-07-13 09:33:13","","","","",,,,,1,0.50,1,1,2,"Designing autonomous agents, that interact with others to perform complex tasks, has always been one of the main objective of the Artificial Intelligence community. For such systems to be employed in complex scenarios, where the information about others is key (e.g., self-driving cars), it is necessary to define robust formalisms that allow each agent to act considering her beliefs on both: i) the state of the world; and ii) the other agents’ perspective of it. The branch of AI that studies such formalisms is known in literature as Multi-Agent Epistemic Planning (MEP). The epistemic action-based language mA, to the best of our knowledge, is the most comprehensive tool to model MEP domains but still lacks concepts that are necessary to reason on real-world scenarios. In this paper we introduce the actions (un)trustworthy announcement and (mis)trustworthy announcement for mA. These actions increase the language’s expressiveness introducing the notion of trust, therefore allowing for a more profound representation of real-world scenarios. In particular, we will provide the characterization, along with some desired properties, of the aforementioned actions’ transition functions. Finally, we will discuss the importance of formalizing the concept of trust in the MEP problem.","",""
1,"M. Bhatt, C. Freksa","Analytical Computing for Spatial Design: An Artificial Intelligence Perspective",2012,"","","","",26,"2022-07-13 09:33:13","","","","",,,,,1,0.10,1,2,10,"Next-generation people-centred design systems, frameworks, assistive tools, educational aids, and design policies necessitate foundational abstraction and computational building blocks where the modalities of human perception, action, environmental experience, and design conception and semantics are central. Our research in this context addresses the following questions: – Contemporary CAAD tools provide robust geometric modeling methods; how can the future evolution of design computing bring notions of design semantics, structure, function, and peoplecentred design to the fore at an ontological, representational and computational level? – What is the role of specialized forms of visuo-spatial perception, abstraction, and commonsense spatial reasoning, within the broader realm of design computing, spatial design assistance, and tools for design learning and education? – What is the nature and form of the assistive design feedback that designers and planners expect during the early design conception and iterative refinement phase? What are the implications of this from the viewpoint of the usability, interface, and interaction design aspects of spatial design (assistance) systems? This article presents an overview of the above stated aspects in the backdrop of relevant examples; we present abstraction, representation, and reasoning problems involving the formal modelling of structural form with respect to a desired / anticipated artefactual (mal)function. The discussion is grounded in the domain of assistive decision-support for computer-aided architecture design. Our methods are essentially AI-centric, i.e., we relate most directly with the articulation of the Science of Design by Herbert Simon and the paradigmatic relevance of Artificial Intelligence in that context.","",""
79,"Stefan Zwicklbauer, C. Seifert, M. Granitzer","Robust and Collective Entity Disambiguation through Semantic Embeddings",2016,"","","","",27,"2022-07-13 09:33:13","","10.1145/2911451.2911535","","",,,,,79,13.17,26,3,6,"Entity disambiguation is the task of mapping ambiguous terms in natural-language text to its entities in a knowledge base. It finds its application in the extraction of structured data in RDF (Resource Description Framework) from textual documents, but equally so in facilitating artificial intelligence applications, such as Semantic Search, Reasoning and Question & Answering. We propose a new collective, graph-based disambiguation algorithm utilizing semantic entity and document embeddings for robust entity disambiguation. Robust thereby refers to the property of achieving better than state-of-the-art results over a wide range of very different data sets. Our approach is also able to abstain if no appropriate entity can be found for a specific surface form. Our evaluation shows, that our approach achieves significantly (>5%) better results than all other publicly available disambiguation algorithms on 7 of 9 datasets without data set specific tuning. Moreover, we discuss the influence of the quality of the knowledge base on the disambiguation accuracy and indicate that our algorithm achieves better results than non-publicly available state-of-the-art algorithms.","",""
12,"D. Bamber, I. Goodman, H. Nguyen","Robust reasoning with rules that have exceptions: From second-order probability to argumentation via upper envelopes of probability and possibility plus directed graphs",2005,"","","","",28,"2022-07-13 09:33:13","","10.1007/s10472-005-9008-8","","",,,,,12,0.71,4,3,17,"","",""
1,"V. Torra, Yasuo Nakamura, 宮本 定明","Modeling Decisions for Artificial Intelligence, Second International Conference, MDAI 2005, Tsukuba, Japan, July 25-27, 2005, Proceedings",2005,"","","","",29,"2022-07-13 09:33:13","","10.1007/978-3-540-31883-5","","",,,,,1,0.06,0,3,17,"","",""
2,"C. Bento, A. Cardoso, G. Dias","Progress in Artificial Intelligence, 12th Portuguese Conference on Artificial Intelligence, EPIA 2005, Covilhã, Portugal, December 5-8, 2005, Proceedings",2006,"","","","",30,"2022-07-13 09:33:13","","10.1007/11595014","","",,,,,2,0.13,1,3,16,"","",""
2,"Moonis Ali, B. Whitehead, U. Gupta, H. Ferber","Identification and interpretation of patterns in rocket engine data: Artificial intelligence and neural network approaches",1995,"","","","",31,"2022-07-13 09:33:13","","","","",,,,,2,0.07,1,4,27,"This paper describes an expert system which is designed to perform automatic data analysis, identify anomalous events, and determine the characteristic features of these events. We have employed both artificial intelligence and neural net approaches in the design of this expert system. The artificial intelligence approach is useful because it provides (1) the use of human experts' knowledge of sensor behavior and faulty engine conditions in interpreting data; (2) the use of engine design knowledge and physical sensor locations in establishing relationships among the events of multiple sensors; (3) the use of stored analysis of past data of faulty engine conditions; and (4) the use of knowledge-based reasoning in distinguishing sensor failure from actual faults. The neural network approach appears promising because neural nets (1) can be trained on extremely noisy data and produce classifications which are more robust under noisy conditions than other classification techniques; (2) avoid the necessity of noise removal by digital filtering and therefore avoid the need to make assumptions about frequency bands or other signal characteristics of anomalous behavior; (3) can, in effect, generate their own feature detectors based on the characteristics of the sensor data used in training; and (4) are inherently parallel and therefore are potentially implementable in special-purpose parallel hardware.","",""
0,"I. Wachsmuth, Claus-Rainer Rollinger, W. Brauer","KI-95: Advances in Artificial Intelligence: 19th Annual German Conference on Artificial Intelligence, Bielefeld, Germany, September 11 - 13, 1995. Proceedings",1995,"","","","",32,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,3,27,"Partially observable Markov decision processes for artificial intelligence.- Robust processing of natural language.- Distinction networks.- The problem of signal and symbol integration: A study of cooperative mobile autonomous agent behaviors.- An extension of explanation-based generalization to negation as failure.- Inducing integrity constraints from knowledge bases.- Dynamic structuring of lexical knowledge in a reusability scenario.- Efficient memory-limited graph search.- Quality-based terminological reasoning for concept learning.- Task acquisition with a description logic reasoner.- Parallelizing description logics.- Automated termination proofs with measure functions.- What is a skeptical proof?.- Default entailment.- Actions that make you change your mind.- Reasoning about action with typical and atypical effects.- Reasoning about action and change: Actions with abnormal effects.- Temporal logic based on characteristic functions.- Computational properties of qualitative spatial reasoning: First results.- An empirically validated model for computing spatial relations.- Integrating vision and language: Towards automatic description of human movements.","",""
5,"A. Ralescu","Fuzzy Logic in Artificial Intelligence Ijcai '93 Workshop, Chamberry, France, August 28, 1993 : Proceedings",1994,"","","","",33,"2022-07-13 09:33:13","","","","",,,,,5,0.18,5,1,28,"Fuzzy reinforcement Learning and dynamic programming.- Fuzzy sets, fuzzy clustering and fuzzy rules in AI.- Robust execution of robot plans using fuzzy logic.- Fuzzy logic, inductive and analogical reasoning.- Possibility theory, belief revision and nonmonotonic logic.- Querying a database with fuzzy attribute values by iterative updating of the selection criteria.- Learning fuzzy membership functions in a function-based object recognition system.- A factor space approach to concept representation.- Connectionist fuzzy production systems.","",""
2,"B. Orchard, Chunsheng Yang, Moonis Ali","Innovations in applied artificial intelligence : 17th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, IEA/AIE 2004, Ottawa, Canada, May 17-20, 2004 : proceedings",2004,"","","","",34,"2022-07-13 09:33:13","","","","",,,,,2,0.11,1,3,18,"Invited Contributions.- Applications of Knowledge Discovery.- Spoken Language Communication with Machines: The Long and Winding Road from Research to Business.- Computer Vision.- Motion-Based Stereovision Method with Potential Utility in Robot Navigation.- Object Tracking Using Mean Shift and Active Contours.- Place Recognition System from Long-Term Observations.- Real-Time People Localization and Tracking Through Fixed Stereo Vision.- Face Recognition by Kernel Independent Component Analysis.- Head Detection of the Car Occupant Based on Contour Models and Support Vector Machines.- A Morphological Proposal for Vision-Based Path Planning.- A New Video Surveillance System Employing Occluded Face Detection.- Image Analysis.- Intelligent Vocal Cord Image Analysis for Categorizing Laryngeal Diseases.- Keyword Spotting on Hangul Document Images Using Two-Level Image-to-Image Matching.- Robust Character Segmentation System for Korean Printed Postal Images.- Speech Recognition.- Case Based Reasoning Using Speech Data for Clinical Assessment.- Feature-Table-Based Automatic Question Generation for Tree-Based State Tying: A Practical Implementation.- Speeding Up Dynamic Search Methods in Speech Recognition.- Robotics.- Conscious Robot That Distinguishes Between Self and Others and Implements Imitation Behavior.- Distance-Based Dynamic Interaction of Humanoid Robot with Multiple People.- Movement Prediction from Real-World Images Using a Liquid State Machine.- Robot Competition Using Gesture Based Interface.- Agents.- Agent Support for a Grid-Based High Energy Physics Application.- Feasibility of Multi-agent Simulation for the Trust and Tracing Game.- Multi-agent Support for Distributed Engineering Design.- Reliable Multi-agent Systems with Persistent Publish/Subscribe Messaging.- A Strategy-Proof Mechanism Based on Multiple Auction Support Agents.- Automated Teleoperation of Web-Based Devices Using Semantic Web Services.- Context Awarable Self-configuration System for Distributed Resource Management.- A Decision Support System for Inventory Control Using Planning and Distributed Agents.- Planning.- Controlling Complex Physical Systems Through Planning and Scheduling Integration.- Plan Execution in Dynamic Environments.- Structural Advantages for Ant Colony Optimisation Inherent in Permutation Scheduling Problems.- Incrementally Scheduling with Qualitative Temporal Information.- New Upper Bounds for the Permutation Flowshop Scheduling Problem.- R-Tree Representations of Disaster Areas Based on Probabilistic Estimation.- Human-Computer Interaction and Natural Language Processing.- AI/NLP Technologies Applied to Spacecraft Mission Design.- Automatic Word Spacing in Korean for Small Memory Devices.- Generating Personalized Tourist Map Descriptions.- Haptic Fruition of 3D Virtual Scene by Blind People.- Ontology-Based Natural Language Parser for E-Marketplaces.- Towards Effective Adaptive Information Filtering Using Natural Language Dialogs and Search-Driven Agents.- Towards Minimization of Test Sets for Human-Computer Systems.- Discovering Learning Paths on a Domain Ontology Using Natural Language Interaction.- A Geometric Approach to Automatic Description of Iconic Scenes.- Man-Machine Interface of a Support System for Analyzing Open-Ended Questionnaires.- Reasoning.- A Holistic Approach to Test-Driven Model Checking.- Inferring Definite-Clause Grammars to Express Multivariate Time Series.- Obtaining a Bayesian Map for Data Fusion and Failure Detection Under Uncertainty.- Event Handling Mechanism for Retrieving Spatio-temporal Changes at Various Detailed Level.- Fault Localization Based on Abstract Dependencies.- Freeway Traffic Qualitative Simulation.- LEADSTO: A Language and Environment for Analysis of Dynamics by SimulaTiOn.- Prediction-Based Diagnosis and Loss Prevention Using Model-Based Reasoning.- Machine Learning.- An Algorithm Based on Counterfactuals for Concept Learning in the Semantic Web.- Classification of Ophthalmologic Images Using an Ensemble of Classifiers.- Comparison of Extreme Learning Machine with Support Vector Machine for Text Classification.- Endoscopy Images Classification with Kernel Based Learning Algorithms.- Local Bagging of Decision Stumps.- Methods for Classifying Spot Welding Processes: A Comparative Study of Performance.- Minimum Spanning Trees in Hierarchical Multiclass Support Vector Machines Generation.- One-Class Classifier for HFGWR Ship Detection Using Similarity-Dissimilarity Representation.- Improving the Readability of Decision Trees Using Reduced Complexity Feature Extraction.- Intelligent Bayesian Classifiers in Network Intrusion Detection.- Data Mining.- Analyzing Multi-level Spatial Association Rules Through a Graph-Based Visualization.- Data Mining for Decision Support: An Application in Public Health Care.- A Domain-Independent Approach to Discourse-Level Knowledge Discovery from Texts.- An Efficient Subsequence Matching Method Based on Index Interpolation.- A Meteorological Conceptual Modeling Approach Based on Spatial Data Mining and Knowledge Discovery.- Mining Generalized Association Rules on Biomedical Literature.- Mining Information Extraction Rules from Datasheets Without Linguistic Parsing.- An Ontology-Supported Data Preprocessing Technique for Real-Life Databases.- Genetic Algorithms.- A Fuzzy Genetic Algorithm for Real-World Job Shop Scheduling.- Pareto-Optimal Hardware for Digital Circuits Using SPEA.- Application of a Genetic Algorithm to Nearest Neighbour Classification.- Applying Genetic Algorithms for Production Scheduling and Resource Allocation. Special Case: A Small Size Manufacturing Company.- An Efficient Genetic Algorithm for TSK-Type Neural Fuzzy Identifier Design.- Hardware Architecture for Genetic Algorithms.- Node-Depth Encoding for Evolutionary Algorithms Applied to Multi-vehicle Routing Problem.- Novel Approach to Optimize Quantitative Association Rules by Employing Multi-objective Genetic Algorithm.- Neural Networks.- GMDH-Type Neural Network Modeling in Evolutionary Optimization.- Predicting Construction Litigation Outcome Using Particle Swarm Optimization.- Self-organizing Radial Basis Function Network Modeling for Robot Manipulator.- A SOM Based Approach for Visualization of GSM Network Performance Data.- Using an Artificial Neural Network to Improve Predictions of Water Levels Where Tide Charts Fail.- Canonical Decision Model Construction by Extracting the Mapping Function from Trained Neural Networks.- Detecting Fraud in Mobile Telephony Using Neural Networks.- An Intelligent Medical Image Understanding Method Using Two-Tier Neural Network Ensembles.- Decision Support and Heuristic Search.- The Coordination of Parallel Search with Common Components.- A Decision Support Tool Coupling a Causal Model and a Multi-objective Genetic Algorithm.- Emergent Restructuring of Resources in Ant Colonies: A Swarm-Based Approach to Partitioning.- The Probabilistic Heuristic In Local (PHIL) Search Meta-strategy.- Search on Transportation Network for Location-Based Service.- A Specification Language for Organisational Performance Indicators.- A New Crowded Comparison Operator in Constrained Multiobjective Optimization for Capacitors Sizing and Siting in Electrical Distribution Systems.- A Two-Phase Backbone-Based Search Heuristic for Partial MAX-SAT - An Initial Investigation.- Fuzzy Logic.- An Algorithm for Peer Review Matching Using Student Profiles Based on Fuzzy Classification and Genetic Algorithms.- Pose-Invariant Face Detection Using Edge-Like Blob Map and Fuzzy Logic.- A Fuzzy Logic-Based Approach for Detecting Shifting Patterns in Cross-Cultural Data.- Minimal Knowledge Anonymous User Profiling for Personalized Services.- Knowledge Management.- Formal Goal Generation for Intelligent Control Systems.- MoA: OWL Ontology Merging and Alignment Tool for the Semantic Web.- Optimizing RDF Storage Removing Redundancies: An Algorithm.- Complementing Search Engines with Text Mining.- A Decision Support Approach to Modeling Trust in Networked Organizations.- An Integrated Approach to Rating and Filtering Web Content.- Applications.- Collaborative Case-Based Preference Elicitation.- Complex Knowledge in the Environmental Domain: Building Intelligent Architectures for Water Management.- An Expert System for the Oral Anticoagulation Treatment.- Formal Verification of Control Software: A Case Study.- GRAPE: An Expert Review Assignment Component for Scientific Conference Management Systems.- A Nurse Scheduling System Based on Dynamic Constraint Satisfaction Problem.- A Semi-autonomous Wheelchair with HelpStar.- ST-Modal Logic to Correlate Traffic Alarms on Italian Highways: Project Overview and Example Installations.- Train Rescheduling Algorithm Which Minimizes Passengers' Dissatisfaction.- Case-Based Reasoning for Financial Prediction.- The Generation of Automated Learner Feedback Based on Individual Proficiency Levels.- A Geographical Virtual Laboratory for the Recomposition of Fragments.- A Meta-level Architecture for Strategic Reasoning in Naval Planning.- A Support Method for Qualitative Simulation-Based Learning System.","",""
2,"B. Nebel, L. Dreschler-Fischer","KI-94 : advances in artificial intelligence : 18th German Annual Conference on Artificial Intelligence, Saarbrücken, Germany, September 18-23, 1994 : proceedings",1994,"","","","",35,"2022-07-13 09:33:13","","","","",,,,,2,0.07,1,2,28,"AI approaches towards sensor-based driver support in road vehicles.- Representing concurrent actions and solving conflicts.- Preselection strategies for case based classification.- Utilizing spatial relations for natural language access to an autonomous mobile robot.- Cardinality restrictions on concepts.- An artificial neural network for high precision eye movement tracking.- A Kripke-Kleene logic over general logic programs.- The stable semantics and its variants: A comparison of recent approaches.- TabVer a case study in table verbalization.- Cooperating to be noncooperative: The dialog system PRACMA.- Robust constructive induction.- Enriching a semantic network language by integrating qualitative reasoning techniques.- Combining spatial and terminological reasoning.- Detecting gestalts in CAD-plans to be used as indices for case-retrieval in architecture.- The NeuDB-system: Towards the integration of neural networks and database systems.- Weighted defaults in description logics: Formal properties and proof theory.- Epistemic queries in Classic.- Communicating rational agents.- Knowledge-level modularization of a complex knowledge base.- Program verification techniques as a tool for reasoning about action and change.- A conditional logic for updating in the possible models approach.- Probabilistic justification of default reasoning.- A prioritized Contextual Default Logic: Curing anomalous extensions with a simple abnormality default theory.- Incorporating specificity into circumscriptive theories.- Coherent choice and epistemic entrenchment (preliminary report).- A note on tableaux of logic of paradox.- When nonmonotonicity comes from distances.- Rigid unification by completion and rigid paramodulation.- Unification in a sorted ?-calculus with term declarations and function sorts.- Goal oriented equational theorem proving using team work.- The hardest random SAT problems.- Formal methods for automated program improvement.- Adapting methods to novel tasks in proof planning.- Using charts for transfer in MT.- A new frame for common-sense reasoning - Towards local inconsistencies.- Prioritized transitions for updates.- An optimal bidirectional search algorithm.- Learning to discriminate phases in gas-liquid flow.- Strategies for semantical contractions.- Conflicts in the spatial interaction of autonomous agents.- Using rough sets theory to predict German word stress.- Graphtheoretical algorithms and knowledge-based design.- Interval situation calculus.","",""
0,"I. Vlahavas, C. Spyropoulos","Methods and Applications of Artificial Intelligence : Second Hellenic Conference on AI, SETN 2002, Thessaloniki, Greece, April 11-12, 2002 : proceedings /Ioannis P. Vlahavas, Constantine D. Spyropoulos (eds.)",2002,"","","","",36,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,2,20,"Invited Talks.- Understanding the Internet.- Agent-Oriented Software Development.- Knowledge Representation & Reasoning.- The Ramification and Qualification Problems in Temporal Databases.- Multi-inference with Multi-neurules.- Decision Making Based on Past Problem Cases.- Logic Programming & Constraint Satisfaction.- Relating Defeasible Logic to Extended Logic Programs.- On Algorithms for Decomposable Constraints.- Cspcons: A Communicating Sequential Prolog with Constraints.- Genetic Evolution of Software Microorganisms.- Planning & Scheduling.- A Probabilistic Approach to Robust Execution of Temporal Plans with Uncertainty.- Crew Pairing Optimization with Genetic Algorithms.- Integration of Topological and Metric Maps for Indoor Mobile Robot Path Planning and Navigation.- Natural Language Processing.- Symbolic Authoring for Multilingual Natural Language Generation.- A User-Sensitive Spoken Dialogue System Incorporating Emotional Responsiveness.- Transforming Spontaneous Telegraphic Language to Well-Formed Greek Sentences for Alternative and Augmentative Communication.- Role Identification from Free Text Using Hidden Markov Models.- Human-Computer Interaction.- Improving SMS Usability Using Bayesian Networks.- Fuzzy Inference for Student Diagnosis in Adaptive Educational Hypermedia.- MultiCAD-GA: A System for the Design of 3D Forms Based on Genetic Algorithms and Human Evaluation.- Intelligent Semantic Access to Audiovisual Content.- Machine Learning.- A Multi-clustering Fusion Algorithm.- Distance and Feature-Based Clustering of Time Series: An Application on Neurophysiology.- Least-Squares Methods in Reinforcement Learning for Control.- Knowledge Discovery.- Association Rules & Evolution in Time.- Managing Uncertainty and Quality in the Classification Process.- The Role of Domain Knowledge in a Large Scale Data Mining Project.- Neural Networks.- Artificial Neural Network Learning: A Comparative Review.- Piecewise Neural Networks for Function Approximation, Cast in a Form Suitable for Parallel Computation.- Using Hopfield Networks to Solve Assignment Problem and N-Queen Problem: An Application of Guided Trial and Error Technique.- A Bayesian Regularization Method for the Probabilistic RBF Network.- Pattern Recognition.- Support Vector Machines with Clustering for Training with Very Large Datasets.- A Temporal Network of Support Vector Machine Classifiers for the Recognition of Visual Speech.- Fuzzy Stochastic Automata for Reactive Learning and Hybrid Control.- Machine Vision.- Overview of Wave Probe-Based High-Resolution Subsurface Sensing, Imaging, and Vision.- 3D Volume Reconstruction by Serially Acquired 2D Slices Using a Distance Transform-Based Global Cost Function.- Definition and Extraction of Visual Landmarks for Indoor Robot Navigation.- Factors Affecting the Accuracy of an Active Vision Head.- Intelligent Internet & Multiagent Systems.- Query Translation for Mediators over Ontology-Based Information Sources.- Intelligent Querying of Web Documents Using a Deductive XML Repository.- Roles in Collaborative Activity.- Formal Modelling of Reactive Agents as an Aggregation of Simple Behaviours.- Intelligent Applications.- On the Application of Artificial Intelligence Techniques to the Quality Improvement of Industrial Processes.- Using Non-uniform Crossover in Genetic Algorithm Methods to Speed up the Generation of Test Patterns for Sequential Circuits.- Hybrid Computational Intelligence Schemes in Complex Domains: An Extended Review.","",""
1,"S. Tran","Propositional Knowledge Representation and Reasoning in Restricted Boltzmann Machines.",2017,"","","","",37,"2022-07-13 09:33:13","","","","",,,,,1,0.20,1,1,5,"While knowledge representation and reasoning are considered the keys for human-level artificial intelligence, connectionist networks have been shown successful in a broad range of applications due to their capacity for robust learning and flexible inference under uncertainty. The idea of representing symbolic knowledge in connectionist networks has been well-received and attracted much attention from research community as this can establish a foundation for integration of scalable learning and sound reasoning. In previous work, there exist a number of approaches that map logical inference rules with feed-forward propagation of artificial neural networks (ANN). However, the discriminative structure of an ANN requires the separation of input/output variables which makes it difficult for general reasoning where any variables should be inferable. Other approaches address this issue by employing generative models such as symmetric connectionist networks, however, they are difficult and convoluted. In this paper we propose a novel method to represent propositional formulas in restricted Boltzmann machines which is less complex, especially in the cases of logical implications and Horn clauses. An integration system is then developed and evaluated in real datasets which shows promising results.","",""
51,"A. Garcez, L. Lamb","Neurosymbolic AI: The 3rd Wave",2020,"","","","",38,"2022-07-13 09:33:13","","","","",,,,,51,25.50,26,2,2,"Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.","",""
0,"Stefan Zwicklbauer","Robust Entity Linking in Heterogeneous Domains",2017,"","","","",39,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,5,"Entity Linking is the task of mapping terms in arbitrary documents to entities in a knowledge base by identifying the correct semantic meaning. It is applied in the extraction of structured data in RDF (Resource Description Framework) from textual documents, but equally so in facilitating artificial intelligence applications, such as Semantic Search, Reasoning and Question and Answering. Most existing Entity Linking systems were optimized for specific domains (e.g., general domain, biomedical domain), knowledge base types (e.g., DBpedia, Wikipedia), or document structures (e.g., tables) and types (e.g., news articles, tweets). This led to very specialized systems that lack robustness and are only applicable for very specific tasks. In this regard, this work focuses on the research and development of a robust Entity Linking system in terms of domains, knowledge base types, and document structures and types.    To create a robust Entity Linking system, we first analyze the following three crucial components of an Entity Linking algorithm in terms of robustness criteria: (i) the underlying knowledge base, (ii) the entity relatedness measure, and (iii) the textual context matching technique. Based on the analyzed components, our scientific contributions are three-fold. First, we show that a federated approach leveraging knowledge from various knowledge base types can significantly improve robustness in Entity Linking systems. Second, we propose a new state-of-the-art, robust entity relatedness measure for topical coherence computation based on semantic entity embeddings. Third, we present the neural-network-based approach Doc2Vec as a textual context matching technique for robust Entity Linking.    Based on our previous findings and outcomes, our main contribution in this work is DoSeR (Disambiguation of Semantic Resources). DoSeR is a robust, knowledge-base-agnostic Entity Linking framework that extracts relevant entity information from multiple knowledge bases in a fully automatic way. The integrated algorithm represents a collective, graph-based approach that utilizes semantic entity and document embeddings for entity relatedness and textual context matching computation. Our evaluation shows, that DoSeR achieves state-of-the-art results over a wide range of different document structures (e.g., tables), document types (e.g., news documents) and domains (e.g., general domain, biomedical domain). In this context, DoSeR outperforms all other (publicly available) Entity Linking algorithms on most data sets.","",""
0,"A. J. Spiessbach","Task -specific knowledge by itself, however, is not sufficient to achieve robust machine perception in unrestricted, uncontrolled, or noncooperativ e environments. A higher -level",2017,"","","","",40,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,5,"Extending the recent successes demonstrated by artificial intelligence expert system technology to the broader domain of scene analysis necessitates a consequent broadening of the concepts and techniques used in current systems. Simple, single mechanisms must give way to multiple lines of reasoning and multiple levels of description. Meta -level reasoning, which is a recursive application of the basic expert system paradigm, is a promising approach to the problem of coping with the complexity inherent in highly variable, dynamic environments. This paper describes research directed towards incorporating meta level reasoning into context -based scene analysis systems. A multi -layered expert system architecture is outlined that is aimed at providing high -level strategies and dynamic planning capability to the basic image understanding process.","",""
3,"Javier Viaña, Kelly Cohen","Extension to Multidimensional Problems of a Fuzzy- based Explainable & Noise-Resilient Algorithm",2021,"","","","",41,"2022-07-13 09:33:13","","","","",,,,,3,3.00,2,2,1,"While Deep Neural Networks (DNNs) have shown incredible performance in a variety of data, they are brittle and opaque: easily fooled by the presence of noise, and difficult to understand the underlying reasoning for their predictions or choices. This focus on accuracy at the expense of interpretability and robustness caused little concern since, until recently, DNNs were employed primarily for scientific and limited commercial work. An increasing, widespread use of artificial intelligence and growing emphasis on user data protections, however, motivates the need for robust solutions with explainable methods and results. In this work, we extend a novel fuzzy based algorithm for regression to multidimensional problems. Previous research demonstrated that this approach outperforms neural network benchmarks while using only 5% of the number of the parameters.","",""
0,"Vandana Jindal, P. K. Jain","Case-Based Reasoning and Learning Systems",2016,"","","","",42,"2022-07-13 09:33:13","","10.18701/imsmanthan.v12i01.10342","","",,,,,0,0.00,0,2,6,"Case based reasoning (CBR) technology presents a foundation for a new technology of building intelligent systems for teaching, learning and training. This Technology directly addresses the problems found in the traditional artificial intelligence (AI) techniques, e.g. the problems of knowledge acquisition, remembering, robust and maintenance. This paper discusses the CBR methodology, the research issues and technical aspects of implementing effective intelligent e-learning systems. Some examples of successful applications in different domain are also given in the paper.","",""
0,"Weijie Kang, Junjie Xue, Jiyang Xiao, Haizhen Zhu, Jianfeng Li, Changjun Li","Multimode Generative Adversarial Networks for Sequence Data Generation",2021,"","","","",43,"2022-07-13 09:33:13","","10.1088/1742-6596/1827/1/012209","","",,,,,0,0.00,0,6,1,"As a new type of artificial intelligence technology, generative adversarial network (GAN) has good data understanding and generation capabilities, and has a wide range of application prospects in the fields of image and speech. However, due to the lack of prior knowledge, its training process is less robust and prone to occur the pattern ignore. Its development is restricted to a certain extent, and its application scope still needs to be expanded. To solve the above problems, this paper introduces a knowledge confidence multimode GAN (KC-MGAN) algorithm, calculates the confidence of the input data through the reasoning method, and then puts the confidence and the input data into the GAN system to generate new sample data. During the training process, the confidence of the input data is continuously calculated, while the generated data samples are continuously evaluated. The training process will end until the GAN system reaches a stable condition. Finally, this paper takes the generation of UAV flight trajectory data as an example to verify the effectiveness of the proposed method. Some explorations have been made for the application of data generation and GAN’s training mode with the prior knowledge.","",""
1,"J. Wolff","The SP Theory of Intelligence as a Foundation for the Development of a General, Human-Level Thinking Machine",2016,"","","","",44,"2022-07-13 09:33:13","","","","",,,,,1,0.17,1,1,6,"This paper summarises how the ""SP theory of intelligence"" and its realisation in the ""SP computer model"" simplifies and integrates concepts across artificial intelligence and related areas, and thus provides a promising foundation for the development of a general, human-level thinking machine, in accordance with the main goal of research in artificial general intelligence.  The key to this simplification and integration is the powerful concept of ""multiple alignment"", borrowed and adapted from bioinformatics. This concept has the potential to be the ""double helix"" of intelligence, with as much significance for human-level intelligence as has DNA for biological sciences.  Strengths of the SP system include: versatility in the representation of diverse kinds of knowledge; versatility in aspects of intelligence (including: strengths in unsupervised learning; the processing of natural language; pattern recognition at multiple levels of abstraction that is robust in the face of errors in data; several kinds of reasoning (including: one-step `deductive' reasoning; chains of reasoning; abductive reasoning; reasoning with probabilistic networks and trees; reasoning with 'rules'; nonmonotonic reasoning and reasoning with default values; Bayesian reasoning with 'explaining away'; and more); planning; problem solving; and more); seamless integration of diverse kinds of knowledge and diverse aspects of intelligence in any combination; and potential for application in several areas (including: helping to solve nine problems with big data; helping to develop human-level intelligence in autonomous robots; serving as a database with intelligence and with versatility in the representation and integration of several forms of knowledge; serving as a vehicle for medical knowledge and as an aid to medical diagnosis; and several more).","",""
50,"J. Sowa","The Role of Logic and Ontology in Language and Reasoning",2010,"","","","",45,"2022-07-13 09:33:13","","10.1007/978-90-481-8845-1_11","","",,,,,50,4.17,50,1,12,"","",""
144,"A. Garcez, L. Lamb, D. Gabbay","Neural-Symbolic Cognitive Reasoning",2008,"","","","",46,"2022-07-13 09:33:13","","10.1007/978-3-540-73246-4","","",,,,,144,10.29,48,3,14,"","",""
13,"R. Shafik, A. Wheeldon, A. Yakovlev","Explainability and Dependability Analysis of Learning Automata based AI Hardware",2020,"","","","",47,"2022-07-13 09:33:13","","10.1109/iolts50870.2020.9159725","","",,,,,13,6.50,4,3,2,"Explainability remains the holy grail in designing the next-generation pervasive artificial intelligence (AI) systems. Current neural network based AI design methods do not naturally lend themselves to reasoning for a decision making process from the input data. A primary reason for this is the overwhelming arithmetic complexity.Built on the foundations of propositional logic and game theory, the principles of learning automata are increasingly gaining momentum for AI hardware design. The lean logic based processing has been demonstrated with significant advantages of energy efficiency and performance. The hierarchical logic underpinning can also potentially provide opportunities for by-design explainable and dependable AI hardware. In this paper, we study explainability and dependability using reachability analysis in two simulation environments. Firstly, we use a behavioral SystemC model to analyze the different state transitions. Secondly, we carry out illustrative fault injection campaigns in a low-level SystemC environment to study how reachability is affected in the presence of hardware stuck-at 1 faults. Our analysis provides the first insights into explainable decision models and demonstrates dependability advantages of learning automata driven AI hardware design.","",""
0,"Daniel Lowd, Brenton Lessley, Mino De Raj","Towards Adversarial Reasoning in Statistical Relational Domains",2014,"","","","",48,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,3,8,"Statistical relational artificial intelligence combines first-order logic and probability in order to handle the complexity and uncertainty present in many real-world domains. However, many real-world domains also include multiple agents that cooperate or compete according to their diverse goals. In order to handle such domains, an autonomous agent must also consider the actions of other agents. In this paper, we show that existing statistical relational modeling and inference techniques can be readily adapted to certain adversarial or non-cooperative scenarios. We also discuss how learning methods can be adapted to be robust to the behavior of adversaries. Extending and applying these methods to real-world problems will extend the scope and impact of statistical relational artificial intelligence.","",""
1,"Nam-Ok Jo, Hyun-jung Kim, K. Shin","Bankruptcy Type Prediction Using A Hybrid Artificial Neural Networks Model",2015,"","","","",49,"2022-07-13 09:33:13","","10.13088/JIIS.2015.21.3.79","","",,,,,1,0.14,0,3,7,"The prediction of bankruptcy has been extensively studied in the accounting and finance field. It can have an important impact on lending decisions and the profitability of financial institutions in terms of risk management. Many researchers have focused on constructing a more robust bankruptcy prediction model. Early studies primarily used statistical techniques such as multiple discriminant analysis (MDA) and logit analysis for bankruptcy prediction. However, many studies have demonstrated that artificial intelligence (AI) approaches, such as artificial neural networks (ANN), decision trees, case-based reasoning (CBR), and support vector machine (SVM), have been outperforming statistical techniques since 1990s for business classification problems because statistical methods have some rigid assumptions in their application. In previous studies on corporate bankruptcy, many researchers have focused on developing a bankruptcy prediction model using financial ratios. However, there are few studies that suggest the specific types of bankruptcy. Previous bankruptcy prediction models have generally been interested in predicting whether or not firms will become bankrupt. Most of the studies on bankruptcy types have focused on reviewing the previous literature or performing a case study. Thus, this study develops a model using data mining techniques for predicting the specific types of bankruptcy as well as the occurrence of bankruptcy in Korean small- and medium-sized construction firms in terms of profitability, stability, and activity index. Thus, firms will be able to prevent it from occurring in advance. We propose a hybrid approach using two artificial neural networks (ANNs) for the prediction of bankruptcy types. The first is a back-propagation neural network (BPN) model using supervised learning for bankruptcy prediction and the second is a self-organizing map (SOM) model using unsupervised learning to classify bankruptcy data into several types. Based on the constructed model, we predict the bankruptcy of companies by applying the BPN model to a validation set that was not utilized in the development of the model. This allows for identifying the specific types of bankruptcy by using bankruptcy data predicted by the BPN model. We calculated the average of selected input variables through statistical test for each cluster to interpret characteristics of the derived clusters in the SOM model. Each cluster represents bankruptcy type classified through data of bankruptcy firms, and input variables indicate financial ratios in interpreting the meaning of each cluster.","",""
0,"M. Azam","A robust cost estimation framework in construction projects by considering cost development",2013,"","","","",50,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,9,"In construction projects avoiding cost overruns depends on a decent estimation of cost for the projects in their initial phase. However due to limited project information in the early phases of projects the degree of uncertainty is high and therefore cost estimation is a challenging task and today many projects still face major cost overruns. The idea behind this thesis is to propose a robust cost estimation framework that takes both managerial aspects of uncertainty management and technical methodologies of conceptual cost estimation technologies into account. Especially artificial intelligence as a decision support system for assisting the decision makers to estimate the cost with a less degree of uncertainty, whereas the magnitude and number of projects with cost overruns would be reduced. The framework asserts that cost development in different phases of project life cycle and each decision gate can be learnt by artificial neural network, and a case-based reasoning system can assist the artificial neural network to choose the most similar case in its training data set. A case study confirmed the assertion of the thesis framework, and the results show that the applicability of artificial neural network in learning complex and nonlinear relationship between inputs of it network which are ?the project phase? and ?the degree of cost development? in that phase, with even very limited training data set is very promising, therefore we can expect that by providing a well documented and structured historical project data in the case based of Case-based reasoning system the accuracy of estimation would increase.","",""
0,"M. Slonecker, M. Slonecker","The AXON : OS Framework Rapid Development of Swarm Intelligence Applications",2015,"","","","",51,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,2,7,"Swarm Intelligence seeks to create artificially intelligent systems where many individually simple active components (“agents”) self-organize to provide the desired application functions as emergent features of the system [1]. Thereby it differs from traditional Artificial Intelligence (AI) approaches where the application is realized with complex reasoning strategies. Robust self-organization of simple entities for emergent system-level functions (i.e., not explicitly represented or reasoned over at the individual level) is demonstrated in many large-scale systems in nature (Figure 1), ranging from colonies of single-celled organisms that, under threatening environmental conditions, may act as a collective to ensure survival, through many examples of social insect colonies, to the flocking behavior of birds, fish, predators, and even crowds of humans.","",""
3,"R. Tiako, D. Jayaweera, S. Islam","Real-time dynamic security assessment of power systems with large amount of wind power using Case-Based Reasoning methodology",2012,"","","","",52,"2022-07-13 09:33:13","","10.1109/PESGM.2012.6345033","","",,,,,3,0.30,1,3,10,"The method of Case-Based Reasoning (CBR) for assessing in real-time the dynamic security assessment of power systems with large amount of wind power is considered. The CBR is an artificial intelligence methodology. The CBR principles consist of using solutions of previous or old cases to calculate with high accuracy solutions of subsequent or real-time cases. The structure and functionalities of the CBR are described. A 19-bus test system model is used to demonstrate the efficiency of the described methodology. Results suggest that real-time dynamic security assessment of power system with large amount of wind power using the CBR methodology is robust and provide lesser computational time.","",""
26,"Kushal Kafle, Robik Shrestha, Christopher Kanan","Challenges and Prospects in Vision and Language Research",2019,"","","","",53,"2022-07-13 09:33:13","","10.3389/frai.2019.00028","","",,,,,26,8.67,9,3,3,"Language grounded image understanding tasks have often been proposed as a method for evaluating progress in artificial intelligence. Ideally, these tasks should test a plethora of capabilities that integrate computer vision, reasoning, and natural language understanding. However, the datasets and evaluation procedures used in these tasks are replete with flaws which allows the vision and language (V&L) algorithms to achieve a good performance without a robust understanding of vision and language. We argue for this position based on several recent studies in V&L literature and our own observations of dataset bias, robustness, and spurious correlations. Finally, we propose that several of these challenges can be mitigated by creation of carefully designed benchmarks.","",""
0,"Rafael V. Borges","A neural-symbolic system for temporal reasoning with application to model verification and learning",2012,"","","","",54,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,10,"The effective integration of knowledge representation, reasoning and learning into a robust computational model is one of the key challenges in Computer Science and Artificial Intelligence. In particular, temporal models have been fundamental in describing the behaviour of Computational and Neural-Symbolic Systems. Furthermore, knowledge acquisition of correct descriptions of the desired system’s behaviour is a complex task in several domains. Several efforts have been directed towards the development of tools that are capable of learning, describing and evolving software models.    This thesis contributes to two major areas of Computer Science, namely Artificial Intelligence (AI) and Software Engineering. Under an AI perspective, we present a novel neural-symbolic computational model capable of representing and learning temporal knowledge in recurrent networks. The model works in integrated fashion. It enables the effective representation of temporal knowledge, the adaptation of temporal models to a set of desirable system properties and effective learning from examples, which in turn can lead to symbolic temporal knowledge extraction from the corresponding trained neural networks. The model is sound, from a theoretical standpoint, but is also tested in a number of case studies.    An extension to the framework is shown to tackle aspects of verification and adaptation under the SE perspective. As regards verification, we make use of established techniques for model checking, which allow the verification of properties described as temporal models and return counter-examples whenever the properties are not satisfied. Our neural-symbolic framework is then extended to deal with different sources of information. This includes the translation of model descriptions into the neural structure, the evolution of such descriptions by the application of learning of counter examples, and also the learning of new models from simple observation of their behaviour.    In summary, we believe the thesis describes a principled methodology for temporal knowledge representation, learning and extraction, shedding new light on predictive temporal models, not only from a theoretical standpoint, but also with respect to a potentially large number of applications in AI, Neural Computation and Software Engineering, where temporal knowledge plays a fundamental role.","",""
3,"R. Brachman, David Gunning, Murray Burke","Integrated AI Systems",2020,"","","","",55,"2022-07-13 09:33:13","","10.1609/aimag.v41i2.5300","","",,,,,3,1.50,1,3,2,"From Shakey the Robot to self-driving cars, from the personal computer to personal assistants on our phones, the Defense Advanced Research Projects Agency (DARPA) has led the development of integrated artificial intelligence (AI) systems for more than half a century. From the earliest days of AI, it was apparent that a robust, generally intelligent system should include a complete set of capabilities: perception, memory, reasoning, learning, planning, and action; and when DARPA initiated AI research in the 1960s, ambitious projects such as Shakey the Robot went after the complete package. As DARPA realized the challenges, they backed away from the ultimate goal of integrated AI and tried to make progress on the individual problems of image understanding, speech and language understanding, knowledge representation and reasoning, planning and decision aids, machine learning, and robotic manipulation. Yet, even as researchers struggled to make progress in these subdisciplines, DARPA periodically resurrected the challenge of integrated intelligent systems and pushed the community to try again. In the 1980s, DARPA’s Strategic Computing Initiative took on challenges of integrated AI projects such as the Autonomous Land Vehicle and the Pilot’s Associate. These did not succeed, but instead set the stage for the several decades of more siloed research that followed, until it was time to try again. In the 2000s, DARPA took on the integrated AI problem again with its Grand Challenges, which led to the first self-driving cars, and projects such as the Personalized Assistant that Learns, which produced Apple’s Siri. These efforts created complex, richly-integrated systems that represented quantum leaps ahead in machine intelligence. The integration of sophisticated capabilities in a fundamental way is the key to general intelligence. This is the story of DARPA’s persistent long-term support for this essential premise of AI","",""
2,"Heather Roff","Expected Utilitarianism",2020,"","","","",56,"2022-07-13 09:33:13","","","","",,,,,2,1.00,2,1,2,"We want artificial intelligence (AI) to be beneficial. This is the grounding assumption of most of the attitudes towards AI research. We want AI to be ""good"" for humanity. We want it to help, not hinder, humans. Yet what exactly this entails in theory and in practice is not immediately apparent. Theoretically, this declarative statement subtly implies a commitment to a consequentialist ethics. Practically, some of the more promising machine learning techniques to create a robust AI, and perhaps even an artificial general intelligence (AGI) also commit one to a form of utilitarianism. In both dimensions, the logic of the beneficial AI movement may not in fact create ""beneficial AI"" in either narrow applications or in the form of AGI if the ethical assumptions are not made explicit and clear. Additionally, as it is likely that reinforcement learning (RL) will be an important technique for machine learning in this area, it is also important to interrogate how RL smuggles in a particular type of consequentialist reasoning into the AI: particularly, a brute form of hedonistic act utilitarianism. Since the mathematical logic commits one to a maximization function, the result is that an AI will inevitably be seeking more and more rewards. We have two conclusions that arise from this. First, is that if one believes that a beneficial AI is an ethical AI, then one is committed to a framework that posits 'benefit' is tantamount to the greatest good for the greatest number. Second, if the AI relies on RL, then the way it reasons about itself, the environment, and other agents, will be through an act utilitarian morality. This proposition may, or may not, in fact be actually beneficial for humanity.","",""
2,"A. Garcez, L. Lamb","A I ] 1 0 D ec 2 02 0 Neurosymbolic AI : The 3 rd Wave",2020,"","","","",57,"2022-07-13 09:33:13","","","","",,,,,2,1.00,1,2,2,"Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.","",""
73,"Yueting Zhuang, Fei Wu, Chun Chen, Yunhe Pan","Challenges and opportunities: from big data to knowledge in AI 2.0",2017,"","","","",58,"2022-07-13 09:33:13","","10.1631/FITEE.1601883","","",,,,,73,14.60,18,4,5,"In this paper, we review recent emerging theoretical and technological advances of artificial intelligence (AI) in the big data settings. We conclude that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI, as follows: from shallow computation to deep neural reasoning; from merely data-driven model to data-driven with structured logic rules models; from task-oriented (domain-specific) intelligence (adherence to explicit instructions) to artificial general intelligence in a general context (the capability to learn from experience). Motivated by such endeavors, the next generation of AI, namely AI 2.0, is positioned to reinvent computing itself, to transform big data into structured knowledge, and to enable better decision-making for our society.","",""
0,"Atriya Sen, N. Franz, Beckett W. Sterner, Nate Upham","The Automated Taxonomic Concept Reasoner",2020,"","","","",59,"2022-07-13 09:33:13","","10.3897/BISS.4.59074","","",,,,,0,0.00,0,4,2,"We present a visual and interactive taxonomic Artificial Intelligence (AI) tool, the Automated Taxonomic Concept Reasoner (ATCR), whose graphical web interface is under development and will also become available via an Application Programming Interface (API). The tool employs automated reasoning (Beeson 2014) to align multiple taxonomies visually, in a web browser, using user or expert-provided taxonomic articulations, i.e. ""Region Connection Calculus (RCC-5) relationships between taxonomic concepts, provided in a specific logical language (Fig. 1). It does this by representing the problem of taxonomic alignment under these constraints in terms of logical inference, while performing these inferences computationally and leveraging the powerful Microsoft Z3 Satisfiability Modulo Theory (SMT) solver (de Moura and Bjørner 2008). This tool represents further development of utilities for the taxonomic concept approach, which fundamentally addresses the challenge of robust biodiversity data aggregation in light of multiple conflicting sources (and source classifications) from which primary biodiversity data almost invariably originate. The approach has proven superior to aggregation, based just on the syntax and semantics provided by the Darwin Core standard Franz and Sterner 2018).  Fig. 1 provides an artificial example of such an alignment. Two taxonomies, A and B, are shown. There are five taxonomic concepts, A.One, A.Two, A.Three, B.One and B.Two. A.Two and A.Three are sub-concepts (children) of A.One, and B.Two is a sub-concept (child) of B.One. These are represented by the direction of the grey arrows. The undirected mustard-coloured lines represent relationships, i.e., the articulations referred to in the previous paragraph. These may be of five kinds: congruent (==), includes (<) and included in (>), overlap (><), and disjointness. These five relationships are known in the AI literature as the Region Connection Calculus-5 (RCC-5) (Randell et al. 1992, Bennett 1994, Bennett 1994), and taken exclusively and in conjunction with each other, have certain desirable properties with respect to the representation of spatial relationships. The provided relationship (i.e. the articulation) may also be an arbitrary disjunction of these five fundamental kinds, thus allowing for representation of some degree of logical uncertainty. Then, and under three assumptions that:        ""sibling"" concepts are disjoint in their instances,      all instances of a parent concept are instances of at least one of its child concepts, and      every concept has at least one instance - the SMT-based automated reasoner is able to deduce the relationships represented by the undirected green lines. It is also able to deduce disjunctive relationships where these are logically implied.        ""sibling"" concepts are disjoint in their instances,  all instances of a parent concept are instances of at least one of its child concepts, and  every concept has at least one instance - the SMT-based automated reasoner is able to deduce the relationships represented by the undirected green lines. It is also able to deduce disjunctive relationships where these are logically implied.  ATCR is related to Euler/X (Franz et al. 2015), an existing tool for the same kinds of taxonomic alignment problems, which was used, for example, to obtain an alignment of two influential primate classifications (Franz et al. 2016). It differs from Euler/X in that it employs a different logical encoding that enables more efficient and more informative computational reasoning, and also in that it provides a graphical web interface, which Euler/X does not.","",""
53,"P. Stone","Learning and Multiagent Reasoning for Autonomous Agents",2007,"","","","",60,"2022-07-13 09:33:13","","","","",,,,,53,3.53,53,1,15,"One goal of Artificial Intelligence is to enable the creation of robust, fully autonomous agents that can coexist with us in the real world. Such agents will need to be able to learn, both in order to correct and circumvent their inevitable imperfections, and to keep up with a dynamically changing world. They will also need to be able to interact with one another, whether they share common goals, they pursue independent goals, or their goals are in direct conflict. This paper presents current research directions in machine learning, multiagent reasoning, and robotics, and advocates their unification within concrete application domains. Ideally, new theoretical results in each separate area will inform practical implementations while innovations from concrete multiagent applications will drive new theoretical pursuits, and together these synergistic research approaches will lead us towards the goal of fully autonomous agents.","",""
43,"Abdel-Badeeh M. Salem","Case Based Reasoning Technology for Medical Diagnosis",2007,"","","","",61,"2022-07-13 09:33:13","","","","",,,,,43,2.87,43,1,15,"Case based reasoning (CBR) methodology presents a foundation for a new technology of building intelligent computer- aided diagnoses systems. This Technology directly addresses the problems found in the traditional Artificial Intelligence (AI) techniques, e.g. the problems of knowledge acquisition, remembering, robust and maintenance. This paper discusses the CBR methodology, the research issues and technical aspects of implementing intelligent medical diagnoses systems. Successful applications in cancer and heart diseases developed by Medical Informatics Research Group at Ain Shams University are also discussed.","",""
2,"R. Tiako, D. Jayaweera, S. Islam","A case-based reasoning approach for dynamic security assessment of power systems with large penetration of wind power",2011,"","","","",62,"2022-07-13 09:33:13","","","","",,,,,2,0.18,1,3,11,"This paper presents Case-Based Reasoning (CBR), a novel methodology for dynamic security assessment of power systems with large penetration of wind power. CBR is a machine learning technique which belongs to the artificial intelligence family. The idea behind the CBR principle is to use solutions of old or previous cases to obtain accurate estimated solutions of new cases. The structure and functionalities of CBR are described. A test system model is used to demonstrate the efficiency of the described technique. Results suggest that dynamic security assessment using the CBR technique is robust and provide lesser computational time which can be applied for an on-line dynamic security assessment.","",""
0,"Angie Shia, F. Bastani, I. Yen","ROBUST Path Strategy Evaluator",2011,"","","","",63,"2022-07-13 09:33:13","","10.1109/ICTAI.2011.91","","",,,,,0,0.00,0,3,11,"A swarm of robots deployed in dynamic, hostile environments may encounter situations that can prevent them from achieving optimality or completing certain tasks. To resolve these situations, the robots must have an adaptive software system that can proactively cope with changes. This adaptive system should emulate the intelligence of human reasoning and common sense but must not assume that the robots can communicate, be tightly coupled, or be constantly at a close range. This paper presents a path strategy evaluator (PSE) that learns an optimal path by considering not just the distance, but also how to minimize damages to each robot and enhance the likelihood that the swarm will succeed in its mission, all with minimal impositions on the functionality of the robots. Our evaluation shows that this PSE is able to learn a dynamic environment and its effect on the robots' critical components and output an optimal path for the robots.","",""
6,"Susan L. Epstein, Raj Korpan","Planning and Explanations with a Learned Spatial Model",2019,"","","","",64,"2022-07-13 09:33:13","","10.4230/LIPIcs.COSIT.2019.22","","",,,,,6,2.00,3,2,3,"This paper reports on a robot controller that learns and applies a cognitively-based spatial model as it travels in challenging, real-world indoor spaces. The model not only describes indoor space, but also supports robust, model-based planning. Together with the spatial model, the controller’s reasoning framework allows it to explain and defend its decisions in accessible natural language. The novel contributions of this paper are an enhanced cognitive spatial model that facilitates successful reasoning and planning, and the ability to explain navigation choices for a complex environment. Empirical evidence is provided by simulation of a commercial robot in a large, complex, realistic world. 2012 ACM Subject Classification Computing methodologies → Artificial intelligence; Computing methodologies → Machine learning; Computing methodologies → Modeling and simulation","",""
4,"Karsten Block, Simon Trumm, Premtim Sahitaj, S. Ollinger, R. Bergmann","Clustering of Argument Graphs Using Semantic Similarity Measures",2019,"","","","",65,"2022-07-13 09:33:13","","10.1007/978-3-030-30179-8_8","","",,,,,4,1.33,1,5,3,"","",""
3,"David B. Leake","Case-Based Reasoning Tomorrow: Provenance, the Web, and Cases in the Future of Intelligent Information Processing",2010,"","","","",66,"2022-07-13 09:33:13","","10.1007/978-3-642-16327-2_1","","",,,,,3,0.25,3,1,12,"","",""
151,"Christopher D. Manning, Bill MacCartney","Natural language inference",2009,"","","","",67,"2022-07-13 09:33:13","","","","",,,,,151,11.62,76,2,13,"Inference has been a central topic in artificial intelligence from the start, but while automatic methods for formal deduction have advanced tremendously, comparatively little progress has been made on the problem of natural language inference (NLI), that is, determining whether a natural language hypothesis h can justifiably be inferred from a natural language premise p. The challenges of NLI are quite different from those encountered in formal deduction: the emphasis is on informal reasoning, lexical semantic knowledge, and variability of linguistic expression.  This dissertation explores a range of approaches to NLI, beginning with methods which are robust but approximate, and proceeding to progressively more precise approaches.  We first develop a baseline system based on overlap between bags of words. Despite its extreme simplicity, this model achieves surprisingly good results on a standard NLI evaluation, the PASCAL RTE Challenge. However, its effectiveness is limited by its failure to represent semantic structure.  To remedy this lack, we next introduce the Stanford RTE system, which uses typed dependency trees as a proxy for semantic structure, and seeks a low-cost alignment between trees for p and h, using a cost model which incorporates both lexical and structural matching costs. This system is typical of a category of approaches to NLI based on approximate graph matching. We argue, however, that such methods work best when the entailment decision is based, not merely on the degree of alignment, but also on global features of the aligned 〈p, h〉 pair motivated by semantic theory.  Seeking still greater precision, we devote the largest part of the dissertation to developing an approach to NLI based on a model of natural logic. We greatly extend past work in natural logic, which has focused solely on semantic containment and monotonicity, to incorporate both semantic exclusion and implicativity. Our system decomposes an inference problem into a sequence of atomic edits which transforms p into h; predicts a lexical entailment relation for each edit using a statistical classifier; propagates these relations upward through a syntax tree according to semantic properties of intermediate nodes; and composes the resulting entailment relations across the edit sequence.  Finally, we address the problem of alignment for NLI, by developing a model of phrase-based alignment inspired by analogous work in machine translation, including an alignment scoring function, inference algorithms for finding good alignments, and training algorithms for choosing feature weights.","",""
3,"V. Kurbalija, Z. Budimac","CASE-BASED REASONING FRAMEWORK FOR GENERATING DECISION SUPPORT SYSTEMS",2009,"","","","",68,"2022-07-13 09:33:13","","","","",,,,,3,0.23,2,2,13,"Case-Based Reasoning (CBR) is a relatively new and promising technique of artificial intelligence. Using CBR, every new problem is solved by adapting the solutions of the previously successfully solved similar problems. The intention of our research is to develop a robust and general framework which supports generation of wide-range of CBR systems using different approaches. Presented framework integrates two previously developed CBR shells: CaBaGe and CuBaGe. CaBaGe (Case Base Generator) is a CBR shell for generating arbitrary decision support systems where the cases and the problems are represented as a set of values of some selected, most important attributes. CuBaGe (Curve Base Generator) is also a CBR shell in which both the problem and the previous cases are presented in the graphical manner using curves or time-series. Presented framework, which encompasses these two shells, inherits a number of advantages including: domain independence, incremental learning, platform independence, fast retrieval algorithm, generality, and robustness. AMS Mathematics Subject Classification (2000): 68T20, 68T30","",""
40,"M. Georgeff, F. Ingrand","Real-time reasoning: the monitoring and control of spacecraft systems",1990,"","","","",69,"2022-07-13 09:33:13","","10.1109/CAIA.1990.89190","","",,,,,40,1.25,20,2,32,"Research concerned with automating the monitoring and control of spacecraft systems is discussed. In particular, the application the procedural reasoning system (PRS) to the handling of malfunctions in the reaction control system (RCS) of NASAs space shuttle is studied. Unlike traditional monitoring and control systems, PRS is able to reason about and perform complex tasks in a very flexible and robust manner, somewhat in the manner of a human assistant. using various RCS malfunctions as examples (including sensor faults, leaking components, multiple alarms, and regulator and jet failures), it is shown how PRS manages to combine both goal-directed reasoning and the ability to react rapidly to unanticipated changes in its environment. Some important issues in the design of PRS are reviewed, and future enhancements are indicated.<<ETX>>","",""
29,"A. Gordon","Commonsense Interpretation of Triangle Behavior",2016,"","","","",70,"2022-07-13 09:33:13","","10.1609/aaai.v30i1.9881","","",,,,,29,4.83,29,1,6,"    The ability to infer intentions, emotions, and other unobservable psychological states from people's behavior is a hallmark of human social cognition, and an essential capability for future Artificial Intelligence systems. The commonsense theories of psychology and sociology necessary for such inferences have been a focus of logic-based knowledge representation research, but have been difficult to employ in robust automated reasoning architectures. In this paper we model behavior interpretation as a process of logical abduction, where the reasoning task is to identify the most probable set of assumptions that logically entail the observable behavior of others, given commonsense theories of psychology and sociology. We evaluate our approach using Triangle-COPA, a benchmark suite of 100 challenge problems based on an early social psychology experiment by Fritz Heider and Marianne Simmel. Commonsense knowledge of actions, social relationships, intentions, and emotions are encoded as defeasible axioms in first-order logic. We identify sets of assumptions that logically entail observed behaviors by backchaining with these axioms to a given depth, and order these sets by their joint probability assuming conditional independence. Our approach solves almost all (91) of the 100 questions in Triangle-COPA, and demonstrates a promising approach to robust behavior interpretation that integrates both logical and probabilistic reasoning.   ","",""
0,"Shailaja Keyur Sampat","Technical, Hard and Explainable Question Answering (THE-QA)",2019,"","","","",71,"2022-07-13 09:33:13","","10.24963/IJCAI.2019/916","","",,,,,0,0.00,0,1,3,"The ability of an agent to rationally answer questions about a given task is the key measure of its intelligence. While we have obtained phenomenal performance over various language and vision tasks separately, 'Technical, Hard and Explainable Question Answering' (THE-QA) is a new challenging corpus which addresses them jointly. THE-QA is a question answering task involving diagram understanding and reading comprehension. We plan to establish benchmarks over this new corpus using deep learning models guided by knowledge representation methods. The proposed approach will envisage detailed semantic parsing of technical figures and text, which is robust against diverse formats. It will be aided by knowledge acquisition and reasoning module that categorizes different knowledge types, identify sources to acquire that knowledge and perform reasoning to answer the questions correctly. THE-QA data will present a strong challenge to the community for future research and will bridge the gap between state-of-the-art Artificial Intelligence (AI) and 'Human-level' AI.","",""
0,"F. Yip, A. K. K. Wong, N. Parameswaran, P. Ray","Ontology-Based Robust Production System",2009,"","","","",72,"2022-07-13 09:33:13","","10.1109/ICSC.2009.87","","",,,,,0,0.00,0,4,13,"Production system (PS) is a forward chaining reasoning system that provides the artificial intelligence found useful in information and decision support systems. Conventional PS uses syntactic rules termed “production rules” for logic representation and reasoning. In this paper, we introduce a novel semantic-based Production System called Ontology-based Robust Production System (OntoRPS). OntoRPS is capable of dealing with uncertainties encountered in the reasoning process, adapt and robustly produce approximated results. An automated and robust reasoning process is achieved by leveraging the semantics modeled in Ontologies and semantic-based rules called ‘Robust Rules’. Ultimately, the application of OntoRPS enables the building of semantic-based solutions for real world use cases.","",""
24,"T. Bardasz, I. Zeid","DEJAVU: Case-based reasoning for mechanical design",1993,"","","","",73,"2022-07-13 09:33:13","","10.1017/S0890060400000809","","",,,,,24,0.83,12,2,29,"The architecture and implementation of a mechanical designer's assistant shell called DEJAVU is presented. The architecture is based on an integration of design and CAD with some of the more well known concepts in case-based reasoning (CBR). DEJAVU provides a flexible and cognitively intuitive approach for acquiring and utilizing design knowledge. It is a domain independent mechanical design shell that can incrementally acquire design knowledge in the domain of the user. DEJAVU provides a design environment that can learn from the designer(s) until it can begin to perform design tasks autonomously or semi-autonomously. The main components of DEJAVU are a knowledge base of design plans, an evaluation module in the form of a design plan system, and a blackboard-based adaptation module. The existance of these components are derived from the utilization of a CBR architecture. DEJAVU is the first step in developing a robust designer's assistant shell for mechanical design problems. One of the major contributions of DEJAVU is the development of a clean architecture for the utilization of case-based reasoning in a mechanical designer's assistant shell. In addition, the components of the architecture have been developed, tailored or modified from a general CBR context into a more synergistic relationship with mechanical design.","",""
1,"Mathieu Guillame-Bert, K. Broda","Connectionist Artificial Neural Networks",2009,"","","","",74,"2022-07-13 09:33:13","","","","",,,,,1,0.08,1,2,13,"Because of the big complexity of the world, the ability to deal with uncertain and to infer “almost” true rules is an obligation for intelligent systems. Therefore, the research of solution to emulate Inductive Reasoning is one of the fundamental problem of Artificial Intelligence. Several approaches have been studied: the techniques inherited from the Statistics one side, or techniques based on Logic on the other side. Both of these families show complementary advantages and weakness. For example, statistics techniques, like decision trees or artificial neural networks, are robust against noisy data, and they are able to deal with a large quantity of information. However, they are generally unable to generate complexes rules. On the other side, Logic based techniques, like ILP, are able to express very complex rules, but they cannot deal with large amount of information. This report presents the study and the development of an hybrid induction technique mixing the essence of statistical and logical learning techniques i.e. an Induction technique based on the First Order Logic semantic that generate hypotheses thanks to Artificial Neural Networks learning techniques. The expression power of the hypotheses is the one of the predicate logic, and the learning process is insensitive to noisy data thanks to the artificial neural network based learning process. During the project presented by this report, four new techniques have been studied and implemented: The first learns propositional relationship with an artificial neural network i.e. induction on propositional logic programs. The three other learn first order predicate relationships with artificial neural networks i.e. induction on predicate logic programs. The last of these techniques is the more complete one, and it is based on the knowledge acquired during the development of all the other techniques. The main advance of this technique is the definition of a convention to allow the interaction of predicate logic programs and artificial neural networks, and the construction of Artificial Neural Networks able to learn rule with the predicate logic power of expression. Mathieu Guillame-Bert 2","",""
6,"A. Salem, S. Parusheva","Exploiting the knowledge engineering paradigms for designing smart learning systems",2018,"","","","",75,"2022-07-13 09:33:13","","10.15587/1729-4061.2018.128410","","",,,,,6,1.50,3,2,4,"Knowledge engineering (KE) is a subarea of artificial intelligence (AI). Recently, KE paradigms have become more widespread within the fields of smart education and learning. Developing of Smart learning Systems (SLS) is very difficult from the technological perspective and a challenging task. In this paper, three KE paradigms, namely: case-based reasoning, data mining, and intelligent agents are discussed. This article demonstrates how SLS can take advantage of the innovative KE paradigms. Therefore, the paper addresses the pros of such smart computing approaches for the industry of SLS. Moreover, we concentrate our discussion on the challenges faced by knowledge engineers and software developers in developing and deploying efficient and robust SLS. Overall, this study introduces the reader the KE techniques, approaches and algorithms currently in use and the open research issues in designing the smart learning systems.","",""
2,"Hoda Sayyahi","AN APPLICATION OF FUZZY CASE BASED REASONING FOR POISON CLASSIFICATION",2008,"","","","",76,"2022-07-13 09:33:13","","","","",,,,,2,0.14,2,1,14,"The purpose of this study is to develop a system that can support people toward healthy life. The main objective of the systems is to assist people in the poison cases by providing a prompt recognition and correct treatment. This aim is achievable by developing a classified system based on Fuzzy case-based reasoning (FCBR) for poison cases that is called FCBRP. Fuzzy and case-based reasoning are leading techniques in artificial intelligence. Case based reasoning (CBR) methodology presents a foundation for a new technology of building intelligent computer aided diagnoses systems. This Technology directly addresses the problems found in the traditional Artificial Intelligence (AI) techniques, e.g. the problems of knowledge acquisition, remembering, robust and maintenance. In this research using a CBR system will assist the physician to quickly diagnose the problem, provide pre hospitalization aid to the patient and hence reduce the risk of death due to poisoning, FCBRP stand for Fuzzy Case-based Reasoning for poison classification can recognize the types of poisoning based on the collective experience attributed by the type of symptoms and their severity. The identification it supplies is a suggestion that the human expert may accept or consider for further analysis, or completely reject.","",""
2,"V. Kurbalija, M. Ivanović, Z. Budimac","Case-Based Reasoning Framework for Generating Wide-Range Decision Support Systems",2008,"","","","",77,"2022-07-13 09:33:13","","","","",,,,,2,0.14,1,3,14,"Case-Based Reasoning (CBR) is a relatively new and promising technique of artificial intelligence. By CBR, every new problem is solved by adapting the solutions of the similar problems previously solved successfully. During the past few years CBR has become a very popular technique for application in knowledge-based systems for different domains because the experience has been included in solving every new problem. The intention of our research is to develop a robust and general framework which supports generation of widerange decision support systems by using different CBR approaches. Presented framework integrates two previously developed CBR shells: CaBaGe and CuBaGe.","",""
1,"P. Stone","Learning and Multiagent Reasoning for Autonomous Agents IJCAI-07 Computers and Thought Paper",2007,"","","","",78,"2022-07-13 09:33:13","","","","",,,,,1,0.07,1,1,15,"One goal of Artificial Intelligence is to enable the creation of robust, fully autonomous agents that can coexist with us in the real world. Such agents will need to be able to learn, both in order to correct and circumvent their inevitable imperfections, and to keep up with a dynamically changing world. They will also need to be able to interact with one another, whether they share common goals, they pursue independent goals, or their goals are in direct conflict. This paper presents current research directions in machine learning, multiagent reasoning, and robotics, and advocates their unification within concrete application domains. Ideally, new theoretical results in each separate area will inform practical implementations while innovations from concrete multiagent applications will drive new theoretical pursuits, and together these synergistic research approaches will lead us towards the goal of fully autonomous agents.","",""
3,"A. Salem","DEVELOPING A WEB-BASED ONTOLOGY FOR E-BUSINESS",2018,"","","","",79,"2022-07-13 09:33:13","","10.7903/IJECS.1654","","",,,,,3,0.75,3,1,4,"Ontological engineering (OE) is a subset of knowledge science. Ontology is a powerful technique for knowledge management and reasoning tasks. Recently, most research of OE is related to developing robust, smart, knowledge-based systems in different domains. Nowadays, e-business, or electronic business, is the integrated execution of all business analytics processes of an enterprise by means of smart computing and informatics. The objective of this study is to develop a web-based ontology for e-business paradigms. In this work, five web-based ontologies were designed for the following: (a) e-business applications; (b) e-business participants; (c) e-business infrastructure; (d) e-business support areas, and (e) fields in e-business. The developed ontologies were implemented in ontology web-based language OWL2 using the Protege smart tool version 5.0.0 editing environment. Keywords: Knowledge Engineering, E-Business, E-Commerce, Web Technology, Ontology, Computer Science, Artificial Intelligence, Smart Computing. To cite this document: Abdel-Badeeh M. Salem and Silvia Parusheva, "" DEVELOPING A WEB-BASED ONTOLOGY FOR E-BUSINESS "", International Journal of Electronic Commerce Studies, Vol.9, No.2, pp.119-132, 2018. Permanent link to this document: http://dx.doi.org/10.7903/ijecs.1654","",""
8,"David Bellot, R. Siegwart, P. Bessière, A. Tapus, C. Coué, J. Diard","Bayesian Modeling and Reasoning for Real World Robotics: Basics and Examples",2004,"","","","",80,"2022-07-13 09:33:13","","10.1007/978-3-540-27833-7_14","","",,,,,8,0.44,1,6,18,"","",""
7,"Ickjai Lee","Fast Qualitative Reasoning about Categories in Conceptual Spaces",2003,"","","","",81,"2022-07-13 09:33:13","","","","",,,,,7,0.37,7,1,19,"Categorization is a central task in cognitive science and artificial intelligence. Efficient reasoning about categories is becoming of great importance as intelligent agents are required to perform complex tasks in data-rich environments. Gardenfors and Williams [6] introduce a robust framework for categorization and reasoning about categories within conceptual spaces. This paper extends their work and presents a number of efficient reasoning properties that greatly reduce the search space resulting in fast derivation of reasoning about categories.","",""
0,"L. Valiant","What needs to be added to machine learning?",2018,"","","","",82,"2022-07-13 09:33:13","","10.1145/3210713.3210716","","",,,,,0,0.00,0,1,4,"The question we ask is how to build on the success of machine learning to address the broader goals of artificial intelligence. We regard reasoning as the major component of cognition, other than learning, that needs to be incorporated. We suggest that the central challenge therefore is to unify the formulation of these two phenomena, learning and reasoning, whose conventional formulations are contradictory, into a single framework with a common semantics. We propose Robust Logic for this role, as a framework with a satisfactory theoretical basis. Testing it experimentally on a significant scale remains a major challenge for the future.","",""
7,"M. Esmaili, R. Safavi-Naini, J. Pieprzyk","Evidential reasoning in network intrusion detection systems",1996,"","","","",83,"2022-07-13 09:33:13","","10.1007/BFb0023304","","",,,,,7,0.27,2,3,26,"","",""
14,"Ndapandula Nakashole","Automatic extraction of facts, relations, and entities for web-scale knowledge base population",2012,"","","","",84,"2022-07-13 09:33:13","","10.22028/D291-26412","","",,,,,14,1.40,14,1,10,"Equipping machines with knowledge, through the construction of machinereadable knowledge bases, presents a key asset for semantic search, machine translation, question answering, and other formidable challenges in artificial intelligence. However, human knowledge predominantly resides in books and other natural language text forms. This means that knowledge bases must be extracted and synthesized from natural language text. When the source of text is the Web, extraction methods must cope with ambiguity, noise, scale, and updates. The goal of this dissertation is to develop knowledge base population methods that address the afore mentioned characteristics of Web text. The dissertation makes three contributions. The first contribution is a method for mining high-quality facts at scale, through distributed constraint reasoning and a pattern representation model that is robust against noisy patterns. The second contribution is a method for mining a large comprehensive collection of relation types beyond those commonly found in existing knowledge bases. The third contribution is a method for extracting facts from dynamic Web sources such as news articles and social media where one of the key challenges is the constant emergence of new entities. All methods have been evaluated through experiments involving Web-scale text collections.","",""
1,"Paolo Remagnino, Graeme A. Jones, D. Monekosso","Reasoning about Dynamic Scenes Using Autonomous Agents",2001,"","","","",85,"2022-07-13 09:33:13","","10.1007/3-540-45411-X_21","","",,,,,1,0.05,0,3,21,"","",""
3,"G. Biswas, G. Lee","Knowledge reorganization. A rule model scheme for efficient reasoning",1994,"","","","",86,"2022-07-13 09:33:13","","10.1109/CAIA.1994.323659","","",,,,,3,0.11,2,2,28,"Discusses the application of conceptual clustering in restructuring large knowledge bases for the purpose of improving their complex problem solving efficiency. The rule base of PLAYMAKER, a system for characterizing hydrocarbon fields and plays, is restructured into a hierarchy of rule models using our conceptual clustering scheme, ITERATE. The rule models, used with a task-specific reasoning methodology, provide a more efficient, focused, and robust inferencing mechanism. A set of case studies that have been conducted demonstrate the improved performance of the reasoning system. PLAYMAKER is implemented on MIDST (Mixed Inferencing Dempster-Shafer Tool), a general-purpose knowledge-based system construction tool that incorporates reasoning mechanisms based on a task-specific architecture and belief functions.<<ETX>>","",""
1,"T. P. Fries, J. Graham","An Agent-Based Approach to Robust Switching Between Abstraction Levels for Fault Diagnosis",2000,"","","","",87,"2022-07-13 09:33:13","","10.1007/3-540-44914-0_20","","",,,,,1,0.05,1,2,22,"","",""
0,"Richard G. Ogler, Julie Wong, I. Khan","Robust Transfiguring Network Protocols.",1996,"","","","",88,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,3,26,"Abstract : In RTNP, we have developed a protocol that uses two artificial intelligence methods, neural networks and evidential reasoning, to recognize and predict adverse network conditions, and that uses fuzzy logic to dynamically control the parameters of a tunable routing protocol in response to the perceived environment. Examples of the tunable protocol parameters are: (1) a parameter that controls the degree to which traffic is spread over multiple paths; (2) a link bias parameter that, when large, increases stability by forcing traffic over minimum-hop paths; and (3) a parameter that determines how often routing updates are sent. Examples of measurements used to recognize adverse conditions are: (1) congestion; (2) probability of a successful transmission on a link; (3) jamming characteristics; and (4) degree of routing oscillations. Neural network methods were developed for predicting link-states and congestion, based on network measurements and estimates. These methods were shown in simulations to predict link states and queuing delay much more accurately than other methods.","",""
35,"Mark A. Finlayson","Collecting Semantics in the Wild: The Story Workbench",2008,"","","","",89,"2022-07-13 09:33:13","","","","",,,,,35,2.50,35,1,14,"Analogical reasoning is crucial to robust and flexible highlevel cognition. However, progress on computational models of analogy has been impeded by our inability to quickly and accurately collect large numbers (100+) of semantically annotated texts. The Story Workbench is a tool that facilitates such annotation by using natural language processing techniques to make a guess at the annotation, followed by approval, correction, and elaboration of that guess by a human annotator. Central to this approach is the use of a sophisticated graphical user interface that can guide even an untrained annotator through the annotation process. I describe five desiderata that govern the design of the Story Workbench, and demonstrate how each principle was fulfilled in the current implementation. The Story Workbench enables numerous experiments that previously were prohibitively laborious, of which I describe three currently underway in my lab. Analogical reasoning underlies many important cognitive processes, including learning, categorization, planning, and natural language understanding (Gentner, Holyoak, and Kokinov 2001). It is crucial to robust and flexible highlevel cognition. Despite great strides early in the computational understanding of analogical reasoning (Gick and Holyoak 1980; Winston 1980; Gentner 1983; Falkenhainer, Forbus, and Gentner 1989; Forbus, Gentner, and Law 1994), recent progress has been slow. Most computational models of analogy require semantic knowledge as input, supplied as semantically annotated texts. Historically, as the models became more complex, vetting them required ever larger sets of annotations, of greater detail and complexity. It is the assembly of these sets that has become a major bottleneck to progress. The sets should contain hundreds of annotations of sufficient richness, must have high interannotator agreement, and need to be collected quickly and without prohibitive expense. Manual assembly of such sets is costly, time-consuming, and error-prone. Automatic annotation systems also provide no relief: they lack coverage, are often imprecise or inaccurate, and are in general unable to provide the full scope of annotations required. This datacollection bottleneck has seriously impaired progress in the computational understanding of analogical reasoning, and a Copyright c © 2008, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. solution is needed if progress is to resume at a reasonable pace.","",""
13,"Prem Pal Singh Tomar, Ranjit Singh, P. Saxena, J. Sharma","Case Based Medical Diagnosis of Occupational Chronic Lung Diseases From Their Symptoms and Signs",2011,"","","","",90,"2022-07-13 09:33:13","","","","",,,,,13,1.18,3,4,11,"The clinical decision support system using the case based reasoning (CBR) methodology of Artificial Intelligence (AI) presents a foundation for a new technology of building intelligent computer aided diagnoses systems. This Technology directly addresses the problems found in the traditional Artificial Intelligence (AI) techniques, e.g. the problems of knowledge acquisition, remembering, robust and maintenance. In this paper, we have used the Case Based Reasoning methodology to develop a clinical decision support system prototype for supporting diagnosis of occupational lung diseases. 127 cases were collected for 14 occupational chronic lung diseases, which contains 26 symptoms. After removing the duplicated cases from the database, the system has trained set of 47 cases for Indian Lung patients. Statistical analysis has been done to determine the importance values of the case features. The retrieval strategy using nearest-neighbor approaches is investigated. The results indicate that the nearest neighbor approach has shown the encouraging outcome, used as retrieval strategy. A Consultant Pathologist’s interpretation was used to evaluate the system. Results for Sensitivity, Specificity, Positive Prediction Value and the Negative Prediction Value are 95.3%, 92.7%, 98.6% and 81.2% respectively. Thus, the result showed that the system is capable of assisting an inexperience pathologist in making accurate, consistent and timely diagnoses, also in the study of diagnostic protocol, education, selfassessment, and quality control. In this paper, clinical decision support system prototype is developed for supporting diagnosis of occupational lung diseases from their symptoms and signs through employing Microsoft Visual Basic .NET 2005 along with Microsoft SQL server 2005 environment with the advantage of Object Oriented Programming technology","",""
2,"T. P. Fries","Automation of rapid fault diagnosis in manufacturing systems using multiple fuzzy agents",2013,"","","","",91,"2022-07-13 09:33:13","","10.1109/CoASE.2013.6654031","","",,,,,2,0.22,2,1,9,"The reasoning process used by humans for fault diagnosis is very difficult to model due to the many factors used in developing a hypothesis. Some of these factors do not correspond to cognitive models. The diagnosis of faults in manufacturing systems is often plagued with human emotions and “gut feelings” which are difficult, if not impossible, to model. Many artificial intelligence approaches to automated fault diagnosis use either structural or symptom-based reasoning. Functional approaches are unable to provide realtime response due to their computational complexity, whereas, symptom-based approaches are only able to handle situations specifically coded in rules. Current hybrid approaches that combine the two methods are too structured in their approach to switching between the reasoning methods and, therefore fail to provide the flexible, rapid response of human experts. This paper presents a robust, extensible approach to fault diagnosis that allows unstructured switching between reasoning models using multiple fuzzy intelligent agents that examine the problem domain from a variety of perspectives.","",""
3,"M. D. Gregorio, Alessandro Rullo, S. Rubinacci","ISIDIS: an intelligent videosurveillance system",2012,"","","","",92,"2022-07-13 09:33:13","","10.1145/2254556.2254721","","",,,,,3,0.30,1,3,10,"In this paper we propose a new approach to active video surveillance intelligence systems based on the integration of artificial neural networks (ANN) and symbolic Artificial Intelligence (AI). In particular, the neurosymbolic hybrid system here presented is formed by virtual neural sensors (WiSARD--like systems) and BDI agents. The coupling of virtual neural sensors with symbolic reasoning for interpreting their outputs, makes this approach both very light from the computational and hardware point of view and quite robust in performances.","",""
0,"Saud Ben Mahmoud Mandourah","DEVELOPING A WEB-BASED ONTOLOGY FOR EXPERT DECISION SUPPORT SYSTEMS",2015,"","","","",93,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,7,"Expert systems were originally developed to solve illdefined problems and well-defined problems that are not efficiently solved with algorithmic approaches. This technology provides an innovative and robust techniques to capture and package knowledge. Its strength lies in its ability to be put to practical use when an expert is not available. This technology has proven to be especially effective when the task is in a rapidly changing environment. On the other side, ontology is the foundation of describing a domain of interest and it consists in a collection of terms organized in a hierarchical structure that shape the reality. The main objective of using ontologies is to share knowledge between computers or computers and human. Most of the usages of ontologies in the field of artificial intelligence are related to knowledge based systems and intelligent systems. These types of ontologies include a small number of concepts and their main objective is to facilitate reasoning tasks. This paper presents the developing of web-based ontology for expert systems technology. The developed ontology was encoded in OWL-DL format using the Protégé-OWL editing environment. Keywords-Ontological Engineering, Expert Systems, Artificial Intelligence, Knowledge Engineering, Web Technology","",""
0,"S. Saratha, Pei Fen Ng, Velavan Muraly","Application of Higher Order Hopfield Network",2013,"","","","",94,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,3,9,"Neural network and logic integration is the latest trend in Artificial Intelligence. Neural Symbolic Integration is a combination of neural networks’ robust learning capabilities with symbolic knowledge representation, reasoning, and explanation capabilities in ways that retain the strengths of each paradigm. In this paper, an Agent Based Modelling (ABM) was introduced by using Netlogo which carry out higher order horn clauses in Hopfield network. Our interest in this paper is confined largely to an important class of neural networks that perform useful computations through a process of learning. So, from the ABM that designed, we can carry out some computer simulation to verify and test the ABM develop.","",""
32,"H. Lieberman, Hugo Liu, P. Singh, Barbara Barry","Beating Some Common Sense into Interactive Applications",2003,"","","","",95,"2022-07-13 09:33:13","","","","",,,,,32,1.68,8,4,19,"A long-standing dream of artificial intelligence has been to put common sense knowledge into computers—enabling machines to reason about everyday life. Some projects, such as Cyc, have begun to amass large collections of such knowledge. However, it is widely assumed that the use of common sense in interactive applications will remain impractical for years, until these collections can be considered sufficiently complete and common sense reasoning sufficiently robust. Recently, at the MIT Media Lab, we have had some success in applying common sense knowledge in a number of intelligent Interface Agents, despite the admittedly spotty coverage and unreliable inference of today's common sense knowledge systems. This paper will survey several of these applications and reflect on interface design principles that enable successful use of common sense knowledge.","",""
0,"Fabio Gagliardi Cozman","Imprecise Probability in Graphical Models : Achievements and Challenges Invited talk at ECSQARU Barcelona",,"","","","",96,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,,"In this issue of the SIPTA newsletter you will find a summary of Serafin Moral’s invited talk on imprecise probabilities at ECSQARU (European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty). The ECSQARU meetings are one of the most important foruns dealing with representations for uncertainty within artificial intelligence and computer science; Serafin’s participation as invited speaker certainly testifies to his leading role in the world of imprecise probabilities. Thanks to Serafin for providing a nice summary of his talk. This issue of the newsletter also brings information on the coming 4th International Symposium on Imprecise Probabilities and their Applications (ISIPTA ’05), to occur in Pittsburgh, United States. You will find here the list of accepted papers, tutorials, and invited talks. We also have the announcement of the workshop on “Info-Gap Analysis of Engineering Systems: Robust Decisions under Severe Uncertainty,” and abstracts of papers announced at the SIPTA mailing list. Finally, in the Software Section, this issue brings information on Thomas Lukasiewicz’s NMPROBLOG, a package that deals with nonmonotonic probababilistic logics and their associated probability intervals. Also, if you know of any event or publication that should be of interest to members of SIPTA, send a message about it to fgcozman@usp.br. Cheers!","",""
45,"J. Hushon","Expert systems for environmental problems",1987,"","","","",97,"2022-07-13 09:33:13","","10.1021/ES00163A604","","",,,,,45,1.29,45,1,35,"Expert systems comprise a branch of artificial intelligence. Defined as man and machine systems with specialized, problem-solving expertise, expert systems rely on a data base of knowledge about a particular subject area, an understanding of the problems addressed within that subject area, and skill at solving these problems. Expert systems software was developed during the early 1970s and was initially applied to well-defined problem areas. Gradually this software has become more robust and has evolved into domain-independent software that can facilitate the construction of applications. These expert system software tools are referred to as shells. Currently a number of these shells are available on microcomputers, and some come on minicomputers as well. The following types of situations are ideal candidates for expert systems solutions: situations that occur often, situations that are complex, situations that require knowledge of experts (higher reasoning), situations in which uncertainty is involved, situations that are dynamic, and situations that demand consistent responses. Nonetheless, expert systems are starting to be used to recognize and manage environmental problems. In general, expert systems can be divided into a number of functional categories: planning, monitoring and control, instruction, interpretation, production, diagnosis and repair, and design. Table 1 shows the environmentalmore » systems, classified according to this scheme. Note that no environmental systems were found that were devoted to monitoring and control, instrumentation, or design.« less","",""
14,"Reasey Praing, Markus Schneider","Efficient Implementation Techniques for Topological Predicates on Complex Spatial Objects",2008,"","","","",98,"2022-07-13 09:33:13","","10.1007/s10707-007-0035-y","","",,,,,14,1.00,7,2,14,"","",""
27,"K. Kempf","Manufacturing planning and scheduling: where we are and where we need to be",1989,"","","","",99,"2022-07-13 09:33:13","","10.1109/CAIA.1989.49132","","",,,,,27,0.82,27,1,33,"The lack of robust geometric reasoning components in most current process planning expert systems is discussed. The lack of metaknowledge in most existing production-scheduling systems is examined. The large amount of effort required to bring a research system into daily factory use is detailed. Finally, the large amount of effort needed to integrate intelligent planning and scheduling is considered.<<ETX>>","",""
10,"M. D. Gregorio","An Intelligent Active Video Surveillance System Based on the Integration of Virtual Neural Sensors and BDI Agents",2008,"","","","",100,"2022-07-13 09:33:13","","10.1093/ietisy/e91-d.7.1914","","",,,,,10,0.71,10,1,14,"In this paper we present an intelligent active video surveillance system currently adopted in two different application domains: railway tunnels and outdoor storage areas. The system takes advantages of the integration of Artificial Neural Networks (ANN) and symbolic Artificial Intelligence (AI). This hybrid system is formed by virtual neural sensors (implemented as WiSARD–like systems) and BDI agents. The coupling of virtual neural sensors with symbolic reasoning for interpreting their outputs, makes this approach both very light from a computational and hardware point of view, and rather robust in performances. The system works on different scenarios and in difficult light conditions.","",""
14,"Ndapandula Nakashole","Automatic extraction of facts, relations, and entities for web-scale knowledge base population",2012,"","","","",101,"2022-07-13 09:33:13","","10.22028/D291-26412","","",,,,,14,1.40,14,1,10,"Equipping machines with knowledge, through the construction of machinereadable knowledge bases, presents a key asset for semantic search, machine translation, question answering, and other formidable challenges in artificial intelligence. However, human knowledge predominantly resides in books and other natural language text forms. This means that knowledge bases must be extracted and synthesized from natural language text. When the source of text is the Web, extraction methods must cope with ambiguity, noise, scale, and updates. The goal of this dissertation is to develop knowledge base population methods that address the afore mentioned characteristics of Web text. The dissertation makes three contributions. The first contribution is a method for mining high-quality facts at scale, through distributed constraint reasoning and a pattern representation model that is robust against noisy patterns. The second contribution is a method for mining a large comprehensive collection of relation types beyond those commonly found in existing knowledge bases. The third contribution is a method for extracting facts from dynamic Web sources such as news articles and social media where one of the key challenges is the constant emergence of new entities. All methods have been evaluated through experiments involving Web-scale text collections.","",""
1,"Paolo Remagnino, Graeme A. Jones, D. Monekosso","Reasoning about Dynamic Scenes Using Autonomous Agents",2001,"","","","",102,"2022-07-13 09:33:13","","10.1007/3-540-45411-X_21","","",,,,,1,0.05,0,3,21,"","",""
3,"G. Biswas, G. Lee","Knowledge reorganization. A rule model scheme for efficient reasoning",1994,"","","","",103,"2022-07-13 09:33:13","","10.1109/CAIA.1994.323659","","",,,,,3,0.11,2,2,28,"Discusses the application of conceptual clustering in restructuring large knowledge bases for the purpose of improving their complex problem solving efficiency. The rule base of PLAYMAKER, a system for characterizing hydrocarbon fields and plays, is restructured into a hierarchy of rule models using our conceptual clustering scheme, ITERATE. The rule models, used with a task-specific reasoning methodology, provide a more efficient, focused, and robust inferencing mechanism. A set of case studies that have been conducted demonstrate the improved performance of the reasoning system. PLAYMAKER is implemented on MIDST (Mixed Inferencing Dempster-Shafer Tool), a general-purpose knowledge-based system construction tool that incorporates reasoning mechanisms based on a task-specific architecture and belief functions.<<ETX>>","",""
1,"T. P. Fries, J. Graham","An Agent-Based Approach to Robust Switching Between Abstraction Levels for Fault Diagnosis",2000,"","","","",104,"2022-07-13 09:33:13","","10.1007/3-540-44914-0_20","","",,,,,1,0.05,1,2,22,"","",""
0,"Richard G. Ogler, Julie Wong, I. Khan","Robust Transfiguring Network Protocols.",1996,"","","","",105,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,3,26,"Abstract : In RTNP, we have developed a protocol that uses two artificial intelligence methods, neural networks and evidential reasoning, to recognize and predict adverse network conditions, and that uses fuzzy logic to dynamically control the parameters of a tunable routing protocol in response to the perceived environment. Examples of the tunable protocol parameters are: (1) a parameter that controls the degree to which traffic is spread over multiple paths; (2) a link bias parameter that, when large, increases stability by forcing traffic over minimum-hop paths; and (3) a parameter that determines how often routing updates are sent. Examples of measurements used to recognize adverse conditions are: (1) congestion; (2) probability of a successful transmission on a link; (3) jamming characteristics; and (4) degree of routing oscillations. Neural network methods were developed for predicting link-states and congestion, based on network measurements and estimates. These methods were shown in simulations to predict link states and queuing delay much more accurately than other methods.","",""
7,"K. Zeb, Komal Saleem, C. A. Mehmood, Waqar Uddin, Muhammad Zia ur Rehman, A. Haider, M. A. Javed","Performance of adaptive PI based on fuzzy logic for Indirect Vector Control Induction Motor drive",2016,"","","","",106,"2022-07-13 09:33:13","","10.1109/ICRAI.2016.7791235","","",,,,,7,1.17,1,7,6,"A Novel Adaptive PI based on Fuzzy Logic Reasoning (FLR) is presented in this paper for Indirect Vector Control (IVC) three phase Induction Motor (IM). The main objective is to achieve fast dynamic response and robustness for speed variation, parameter uncertainties, load disturbances, electrical faults perturbations, and to acquire maximum torque and efficiency. The d-q modeling of the IM in synchronously rotating reference frame and Space Vector Pulse Width Modulation (SVPWM) employed in power inverter are carried out in Matlab/Simulink. Both PI and Adaptive PI based on FLR are analyzed, designed, and simulated for IVC IM drive system. Furthermore, the critical and analytical assessment of the aforesaid designed control methodology provides robust and faster response with low overshoot, rise, and settling time for the load disturbances, parameter uncertainties, speed variation, and electrical faults perturbation of IVC IM drive system, compared to prior works.","",""
18,"M. Klenk, Kenneth D. Forbus, E. Tomai, Hyeonkyeong Kim","Using analogical model formulation with sketches to solve Bennett Mechanical Comprehension Test problems",2011,"","","","",107,"2022-07-13 09:33:13","","10.1080/0952813X.2010.502312","","",,,,,18,1.64,5,4,11,"One of the central problems of artificial intelligence is capturing the breadth and flexibility of human common sense reasoning. One way to evaluate common sense is to use versions of human tests that rely on everyday reasoning. The Bennett Mechanical Comprehension Test consists of everyday reasoning problems posed via pictures and is used to evaluate technicians. This test is challenging because it requires conceptual knowledge spanning a broad range of domains, experience with a wide variety of everyday situations, and spatial reasoning. This article describes how we have extended our Companion Cognitive Architecture, which treats analogical processing as central, to perform well over a subset of the Bennett test. We introduce analogical model formulation as a robust method for reasoning about everyday scenarios, by analogy with cases that represent prior experiences. This enables a companion to perform qualitative reasoning (QR) without a complete domain theory, as typically required for QR. We introduce sketch annotations to communicate linkages between visual and conceptual properties in sketches. We introduce analogical reference frames to enable comparative analysis to operate over a broader range of problems than prior techniques. We show that these techniques enable a companion to score reasonably well on a difficult subset of the Bennett test.","",""
0,"A. Salem, Mona Saad Khalil Morgan","Exploiting the Intelligent Bio-inspired Computing (IBioC) for e-Business",2017,"","","","",108,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,2,5,"Intelligent Bio-inspired Computing (IBioC) has emerged as a powerful paradigm in e-Science. BioC is a sub area of research of artificial intelligence technologies. IBioC provides both of software and knowledge engineers a robust methodologies and techniques to develop smart applications for e-government tasks. This paper explores the different IBioC paradigms used in developing smart e- business systems. Our analysis includes the following biological paradigms; artificial neural networks, genetic algorithms, support vector machines, and swarm intelligence. The results prove that, e-business systems based on the Bio-inspired computing approaches are characterized by smart behavior , such as high efficiency, reasoning and learning abilities, from the knowledge engineering and computing perspective.","",""
35,"Mark A. Finlayson","Collecting Semantics in the Wild: The Story Workbench",2008,"","","","",109,"2022-07-13 09:33:13","","","","",,,,,35,2.50,35,1,14,"Analogical reasoning is crucial to robust and flexible highlevel cognition. However, progress on computational models of analogy has been impeded by our inability to quickly and accurately collect large numbers (100+) of semantically annotated texts. The Story Workbench is a tool that facilitates such annotation by using natural language processing techniques to make a guess at the annotation, followed by approval, correction, and elaboration of that guess by a human annotator. Central to this approach is the use of a sophisticated graphical user interface that can guide even an untrained annotator through the annotation process. I describe five desiderata that govern the design of the Story Workbench, and demonstrate how each principle was fulfilled in the current implementation. The Story Workbench enables numerous experiments that previously were prohibitively laborious, of which I describe three currently underway in my lab. Analogical reasoning underlies many important cognitive processes, including learning, categorization, planning, and natural language understanding (Gentner, Holyoak, and Kokinov 2001). It is crucial to robust and flexible highlevel cognition. Despite great strides early in the computational understanding of analogical reasoning (Gick and Holyoak 1980; Winston 1980; Gentner 1983; Falkenhainer, Forbus, and Gentner 1989; Forbus, Gentner, and Law 1994), recent progress has been slow. Most computational models of analogy require semantic knowledge as input, supplied as semantically annotated texts. Historically, as the models became more complex, vetting them required ever larger sets of annotations, of greater detail and complexity. It is the assembly of these sets that has become a major bottleneck to progress. The sets should contain hundreds of annotations of sufficient richness, must have high interannotator agreement, and need to be collected quickly and without prohibitive expense. Manual assembly of such sets is costly, time-consuming, and error-prone. Automatic annotation systems also provide no relief: they lack coverage, are often imprecise or inaccurate, and are in general unable to provide the full scope of annotations required. This datacollection bottleneck has seriously impaired progress in the computational understanding of analogical reasoning, and a Copyright c © 2008, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. solution is needed if progress is to resume at a reasonable pace.","",""
13,"Prem Pal Singh Tomar, Ranjit Singh, P. Saxena, J. Sharma","Case Based Medical Diagnosis of Occupational Chronic Lung Diseases From Their Symptoms and Signs",2011,"","","","",110,"2022-07-13 09:33:13","","","","",,,,,13,1.18,3,4,11,"The clinical decision support system using the case based reasoning (CBR) methodology of Artificial Intelligence (AI) presents a foundation for a new technology of building intelligent computer aided diagnoses systems. This Technology directly addresses the problems found in the traditional Artificial Intelligence (AI) techniques, e.g. the problems of knowledge acquisition, remembering, robust and maintenance. In this paper, we have used the Case Based Reasoning methodology to develop a clinical decision support system prototype for supporting diagnosis of occupational lung diseases. 127 cases were collected for 14 occupational chronic lung diseases, which contains 26 symptoms. After removing the duplicated cases from the database, the system has trained set of 47 cases for Indian Lung patients. Statistical analysis has been done to determine the importance values of the case features. The retrieval strategy using nearest-neighbor approaches is investigated. The results indicate that the nearest neighbor approach has shown the encouraging outcome, used as retrieval strategy. A Consultant Pathologist’s interpretation was used to evaluate the system. Results for Sensitivity, Specificity, Positive Prediction Value and the Negative Prediction Value are 95.3%, 92.7%, 98.6% and 81.2% respectively. Thus, the result showed that the system is capable of assisting an inexperience pathologist in making accurate, consistent and timely diagnoses, also in the study of diagnostic protocol, education, selfassessment, and quality control. In this paper, clinical decision support system prototype is developed for supporting diagnosis of occupational lung diseases from their symptoms and signs through employing Microsoft Visual Basic .NET 2005 along with Microsoft SQL server 2005 environment with the advantage of Object Oriented Programming technology","",""
0,"J. Tao, Yilun Liu, Yiping Wen, J. Su","The Expert System of Locomotive Running Gear Based on Sematic Network",2016,"","","","",111,"2022-07-13 09:33:13","","10.1109/IMIS.2016.76","","",,,,,0,0.00,0,4,6,"As an important part of artificial intelligence, expert systems have widely used in the field of mechanical fault diagnosis. But with the development of the large data and cloud computing, some systems' hardware scale have inflated, which makes the energy consumption become a problem to be solved in the expert system. However the traditional database system is hard to satisfy the semantics need of the knowledge repository management, and it spends a lot of time and energy to complete the data management and reasoning. For this reason, the paper presents an approach to construct the fault diagnosis system based on semantic networks, and focus on the research of semantic knowledge organization, management, inference mechanism and knowledge acquisition. In the experiments, we built the model of locomotive's diagnosis expert system. Compared with the relationship database, the proposed approach was more accurate and robust than other method.","",""
2,"T. P. Fries","Automation of rapid fault diagnosis in manufacturing systems using multiple fuzzy agents",2013,"","","","",112,"2022-07-13 09:33:13","","10.1109/CoASE.2013.6654031","","",,,,,2,0.22,2,1,9,"The reasoning process used by humans for fault diagnosis is very difficult to model due to the many factors used in developing a hypothesis. Some of these factors do not correspond to cognitive models. The diagnosis of faults in manufacturing systems is often plagued with human emotions and “gut feelings” which are difficult, if not impossible, to model. Many artificial intelligence approaches to automated fault diagnosis use either structural or symptom-based reasoning. Functional approaches are unable to provide realtime response due to their computational complexity, whereas, symptom-based approaches are only able to handle situations specifically coded in rules. Current hybrid approaches that combine the two methods are too structured in their approach to switching between the reasoning methods and, therefore fail to provide the flexible, rapid response of human experts. This paper presents a robust, extensible approach to fault diagnosis that allows unstructured switching between reasoning models using multiple fuzzy intelligent agents that examine the problem domain from a variety of perspectives.","",""
3,"M. D. Gregorio, Alessandro Rullo, S. Rubinacci","ISIDIS: an intelligent videosurveillance system",2012,"","","","",113,"2022-07-13 09:33:13","","10.1145/2254556.2254721","","",,,,,3,0.30,1,3,10,"In this paper we propose a new approach to active video surveillance intelligence systems based on the integration of artificial neural networks (ANN) and symbolic Artificial Intelligence (AI). In particular, the neurosymbolic hybrid system here presented is formed by virtual neural sensors (WiSARD--like systems) and BDI agents. The coupling of virtual neural sensors with symbolic reasoning for interpreting their outputs, makes this approach both very light from the computational and hardware point of view and quite robust in performances.","",""
34,"O. Arieli","Paraconsistent Declarative Semantics for Extended Logic Programs",2002,"","","","",114,"2022-07-13 09:33:13","","10.1023/A:1016358201013","","",,,,,34,1.70,34,1,20,"","",""
0,"Saud Ben Mahmoud Mandourah","DEVELOPING A WEB-BASED ONTOLOGY FOR EXPERT DECISION SUPPORT SYSTEMS",2015,"","","","",115,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,7,"Expert systems were originally developed to solve illdefined problems and well-defined problems that are not efficiently solved with algorithmic approaches. This technology provides an innovative and robust techniques to capture and package knowledge. Its strength lies in its ability to be put to practical use when an expert is not available. This technology has proven to be especially effective when the task is in a rapidly changing environment. On the other side, ontology is the foundation of describing a domain of interest and it consists in a collection of terms organized in a hierarchical structure that shape the reality. The main objective of using ontologies is to share knowledge between computers or computers and human. Most of the usages of ontologies in the field of artificial intelligence are related to knowledge based systems and intelligent systems. These types of ontologies include a small number of concepts and their main objective is to facilitate reasoning tasks. This paper presents the developing of web-based ontology for expert systems technology. The developed ontology was encoded in OWL-DL format using the Protégé-OWL editing environment. Keywords-Ontological Engineering, Expert Systems, Artificial Intelligence, Knowledge Engineering, Web Technology","",""
0,"S. Saratha, Pei Fen Ng, Velavan Muraly","Application of Higher Order Hopfield Network",2013,"","","","",116,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,3,9,"Neural network and logic integration is the latest trend in Artificial Intelligence. Neural Symbolic Integration is a combination of neural networks’ robust learning capabilities with symbolic knowledge representation, reasoning, and explanation capabilities in ways that retain the strengths of each paradigm. In this paper, an Agent Based Modelling (ABM) was introduced by using Netlogo which carry out higher order horn clauses in Hopfield network. Our interest in this paper is confined largely to an important class of neural networks that perform useful computations through a process of learning. So, from the ABM that designed, we can carry out some computer simulation to verify and test the ABM develop.","",""
32,"H. Lieberman, Hugo Liu, P. Singh, Barbara Barry","Beating Some Common Sense into Interactive Applications",2003,"","","","",117,"2022-07-13 09:33:13","","","","",,,,,32,1.68,8,4,19,"A long-standing dream of artificial intelligence has been to put common sense knowledge into computers—enabling machines to reason about everyday life. Some projects, such as Cyc, have begun to amass large collections of such knowledge. However, it is widely assumed that the use of common sense in interactive applications will remain impractical for years, until these collections can be considered sufficiently complete and common sense reasoning sufficiently robust. Recently, at the MIT Media Lab, we have had some success in applying common sense knowledge in a number of intelligent Interface Agents, despite the admittedly spotty coverage and unreliable inference of today's common sense knowledge systems. This paper will survey several of these applications and reflect on interface design principles that enable successful use of common sense knowledge.","",""
0,"Fabio Gagliardi Cozman","Imprecise Probability in Graphical Models : Achievements and Challenges Invited talk at ECSQARU Barcelona",,"","","","",118,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,,"In this issue of the SIPTA newsletter you will find a summary of Serafin Moral’s invited talk on imprecise probabilities at ECSQARU (European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty). The ECSQARU meetings are one of the most important foruns dealing with representations for uncertainty within artificial intelligence and computer science; Serafin’s participation as invited speaker certainly testifies to his leading role in the world of imprecise probabilities. Thanks to Serafin for providing a nice summary of his talk. This issue of the newsletter also brings information on the coming 4th International Symposium on Imprecise Probabilities and their Applications (ISIPTA ’05), to occur in Pittsburgh, United States. You will find here the list of accepted papers, tutorials, and invited talks. We also have the announcement of the workshop on “Info-Gap Analysis of Engineering Systems: Robust Decisions under Severe Uncertainty,” and abstracts of papers announced at the SIPTA mailing list. Finally, in the Software Section, this issue brings information on Thomas Lukasiewicz’s NMPROBLOG, a package that deals with nonmonotonic probababilistic logics and their associated probability intervals. Also, if you know of any event or publication that should be of interest to members of SIPTA, send a message about it to fgcozman@usp.br. Cheers!","",""
45,"J. Hushon","Expert systems for environmental problems",1987,"","","","",119,"2022-07-13 09:33:13","","10.1021/ES00163A604","","",,,,,45,1.29,45,1,35,"Expert systems comprise a branch of artificial intelligence. Defined as man and machine systems with specialized, problem-solving expertise, expert systems rely on a data base of knowledge about a particular subject area, an understanding of the problems addressed within that subject area, and skill at solving these problems. Expert systems software was developed during the early 1970s and was initially applied to well-defined problem areas. Gradually this software has become more robust and has evolved into domain-independent software that can facilitate the construction of applications. These expert system software tools are referred to as shells. Currently a number of these shells are available on microcomputers, and some come on minicomputers as well. The following types of situations are ideal candidates for expert systems solutions: situations that occur often, situations that are complex, situations that require knowledge of experts (higher reasoning), situations in which uncertainty is involved, situations that are dynamic, and situations that demand consistent responses. Nonetheless, expert systems are starting to be used to recognize and manage environmental problems. In general, expert systems can be divided into a number of functional categories: planning, monitoring and control, instruction, interpretation, production, diagnosis and repair, and design. Table 1 shows the environmentalmore » systems, classified according to this scheme. Note that no environmental systems were found that were devoted to monitoring and control, instrumentation, or design.« less","",""
4,"H. V. Ditmarsch, Tim French","On the Interactions of Awareness and Certainty",2011,"","","","",120,"2022-07-13 09:33:13","","10.1007/978-3-642-25832-9_74","","",,,,,4,0.36,2,2,11,"","",""
14,"Reasey Praing, Markus Schneider","Efficient Implementation Techniques for Topological Predicates on Complex Spatial Objects",2008,"","","","",121,"2022-07-13 09:33:13","","10.1007/s10707-007-0035-y","","",,,,,14,1.00,7,2,14,"","",""
27,"K. Kempf","Manufacturing planning and scheduling: where we are and where we need to be",1989,"","","","",122,"2022-07-13 09:33:13","","10.1109/CAIA.1989.49132","","",,,,,27,0.82,27,1,33,"The lack of robust geometric reasoning components in most current process planning expert systems is discussed. The lack of metaknowledge in most existing production-scheduling systems is examined. The large amount of effort required to bring a research system into daily factory use is detailed. Finally, the large amount of effort needed to integrate intelligent planning and scheduling is considered.<<ETX>>","",""
10,"M. D. Gregorio","An Intelligent Active Video Surveillance System Based on the Integration of Virtual Neural Sensors and BDI Agents",2008,"","","","",123,"2022-07-13 09:33:13","","10.1093/ietisy/e91-d.7.1914","","",,,,,10,0.71,10,1,14,"In this paper we present an intelligent active video surveillance system currently adopted in two different application domains: railway tunnels and outdoor storage areas. The system takes advantages of the integration of Artificial Neural Networks (ANN) and symbolic Artificial Intelligence (AI). This hybrid system is formed by virtual neural sensors (implemented as WiSARD–like systems) and BDI agents. The coupling of virtual neural sensors with symbolic reasoning for interpreting their outputs, makes this approach both very light from a computational and hardware point of view, and rather robust in performances. The system works on different scenarios and in difficult light conditions.","",""
0,"Y. Fu, Shu Qian Chen, Li Hong Zhang","Ant Colony Algorithm’s Application of Textile Monitoring Image Recognition",2011,"","","","",124,"2022-07-13 09:33:13","","10.4028/www.scientific.net/AMR.328-330.1701","","",,,,,0,0.00,0,3,11,"We can use video surveillance method to detection the weft in Glass fiber textile machine, avoids glass fiber weft bristling by contact weft detection sensor, Glass fiber dust damages to human health. Using Ant Colony algorithm of intelligent search, global optimization, robust, positive feedback, distributed computing, easy combination with other methods and other characteristics, resolve image segmentation, extraction monitor weft system in regional conditions, then use the default rule-based artificial intelligence reasoning in the region separately.","",""
16,"P. Hitzler, Sebastian Bader, A. Garcez","Ontology learning as a use-case for neural-symbolic integration",2005,"","","","",125,"2022-07-13 09:33:13","","","","",,,,,16,0.94,5,3,17,"We argue that the field of neural-symbolic integration is in need of identifying application scenarios for guiding further research. We furthermore argue that ontology learning — as occuring in the context of semantic technologies — provides such an application scenario with potential for success and high impact for neural-symbolic integration. 1 Neural-Symbolic Integration Intelligent systems based on symbolic knowledge processing on the one hand, and on artificial neural networks (also called connectionist systems) on the other, differ substantially. They are both standard approaches to artificial intelligence and it would be very desirable to combine the robust neural networking machinery with symbolic knowledge representation and reasoning paradigms like logic programming in such a way that the strengths of either paradigm will be retained. The importance of these efforts to bridge the gap between the connectionist and symbolic paradigms of Artificial Intelligence has been widely recognised. Since the amount of hybrid data which includes symbolic elements as well as statistical aspects and noise increases dramatically in diverse areas such as bioinformatics or text and web domains, this problem is of particular practical importance. The merging of theory (background knowledge) and data learning (learning from examples) in neural networks has been indicated to provide learning systems that are more effective than purely symbolic and purely connectionist systems, especially when data are noisy and described by real-valued as well as symbolic components. The above results, due also to the massively parallel architecture of neural networks, contributed decisively to the growing interest in developing neural-symbolic systems, i.e. hybrid systems based on neural networks that are capable of learning from examples and background knowledge, and of performing reasoning tasks in a massively parallel fashion. Typically, translation algorithms from a symbolic to a connectionist representation and vice-versa are employed to provide either (i) a neural implementation of a logic, (ii) a logical characterization of a neural system, or (iii) a hybrid system that brings together features from connectionism and symbolic Artificial Intelligence. However, while symbolic knowledge representation is highly recursive and well understood from a declarative point of view, neural networks encode knowledge implicitly in their weights as a result of learning and generalisation from raw data which is usually characterized by simple feature vectors. While significant theoretical progress has recently been made on knowledge representation and reasoning using neural networks on the one side and direct processing of symbolic and structured data with neural methods on the other side, the integration of neural computation and expressive logics such as first order logic is still in its early stages of methodological development. As for knowledge extraction, neural networks have been applied to a variety of real-world problems (e.g. in bioinformatics, engineering, robotics), having been particularly successful when data are noisy, but entirely satisfactory methods for extracting symbolic knowledge from such trained networks are still to be found, and principled problems to ensure the stability and learnability of recursive models currently impose severe restrictions on connectionist systems. In order to advance the state of the art, we believe that it is necessary to look at the biological inspiration for neural-symbolic integration, to use more formal approaches for translating between the connectionist and symbolic paradigms, and to pay more attention to potential application scenarios. We will argue in the following that ontology learning provides such an application scenario with potential for success and high impact. 2 The Need for Use Cases The general motivation for research in the field of neuralsymbolic integration just given arises from conceptual observations on the complementary nature of symbolic and neuralnetwork-based artificial intelligence which we described. This conceptual perspective is sufficient for justifying the mainly foundations-driven lines of research being undertaken in this area so far. However, it appears that this conceptual approach to the study of neural-symbolic integration has now reached an impasse which requires the identification of use cases and application scenarios in order to drive future research. Indeed, the theory of integrated neural-symbolic systems has reached a quite mature state but has not been tested so far on real application data. From the pioneering work by McCulloch and Pitts [22], a number of systems have been developed in the 80s and 90s, including Towell and Shavlik’s KBANN [28], Shastri’s SHRUTI [26], the work by Pinkas [24], Holldobler [17], and d’Avila Garcez et al. [11; 13], to mention a few, and we refer to [8; 12; 15] for comprehensive literature overviews. These systems, however, have been developed for the study of general principles, and are in general not suitable for real data or application scenarios. Nevertheless, these studies provide methods which can be exploited for the development of tools for use cases, and significant progress can now only be expected by developing practical tools out of the fundamental research undertaken in the past. The systems just mentioned — and most of the research on neural-symbolic integration to date — is based on propositional logic or similarly finitistic paradigms. Significantly large and expressible fragments of first order logic are rarely being used because the integration task becomes much harder due to the fact that the underlying language is infinite but shall be encoded using networks with a finite number of nodes [6]. The few approaches known to us for overcoming this problem are work on recursive autoassociative memory, RAAM, initiated by Pollack [25], which concerns the learning of recursive terms over a first-order language, and research based on a proposal by Holldobler et al. [19], spelled out first for the propositional case in [18], and reported also in [16]. It is based on the idea that logic programs can be represented — at least up to subsumption equivalence [21] — by their associated single-step or immediate consequence operators. Such an operator can then be mapped to a function on the real numbers, which can under certain conditions in turn be encoded or approximated e.g. by feedforward networks with sigmoidal activation functions using an approximation theorem due to Funahashi [10]. Despite a number of sophisticated theoretical results building on the latter approach — reported e.g. in [19; 4; 16; 6; 5] —, first-order neural-symbolic integration still appears to be a widely open issue, where advances are very difficult, and it is very hard to judge to date to what extent the theoretical approaches can work in practice. The development of use cases with varying levels of expressive complexity are therefore needed in order to drive the development of methods for neural-symbolic integration beyond propositional logic. 3 Semantic Technologies and Ontology","",""
3,"Rafael V. Borges, A. Garcez, L. Lamb","Representing, Learning and Extracting Temporal Knowledge from Neural Networks: A Case Study",2010,"","","","",126,"2022-07-13 09:33:13","","10.1007/978-3-642-15822-3_13","","",,,,,3,0.25,1,3,12,"","",""
17,"S. Parsons, O. Pettersson, A. Saffiotti, M. Wooldridge","Robots with the Best of Intentions",1999,"","","","",127,"2022-07-13 09:33:13","","10.1007/3-540-48317-9_13","","",,,,,17,0.74,4,4,23,"","",""
1,"D. Aha, M. Boddy, V. Bulitko, A. Garcez, P. Doshi, S. Edelkamp, C. Geib, P. Gmytrasiewicz, R. Goldman, P. Hitzler, C. Isbell, D. Josyula, L. Kaelbling, K. Kersting, M. Kunda, L. Lamb, B. Marthi, Keith McGreggor, Vivi Nastase, G. Provan, A. Raja, A. Ram, Mark O. Riedl, Stuart J. Russell, Ashish Sabharwal, J. Smaus, G. Sukthankar, K. Tuyls, R. V. D. Meyden, A. Halevy, Lilyana Mihalkova, Sriraam Natarajan","Reports of the AAAI 2010 Conference Workshops",2010,"","","","",128,"2022-07-13 09:33:13","","10.1609/aimag.v31i4.2318","","",,,,,1,0.08,0,32,12,"The AAAI-10 Workshop program was held Sunday and Monday, July 11–12, 2010 at the Westin Peachtree Plaza in Atlanta, Georgia. The AAAI-10 workshop program included 13 workshops covering a wide range of topics in artificial intelligence. The titles of the workshops were AI and Fun, Bridging the Gap between Task and Motion Planning, Collaboratively-Built Knowledge Sources and Artificial Intelligence, Goal-Directed Autonomy, Intelligent Security, Interactive Decision Theory and Game Theory, Metacognition for Robust Social Systems, Model Checking and Artificial Intelligence, Neural-Symbolic Learning and Reasoning, Plan, Activity, and Intent Recognition, Statistical Relational AI, Visual Representations and Reasoning, and Abstraction, Reformulation, and Approximation. This article presents short summaries of those events.","",""
1,"Harold Blake Cooper","Learning Meaning in Genesis",2009,"","","","",129,"2022-07-13 09:33:13","","","","",,,,,1,0.08,1,1,13,"Genesis is an existing software system for understanding and reasoning about language and vision. One of the modules in Genesis uses about 1000 lines of Java code representing 31 rules to turn English sentences into a variety of more meaningful semantic representations. I reproduced the functionality of these rules by training the existing rule-learning program Understand with 43 human-readable examples of English sentences and corresponding semantic representations, resulting in 18 rules. These new rules and the framework for training and using them provides Genesis with a more robust and extensible semantic parser. This research also led me to make several improvements to Understand, making it both more powerful and easier to train. Thesis Supervisor: Patrick H. Winston Title: Ford Professor of Artificial Intelligence and Computer Science","",""
5,"T. P. Fries","Multi-Agent Fault Diagnosis in Manufacturing Systems Using Soft Computing",2007,"","","","",130,"2022-07-13 09:33:13","","10.1109/KIMAS.2007.369804","","",,,,,5,0.33,5,1,15,"The expeditious and accurate diagnosis of faults in manufacturing systems is essential in order to avoid expensive downtime. Many artificial intelligence approaches to automated fault diagnosis use techniques that are too computationally complex to achieve a diagnosis in real-time or are too inflexible for dynamic systems. Other approaches use either structural or symptom-based reasoning. Functional approaches are unable to provide real-time response due to their computational complexity, whereas, symptom-based approaches are only able to handle situations specifically coded in rules. Current hybrid approaches that combine the two methods are too structured in their approach to switching between the reasoning methods and, therefore fail to provide the flexible, rapid response of humans experts. This paper presents a robust, extensible approach to fault diagnosis that allows unstructured switching between reasoning methods using multiple fuzzy intelligent agents that examine the problem domain from a variety of perspectives.","",""
4,"Xiaoyang Tong, Xiaoru Wang","Agent-oriented Petri Net based Modeling of Dynamic Behavior for Wide-area Backup Protection",2007,"","","","",131,"2022-07-13 09:33:13","","10.1109/SNPD.2007.95","","",,,,,4,0.27,2,2,15,"The study of agent-based wide-area backup protection (WABP) in power system has become a hot. An improved agent-oriented Petri net (AOPN) is proposed to simulate dynamic behaviors of multi-agent system. The general architecture of improved AOPN is set up, as well as formalized definitions, structural properties and theorems to describe Petri net. Agent-oriented Petri net for WABP is constructed; autonomy, corporation, concurrency and robustness characters of WABP agent are designed. The analysis of L3-liveness and consistency of Petri net are given. The reasoning results of three samples illustrate the accurateness of Petri net for WABP and effectiveness of capturing dynamic behaviors. Design errors can be found to make the system being robust and reliable.","",""
3,"Burkhard Schafer","Can you have too much of a good thing? A comment on Bart Verheij's legal argumentation support software",2007,"","","","",132,"2022-07-13 09:33:13","","10.1093/LPR/MGM038","","",,,,,3,0.20,3,1,15,"Bart Verheij’s paper (this volume, p. 187) on argumentation support software (ASS) gives an excellent account of the past and present of ASS for legal reasoning, and offers some tantalizing glimpses of what the future may have to offer. In my reply, I want to focus on one particular aspect of his presentation, the use of ASS as a teaching tool and in particular a tool for the teaching of reasoning with facts and evidence. Generally speaking, there are good reasons to be sceptical when artificial intelligence (AI) systems are presented as teaching aids. The search for commercial strength legal expert systems that perform autonomously the tasks of human experts has so far proved largely elusive. Two related issues in particular have been identified as recurrent problems. The first is robustness, i.e. the ability to deal with new scenarios not anticipated by the developers. Systems are said to be robust if they remain operational in circumstances for which they were not designed. In the context of criminal evidence, for instance, robustness would require adaptability to unforeseen crime scenarios. This objective is difficult to achieve because low-volume major crimes tend to be virtually unique. Each major crime scenario potentially consists of a unique set of circumstances, while many conventional AI techniques have difficulties in handling previously unseen problem settings. This then results in the second problem, the knowledge acquisition bottleneck. Reasoning about evidence in legal settings is knowledge intensive, requiring input from a broad range of scientific disciplines and also formal representations of large chunks of everyday knowledge. In teaching environments by contrast, the educator has control over the type of problems they choose, their complexity and relevant parameters and features. This brings teaching applications seemingly closer to the ‘worked examples’ or prototypes that are so often the result of the research programs by small teams of academics that dominate the AI and law field—including projects by the author of this reply. Verheij deserves considerable credit for resisting the temptation to see teaching applications just as a simpler task for AI research. Of particular value is his emphasis on rigorous empirical evaluation of the effectiveness of his systems in a teaching environment, and the systematic way in which evaluations that he has carried out in the past influence his theoretical analysis of the problem. This type of evidence-based approach to software-supported teaching in law has so far been missing. Indeed, with few exceptions such as Hall and Zeleznikow (2001), there has been little research into the empirical valuation of legal AI in general. His conclusions are refreshingly honest too, identifying some potential problems in his own approach and indicating a whole range of possible extensions and even wholesale revisions. My observations and comments will elaborate on these findings. In","",""
3,"M. De Gregorio","A Hybrid Intelligent System for Active Video Surveillance",2007,"","","","",133,"2022-07-13 09:33:13","","","","",,,,,3,0.20,3,1,15,"In this paper we propose a new approach to active video surveillance intelligence systems based on the integration of artificial neural networks (ANN) and symbolic Artificial Intelligence (AI). In particular, the neurosymbolic hybrid system here presented is formed by virtual neural sensors (WiSARD-like systems) and BDI agents. The coupling of virtual neural sensors with symbolic reasoning for interpreting their outputs, makes this approach both very light from the computational and hardware point of view and quite robust in performances.","",""
0,"K. Fernando","Soft computing techniques in power system analysis",2008,"","","","",134,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,14,"Soft computing is a concept that has come into prominence in recent times and its application to power system analysis is still more recent. This thesis explores the application of soft computing techniques in the area of voltage stability of power systems.  Soft computing, as opposed to conventional “hard” computing, is a technique that is tolerant of imprecision, uncertainty, partial truth and approximation.  Its methods are based on the working of the human brain and it is commonly known as artificial intelligence. The human brain is capable of arriving at valid conclusions based on incomplete and partial data obtained from prior  experience. It is an approximation of this process on a very small scale that is used in soft computing. Some of the important branches of soft computing (SC) are artificial neural networks (ANNs), fuzzy logic (FL), genetic  computing (GC) and probabilistic reasoning (PR). The soft computing methods are robust and low cost.  It is to be noted that soft computing methods are used in such diverse fields as missile guidance, robotics, industrial plants, pattern recognition, market prediction, patient diagnosis, logistics and of course power system analysis and prediction. However in all these fields its application is comparatively new and research is being carried out continuously in many universities and  research institutions worldwide.  The research presented in this thesis uses the soft computing method of Artificial Neural Networks (ANN’s) for the prediction of voltage instability in power systems. The research is very timely and current and would be a substantial contribution to the present body of knowledge in soft computing and voltage stability, which by itself is a new field. The methods developed in this research would be faster and more economical than presently available methods enabling their use online.","",""
7,"H. Vafaie, C. Cecere","CORMS AI: Decision Support System for Monitoring US Maritime Environment",2005,"","","","",135,"2022-07-13 09:33:13","","","","",,,,,7,0.41,4,2,17,"Rule based reasoning and case based reasoning have emerged as two important and complementary reasoning methodologies in artificial intelligence (AI). This paper describes the approach for the development of CORMS AI, a decision support system which employs rule-based and case-based reasoning to assist NOAA's Center for Operational Oceanographic Products and Services watch standing personnel in monitoring the quality of marine environmental data and information.    CORMS AI has been in operation since July 2003. The system accurately and reliably identifies suspect data and network disruptions, and has decreased the amount of time it takes to identify and troubleshoot sensor, network, and server failures. CORMS AI has proven to be robust, extendable, and cost effective. It is estimated that CORMS AI will save government over one million dollars per year when its full range of quality control monitoring capabilities is implemented.","",""
8,"A. Martin-Alvarez, R. Volpe, S. Hayati, R. Petras","Fuzzy reactive piloting for continuous driving of long range autonomous planetary micro-rovers",1999,"","","","",136,"2022-07-13 09:33:13","","10.1109/AERO.1999.793152","","",,,,,8,0.35,2,4,23,"A complete piloting control subsystem for a highly autonomous long range rover will be defined in order to identify the key control functions needed to achieve continuous driving. This capability can maximize range and number of interesting scientific sites visited during the limited life time of a planetary rover. To achieve continuous driving, a complete set of techniques have been employed: fuzzy based control, real-time artificial intelligence reasoning, fast and robust rover position estimation based on odometry and angular rate sensing, efficient stereo vision elevation maps based on grids, and fast reaction and planning for obstacle detection and obstacle avoidance based on a simple IF-THEN expert system with fuzzy reasoning. To quickly design and implement these techniques, graphical programming has been used to build a fully autonomous piloting system using just the techniques of classic control concepts of cyclic data processing and event driven reaction. Experimental results using the JPL rover Rocky 7 are given in order to validate the mentioned techniques for continuous driving.","",""
0,"M. D. Gregorio","A Hybrid Intelligent System for Active Video Surveillance",2007,"","","","",137,"2022-07-13 09:33:13","","10.1109/ISDA.2007.9","","",,,,,0,0.00,0,1,15,"In this paper we propose a new approach to active video surveillance intelligence systems based on the integration of artificial neural networks (ANN) and symbolic Artificial Intelligence (AI). In particular, the neurosymbolic hybrid system here presented is formed by virtual neural sensors (WiSARD-like systems) and BDI agents. The coupling of virtual neural sensors with symbolic reasoning for interpreting their outputs, makes this approach both very light from the computational and hardware point of view and quite robust in performances.","",""
7,"Jiejun Huang, Heping Pan, Youchuan Wan","An Algorithm for Cooperative Learning of Bayesian Network Structure from Data",2004,"","","","",138,"2022-07-13 09:33:13","","10.1007/11568421_9","","",,,,,7,0.39,2,3,18,"","",""
7,"K. Krawiec","Constructive induction in learning of image representation",2000,"","","","",139,"2022-07-13 09:33:13","","","","",,,,,7,0.32,7,1,22,"Abstract This report describes the results of investigations on the use of genetic programming for learning in pattern recognition problems. The general idea consists in evolutionary search in the space of pattern recognition programs. The solutions are expressed in terms of the Genetic Programming for Visual Learning language (GPVISL), described in this work. This paper continues the work initiated in [Krawiec 2000]. Introduction Reasoning from the visual information belongs to the most complex problems ever faced in computer science and artificial intelligence. Despite several decades of research and experimental efforts, it is generally still not clear how to detect, represent, process, and make use of visual information in robust and effective way. Moreover, we still lack general methodology for design and implementation of pattern recognition systems. And, last but not least, the problem of automatic search for an optimal or sub-optimal (wrt the accuracy of classification) pattern recognition program based on example data or, in other words, the task of incorporating","",""
4,"L. Portinale, A. Bobbio, S. Montani","From AI to Dependability : using Bayesian Networks for Reliability Modeling and Analysis",2004,"","","","",140,"2022-07-13 09:33:13","","","","",,,,,4,0.22,1,3,18,"Bayesian Networks (BN) provide a robust probabilistic method of reasoning under uncertainty. They have been successfully proposed in the field of Artificial Intelligence (AI) as the most flexible formalism for reasoning under uncertain knowledge (Neapolitan 1990; Pearl 1989; Jensen 2001). Their success stands from several factors: • the graphical representation of the knowledge to reason with; in particular the graphical representation of the set of dependencies among the modeled variables, through the notion of d-separation (Pearl 1989); • the restricted number of probabilities to be specified with respect to a complete joint probability model; • the possibility of performing different kinds of inferences such as prediction (i.e. to infer information about effects starting from causes), abduction or diagnosis (i.e. to infer information about causes starting from effects) and inter-causal reasoning (i.e. to infer information about one cause given information about the effect and another cause); • the possibility of "" learning "" the model from a database of observations. For these reasons, they have been successfully applied in a variety of real-world tasks (Heckermann and Wellman 1995). However, they have received little attention in the area of dependability and reliability analysis. A few exceptions are the work by Almond exploiting a special kind of graphical models for modeling the reliability of a system (Almond 1992), the approach in (Torres-Toledano and Sucar 1998; Solano-Soto and Sucar 2001) where reliability block diagrams are converted into Bayesian Networks for the analysis and the recent work by Langseth (Langseth 2002). The present talk is aimed at exploring the capabilities of the BN formalism in the modeling and analysis of dependable systems. Starting from the work described in (Portinale and Bobbio 1999; Bobbio, Portinale, Minichino, and Ciancamerla 2001), we compare BN with one of the most popular techniques for dependability analysis of large, safety critical systems, namely Fault Trees Analysis (FTA). The talk shows that any Fault Tree (FT) can be directly mapped into a BN and that basic inference techniques on the latter may be used to obtain classical parameters computed from the former (i.e. reliability of the Top Event or of any subsystem , criticality of components, etc). The advantage is that, by using BN, some additional power can be obtained, both at the modeling and at the analysis level. At the modeling level, several restrictive assumptions implicit in the FT methodology can be removed and various kinds of dependencies among components can …","",""
2,"Abdel-Badeeh M. Salem","Case-based intelligent e-learning systems",2005,"","","","",141,"2022-07-13 09:33:13","","","","",,,,,2,0.12,2,1,17,"Case based reasoning (CBR) technology presents a foundation for a new technology of building intelligent systems for teaching, learning and training. This Technology directly addresses the problems found in the traditional artificial intelligence (AI) techniques, e.g. the problems of knowledge acquisition, remembering, robust and maintenance. This paper discusses the CBR methodology, the research issues and technical aspects of implementing effective intelligent e-learning systems. Some examples of successful applications in different domain are also given in the paper.","",""
7,"J. E. Arnold","Experiences with the subsumption architecture",1989,"","","","",142,"2022-07-13 09:33:13","","10.1109/CAIA.1989.49141","","",,,,,7,0.21,7,1,33,"A subsumption architecture has been proposed as an effective approach for the construction of robust, real-time control systems for mobile robots. To investigate its strengths and weaknesses, a simulation of the architecture was developed called the Subsumption Architecture Tool (SAT). This simulation allows various models of system behavior to be quickly built and tested. During the building and testing of the SAT, issues related to some architectural features became evident: level of commitment of each layer; code redundancy; problem decomposition and programming style; complexity of large system; and abstract reasoning capabilities. The effects of these issues are presented with respect to the design and implementation choices of two sample layers of behavior. These layers are used to illustrate considerations that need to be taken into account when a project team is considering the use of the subsumption architecture or when a subsumption-architecture-based system is being designed and implemented.<<ETX>>","",""
5,"K. Monta, J. Itoh, M. Makino","An advanced man-machine system for BWR nuclear power plants",1992,"","","","",143,"2022-07-13 09:33:13","","10.1109/HFPP.1992.283393","","",,,,,5,0.17,2,3,30,"Developmental efforts to improve man-machine systems for BWR nuclear power plants have been carried out. A computerized operator support system has been developed based on the operators' role from the plant operational safety point of view. The support of human operators in their knowledge-based behaviour to cope with unanticipated abnormal events has been developed, considering the advance in artificial intelligence and cognitive system engineering. A top down design approach has been adopted based on cognitive work analysis, and the following main functions have been established: an ecological interface-support of the operator's direct preception and analytical reasoning; an cognitive model-based advisor-support of the operators' cognitive resources; and a robust automatic sequence controller.<<ETX>>","",""
1,"H. Vafaie, C. Cecere","CORMS AI: continuous operational real-time monitoring system",2004,"","","","",144,"2022-07-13 09:33:13","","10.1109/ICTAI.2004.44","","",,,,,1,0.06,1,2,18,"Rule based reasoning and case based reasoning have emerged as two important and complementary reasoning methodologies in artificial intelligence (AI). We describe the approach for the development of CORMS AI, a decision support system which employs rule-based and case-based reasoning to assist National Ocean Service watch standing personnel in monitoring the quality of incoming and outgoing marine environmental data and information. CORMS AI has proven to be robust, extendable, and cost effective. It is estimated that CORMS AI save government over one million dollars per year when its full range of quality control monitoring capabilities is implemented.","",""
3,"K. Chau, Chun-tian Cheng, Y. S. Li, C. W. Li, O. Wai","An Intelligent Knowledge Processing System on Hydrodynamics and Water Quality Modeling",2002,"","","","",145,"2022-07-13 09:33:13","","10.1007/3-540-48035-8_65","","",,,,,3,0.15,1,5,20,"","",""
3,"G. DeJong, S. Hutchinson, M. Spong","Integration of Machine Learning and Sensor-Based Control in Intelligent Robotic Systems",1993,"","","","",146,"2022-07-13 09:33:13","","10.23919/ACC.1993.4792873","","",,,,,3,0.10,1,3,29,"This paper discusses the integration of machine learning and sensor-based control in intelligent robotic systems. Our research is interdisciplinary and combines techniques of explanation-based control with robust and adaptive nonlinear control, computer vision, and motion planning. Our intent in this research is to go beyond the strict hierarchical control architectures typically used in robotic systems by integrating modeling, dynamics, and control across traditional levels of planning and control at all levels of intelligence. Our ultimate goal is to combine analytical techniques of nonlinear dynamics and control with artificial intelligence into a single new paradigm in which symbolic reasoning holds an equal place with differential equation based modeling and control.","",""
1,"E. Ruspini","Applications of Intelligent Multiobjective Fuzzy Decision Making",1998,"","","","",147,"2022-07-13 09:33:13","","10.1007/978-3-642-58930-0_25","","",,,,,1,0.04,1,1,24,"","",""
1,"M. Quafafou","GAITS II: An Intelligent System for Computer-Aided Education",1994,"","","","",148,"2022-07-13 09:33:13","","10.1007/3-540-58495-1_23","","",,,,,1,0.04,1,1,28,"","",""
0,"Pan Quan, Zhang Shan-ying, Wang Gang, Z. Hongcai","Some Research on Conflict and Robustness of Evidence Theory",2001,"","","","",149,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,4,21,"Evidence reasoning has good performance in dealing with uncertain information. But in general, Dempster’ s rule is suitable to solve the problem with high belief and low conflict. In this paper, the drawbacks of Dempster’ s rule mentioned above are analyzed firstly. According to the different resource of conflict, two methods are proposed to solve the problem of high conflict. Furthermore, a new concept “conflict rate” is defined and its formula is given out. The robust range of Dempster’ s rule and these two new methods are easily analyzed with the sectional conflict rate and then extended to general discernment frame. As a conclusion, the two methods have better performance in treating with conflict and robustness than Dempster’ s rule and other rules. Key word: Evidence reasoning, conflict rate, artificial intelligence, robustness.","",""
0,"L. Fesq, E. Atkins, L. Khatib, C. Pecheur, P. Cohen, L. Stein, M. Lent, J. Laird, A. Provetti, Tran Cao Son","AAAI 2001 Spring Symposium Series Reports",2001,"","","","",150,"2022-07-13 09:33:13","","10.1609/aimag.v22i3.1585","","",,,,,0,0.00,0,10,21,"The Association for the Advancement of Artificial Intelligence, in cooperation with Stanford University's Department of Computer Science, presented the 2001 Spring Symposium Series on Monday through Wednesday, 26 to 28 March 2001, at Stanford University. The titles of the seven symposia were (1) Answer Set Programming: Toward Efficient and Scalable Knowledge, Representation and Reasoning, (2) Artificial Intelligence and Interactive Entertainment, (3) Game-Theoretic and Decision-Theoretic Agents, (4) Learning Grounded Representations, (5) Model-Based Validation of Intelligence, (6) Robotics and Education, and (7) Robust Autonomy.","",""
0,"Michael Lebowitz","Automatic Concept Formation in a Rich Input Domain",1988,"","","","",151,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,1,34,"Abstract : Learning by observation involves the creation of categories summarizing experience. In this research note, we summarize our research during the contact period with UNIMEM, an Artificial Intelligence system that learns by observation. UNIMEM is a robust computer program that can be run on many domains with real-world problem characteristics, such as uncertainty, incompleteness, and large numbers of examples. We give an overview of the program that illustrates UNIMEM's key elements, including the automatic creation of non- disjoint concept hierarchies that are evaluated over time. We then describe several experiments that we have carried out with UNIMEM, testing it on different domains (universities, Congressional voting records, and terrorist events), and an examination of the effect of varying UNIMEM's parameters on the resulting concept hierarchies. Finally, we discuss future directions for our work with the program. Keywords: Expert systems, Reasoning, UNIMEM(Universal Memory).","",""
0,"A. Choi","Colloquium",1995,"","","","",152,"2022-07-13 09:33:13","","10.1002/yea.320111804","","",,,,,0,0.00,0,1,27,"Recent and rapid advances in Artificial Intelligence (AI), particularly in the form of deep neural networks, has opened many new possibilities, but it has also brought with it many new challenges. In particular, it has become increasingly apparent that while deep neural networks are highly performant, they can also be opaque and brittle. We do not have enough understanding of why and when they work well, and why they may fail completely when faced with new situations not seen in the training data. In this talk, we propose a symbolic approach to explaining the behavior and verifying the properties of machine learning models, which is based on sustained advances in logical and probabilistic reasoning. We show how our approach facilitates the analysis of a neural network, helping us to understand its behavior, and in turn, providing directions towards learning better and more robust models.","",""
1,"V. Lesser, B. Horling, F. Klassner, A. Raja, T. W. Zhang","Recent Extensions to BI: A Resource-Bounded Information Gathering System",1999,"","","","",153,"2022-07-13 09:33:13","","","","",,,,,1,0.04,0,5,23,"BIG (resource-Bounded Information Gathering) is a next generation information gathering agent which integrates several areas of Artificial Intelligence research under a single umbrella. To date, reported work has presented the rationale, architecture, and implementation of the system. This has included planning, reasoning about resource trade-offs of different possible gathering and extraction approaches, information extraction from both structured as well as unstructured documents, and opportunistic refinement of the search process using the extracted information. In this paper, we present recent improvements made to BIG, which make it a more versatile and robust system. These include documentation classification to handle distraction, sophisticated information fusion techniques, and finally the logistics behind search precision versus coverage tradeoffs. We also present empirical evaluations which show the performance improvement due to these extensions.","",""
1,"T. Bearse, M. L. Lynch","An improved technique for applying fuzzy logic in a model-based diagnostics reasoner",1999,"","","","",154,"2022-07-13 09:33:13","","10.1109/AERO.1999.789774","","",,,,,1,0.04,1,2,23,"The authors apply an improved technique based on fuzzy logic to fulfill the requirement to compute a fault hypothesis in a model-based diagnostic reasoner. The primary focus of the paper is to extend previous work and illustrate the use of the improved algorithm. The paper deals primarily with two types of uncertainty: test outcome uncertainty and inference uncertainty. The issue of conflict detection and conclusion rehabilitation is addressed. This proposed fuzzy logic approach uses the confidence parameters defined in the IEEE 1232: Artificial Intelligence Exchange and Service Tie to All Test Environments (AI-ESTATE) standard to provide a robust reasoning under uncertainty capability.","",""
0,"J. Elling, Randy S. Roberts, Sharbari Lahiri","Analysis assessment expert system for gas chromatography",1995,"","","","",155,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,3,27,"An artificial intelligence based analysis assessment system is presented to automate gas chromatography instrument troubleshooting. This system is capable of recognizing symptoms of common problems with GC analysis, reasoning with the symptoms to make a problem diagnosis, and suggest appropriate solutions. In this system, signal processing techniques are used to search for symptoms of problems in the time-series data. For example, peak shapes are analyzed for fronting and tailing and the baseline is analyzed for drift and the presence of electronic spikes. A measurement of the severity of each symptom is then used by the expert system to diagnose potential problems with the analysis. This system will be integrated with the instrument control and laboratory automation that is necessary to effect the recommended solutions when possible. The result will be a more robust instrument capable of recognizing failures and error modes from the sample data and capable of correcting many of the common failures.","",""
0,"S. Anand","Data mining applications to dermatological diseases, colorectal cancer, diabetes, cardiology and medical audit systems",1998,"","","","",156,"2022-07-13 09:33:13","","10.1145/956034.956059","","",,,,,0,0.00,0,1,24,"Diagnosis of Dermatological DiseasesThis project aims to develop tools that would provide doctors with the ability to discover the typical characteristics of certain inflammatory dermatological diseases. It is hoped that this will aid doctors in accurately diagnosing the dermatological disorder, especially between two skin diseases with very similar characteristics such as psoriasis and atopic dermatitis.Prognostic Models for Colorectal Cancer PatientsThe goal of this project is to build a robust prognostic model that will predict length of survival for patients with colorectal cancer. Techniques employed for this purpose include Neural Networks, Case-based reasoning (CBR), Cox's Regression and Regression Tree Induction. Accomplishments have been the development of point estimates of survival from Cox's regression to allow direct comparison of Artificial Intelligence techniques with Cox's results and the development of techniques for building more perspicuous models that are intuitive to medical practitioners.Pre-empting Complications in Diabetic PatientsData, provided by Data Retrieval in General Practice, is currently being used to discover common trends that appear among diabetic patients. These trends can then be used to predict complications in a diabetic's life cycle. This will allow patients who are not at risk to be filtered out and those who are at risk to be carefully monitored. Data mining techniques such as Sequential Pattern Discovery are being employed for this purpose.Risk Assessment in CardiologyThis project has been investigating the use of case-based reasoning and the incorporation of fuzzy logic to provide insight into the understanding of the underlying mechanisms of coronary heart disease. By identifying patients at risk early on, it is easier to stop the progression of this disease. A series of qualitative and quantitative information was gathered from middle aged men, such as weight, blood pressure, body fat and family medical histories over a three year time span, to help identify which factors contribute to coronary heart disease.Integrating Data Mining into Medical Audit SystemsThe aim of this project is to bring Data Mining into mainstream medical audit by integrating it with Medical statistics techniques already in use. This will encourage the practice of Evidence-based medicine, that is becoming a norm in western societies, providing IT support for it. The motivation behind this project is the realization that current Medical statistics techniques fall short of certain objectives and requirements of medical audit.","",""
0,"Bushra Rasheed, M. Usama, Asmara Safdar","Robust Artificial Intelligence Approach to Stabilize and Control Propeller Driven Hybrid UGV",2022,"","","","",157,"2022-07-13 09:33:13","","10.1109/ICAI55435.2022.9773375","","",,,,,0,0.00,0,3,1,"Hybrid Unmanned Ground Vehicle (HUGV) can drive on any terrain including walls and fly as well, using the multi directional thrust force of propellers. In the era of industrial revolution, hybrid UGVs need to be autonomous with intelligent decision making capabilities. During wall climbing of hybrid UGVs, stability is essential and depends on real time feedback from multiple sensors. To increase stability and control, it is proposed that PID control loops should be replaced by AI based algorithms that reduce the decision time and mathematical complexity. For autonomous movement in any terrain using the proposed model, intelligent UGVs can map and localize simultaneously.They can make intelligent decisions about mode of movement i.e. driving on ground or wall, steering on ground or wall, flying and maneuvering by using real time sensor readings. Integration of the proposed AI models with HUGV can be applied to many areas which are hard for humans to access, for instance; inspection of large structures, bio & nuclear hazard environments, planetary exploration & magnetic fields detection.","",""
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",158,"2022-07-13 09:33:13","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
2,"Qiwei-Kong, Jing He, Peizhuang Wang","Factor space:a new idea for artificial intelligence based on causal reasoning",2020,"","","","",159,"2022-07-13 09:33:13","","10.1109/WIIAT50758.2020.00089","","",,,,,2,1.00,1,3,2,"In the rapid development of artificial intelligence in the last several years, machine learning is the mainstream method to realize artificial intelligence. What people usually call machine learning can be equivalent to statistical learning, which requires big data and powerful computing power; This is a machine learning trend driven by data, using algorithms to get a model with clear parameters, ignoring causal reasoning and focusing on statistical data; The machine learning method lacking logical causal reasoning will greatly hinder the advancement of artificial intelligence; How knowledge-driven causal reasoning provides new ideas for artificial intelligence is a question worth thinking about for scholars of artificial intelligence. Factor space theory that emphasizes causal reasoning will provide a new perspective and thinking for the development of artificial intelligence.","",""
120,"R. Byrne","Counterfactuals in Explainable Artificial Intelligence (XAI): Evidence from Human Reasoning",2019,"","","","",160,"2022-07-13 09:33:13","","10.24963/IJCAI.2019/876","","",,,,,120,40.00,120,1,3,"Counterfactuals about what could have happened are increasingly used in an array of Artificial Intelligence (AI) applications, and especially in explainable AI (XAI). Counterfactuals can aid the provision of interpretable models to make the decisions of inscrutable systems intelligible to developers and users. However, not all counterfactuals are equally helpful in assisting human comprehension. Discoveries about the nature of the counterfactuals that humans create are a helpful guide to maximize the effectiveness of counterfactual use in AI.","",""
0,"M. Manna, Andreas Pieris","Reasoning Web. Declarative Artificial Intelligence: 16th International Summer School 2020, Oslo, Norway, June 24–26, 2020, Tutorial Lectures",2020,"","","","",161,"2022-07-13 09:33:13","","10.1007/978-3-030-60067-9","","",,,,,0,0.00,0,2,2,"","",""
134,"J. Lamy, B. Sekar, Gilles Guézennec, J. Bouaud, B. Séroussi","Explainable artificial intelligence for breast cancer: A visual case-based reasoning approach",2019,"","","","",162,"2022-07-13 09:33:13","","10.1016/J.ARTMED.2019.01.001","","",,,,,134,44.67,27,5,3,"","",""
2,"Frank Guerin","Projection: A Mechanism for Human-like Reasoning in Artificial Intelligence",2021,"","","","",163,"2022-07-13 09:33:13","","10.1080/0952813x.2022.2078889","","",,,,,2,2.00,2,1,1,"Artiﬁcial Intelligence systems cannot yet match human abilities to apply knowledge to situations that vary from what they have been programmed for, or trained for. In visual object recognition, methods of inference exploiting top-down information (from a model) have been shown to be eﬀective for recognising entities in diﬃcult conditions. Here a component of this type of inference, called ‘projection’, is shown to be a key mechanism to solve the problem of applying knowledge to varied or challenging situations, across a range of AI domains, such as vision, robotics, or language. Finally the relevance of projection to tackling the commonsense knowledge problem is discussed.","",""
0,"Janmanchi Harika, Palavadi Baleeshwar, Kummari Navya, Hariharan Shanmugasundaram","A Review on Artificial Intelligence with Deep Human Reasoning",2022,"","","","",164,"2022-07-13 09:33:13","","10.1109/icaaic53929.2022.9793310","","",,,,,0,0.00,0,4,1,"Artificial Intelligence (AI) is a broad term that can be construed to mean a focusing computer programming and development that is designed to train machines and to perform task. Artificial intelligence can be used to test theories of reasoning like cognitive reasoning and consciousness. Research has been conducted on the development of machines with human behavior and cognitive characteristics that are related to consciousness. Artificial Intelligence and Reasoning that are dealt with, can necessarily solve problems related to mental health issues that humans find complex, but research on new interaction techniques and human for cooperation theories, technologies limited the issues and challenges facing the application of artificial reasoning. Here in this paper, the relation between artificial intelligence human reasoning that is also called as AI reasoning or artificial reasoning has been studied. Artificial intelligence impacts reasoning and how artificial reasoning can be used in day-to-day activities to regain our mental health. Moreover, this work focuses on problems that can be solved with AI Reasoning in trying to find the possible solutions.","",""
0,"","Reasoning Web. Declarative Artificial Intelligence: 17th International Summer School 2021, Leuven, Belgium, September 8–15, 2021, Tutorial Lectures",2022,"","","","",165,"2022-07-13 09:33:13","","10.1007/978-3-030-95481-9","","",,,,,0,0.00,0,0,1,"","",""
0,"M. Krötzsch, D. Stepanova","Reasoning Web. Explainable Artificial Intelligence: 15th International Summer School 2019, Bolzano, Italy, September 20–24, 2019, Tutorial Lectures",2019,"","","","",166,"2022-07-13 09:33:13","","10.1007/978-3-030-31423-1","","",,,,,0,0.00,0,2,3,"","",""
3,"A. Sans, D. Casacuberta","Remarks on the Possibility of Ethical Reasoning in an Artificial Intelligence System by Means of Abductive Models",2018,"","","","",167,"2022-07-13 09:33:13","","10.1007/978-3-030-32722-4_19","","",,,,,3,0.75,2,2,4,"","",""
0,"德钧 邱","Automatic Logic Reasoning in Artificial Intelligence",2019,"","","","",168,"2022-07-13 09:33:13","","10.12677/airr.2019.81002","","",,,,,0,0.00,0,1,3,"","",""
12,"S. Craw, A. Aamodt","Case Based Reasoning as a Model for Cognitive Artificial Intelligence",2018,"","","","",169,"2022-07-13 09:33:13","","10.1007/978-3-030-01081-2_5","","",,,,,12,3.00,6,2,4,"","",""
15,"M. Bonacina","Automated Reasoning for Explainable Artificial Intelligence",2017,"","","","",170,"2022-07-13 09:33:13","","10.29007/4B7H","","",,,,,15,3.00,15,1,5,"Reasoning and learning have been considered fundamental features of intelligence ever since the dawn of the field of artificial intelligence, leading to the development of the research areas of automated reasoning and machine learning. This paper discusses the relationship between automated reasoning and machine learning, and more generally between automated reasoning and artificial intelligence. We suggest that the emergence of the new paradigm of XAI, that stands for eXplainable Artificial Intelligence, is an opportunity for rethinking these relationships, and that XAI may offer a grand challenge for future research on automated reasoning. 1 Artificial Intelligence, Automated Reasoning, and Ma-","",""
462,"Stuart J. Russell, Dan Dewey, Max Tegmark","Research Priorities for Robust and Beneficial Artificial Intelligence",2015,"","","","",171,"2022-07-13 09:33:13","","10.1609/aimag.v36i4.2577","","",,,,,462,66.00,154,3,7,"Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls. This article gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial.","",""
50,"L. D. Raedt, Sebastijan Dumancic, Robin Manhaeve, G. Marra","From Statistical Relational to Neuro-Symbolic Artificial Intelligence",2020,"","","","",172,"2022-07-13 09:33:13","","10.24963/ijcai.2020/677","","",,,,,50,25.00,13,4,2,"Neuro-symbolic and statistical relational artificial intelligence both integrate frameworks for learning with logical reasoning. This survey identifies several parallels across seven different dimensions between these two fields. These cannot only be used to characterize and position neuro-symbolic artificial intelligence approaches but also to identify a number of directions for further research.","",""
1,"Y. Sheng, Jiahan Zhang, Y. Ge, Xinyi Li, Wentao Wang, H. Stephens, F. Yin, Qiuwen Wu, Q. Wu","Artificial intelligence applications in intensity modulated radiation treatment planning: an overview.",2021,"","","","",173,"2022-07-13 09:33:13","","10.21037/qims-21-208","","",,,,,1,1.00,0,9,1,"Artificial intelligence (AI) refers to methods that improve and automate challenging human tasks by systematically capturing and applying relevant knowledge in these tasks. Over the past decades, a number of approaches have been developed to address different types and needs of system intelligence ranging from search strategies to knowledge representation and inference to robotic planning. In the context of radiation treatment planning, multiple AI approaches may be adopted to improve the planning quality and efficiency. For example, knowledge representation and inference methods may improve dose prescription by integrating and reasoning about the domain knowledge described in many clinical guidelines and clinical trials reports. In this review, we will focus on the most studied AI approach in intensity modulated radiation therapy (IMRT)/volumetric modulated arc therapy (VMAT)-machine learning (ML) and describe our recent efforts in applying ML to improve the quality, consistency, and efficiency of IMRT/VMAT planning. With the available high-quality data, we can build models to accurately predict critical variables for each step of the planning process and thus automate and improve its outcomes. Specific to the IMRT/VMAT planning process, we can build models for each of the four critical components in the process: dose-volume histogram (DVH), Dose, Fluence, and Human Planner. These models can be divided into two general groups. The first group focuses on encoding prior experience and knowledge through ML and more recently deep learning (DL) from prior clinical plans and using these models to predict the optimal DVH (DVH prediction model), or 3D dose distribution (dose prediction model), or fluence map (fluence map model). The goal of these models is to reduce or remove the trial-and-error process and guarantee consistently high-quality plans. The second group of models focuses on mimicking human planners' decision-making process (planning strategy model) during the iterative adjustments/guidance of the optimization engine. Each critical step of the IMRT/VMAT treatment planning process can be improved and automated by AI methods. As more training data becomes available and more sophisticated models are developed, we can expect that the AI methods in treatment planning will continue to improve accuracy, efficiency, and robustness.","",""
1,"R. Joshi, Neeraj Kumar","Artificial Intelligence for Autonomous Molecular Design: A Perspective",2021,"","","","",174,"2022-07-13 09:33:13","","10.3390/molecules26226761","","",,,,,1,1.00,1,2,1,"Domain-aware artificial intelligence has been increasingly adopted in recent years to expedite molecular design in various applications, including drug design and discovery. Recent advances in areas such as physics-informed machine learning and reasoning, software engineering, high-end hardware development, and computing infrastructures are providing opportunities to build scalable and explainable AI molecular discovery systems. This could improve a design hypothesis through feedback analysis, data integration that can provide a basis for the introduction of end-to-end automation for compound discovery and optimization, and enable more intelligent searches of chemical space. Several state-of-the-art ML architectures are predominantly and independently used for predicting the properties of small molecules, their high throughput synthesis, and screening, iteratively identifying and optimizing lead therapeutic candidates. However, such deep learning and ML approaches also raise considerable conceptual, technical, scalability, and end-to-end error quantification challenges, as well as skepticism about the current AI hype to build automated tools. To this end, synergistically and intelligently using these individual components along with robust quantum physics-based molecular representation and data generation tools in a closed-loop holds enormous promise for accelerated therapeutic design to critically analyze the opportunities and challenges for their more widespread application. This article aims to identify the most recent technology and breakthrough achieved by each of the components and discusses how such autonomous AI and ML workflows can be integrated to radically accelerate the protein target or disease model-based probe design that can be iteratively validated experimentally. Taken together, this could significantly reduce the timeline for end-to-end therapeutic discovery and optimization upon the arrival of any novel zoonotic transmission event. Our article serves as a guide for medicinal, computational chemistry and biology, analytical chemistry, and the ML community to practice autonomous molecular design in precision medicine and drug discovery.","",""
139,"D. Parkes, Michael P. Wellman","Economic reasoning and artificial intelligence",2015,"","","","",175,"2022-07-13 09:33:13","","10.1126/science.aaa8403","","",,,,,139,19.86,70,2,7,"The field of artificial intelligence (AI) strives to build rational agents capable of perceiving the world around them and taking actions to advance specified goals. Put another way, AI researchers aim to construct a synthetic homo economicus, the mythical perfectly rational agent of neoclassical economics. We review progress toward creating this new species of machine, machina economicus, and discuss some challenges in designing AIs that can reason effectively in economic contexts. Supposing that AI succeeds in this quest, or at least comes close enough that it is useful to think about AIs in rationalistic terms, we ask how to design the rules of interaction in multi-agent systems that come to represent an economy of AIs. Theories of normative design from economics may prove more relevant for artificial agents than human agents, with AIs that better respect idealized assumptions of rationality than people, interacting through novel rules and incentive systems quite distinct from those tailored for people.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",176,"2022-07-13 09:33:13","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
0,"Ranjith Raveendran, Suresh Perumbure, Sameera G Nath","Artificial intelligence: A newer vista in dentistry.",2021,"","","","",177,"2022-07-13 09:33:13","","10.1111/aor.14128","","",,,,,0,0.00,0,3,1,"BACKGROUND Artificial intelligence (AI) is one of the newest fields in science and engineering. It refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. Artificial intelligence as a science is very broad and encompasses various fields, including reasoning, natural language processing, planning, and machine learning. In modern times the real-world current applications of AI include health care, automotive, finance and economics, playing video games, solving mathematical theorems, writing poetry, driving a car on a crowded street, and many more all of which aim to improve human life.   METHODS The aim of this article is to review the current application of AI in the field of dentistry based on electronic search in various data bases like Google scholar, PubMed, and Scopus.   RESULTS The present review outlines the potential applications of AI in the field of Dentistry in diagnosis, treatment planning, and disease prediction and discusses its impact on dentists, with the objective of creating a support for future research in this rapidly expanding arena.   CONCLUSIONS Artificial intelligence systems can simplify the tasks, give a standardization to the procedures and provide results in quick time which can save the dentist time and help the dentist to perform his duties more efficiently.","",""
0,"J. Dipnall, R. Page, Lan Du, M. Costa, R. Lyons, Peter Cameron, R. D. de Steiger, R. Hau, A. Bucknill, A. Oppy, E. Edwards, D. Varma, M. C. Jung, B. Gabbe","Predicting fracture outcomes from clinical registry data using artificial intelligence supplemented models for evidence-informed treatment (PRAISE) study protocol",2021,"","","","",178,"2022-07-13 09:33:13","","10.1371/journal.pone.0257361","","",,,,,0,0.00,0,14,1,"Background Distal radius (wrist) fractures are the second most common fracture admitted to hospital. The anatomical pattern of these types of injuries is diverse, with variation in clinical management, guidelines for management remain inconclusive, and the uptake of findings from clinical trials into routine practice limited. Robust predictive modelling, which considers both the characteristics of the fracture and patient, provides the best opportunity to reduce variation in care and improve patient outcomes. This type of data is housed in unstructured data sources with no particular format or schema. The “Predicting fracture outcomes from clinical Registry data using Artificial Intelligence (AI) Supplemented models for Evidence-informed treatment (PRAISE)” study aims to use AI methods on unstructured data to describe the fracture characteristics and test if using this information improves identification of key fracture characteristics and prediction of patient-reported outcome measures and clinical outcomes following wrist fractures compared to prediction models based on standard registry data. Methods and design Adult (16+ years) patients presenting to the emergency department, treated in a short stay unit, or admitted to hospital for >24h for management of a wrist fracture in four Victorian hospitals will be included in this study. The study will use routine registry data from the Victorian Orthopaedic Trauma Outcomes Registry (VOTOR), and electronic medical record (EMR) information (e.g. X-rays, surgical reports, radiology reports, images). A multimodal deep learning fracture reasoning system (DLFRS) will be developed that reasons on EMR information. Machine learning prediction models will test the performance with/without output from the DLFRS. Discussion The PRAISE study will establish the use of AI techniques to provide enhanced information about fracture characteristics in people with wrist fractures. Prediction models using AI derived characteristics are expected to provide better prediction of clinical and patient-reported outcomes following distal radius fracture.","",""
38,"H. Jaeger","Artificial intelligence: Deep neural reasoning",2016,"","","","",179,"2022-07-13 09:33:13","","10.1038/nature19477","","",,,,,38,6.33,38,1,6,"","",""
26,"T. Denœux, D. Dubois, H. Prade","Representations of Uncertainty in Artificial Intelligence: Probability and Possibility",2020,"","","","",180,"2022-07-13 09:33:13","","10.1007/978-3-030-06164-7_3","","",,,,,26,13.00,9,3,2,"","",""
301,"E. Davis, G. Marcus","Commonsense reasoning and commonsense knowledge in artificial intelligence",2015,"","","","",181,"2022-07-13 09:33:13","","10.1145/2701413","","",,,,,301,43.00,151,2,7,"AI has seen great advances of many kinds recently, but there is one critical area where progress has been extremely slow: ordinary commonsense.","",""
47,"T. Frei","An Artificial Intelligence Approach To Legal Reasoning",2016,"","","","",182,"2022-07-13 09:33:13","","","","",,,,,47,7.83,47,1,6,"ed to be an introduction to computational jurisprudence for both groups. It identifies issues critical to the purpose , behavior, knowledge sources, knowledge structures, and reasoning processes of expert legal systems. The second part implements a simple prototype system for a well-defined area of contract law and is more appropriate for experienced developers of knowledge-based systems. Law is a domain in which the experts are supposed to disagree, and lawyers must be able to argue either side of a case. A judge or juror must decide which argument is "" best. "" A knowledge based legal reasoning program can only guide analysis and identification of technically defensi-ble positions in a case. However, it should also be able to distinguish between questions that are "" easy "" to decide, and those demanding human analysis. These two ideas form the basis of the prototype's behavior, making it somewhat different from knowledge based systems in most other expert domains. According to Gardner, legal reasoning systems are further distinguished by their knowledge sources and knowledge structures. She reviews the evolution of legal thought in the context of knowledge engineering, raises several critical issues, and draws conclusions about how legal knowledge must be used and represented in programs. In the human world, legal knowledge is represented in cases, and statutes. Although not all areas of law use both sources, she concludes that expert legal systems need both types of knowledge, plus some additional "" common sense knowledge "" to guide analysis effectively. Gardner views statutes as rules defining legal states and their consequences. Although they are convenient starting points for legal analysis , they are usually insufficient for making wise legal decisions. Most litigation involves questions about whether the rules have been followed, what the rules actually mean, and sometimes, which set of rules should be used. Cases contain written arguments about how to answer these questions under specific circumstances, along with their final interpretation by the juror. Lawyers can use similar cases as examples to guide their formulation of arguments in future disputes. Cases are used as precedents for deciding which rules to use in a given situation, and how to apply them. They can be used to annotate and clarify rules that conflict in some context, or whose relevance might be disputed. They can even change the way rules are applied to similar factual situations in the future. In these respects, cases embody …","",""
0,"A. Raglin, Henry Hoffman, Mark R. Mittrick, Haitao Zheng, Justine P. Caylor","Artificial Reasoning Toward Goal-Oriented Adaptive Arrays of Sensors",2021,"","","","",183,"2022-07-13 09:33:13","","10.1109/CogMI52975.2021.00034","","",,,,,0,0.00,0,5,1,"Army future modernization will require an increased focus on data analytics, autonomous systems, cyber security, and automated decision-making, all influenced by emerging capabilities from artificial intelligence research. A critical area of importance is autonomous sensing on the battlefield, such as the ability to detect and reason about people, equipment, and obstacles within the Army's operational environment. The operational environment is extremely complex, dynamic, and fast-paced with highly cluttered data from multiple information sources and heterogeneous systems. The creation and deployment of goal-oriented adaptive arrays of sensors, with various levels of reasoning, could potentially provide capabilities to address these challenges. This paper will present research ideas for incorporating artificial reasoning within a goal-oriented adaptive array of sensors, granting them the ability to reason about methods to improve their performance, use context to interpret multisource data, detect outliers that impact decision-making, and leverage inferencing techniques to support mission goals.","",""
0,"E. Cambouropoulos, Maximos A. Kaliakatsos-Papakostas","Cognitive Musicology and Artificial Intelligence: Harmonic Analysis, Learning, and Generation",2021,"","","","",184,"2022-07-13 09:33:13","","10.1007/978-3-030-72116-9_10","","",,,,,0,0.00,0,2,1,"","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",185,"2022-07-13 09:33:13","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",186,"2022-07-13 09:33:13","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
19,"B. Verheij","Artificial intelligence as law",2020,"","","","",187,"2022-07-13 09:33:13","","10.1007/s10506-020-09266-0","","",,,,,19,9.50,19,1,2,"","",""
0,"Yusen Xie, Ting Sun, Xinglong Cui, Shuixin Deng, Lei Deng, Baohua Chen","Fast-robust book information extraction system for automated intelligence library",2021,"","","","",188,"2022-07-13 09:33:13","","10.1109/AIID51893.2021.9456499","","",,,,,0,0.00,0,6,1,"At present, in the large-scale book management scene, book sorting, daily maintenance and book retrieval are very common, but the book information is complicated and the efficiency of relying on manual management is extremely poor. Although there have been many self-service book systems based on optics or vision, they are mostly based on traditional computer vision algorithms such as boundary extraction. Due to the fact that there are more artificial experience thresholds, some shortcomings such as low detection accuracy, poor robustness, and inability to systematically deploy on a large scale, which lack of insufficient intelligence. Therefore, we proposed a book information extraction algorithm based on object detection and optical character recognition (OCR) that is suitable for multiple book information recognition, multiple book image angles and multiple book postures. It can be applied to scenes such as book sorting, bookshelf management and book retrieval. The system we designed includes the classification of book covers and back covers, the classification of books upright and inverted, the detection of book pages side and spine side, the recognition of book pricing. In terms of accuracy, the classification accuracy of the front cover and the back cover is 99.9%, the upright classification accuracy of book front covers is 98.8%, the back cover reaches 99.9%, the accuracy of book price recognition get 94.5%, and the book spine/page side detection mAP reaches 99.6%; in terms of detection speed, Yolov5 detection model was improved and the statistical-based pre-pruning strategy was adopted, support by our algorithm the system reaches 2.09 FPS in book price recognition, which improves the detection speed to meet actual needs.","",""
77,"Alon Jacovi, Ana Marasović, Tim Miller, Yoav Goldberg","Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI",2020,"","","","",189,"2022-07-13 09:33:13","","10.1145/3442188.3445923","","",,,,,77,38.50,19,4,2,"Trust is a central component of the interaction between people and AI, in that 'incorrect' levels of trust may cause misuse, abuse or disuse of the technology. But what, precisely, is the nature of trust in AI? What are the prerequisites and goals of the cognitive mechanism of trust, and how can we promote them, or assess whether they are being satisfied in a given interaction? This work aims to answer these questions. We discuss a model of trust inspired by, but not identical to, interpersonal trust (i.e., trust between people) as defined by sociologists. This model rests on two key properties: the vulnerability of the user; and the ability to anticipate the impact of the AI model's decisions. We incorporate a formalization of 'contractual trust', such that trust between a user and an AI model is trust that some implicit or explicit contract will hold, and a formalization of 'trustworthiness' (that detaches from the notion of trustworthiness in sociology), and with it concepts of 'warranted' and 'unwarranted' trust. We present the possible causes of warranted trust as intrinsic reasoning and extrinsic behavior, and discuss how to design trustworthy AI, how to evaluate whether trust has manifested, and whether it is warranted. Finally, we elucidate the connection between trust and XAI using our formalization.","",""
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",190,"2022-07-13 09:33:13","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",191,"2022-07-13 09:33:13","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
260,"Huiying Liang, B. Tsui, H. Ni, C. Valentim, Sally L. Baxter, Guangjian Liu, Wenjia Cai, Daniel S. Kermany, Xin Sun, Jiancong Chen, Liya He, Jie Zhu, Pin Tian, Hua Shao, Lianghong Zheng, Rui Hou, Sierra Hewett, Gen Li, P. Liang, Xuan Zang, Zhiqi Zhang, Liyan Pan, Huimin Cai, Rujuan Ling, Shuhua Li, Yongwang Cui, Shusheng Tang, Hong Ye, Xiaoyan Huang, Waner He, W. Liang, Qing Zhang, Jianmin Jiang, Wei Yu, Jianqun Gao, Wanxing Ou, Ying Deng, Qiaozhen Hou, Bei Wang, Cuichan Yao, Yan Liang, Shu Zhang, Yaou Duan, Runze Zhang, Sarah Gibson, Charlotte L. Zhang, Oulan Li, Edward D. Zhang, Gabriel Karin, N. Nguyen","Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence",2019,"","","","",192,"2022-07-13 09:33:13","","10.1038/s41591-018-0335-9","","",,,,,260,86.67,26,50,3,"","",""
1,"T. Sethi, R. Awasthi","Use of artificial intelligence based models for learning better policy for maternal and child health",2020,"","","","",193,"2022-07-13 09:33:13","","10.1093/eurpub/ckaa165.291","","",,,,,1,0.50,1,2,2,"  More than 640,000 babies died of sepsis before they reach the age of one month in India in 2016. Despite a large number of government schemes aimed at reducing this rate, this number still remains high because of the complexity and interplay of factors involved. Finding an optimum policy and solutions to this problem needs learning from data. We integrated diverse sources of data and applied Bayesian Artificial Intelligence methods for learning to mitigate sepsis and adverse pregnancy outcomes in India. In this project, we created models that combine the robustness of ensemble averaged Baeysian Networks with decision learning and impact evaluation by using simulations and counterfactual reasoning respectively. We will demonstrate the process of learning these models and how these led us to infer the pivotal role of Water, Sanitation and Hygiene for reducing Adverse Pregnancy Outcome and neonatal sepsis in the population studied. We will also demonstrate the creation of explainable AI models for complex public health challenges and their deployment with wiseR, our in-house, open source platform for doing end-to-end Bayesian Decision Network learning.","",""
1,"D. Dubois, H. Prade","A Glance at Causality Theories for Artificial Intelligence",2020,"","","","",194,"2022-07-13 09:33:13","","10.1007/978-3-030-06164-7_9","","",,,,,1,0.50,1,2,2,"","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",195,"2022-07-13 09:33:13","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
0,"R. Brachman, David Gunning, Murray Burke","Integrated Artificial Intelligence Systems",2020,"","","","",196,"2022-07-13 09:33:13","","","","",,,,,0,0.00,0,3,2,"Copyright © 2020, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 66 AI MAGAZINE When one thinks about what it might take to build an intelligent system, it is evident that multiple capabilities will be required. Intelligence is generally considered to be reflected in the ability of a system to learn and understand the world around it, and to deal successfully with new or challenging situations. A closer look at what it might take to accomplish this reveals a surprisingly complex set of abilities that must work together. There are many variations on these themes, but roughly speaking, a robustly intelligent, autonomous agent embedded in the real world will need perceptual capabilities to sense and help interpret external signals and phenomena; a set of beliefs about the world, including itself and other agents, cause and effect, and a host of other things relevant to its survival and success in achieving its goals; a variety of reasoning capabilities to determine implications of its beliefs, understand its environment, plan ahead, solve problems, and so forth; a wide array of learning and adaptation capabilities; the ability to affect the world through action; and, some kind of rich communication mechanism along the lines of natural human language generation and understanding.  From Shakey the Robot to self-driving cars, from the personal computer to personal assistants on our phones, the Defense Advanced Research Projects Agency (DARPA) has led the development of integrated artificial intelligence (AI) systems for more than half a century. From the earliest days of AI, it was apparent that a robust, generally intelligent system should include a complete set of capabilities: perception, memory, reasoning, learning, planning, and action; and when DARPA initiated AI research in the 1960s, ambitious projects such as Shakey the Robot went after the complete package. As DARPA realized the challenges, they backed away from the ultimate goal of integrated AI and tried to make progress on the individual problems of image understanding, speech and language understanding, knowledge representation and reasoning, planning and decision aids, machine learning, and robotic manipulation. Yet, even as researchers struggled to make progress in these subdisciplines, DARPA periodically resurrected the challenge of integrated intelligent systems and pushed the community to try again. In the 1980s, DARPA’s Strategic Computing Initiative took on challenges of integrated AI projects such as the Autonomous Land Vehicle and the Pilot’s Associate. These did not succeed, but instead set the stage for the several decades of more siloed research that followed, until it was time to try again. In the 2000s, DARPA took on the integrated AI problem again with its Grand Challenges, which led to the first self-driving cars, and projects such as the Personalized Assistant that Learns, which produced Apple’s Siri. These efforts created complex, richlyintegrated systems that represented quantum leaps ahead in machine intelligence. The integration of sophisticated capabilities in a fundamental way is the key to general intelligence. This is the story of DARPA’s persistent long-term support for this essential premise of AI. Integrated Artificial Intelligence Systems","",""
0,"Wei Yan","IEEE Transactions on Artificial Intelligence",2020,"","","","",197,"2022-07-13 09:33:13","","10.1109/tfuzz.2020.2987029","","",,,,,0,0.00,0,1,2,"The IEEE Transactions on Artificial Intelligence (TAI) is a multidisciplinary journal publishing papers on theories and methodologies of Artificial Intelligence. Applications of Artificial Intelligence are also considered. Topics covered by IEEE TAI include, but not limited to, Agent-based Systems, Augmented Intelligence, Autonomic Computing, Constraint Systems, Explainable AI, Knowledge-Based Systems, Learning Theories, Planning, Reasoning, Search, Natural Language Processing, and Applications. Technical papers addressing contemporary topics in AI such as Ethics and Social Implications are welcomed.","",""
1,"Liheng Gong, Xiao Zhang, Ling Li","An Artificial Intelligence Fusion Model for Cardiac Emergency Decision Making: Application and Robustness Analysis (Preprint)",2020,"","","","",198,"2022-07-13 09:33:13","","10.2196/preprints.19428","","",,,,,1,0.50,0,3,2,"  BACKGROUND  During cardiac emergency medical treatment, reducing the incidence of avoidable adverse events, ensuring the safety of patients, and generally improving the quality and efficiency of medical treatment have been important research topics in theoretical and practical circles.      OBJECTIVE  This paper examines the robustness of the decision-making reasoning process from the overall perspective of the cardiac emergency medical system.      METHODS  The principle of robustness was introduced into our study on the quality and efficiency of cardiac emergency decision making. We propose the concept of robustness for complex medical decision making by targeting the problem of low reasoning efficiency and accuracy in cardiac emergency decision making. The key bottlenecks such as anti-interference capability, fault tolerance, and redundancy were studied. The rules of knowledge acquisition and transfer in the decision-making process were systematically analyzed to reveal the core role of knowledge reasoning.      RESULTS  The robustness threshold method was adopted to construct the robustness criteria group of the system, and the fusion and coordination mechanism was realized through information entropy, information gain, and mutual information methods.      CONCLUSIONS  A set of fusion models and robust threshold methods such as the R2CMIFS (treatment mode of fibroblastic sarcoma) model and the RTCRF (clinical trial observation mode) model were proposed. Our study enriches the theoretical research on robustness in this field. ","",""
0,"Liheng Gong, Xiao Zhang, Ling Li","An Artificial Intelligence Fusion Model for Cardiac Emergency Decision Making: Application and Robustness Analysis",2020,"","","","",199,"2022-07-13 09:33:13","","10.2196/19428","","",,,,,0,0.00,0,3,2,"Background During cardiac emergency medical treatment, reducing the incidence of avoidable adverse events, ensuring the safety of patients, and generally improving the quality and efficiency of medical treatment have been important research topics in theoretical and practical circles. Objective This paper examines the robustness of the decision-making reasoning process from the overall perspective of the cardiac emergency medical system. Methods The principle of robustness was introduced into our study on the quality and efficiency of cardiac emergency decision making. We propose the concept of robustness for complex medical decision making by targeting the problem of low reasoning efficiency and accuracy in cardiac emergency decision making. The key bottlenecks such as anti-interference capability, fault tolerance, and redundancy were studied. The rules of knowledge acquisition and transfer in the decision-making process were systematically analyzed to reveal the core role of knowledge reasoning. Results The robustness threshold method was adopted to construct the robustness criteria group of the system, and the fusion and coordination mechanism was realized through information entropy, information gain, and mutual information methods. Conclusions A set of fusion models and robust threshold methods such as the R2CMIFS (treatment mode of fibroblastic sarcoma) model and the RTCRF (clinical trial observation mode) model were proposed. Our study enriches the theoretical research on robustness in this field.","",""
32,"Matt Taddy","The Technological Elements of Artificial Intelligence",2018,"","","","",200,"2022-07-13 09:33:13","","10.3386/W24301","","",,,,,32,8.00,32,1,4,"We have seen in the past decade a sharp increase in the extent that companies use data to optimize their businesses. Variously called the `Big Data' or `Data Science' revolution, this has been characterized by massive amounts of data, including unstructured and nontraditional data like text and images, and the use of fast and flexible Machine Learning (ML) algorithms in analysis. With recent improvements in Deep Neural Networks (DNNs) and related methods, application of high-performance ML algorithms has become more automatic and robust to different data scenarios. That has led to the rapid rise of an Artificial Intelligence (AI) that works by combining many ML algorithms together – each targeting a straightforward prediction task – to solve complex problems. We will define a framework for thinking about the ingredients of this new ML-driven AI. Having an understanding of the pieces that make up these systems and how they fit together is important for those who will be building businesses around this technology. Those studying the economics of AI can use these definitions to remove ambiguity from the conversation on AI's projected productivity impacts and data requirements. Finally, this framework should help clarify the role for AI in the practice of modern business analytics and economic measurement.","",""
