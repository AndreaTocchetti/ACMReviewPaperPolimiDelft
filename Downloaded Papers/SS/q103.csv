Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
0,"W. Hanif, Ythan H. Goldberg, C. Taub, D. Vorchheimer, L. Slipczuk, Edwin Ho, Carlos J Rodriguez, Muhammad Farooq, Mario J. Garcia, Lili Zhang","Abstract 11383: Automated Measurement of Global Longitudinal Strain by Speckle-Tracking Echocardiography in Cardio-Oncology Patients Using Artificial Intelligence",2021,"","","","",1,"2022-07-13 09:37:36","","10.1161/circ.144.suppl_1.11383","","",,,,,0,0.00,0,10,1,"  Introduction:  Left ventricular (LV) global longitudinal strain (GLS) is a robust LV systolic function measure used to detect subtle chemotherapy cardiotoxicity. However, inter-reader and inter-vendor variabilities compromise the clinical value of longitudinal follow-up of GLS. Artificial intelligence (AI)-based, fully automated measurement of longitudinal strain may be more reliable compared with human interpretation.      Methods:  We studied 52 transthoracic echocardiographic examinations randomly selected from a Cardio-oncology registry. All subjects received anthracycline-based chemotherapy in 2016-2019. AI-based longitudinal strain was assessed by EchoGo Core using standard 2- and 4-chamber apical views. Two readers verified the myocardium tracing by AI and found no errors. Longitudinal strain results by EchoGo were compared to GLS measured by conventional software (TomTec and Philips QLAB) using standard 3-, 2- and 4-chamber apical views.      Results:  AI-based longitudinal strain analysis was feasible in 51/52 (98%) transthoracic echocardiographic studies. The mean longitudinal strain was -17.3±3.3% for EchoGo, -16.9±2.4% for TomTec and -17.5±3.1% for QLAB. Bland-Altman analysis showed a bias of -0.4 ± 2.7% and 95% limits of -5.7 to 4.9% between EchoGo longitudinal strain and TomTec GLS (Figure 1A). A bias of 0.2 ± 3.3% and 95% limits of -6.2 to 6.6% between EchoGo longitudinal strain and QLAB GLS (Figure 1B) were seen. The bias between TomTec GLS and QLAB GLS was 0.6 ±2.2% (Figure 1C). The inter-reader correlation coefficients of TomTec GLS and QLAB GLS were 0.57 and 0.71, respectively.      Conclusions:  This novel AI-based longitudinal strain analysis was feasible in the majority of echocardiograms without any operator input. The bias between EchoGo longitudinal strain and conventional software appears small. AI-based myocardial strain analysis may reduce variabilities and facilitate longitudinal follow-up of GLS in Cardio-oncology patients.       ","",""
2,"Dr. Uma Devi, Maria Tresita, V. Paul","Artificial Intelligence: Pertinence in Supply Chain and Logistics Management",2020,"","","","",2,"2022-07-13 09:37:36","","","","",,,,,2,1.00,1,3,2,"-Artificial Intelligence (AI) is the revolutionary invention of human intelligence. Artificial Intelligence is nothing but the duplication of human in which machines are programmed to rationally think and behave like humans developed for very many purposes including business decision making, problem-solving, business data analysis and interpretation and information management. The application of AI in business endeavours decides the competitive advantage, market leadership, robust operating efficiency of corporates and other business houses. Exploiting the application of AI in the manufacturing and distribution process enables the organisations to reach the pinnacle in their business graph. Businesses are operating in the international market which is highly multifaceted and challenging to serve the world as a sole market for their products, services and their products and without the integration of technology into their business processes, they cannot assure the sustainable growth. The management of the process of transforming the raw materials into the final product is called Supply Chain Management (SCM) and the effective movement and storage of goods, services and information are called Logistics Management (LM). This article analyses the applications of Artificial Intelligence in Supply Chain and Logistics Management (SC&LM) Keywords--Artificial Intelligence, Supply Chain Management, Logistics Management, Supply Chain Profitability","",""
0,"David A. Hindin","Artificial Intelligence and Machine Learning: Implications for Surgery",2020,"","","","",3,"2022-07-13 09:37:36","","10.1007/978-3-030-49100-0_23","","",,,,,0,0.00,0,1,2,"","",""
1,"N. Pescetelli","A Brief Taxonomy of Hybrid Intelligence",2021,"","","","",4,"2022-07-13 09:37:36","","10.3390/forecast3030039","","",,,,,1,1.00,1,1,1,"As artificial intelligence becomes ubiquitous in our lives, so do the opportunities to combine machine and human intelligence to obtain more accurate and more resilient prediction models across a wide range of domains. Hybrid intelligence can be designed in many ways, depending on the role of the human and the algorithm in the hybrid system. This paper offers a brief taxonomy of hybrid intelligence, which describes possible relationships between human and machine intelligence for robust forecasting. In this taxonomy, biological intelligence represents one axis of variation, going from individual intelligence (one individual in isolation) to collective intelligence (several connected individuals). The second axis of variation represents increasingly sophisticated algorithms that can take into account more aspects of the forecasting system, from information to task to human problem-solvers. The novelty of the paper lies in the interpretation of recent studies in hybrid intelligence as precursors of a set of algorithms that are expected to be more prominent in the future. These algorithms promise to increase hybrid system’s resilience across a wide range of human errors and biases thanks to greater human-machine understanding. This work ends with a short overview for future research in this field.","",""
0,"Essam, Ahmod, Ados, D. R, Ileep, Umar","Classification by using Artificial Intelligence Techniques",2015,"","","","",5,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,6,7,"As known, the brain tumor is the most common fatality in the current scenario of health care society. Hence, a robust and more accurate detection system provides an efficient and fast way for diagnosis of the brain tumor is highly essential for treatment planning which can minimize the fatal results. Accurate results can be obtained only through computer aided automated systems to avoid the human error in manual interpretation of medical image content and to obtain high performance and efficiency. The proposed method consists of many stages, namely, image acquisition, image segmentation, features extraction, and classification. Modified K-means clustering algorithm that named weighted K-means used in segmentation stage to convert images into set of regions, the output of this stage will be input to features extraction stage. In features extraction stage multi extracted textural features using Gray Level Co-occurrence Matrix (GLCM) matrices in four directions, these features are used in classification stage. K-Nearest Neighbor classifier is used in decision making. In the experiment we test many MRI images and the results show that provides better output and the classification accuracy of our method is 86%.","",""
2,"Essam, Ahmod, Ados","Medical Images Classification by using Artificial Intelligence Techniques",2014,"","","","",6,"2022-07-13 09:37:36","","","","",,,,,2,0.25,1,3,8,"As known, the brain tumor is the most common fatality in the current scenario of health care society. Hence, a robust and more accurate detection system provides an efficient and fast way for diagnosis of the brain tumor is highly essential for treatment planning which can minimize the fatal results. Accurate results can be obtained only through computer aided automated systems to avoid the human error in manual interpretation of medical image content and to obtain high performance and efficiency. In this work, we proposed an artificial technique for automatic classification of the Magnetic Resonance Imaging (MRI) brain images as normal or abnormal. The proposed method consists of many stages, namely, image acquisition, image segmentation, features extraction, and classification. Modified K-means clustering algorithm that named weighted K-means used in segmentation stage to convert images into set of regions, the output of this stage will be input to features extraction stage. In features extraction stage multi extracted textural features using Gray Level Co-occurrence Matrix (GLCM) matrices in four directions, these features are used in classification stage. K-Nearest Neighbor classifier is used in decision making. In the experiment we test many MRI images and the results show that provides better output and the classification accuracy of our method is 86%.","",""
2,"Moonis Ali, B. Whitehead, U. Gupta, H. Ferber","Identification and interpretation of patterns in rocket engine data: Artificial intelligence and neural network approaches",1995,"","","","",7,"2022-07-13 09:37:36","","","","",,,,,2,0.07,1,4,27,"This paper describes an expert system which is designed to perform automatic data analysis, identify anomalous events, and determine the characteristic features of these events. We have employed both artificial intelligence and neural net approaches in the design of this expert system. The artificial intelligence approach is useful because it provides (1) the use of human experts' knowledge of sensor behavior and faulty engine conditions in interpreting data; (2) the use of engine design knowledge and physical sensor locations in establishing relationships among the events of multiple sensors; (3) the use of stored analysis of past data of faulty engine conditions; and (4) the use of knowledge-based reasoning in distinguishing sensor failure from actual faults. The neural network approach appears promising because neural nets (1) can be trained on extremely noisy data and produce classifications which are more robust under noisy conditions than other classification techniques; (2) avoid the necessity of noise removal by digital filtering and therefore avoid the need to make assumptions about frequency bands or other signal characteristics of anomalous behavior; (3) can, in effect, generate their own feature detectors based on the characteristics of the sensor data used in training; and (4) are inherently parallel and therefore are potentially implementable in special-purpose parallel hardware.","",""
29,"A. Gordon","Commonsense Interpretation of Triangle Behavior",2016,"","","","",8,"2022-07-13 09:37:36","","10.1609/aaai.v30i1.9881","","",,,,,29,4.83,29,1,6,"    The ability to infer intentions, emotions, and other unobservable psychological states from people's behavior is a hallmark of human social cognition, and an essential capability for future Artificial Intelligence systems. The commonsense theories of psychology and sociology necessary for such inferences have been a focus of logic-based knowledge representation research, but have been difficult to employ in robust automated reasoning architectures. In this paper we model behavior interpretation as a process of logical abduction, where the reasoning task is to identify the most probable set of assumptions that logically entail the observable behavior of others, given commonsense theories of psychology and sociology. We evaluate our approach using Triangle-COPA, a benchmark suite of 100 challenge problems based on an early social psychology experiment by Fritz Heider and Marianne Simmel. Commonsense knowledge of actions, social relationships, intentions, and emotions are encoded as defeasible axioms in first-order logic. We identify sets of assumptions that logically entail observed behaviors by backchaining with these axioms to a given depth, and order these sets by their joint probability assuming conditional independence. Our approach solves almost all (91) of the 100 questions in Triangle-COPA, and demonstrates a promising approach to robust behavior interpretation that integrates both logical and probabilistic reasoning.   ","",""
1,"C. Moreno-García","Digital Interpretation of Sensor-Equipment Diagrams",2018,"","","","",9,"2022-07-13 09:37:36","","","","",,,,,1,0.25,1,1,4,"A sensor-equipment diagram is a type of engineering drawing used in the industrial practice that depicts the interconnectivity between a group of sensors and a portion of an Oil & Gas facility. The interpretation of these documents is not a straightforward task even for human experts. Some of the most common limitations are the large size of the drawing, a lack of standard in defining equipment symbols, and a complex and entangled representation of the connectors. This paper presents a system that, given a sensor-equipment diagram and a few impositions by the user, outputs a list with the reading of the content of the sensors and the equipment parts plus their interconnectivity. This work has been developed using open source Python modules and code, and its main purpose is to provide a tool which can help in the collection of labelled samples for a more robust artificial intelligence based solution in the near future.","",""
1,"Y. Xiang, B. Chaib-draa","Advances in artificial intelligence : 16th Conference of the Canadian Society for Computational Studies of Intelligence, AI 2003, Halifax, Canada, June 11-13, 2003 : proceedings",2003,"","","","",10,"2022-07-13 09:37:36","","","","",,,,,1,0.05,1,2,19,"Experiences Building a Distributed Sensor Network.- Artificial Intelligence and Human Brain Imaging.- Machine Learning Methods for Computational Proteomics and Beyond.- The Structure Model Interpretation of Wright's NESS Test.- Answer Formulation for Question-Answering.- Patttern-Based AI Scripting Using ScriptEase.- Enumerating the Preconditions of Agent Message Types.- Monadic Memoization towards Correctness-Preserving Reduction of Search.- Searching Solutions in the Crypto-arithmetic Problems: An Adaptive Parallel Genetic Algorithm Approach.- Stochastic Local Search for Multiprocessor Scheduling for Minimum Total Tardiness.- A Graph Based Backtracking Algorithm for Solving General CSPs.- Iterated Robust Tabu Search for MAX-SAT.- Scaling and Probabilistic Smoothing: Dynamic Local Search for Unweighted MAX-SAT.- A Comparison of Consistency Propagation Algorithms in Constraint Optimization.- Discovering Temporal/Causal Rules: A Comparison of Methods.- Selective Transfer of Task Knowledge Using Stochastic Noise.- Efficient Mining of Indirect Associations Using HI-Mine.- Case Authoring from Text and Historical Experiences.- Session Boundary Detection for Association Rule Learning Using n-Gram Language Models.- Negotiating Exchanges of Private Information for Web Service Eligibility.- Post-supervised Template Induction for Dynamic Web Sources.- Summarizing Web Sites Automatically.- Cycle-Cutset Sampling for Bayesian Networks.- Learning First-Order Bayesian Networks.- AUC: A Better Measure than Accuracy in Comparing Learning Algorithms.- Model-Based Least-Squares Policy Evaluation.- DIAGAL: A Tool for Analyzing and Modelling Commitment-Based Dialogues between Agents.- Situation Event Logic for Early Validation of Multi-Agent Systems.- Understanding ""Not-Understood"": Towards an Ontology of Error Conditions for Agent Communication.- An Improved Ant Colony Optimisation Algorithm for the 2D HP Protein Folding Problem.- Hybrid Randomised Neighbourhoods Improve Stochastic Local Search for DNA Code Design.- A Strategy for Improved Satisfaction of Selling Software Agents in E-Commerce.- Pre-negotiations over Services - A Framework for Evaluation.- Formal Theory for Describing Action Concepts in Terminological Knowledge Bases.- Improving User-Perceived QoS in Mobile Ad Hoc Networks Using Decision Rules Induction.- Risk Neutral Calibration of Classifiers.- Search Bound Strategies for Rule Mining by Iterative Deepening.- Methods for Mining Frequent Sequential Patterns.- Learning by Discovering Conflicts.- Enhancing Caching in Distributed Databases Using Intelligent Polytree Representations.- Feature Selection Strategies for Text Categorization.- Learning General Graphplan Memos through Static Domain Analysis.- Classification Automaton and Its Construction Using Learning.- A Genetic K-means Clustering Algorithm Applied to Gene Expression Data.- Explanation-Oriented Association Mining Using a Combination of Unsupervised and Supervised Learning Algorithms.- Motion Recognition from Video Sequences.- Noun Sense Disambiguation with WordNet for Software Design Retrieval.- Not as Easy as It Seems: Automating the Construction of Lexical Chains Using Roget's Thesaurus.- The Importance of Fine-Grained Cue Phrases in Scientific Citations.- Fuzzy C-Means Clustering of Web Users for Educational Sites.- Re-using Web Information for Building Flexible Domain Knowledge.- A New Inference Axiom for Probabilistic Conditional Independence.- Probabilistic Reasoning for Meal Planning in Intelligent Fridges.- Probabilistic Reasoning in Bayesian Networks: A Relational Database Approach.- Fundamental Issue of Naive Bayes.- The Virtual Driving Instructor Creating Awareness in a Multiagent System.- Multi-attribute Exchange Market: Theory and Experiments.- Agent-Based Online Trading System.- On the Applicability of L-systems and Iterated Function Systems for Grammatical Synthesis of 3D Models.- An Unsupervised Clustering Algorithm for Intrusion Detection.- Dueling CSP Representations: Local Search in the Primal versus Dual Constraint Graph.- A Quick Look at Methods for Mining Long Subsequences.- Back to the Future: Changing the Direction of Time to Discover Causality.- Learning Coordination in RoboCupRescue.- Accent Classification Using Support Vector Machine and Hidden Markov Model.- A Neural Network Based Approach to the Artificial Aging of Facial Images.- Adaptive Negotiation for Agent Based Distributed Manufacturing Scheduling.- Multi-agent System Architecture for Tracking Moving Objects.","",""
4,"R. Zicari, J. Brusseau, S. Blomberg, H. Christensen, M. Coffee, M. B. Ganapini, S. Gerke, T. Gilbert, Eleanore Hickman, E. Hildt, Sune Holm, U. Kühne, V. Madai, W. Osika, Andy Spezzatti, Eberhard Schnebel, Jesmin Jahan Tithi, Dennis Vetter, Magnus Westerlund, Reneé C. Wurth, J. Amann, Vegard Antun, Valentina Beretta, Frédérick Bruneault, Erik Campano, Boris Düdder, Alessio Gallucci, Emmanuel R. Goffi, C. Haase, Thilo Hagendorff, P. Kringen, Florian Möslein, D. Ottenheimer, M. Ozols, L. Palazzani, M. Petrin, Karin Tafur, J. Tørresen, H. Volland, G. Kararigas","On Assessing Trustworthy AI in Healthcare. Machine Learning as a Supportive Tool to Recognize Cardiac Arrest in Emergency Calls",2021,"","","","",11,"2022-07-13 09:37:36","","10.3389/fhumd.2021.673104","","",,,,,4,4.00,0,40,1,"Artificial Intelligence (AI) has the potential to greatly improve the delivery of healthcare and other services that advance population health and wellbeing. However, the use of AI in healthcare also brings potential risks that may cause unintended harm. To guide future developments in AI, the High-Level Expert Group on AI set up by the European Commission (EC), recently published ethics guidelines for what it terms “trustworthy” AI. These guidelines are aimed at a variety of stakeholders, especially guiding practitioners toward more ethical and more robust applications of AI. In line with efforts of the EC, AI ethics scholarship focuses increasingly on converting abstract principles into actionable recommendations. However, the interpretation, relevance, and implementation of trustworthy AI depend on the domain and the context in which the AI system is used. The main contribution of this paper is to demonstrate how to use the general AI HLEG trustworthy AI guidelines in practice in the healthcare domain. To this end, we present a best practice of assessing the use of machine learning as a supportive tool to recognize cardiac arrest in emergency calls. The AI system under assessment is currently in use in the city of Copenhagen in Denmark. The assessment is accomplished by an independent team composed of philosophers, policy makers, social scientists, technical, legal, and medical experts. By leveraging an interdisciplinary team, we aim to expose the complex trade-offs and the necessity for such thorough human review when tackling socio-technical applications of AI in healthcare. For the assessment, we use a process to assess trustworthy AI, called 1 Z-Inspection® to identify specific challenges and potential ethical trade-offs when we consider AI in practice.","",""
0,"S. Goto, Genki Ichihara, H. Ikura, Y. Katsumata, Y. Itabashi, C. Macrae, R. Deo","Abstract 11222: A Combined, Fully Automated Electrocardiogram and Echocardiogram Strategy for Detection of Hypertrophic Cardiomyopathy",2021,"","","","",12,"2022-07-13 09:37:36","","10.1161/circ.144.suppl_1.11222","","",,,,,0,0.00,0,7,1,"  Introduction:  Hypertrophic cardiomyopathy (HCM) is a disorder characterized by abnormal thickening of the heart muscle and may affect up to 1 in 200 people in the general population. Detection of HCM, like other rare diseases, is challenging both because of its low prevalence and the fact that there are other more common diseases such as aortic valve stenosis (AS) and hypertension that also manifest as cardiac hypertrophy. Distinguishing among such conditions, though challenging for human interpretation, may be feasible with artificial intelligence (AI)-based approaches, but strategies to date have looked only at data from single centers using single modalities.      Methods:  Here we developed and validated a robust approach to accelerate detection of HCM using a combination of fully automated interpretation of electrocardiograms (ECG) and echocardiograms using convolutional neural networks and evaluated it on data from multiple institutions in multiple countries. The ECG model was trained on 4,935 ECGs from Brigham and Women’s Hospital (BWH) and was tested on an internal test set of 1,950 ECGs along with 842 and 1,103 ECGs from 2 different academic medical centers (AMC) in the United States (US). The echocardiogram model was trained on 4,483 studies from BWH and was tested on an internal test set of 1,945 studies, 1,025 and 554 studies from 2 AMCs in the US, and 239 studies from an AMC in Japan.      Results:  Both models had excellent accuracy for detecting HCM with C-statistics of 0.84-0.91 and 0.91-0.94 for the ECG and echocardiography models, respectively. The echocardiography model, which uses only a single commonly acquired view, discriminates HCM from AS and HTN with C-statistics of 0.92 and 0.86, respectively. Simulating deployment on 13,906 and 7,775 patients with ECG-echocardiography paired data for AMC2, and AMC3 indicated a positive predictive value (PPV) for the ECG model of 7% and 8% at 50% and 59% recall, respectively. Pre-screening with ECG enhanced the echocardiography model performance from PPV 43% and 36% to PPV 71% and 73% at 46% recall, respectively, for AMC2 and AMC3.      Conclusions:  We have developed a robust pipeline to augment detection of HCM, and that could enable patient identification in less specialized settings. ","",""
5,"A. Ramirez-Hernandez, J. Rivera-Bautista, A. Marín-Hernández, V. A. García-Vega","Detection and Interpretation of Human Walking Gestures for Human-Robot Interaction",2009,"","","","",13,"2022-07-13 09:37:36","","10.1109/MICAI.2009.35","","",,,,,5,0.38,1,4,13,"Human-Robot Interaction (HRI) has become a very important field on Mobile robotics community. Service Robots must have efficient modules for HRI, in order to deal with humans in a robust way. For a service robot, it is very important to interpret when a person needs or requires assistance. In this paper a system for the detection and analysis of corporal gestures (particularly walking gestures) is presented. The system is used to interpret human attitudes. In order to detect and track humans on interior environments the system uses a PTZ camera and a laser range finder mounted on a mobile robot platform. The digital images obtained through the camera are processed to detect and track people. While a person is tracked by the PTZ camera, pan configuration parameter from camera is used in order to track the legs of the person by the LRF. Motion of the person on the global reference frame is then used to interpret walking gestures.","",""
0,"Joe Hays, S. Ramamoorthy, Christian Tetzlaff","Editorial: Robust Artificial Intelligence for Neurorobotics",2021,"","","","",14,"2022-07-13 09:37:36","","10.3389/fnbot.2021.809903","","",,,,,0,0.00,0,3,1,"Neural computing is a powerful paradigm that has revolutionized machine learning. Building from early roots in the study of adaptive behavior and attempts to understand information processing in parallel and distributed neural architectures, modern neural networks have convincingly demonstrated successes in numerous areas—transforming the practice of computer vision, natural language processing, and even computational biology. Applications in robotics bring stringent constraints on size, weight and power constraints (SWaP), which challenge the developers of these technologies in new ways. Indeed, these requirements take us back to the roots of the field of neural computing, forcing us to ask how it could be that the human brain achieves with as little as 12 watts of power what seems to require entire server farms with state of the art computational and numerical methods. Likewise, even lowly insects demonstrate a degree of adaptivity and resilience that still defy easy explanation or computational replication. In this Research Topic, we have compiled the latest research addressing several aspects of these broadly defined challenge questions. As illustrated in Figure 1, the articles are organized into four prevailing themes: Sense, Think, Act, and Tools.","",""
1,"Nikita Mokhashi, Julia Grachevskaya, Lorrie Cheng, Daohai Yu, Xiaoning Lu, Yi Zhang, J. Henderer","A Comparison of Artificial Intelligence and Human Diabetic Retinal Image Interpretation in an Urban Health System",2021,"","","","",15,"2022-07-13 09:37:36","","10.1177/1932296821999370","","",,,,,1,1.00,0,7,1,"Introduction: Artificial intelligence (AI) diabetic retinopathy (DR) software has the potential to decrease time spent by clinicians on image interpretation and expand the scope of DR screening. We performed a retrospective review to compare Eyenuk’s EyeArt software (Woodland Hills, CA) to Temple Ophthalmology optometry grading using the International Classification of Diabetic Retinopathy scale. Methods: Two hundred and sixty consecutive diabetic patients from the Temple Faculty Practice Internal Medicine clinic underwent 2-field retinal imaging. Classifications of the images by the software and optometrist were analyzed using sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and McNemar’s test. Ungradable images were analyzed to identify relationships with HbA1c, age, and ethnicity. Disagreements and a sample of 20% of agreements were adjudicated by a retina specialist. Results: On patient level comparison, sensitivity for the software was 100%, while specificity was 77.78%. PPV was 19.15%, and NPV was 100%. The 38 disagreements between software and optometrist occurred when the optometrist classified a patient’s images as non-referable while the software classified them as referable. Of these disagreements, a retina specialist agreed with the optometrist 57.9% the time (22/38). Of the agreements, the retina specialist agreed with both the program and the optometrist 96.7% of the time (28/29). There was a significant difference in numbers of ungradable photos in older patients (≥60) vs younger patients (<60) (p=0.003). Conclusions: The AI program showed high sensitivity with acceptable specificity for a screening algorithm. The high NPV indicates that the software is unlikely to miss DR but may refer patients unnecessarily.","",""
19,"Thomas G. Dietterich","Robust artificial intelligence and robust human organizations",2018,"","","","",16,"2022-07-13 09:37:36","","10.1007/s11704-018-8900-4","","",,,,,19,4.75,19,1,4,"","",""
0,"Olivia M. Brown, B. Dillman","Proceedings of the Robust Artificial Intelligence System Assurance (RAISA) Workshop 2022",2022,"","","","",17,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,2,1,"The Robust Artificial Intelligence System Assurance (RAISA) workshop will focus on research, development and application of robust artificial intelligence (AI) and machine learning (ML) systems. Rather than studying robustness with respect to particular ML algorithms, our approach will be to explore robustness assurance at the system architecture level, during both development and deployment, and within the human-machine teaming context. While the research community is converging on robust solutions for individual AI models in specific scenarios, the problem of evaluating and assuring the robustness of an AI system across its entire life cycle is much more complex. Moreover, the operational context in which AI systems are deployed necessitates consideration of robustness and its relation to principles of fairness, privacy, and explainability.","",""
1793,"E. Topol","High-performance medicine: the convergence of human and artificial intelligence",2019,"","","","",18,"2022-07-13 09:37:36","","10.1038/s41591-018-0300-7","","",,,,,1793,597.67,1793,1,3,"","",""
4,"Z. Akkus, Yousof H. Aly, Itzhak Z. Attia, F. Lopez‐Jimenez, A. Arruda-Olson, P. Pellikka, S. Pislaru, G. Kane, P. Friedman, J. Oh","Artificial Intelligence (AI)-Empowered Echocardiography Interpretation: A State-of-the-Art Review",2021,"","","","",19,"2022-07-13 09:37:36","","10.3390/jcm10071391","","",,,,,4,4.00,0,10,1,"Echocardiography (Echo), a widely available, noninvasive, and portable bedside imaging tool, is the most frequently used imaging modality in assessing cardiac anatomy and function in clinical practice. On the other hand, its operator dependability introduces variability in image acquisition, measurements, and interpretation. To reduce these variabilities, there is an increasing demand for an operator- and interpreter-independent Echo system empowered with artificial intelligence (AI), which has been incorporated into diverse areas of clinical medicine. Recent advances in AI applications in computer vision have enabled us to identify conceptual and complex imaging features with the self-learning ability of AI models and efficient parallel computing power. This has resulted in vast opportunities such as providing AI models that are robust to variations with generalizability for instantaneous image quality control, aiding in the acquisition of optimal images and diagnosis of complex diseases, and improving the clinical workflow of cardiac ultrasound. In this review, we provide a state-of-the art overview of AI-empowered Echo applications in cardiology and future trends for AI-powered Echo technology that standardize measurements, aid physicians in diagnosing cardiac diseases, optimize Echo workflow in clinics, and ultimately, reduce healthcare costs.","",""
1,"Bharath Subramani, SP Deepika","A Robust Artificial Intelligence: Smart Indoor Positioning System",2019,"","","","",20,"2022-07-13 09:37:36","","10.35940/ijitee.a1001.0881019","","",,,,,1,0.33,1,2,3,"Over the previous few centuries, technology has converted massively from being a desktop personal computer to handheld mobile phones, with lower energy consumption of raw computing power. This computability is now incorporated with other systems as well as isolated to a single device. This paradigm was first noted in cyber-physical systems with the introduction of cloud services. The evolution of Artificial Intelligence(AI) with cloud computing and the importance of this field in human life, induce us to make simple and efficient talkative assistant robot for indoor navigation. The navigation system in outdoor typically rely upon Global Positioning System (GPS) but the indoor navigation systems have to rely on different technologies, as GPS signals cannot be received indoors. Thus, several technologies have been proposed and implemented over the past decade to improve navigation in indoors. But they were costly and less effective. Therefore, we have proposed a system that assists humans to find their location in a conversational manner. The suggested system was constructed by introducing the advantages of a personal assistant device, Amazon Alexa, the cloud services of Amazon and its voice services for indoor navigation. A Raspberry Pi 3 Model B is used as the element of the hardware to provide our system with intelligent characteristics. You can trigger the speech service using the ""Alexa"" keyword. Using the voice command, the skill / application we created can be initiated. It operates a script on the cloud once Alexa is enabled, which runs a subroutine on the Raspberry Pi 3 in-turn to provide a path for that specific place. Once the Raspberry Pi calculation is finished, it sends the message back to Alexa. Alexa transforms the text into a voice and informs the user path.","",""
3,"M. Charalambides, C. Flohr, P. Bahadoran, R. Matin","New international reporting guidelines for clinical trials evaluating effectiveness of artificial intelligence interventions in dermatology: strengthening the SPIRIT of robust trial reporting",2021,"","","","",21,"2022-07-13 09:37:36","","10.1111/bjd.19616","","",,,,,3,3.00,1,4,1,"AI can refer to either machine learning or deep learning 1 The potential for AI and machine learning to improve the management of skin diseases is immense Artificial intelligence (AI) can be defined simply as the ability of computers to simulate intelligent human behaviour [Extracted from the article] Copyright of British Journal of Dermatology is the property of Wiley-Blackwell and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission However, users may print, download, or email articles for individual use This abstract may be abridged No warranty is given about the accuracy of the copy Users should refer to the original published version of the material for the full abstract (Copyright applies to all Abstracts )","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",22,"2022-07-13 09:37:36","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
0,"Canan Tiftik","Investigation of Human Resources Dimension in Management and Organization Structure of the Effects of Artificial Intelligence",2021,"","","","",23,"2022-07-13 09:37:36","","10.21733/IBAD.833256","","",,,,,0,0.00,0,1,1,"In the competitive time, there has been a great deal of progress in the industry. It is one of the most serious obstacles to the industry in many industries that adopt contemporary technologies to manage continuous development and faster than ordinary jobs. Many of the scientists and researchers recommend using AI tools and digital technologies for industries. Machine language and artificial intelligence are used by many organizations in the human resources unit, where it undertakes an integrated task in recruiting, performance analysis, personnel selection, data collection for employees, providing real-time information and obtaining the right information. Artificial intelligence-based Human Resources (HR) applications have a solid potential to increase employee productivity and support HR experts to become knowledge and trained consultants that increase the success of the employee. HR applications authorized by artificial intelligence have the ability to analyze, predict, diagnose and seek and find more robust and capable resources.","",""
0,"R. Porcher","CORR Insights®: Does Artificial Intelligence Outperform Natural Intelligence in Interpretation of Musculoskeletal Radiological Studies? A Systematic Review.",2020,"","","","",24,"2022-07-13 09:37:36","","10.1097/CORR.0000000000001415","","",,,,,0,0.00,0,1,2,"Machine learning, and artificial intelligence more generally, are quickly growing areas of applied medical decisionmaking research. Compared with what are now considered moretraditional analytical approaches, such as statistical prediction models, machine learning is seen as providing unique advantages; in particular, it may improve healthcare delivery because it can learn from millions of digitized patient charts or images, and so provide robust, reproducible, and rapid decision-support tools [8, 14]. Artificial intelligence has already transformed many aspects of daily life outside health care; machine-learning algorithms allow us to translate large pieces of text into any language, recognize speech, drive a car, make a plane take off or land, or detect banking fraud. The advantages of machine learning include the ability to analyze enormous amounts of data, capture complex nonlinear relationships among these data, and consider a wide range of data. It can handle structured data, similar to other statistical prediction methods, but machine learning can also analyze free text and images, as well as high-frequency sampled data streams such as those produced by wearable devices. In this respect, no approach other than artificial intelligence and machine learning has enabled the analysis of such data so far. These approaches have begun to show promise in orthopaedic surgery, specifically. For example, one recent study used machine learning to predict whether patients would achieve clinically important improvements in validated outcome scores 2 years after joint arthroplasty [5, 10], which is important in light of the fact that even experienced surgeons’ abilities in this sort of prediction for patients undergoing TKA are no better than a coin toss [6]. However, despite the hype and hopes about artificial intelligence, more-nuanced opinions have emerged [1, 13]. Identifying associations among data does not prevent confounding, and this may prevent us from translating modifiable factors flagged by algorithms into real targets for interventions. Additionally, despite the underlying idea that the more data we have to train an algorithm, the more accurate they are, the greed for more data does not always translate into more-accurate predictions [1]. Predicting what will occur in 1, 5, or 10 years may be difficult because all past data, not just available data, do not contain sufficient information. This may explain why machine-learning algorithms have often outperformed human experts in imaging or diagnostics, where most information is present in the data analyzed [8]. The advantage over moreclassic statistical models for longer-term risk prediction modeling is likely less evident [2]. This CORR Insights is a commentary on the article “Does Artificial Intelligence Outperform Natural Intelligence in Interpretation of Musculoskeletal Radiological Studies? A Systematic Review” by Groot and colleagues available at: DOI: 10.1097/CORR.0000000000001360. The author certifies that he, or anymembers of his immediate family, has no commercial associations (eg, consultancies, stock ownership, equity interest, patent/licensing arrangements, etc) that might pose a conflict of interest in connection with the submitted article. All ICMJE Conflict of Interest Forms for authors and Clinical Orthopaedics and Related Research editors and board members are on file with the publication and can be viewed on request. The opinions expressed are those of the writer, and do not reflect the opinion or policy of CORR or the Association of Bone and Joint Surgeons. R. Porcher ✉, Centre d’Epidémiologie Clinique, Hôpital Hôtel-Dieu, 1 Parvis NotreDame Place Jean-Paul II, 75004 Paris, France, Email: raphael.porcher@aphp.fr R. Porcher, Université de Paris, CRESS UMR1153, INSERM, INRA, F-75004 Paris, France; Centre d’Epidémiologie Clinique, AP-HP, Hôtel-Dieu, F-75004 Paris, France","",""
3,"Fatemeh Homayounieh, S. Digumarthy, S. Ebrahimian, J. Rueckel, B. Hoppe, B. Sabel, Sailesh Conjeti, Karsten Ridder, Markus Sistermanns, Lei Wang, Alexander Preuhs, Florin C. Ghesu, Awais Mansoor, M. Moghbel, Ariel Botwin, Ramandeep Singh, Samuel Cartmell, J. Patti, Christian Huemmer, A. Fieselmann, Clemens Joerger, Negar Mirshahzadeh, V. Muse, M. Kalra","An Artificial Intelligence–Based Chest X-ray Model on Human Nodule Detection Accuracy From a Multicenter Study",2021,"","","","",25,"2022-07-13 09:37:36","","10.1001/jamanetworkopen.2021.41096","","",,,,,3,3.00,0,24,1,"Key Points Question Can artificial intelligence (AI) improve detection of pulmonary nodules on chest radiographs at different levels of detection difficulty? Findings In this diagnostic study, AI-aided interpretation was associated with significantly improved detection of pulmonary nodules on chest x-rays as compared with unaided interpretation of chest x-rays. Meaning These results suggest that an AI algorithm may improve diagnostic performance of radiologists with different levels of experience for detecting pulmonary nodules on chest radiographs compared with unaided interpretation.","",""
2,"E. Veitch, O. Alsos","Human-Centered Explainable Artificial Intelligence for Marine Autonomous Surface Vehicles",2021,"","","","",26,"2022-07-13 09:37:36","","10.3390/jmse9111227","","",,,,,2,2.00,1,2,1,"Explainable Artificial Intelligence (XAI) for Autonomous Surface Vehicles (ASVs) addresses developers’ needs for model interpretation, understandability, and trust. As ASVs approach wide-scale deployment, these needs are expanded to include end user interactions in real-world contexts. Despite recent successes of technology-centered XAI for enhancing the explainability of AI techniques to expert users, these approaches do not necessarily carry over to non-expert end users. Passengers, other vessels, and remote operators will have XAI needs distinct from those of expert users targeted in a traditional technology-centered approach. We formulate a concept called ‘human-centered XAI’ to address emerging end user interaction needs for ASVs. To structure the concept, we adopt a model-based reasoning method for concept formation consisting of three processes: analogy, visualization, and mental simulation, drawing from examples of recent ASV research at the Norwegian University of Science and Technology (NTNU). The examples show how current research activities point to novel ways of addressing XAI needs for distinct end user interactions and underpin the human-centered XAI approach. Findings show how representations of (1) usability, (2) trust, and (3) safety make up the main processes in human-centered XAI. The contribution is the formation of human-centered XAI to help advance the research community’s efforts to expand the agenda of interpretability, understandability, and trust to include end user ASV interactions.","",""
0,"Roberto Rodriguez, R. Perroy, J. Leary, D. Jenkins, Max Panoff, Travis Mandel, Patricia Perez","Comparing Interpretation of High-Resolution Aerial Imagery by Humans and Artificial Intelligence to Detect an Invasive Tree Species",2021,"","","","",27,"2022-07-13 09:37:36","","10.3390/rs13173503","","",,,,,0,0.00,0,7,1,"Timely, accurate maps of invasive plant species are critical for making appropriate management decisions to eliminate emerging target populations or contain infestations. High-resolution aerial imagery is routinely used to map, monitor, and detect invasive plant populations. While conventional image interpretation involving human analysts is straightforward, it can require high demands for time and resources to produce useful intelligence. We compared the performance of human analysts with a custom Retinanet-based deep convolutional neural network (DNN) for detecting individual miconia (Miconia calvescens DC) plants, using high-resolution unmanned aerial system (UAS) imagery collected over lowland tropical forests in Hawai’i. Human analysts (n = 38) examined imagery at three linear scrolling speeds (100, 200 and 300 px/s), achieving miconia detection recalls of 74 ± 3%, 60 ± 3%, and 50 ± 3%, respectively. The DNN achieved 83 ± 3% recall and completed the image analysis in 1% of the time of the fastest scrolling speed tested. Human analysts could discriminate large miconia leaf clusters better than isolated individual leaves, while the DNN detection efficacy was independent of leaf cluster size. Optically, the contrast in the red and green color channels and all three (i.e., red, green, and blue) signal to clutter ratios (SCR) were significant factors for human detection, while only the red channel contrast, and the red and green SCRs were significant factors for the DNN. A linear cost analysis estimated the operational use of a DNN to be more cost effective than human photo interpretation when the cumulative search area exceeds a minimum area. For invasive species like miconia, which can stochastically spread propagules across thousands of ha, the DNN provides a more efficient option for detecting incipient, immature miconia across large expanses of forested canopy. Increasing operational capacity for large-scale surveillance with a DNN-based image analysis workflow can provide more rapid comprehension of invasive plant abundance and distribution in forested watersheds and may become strategically vital to containing these invasions.","",""
0,"F. LeRon Shults","Progress in simulating human geography: Assemblage theory and the practice of multi-agent artificial intelligence modeling",2021,"","","","",28,"2022-07-13 09:37:36","","10.1177/03091325211059567","","",,,,,0,0.00,0,1,1,"Over the last few years, there has been an explosion of interest in assemblage theory among human geographers. During this same period, a growing number of scholars in the field have utilized computational methodologies to simulate the complex adaptive systems they study. However, very little attention has been paid to the connections between these two developments. This article outlines those connections and argues that more explicitly integrating assemblage theory and computer modeling can encourage a more robust philosophical understanding of both and facilitate progress in scientific research on the ways in which complex socio-material systems form and transform.","",""
179,"S. Michie, James Thomas, M. Johnston, Pol Mac Aonghusa, J. Shawe-Taylor, M. Kelly, L. Deleris, Ailbhe N. Finnerty, M. Marques, E. Norris, A. O'Mara-Eves, R. West","The Human Behaviour-Change Project: harnessing the power of artificial intelligence and machine learning for evidence synthesis and interpretation",2017,"","","","",29,"2022-07-13 09:37:36","","10.1186/s13012-017-0641-5","","",,,,,179,35.80,18,12,5,"","",""
56,"Konstantinos C. Siontis, P. Noseworthy, Z. Attia, P. Friedman","Artificial intelligence-enhanced electrocardiography in cardiovascular disease management",2021,"","","","",30,"2022-07-13 09:37:36","","10.1038/s41569-020-00503-2","","",,,,,56,56.00,14,4,1,"","",""
0,"Bushra Rasheed, M. Usama, Asmara Safdar","Robust Artificial Intelligence Approach to Stabilize and Control Propeller Driven Hybrid UGV",2022,"","","","",31,"2022-07-13 09:37:36","","10.1109/ICAI55435.2022.9773375","","",,,,,0,0.00,0,3,1,"Hybrid Unmanned Ground Vehicle (HUGV) can drive on any terrain including walls and fly as well, using the multi directional thrust force of propellers. In the era of industrial revolution, hybrid UGVs need to be autonomous with intelligent decision making capabilities. During wall climbing of hybrid UGVs, stability is essential and depends on real time feedback from multiple sensors. To increase stability and control, it is proposed that PID control loops should be replaced by AI based algorithms that reduce the decision time and mathematical complexity. For autonomous movement in any terrain using the proposed model, intelligent UGVs can map and localize simultaneously.They can make intelligent decisions about mode of movement i.e. driving on ground or wall, steering on ground or wall, flying and maneuvering by using real time sensor readings. Integration of the proposed AI models with HUGV can be applied to many areas which are hard for humans to access, for instance; inspection of large structures, bio & nuclear hazard environments, planetary exploration & magnetic fields detection.","",""
6,"Wilfried Niehueser, G. Boak","Introducing artificial intelligence into a human resources function",2020,"","","","",32,"2022-07-13 09:37:36","","10.1108/ict-10-2019-0097","","",,,,,6,3.00,3,2,2," Purpose The purpose of this paper is to examine the attitudes of employees in a company dedicated to strategic recruitment towards the introduction of artificial intelligence (AI) into their work processes and to consider the implications for training and development.   Design/methodology/approach Semi-structured interviews were carried out with seven employees who were using the new technology. Survey data was gathered from 109 employees who had not, at the time of the research, used the new technology.   Findings The introduction of AI considerably improved the speed and efficiency of the work processes. The research found that those employees who had used the new technology were positive about its effects, indicating that it was easy to use, robust and highly productive. A proportion of employees who had not, at the time of the research, used the new system, were less sure that it would improve their ability to do their job. Implications for introducing such a system and for employee training are discussed.   Research limitations/implications This is a relatively small sample in one organisation; further research should be undertaken to assess whether these findings apply more widely.   Practical implications If these attitudes are found elsewhere, there are a number of simple, practical suggestions for how to introduce AI into similar work processes.   Originality/value The use of AI is a topic attracting increasing interest and speculation, but there is as yet little empirical research on factors affecting its introduction and use. ","",""
2,"Avishek Choudhury, Onur Asan","Human factors: bridging artificial intelligence and patient safety",2020,"","","","",33,"2022-07-13 09:37:36","","10.1177/2327857920091007","","",,,,,2,1.00,1,2,2,"The recent launch of complex artificial intelligence (AI) in the domain of healthcare has embedded perplexities within patients, clinicians, and policymakers. The opaque and complex nature of artificial intelligence makes it challenging for clinicians to interpret its outcome. Incorrect interpretation and poor utilization of AI might hamper patient safety. The principles of human factors and ergonomics (HFE) can assist in simplifying AI design and consecutively optimize human performance ensuring better understanding of AI outcome, their interaction with the clinical workflow. In this paper, we discuss the interactions of providers with AI and how HFE can influence these interacting components to patient safety.","",""
1,"Bráulio Nascimento Lima, Pietro Balducci, Ricardo Pablo Passos, C. Novelli, Carlos Henrique Prevital Fileni, Fábio Vieira, L. B. Camargo, Guanis de Barros Vilela Junior","Artificial intelligence based on fuzzy logic for the analysis of human movement in healthy people: a systematic review",2020,"","","","",34,"2022-07-13 09:37:36","","10.1007/s10462-020-09885-8","","",,,,,1,0.50,0,8,2,"","",""
195,"Jessica Fjeld, Nele Achten, Hannah Hilligoss, Ádám Nagy, Madhulika Srikumar","Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI",2020,"","","","",35,"2022-07-13 09:37:36","","10.2139/ssrn.3518482","","",,,,,195,97.50,39,5,2,"The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and human rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles,"" there has been little scholarly focus on understanding these efforts either individually or as contextualized within an expanding universe of principles with discernible trends.    To that end, this white paper and its associated data visualization compare the contents of thirty-six prominent AI principles documents side-by-side. This effort uncovered a growing consensus around eight key thematic trends: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. Underlying this “normative core,” our analysis examined the forty-seven individual principles that make up the themes, detailing notable similarities and differences in interpretation found across the documents. In sharing these observations, it is our hope that policymakers, advocates, scholars, and others working to maximize the benefits and minimize the harms of AI will be better positioned to build on existing efforts and to push the fractured, global conversation on the future of AI toward consensus.","",""
10,"Bo Zhao, Shaozeng Zhang, Chunxue Xu, Yifan Sun, Chengbin Deng","Deep fake geography? When geospatial data encounter Artificial Intelligence",2021,"","","","",36,"2022-07-13 09:37:36","","10.1080/15230406.2021.1910075","","",,,,,10,10.00,2,5,1,"ABSTRACT The developing convergence of Artificial Intelligence and GIScience has raised a concern on the emergence of deep fake geography and its potentials in transforming human perception of the geographic world. Situating fake geography under the context of modern cartography and GIScience, this paper presents an empirical study to dissect the algorithmic mechanism of falsifying satellite images with non-existent landscape features. To demonstrate our pioneering attempt at deep fake detection, a robust approach is then proposed and evaluated. Our proactive study warns of the emergence and proliferation of deep fakes in geography just as “lies” in maps. We suggest timely detections of deep fakes in geospatial data and proper coping strategies when necessary. More importantly, it is encouraged to cultivate a critical geospatial data literacy and thus to understand the multi-faceted impacts of deep fake geography on individuals and human society.","",""
10,"Da-Wei Chang, Chin Lin, T. Tsao, Chia-Cheng Lee, Jiann-Torng Chen, Chien-Sung Tsai, Wei-Shiang Lin, Chin Lin","Detecting Digoxin Toxicity by Artificial Intelligence-Assisted Electrocardiography",2021,"","","","",37,"2022-07-13 09:37:36","","10.3390/ijerph18073839","","",,,,,10,10.00,1,8,1,"Although digoxin is important in heart rate control, the utilization of digoxin is declining due to its narrow therapeutic window. Misdiagnosis or delayed diagnosis of digoxin toxicity is common due to the lack of awareness and the time-consuming laboratory work that is involved. Electrocardiography (ECG) may be able to detect potential digoxin toxicity based on characteristic presentations. Our study attempted to develop a deep learning model to detect digoxin toxicity based on ECG manifestations. This study included 61 ECGs from patients with digoxin toxicity and 177,066 ECGs from patients in the emergency room from November 2011 to February 2019. The deep learning algorithm was trained using approximately 80% of ECGs. The other 20% of ECGs were used to validate the performance of the Artificial Intelligence (AI) system and to conduct a human-machine competition. Area under the receiver operating characteristic curve (AUC), sensitivity, and specificity were used to evaluate the performance of ECG interpretation between humans and our deep learning system. The AUCs of our deep learning system for identifying digoxin toxicity were 0.912 and 0.929 in the validation cohort and the human-machine competition, respectively, which reached 84.6% of sensitivity and 94.6% of specificity. Interestingly, the deep learning system using only lead I (AUC = 0.960) was not worse than using complete 12 leads (0.912). Stratified analysis showed that our deep learning system was more applicable to patients with heart failure (HF) and without atrial fibrillation (AF) than those without HF and with AF. Our ECG-based deep learning system provides a high-accuracy, economical, rapid, and accessible way to detect digoxin toxicity, which can be applied as a promising decision supportive system for diagnosing digoxin toxicity in clinical practice.","",""
148,"Jos'e Jim'enez-Luna, F. Grisoni, G. Schneider","Drug discovery with explainable artificial intelligence",2020,"","","","",38,"2022-07-13 09:37:36","","10.1038/s42256-020-00236-4","","",,,,,148,74.00,49,3,2,"","",""
4,"Anshuman Darbari, K. Kumar, Shubhankar Darbari, Prashant L. Patil","Requirement of artificial intelligence technology awareness for thoracic surgeons",2021,"","","","",39,"2022-07-13 09:37:36","","10.1186/s43057-021-00053-4","","",,,,,4,4.00,1,4,1,"","",""
28,"J. Balayla, Guy Shrem","Use of artificial intelligence (AI) in the interpretation of intrapartum fetal heart rate (FHR) tracings: a systematic review and meta-analysis",2019,"","","","",40,"2022-07-13 09:37:36","","10.1007/s00404-019-05151-7","","",,,,,28,9.33,14,2,3,"","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",41,"2022-07-13 09:37:36","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
5,"Shen Wang, Zhuobiao Qiao","Robust Pervasive Detection for Adversarial Samples of Artificial Intelligence in IoT Environments",2019,"","","","",42,"2022-07-13 09:37:36","","10.1109/ACCESS.2019.2919695","","",,,,,5,1.67,3,2,3,"Nowadays, artificial intelligence technologies (e.g., deep neural networks) have been used widely in the Internet of Things (IoT) to provide smart services and sensing data processing. The evolving neural network even exceeds the human cognitive level. However, the accuracy of these structures depends to some extent on the accuracy of the training data. Some well-designed generated antagonistic disturbances are sufficient to deceive model when added to images. Such attacks cause the classifiers trained by the neural network to misidentify the object and thus completely fail. On the other hand, the various existing defensive methods that have been proposed suffer from two criticisms. The first thing that bears the brunt is unsatisfactory detection rate due to low robustness toward the adversarial sample. Second, the excessive dependence on the output of specific network structure layers hinders the emergence of universal schemes. In this paper, we propose the large margin cosine estimation (LMCE) detection scheme to overcome the above shortcomings, making the detection independent and universal. We illustrate the principle of our approach and demonstrate the significance and analysis of some important parameters. Moreover, we model various types of adversarial attacks and establish proposed defense mechanisms against them and evaluate our approach from different aspects. This method has been clearly validated on a range of standard datasets including MNIST, CIFAR-10, and SVHN. The assessment strongly reflects the robustness and pervasive of this approach in the face of various white and semi-white box attacks.","",""
10,"Miao Chu, H. Jia, J. Gutiérrez-Chico, A. Maehara, Z. Ali, Xiaoling Zeng, L. He, Chen Zhao, M. Matsumura, Peng Wu, M. Zeng, T. Kubo, Bo Xu, Lianglong Chen, Bo Yu, G. Mintz, W. Wijns, N. Holm, S. Tu","Automatic Characterisation of Human Atherosclerotic Plaque Composition from Intravascular Optical Coherence Tomography Using Artificial Intelligence.",2021,"","","","",43,"2022-07-13 09:37:36","","10.4244/EIJ-D-20-01355","","",,,,,10,10.00,1,19,1,"BACKGROUND Intravascular optical coherence tomography (IVOCT) enables detailed plaque characterisation in-vivo, but visual assessment is time-consuming and subjective.   AIMS This study aims to develop and validate an automatic framework for IVOCT plaque characterisation using artificial intelligence (AI).   METHODS IVOCT pullbacks from 5 international centres were analysed in a corelab, annotating basic plaque components, inflammatory markers and other structures. A deep convolutional network with encoding-decoding architecture and pseudo-3D input was developed and trained using hybrid loss. The proposed network was integrated into commercial software to be externally validated on additional IVOCT pullbacks from three international corelabs, taking the consensus among corelabs as reference.   RESULTS Annotated images from 509 pullbacks (391 patients) were divided into 10,517 and 1,156 cross-sections for the training and testing datasets, respectively. Dice coefficient of the model was 0.906 for fibrous plaque, 0.848 for calcium and 0.772 for lipid in the testing dataset. Excellent agreement in plaque burden quantification was observed between the model and manual measurements (R2=0.98). In the external validation, the software correctly identified 518 out of 598 plaque regions from 300 IVOCT cross-sections, with a diagnostic accuracy of 97.6%[95%CI:93.4%-99.3%] in fibrous plaque, 90.5%[95%CI:85.2%-94.1%] in lipid and 88.5%[95%CI:82.4%-92.7%] in calcium. The median time required for analysis was 21.4 (18.6-25.0) seconds per pullback.   CONCLUSIONS A novel AI framework for automatic plaque characterisation in IVOCT was developed, providing excellent diagnostic accuracy in both internal and external validation. This model might reduce subjectivity in image interpretation and facilitate IVOCT quantification of plaque composition, with potential applications in research and IVOCT-guided PCI.","",""
0,"A. Hamed, Ibrahim Ibrahim, S. Abdelwahab, M. Elfayoumi","Using artificial intelligence in the interpretation of corneal topography for laser vision correction",2021,"","","","",44,"2022-07-13 09:37:36","","10.21608/ejomos.2021.102949.1036","","",,,,,0,0.00,0,4,1,"PURPOSE: Development and validation of an artificial intelligence program for interpretation of corneal tomography. SETTING: Ebsar eye center, Benha, Qalyopia, Egypt. METHODS: In this retrospective cohort study, we analyzed the tomography of 611 eyes of 4 groups of patients using manual interpretation and Hamed’s Interpreter as well. RESULTS: There is a statistically significant difference between group 2 and group 1 regarding the inter eye differences in thinnest location (P-value 0.021) and also manifest refraction spherical equivalent (P-value 0.011). The mean of both was significantly high in group 1 (patients with postoperative ectasia) 17.0 ± 7.87 and -5.56 ± 2.16 respectively. There is a statistically significant difference between group 3 and group 1 regarding percent tissue altered (P-value <0.001) and residual stromal thickness (P-value <0.001). The mean of percent tissue altered was significantly higher among patients who had post-laser keratorefractive surgery ectasia group (37.23 ± 5.18) while the mean of residual stromal thickness was significantly low among this group (328.25 ± 41.6). In respect to group 4, the mean of the Inter eye score was 3.38 ± 1.04, and the mean of relative thickness map was -9.2 ± 0.596. The shape of the thickness profile map curve was a quick slope in 61.5% of eyes and normal in 38.5% of eyes in group 4. Some ectasia risk factors were missed during manual interpretation of topography that led to post LVC ectasia. CONCLUSIONS: Developing an artificial intelligence system that can interpret corneal tomography will alleviate the human errors of manual interpretation.","",""
23,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, Craig Williams, Jayde Whittingham-Dowd, E. Shaw, Matt D. Hodges, L. Butler, M. Bates, R. L. La Ragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (AI-LAMP) for Rapid Detection of SARS-CoV-2",2020,"","","","",45,"2022-07-13 09:37:36","","10.3390/v12090972","","",,,,,23,11.50,2,28,2,"Until vaccines and effective therapeutics become available, the practical solution to transit safely out of the current coronavirus disease 19 (CoVID-19) lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of results, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected NHS patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. Therefore, this system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",46,"2022-07-13 09:37:36","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
121,"T. Schaffter, D. Buist, Christoph I. Lee, Yaroslav Nikulin, D. Ribli, Y. Guan, William Lotter, Zequn Jie, Hao Du, Sijia Wang, Jiashi Feng, Mengling Feng, Hyo-Eun Kim, F. Albiol, A. Albiol, Stephen Morrell, Z. Wojna, M. Ahsen, U. Asif, Antonio José Jimeno Yepes, Shivanthan A. C. Yohanandan, S. Rabinovici-Cohen, Darvin Yi, B. Hoff, Thomas Yu, E. Chaibub Neto, D. Rubin, Peter Lindholm, L. Margolies, R. McBride, J. Rothstein, W. Sieh, Rami Ben-Ari, S. Harrer, A. Trister, S. Friend, Thea C. Norman, B. Sahiner, Fredrik Strand, J. Guinney, G. Stolovitzky, Lester W. Mackey, Joyce Cahoon, Li Shen, J. H. Sohn, H. Trivedi, Yiqiu Shen, L. Buturovic, J. C. Pereira, Jaime S. Cardoso","Evaluation of Combined Artificial Intelligence and Radiologist Assessment to Interpret Screening Mammograms",2020,"","","","",47,"2022-07-13 09:37:36","","10.1001/jamanetworkopen.2020.0265","","",,,,,121,60.50,12,50,2,"This diagnostic accuracy study evaluates whether artificial intelligence can overcome human mammography interpretation limits with a rigorous, unbiased evaluation of machine learning algorithms.","",""
6,"Anton Schreuder, E. Scholten, B. Ginneken, C. Jacobs","Artificial intelligence for detection and characterization of pulmonary nodules in lung cancer CT screening: ready for practice?",2020,"","","","",48,"2022-07-13 09:37:36","","10.21037/TLCR-2020-LCS-06","","",,,,,6,3.00,2,4,2,"Lung cancer computed tomography (CT) screening trials using low-dose CT have repeatedly demonstrated a reduction in the number of lung cancer deaths in the screening group compared to a control group. With various countries currently considering the implementation of lung cancer screening, recurring discussion points are, among others, the potentially high false positive rates, cost-effectiveness, and the availability of radiologists for scan interpretation. Artificial intelligence (AI) has the potential to increase the efficiency of lung cancer screening. We discuss the performance levels of AI algorithms for various tasks related to the interpretation of lung screening CT scans, how they compare to human experts, and how AI and humans may complement each other. We discuss how AI may be used in the lung cancer CT screening workflow according to the current evidence and describe the additional research that will be required before AI can take a more prominent role in the analysis of lung screening CT scans.","",""
0,"Evander van Wolfswinkel, Jette Wielaard, J. Lavalaye, J. Hoff, J. Booij, T. D. de Wit, J. Habraken","Artificial Intelligence-Based Assistance in Clinical 123I-FP-CIT SPECT Scan Interpretation",2021,"","","","",49,"2022-07-13 09:37:36","","10.21203/rs.3.rs-721186/v1","","",,,,,0,0.00,0,7,1,"  Purpose: Dopamine transporter (DAT) imaging with 123I-FP-CIT SPECT is used to support the diagnosis of Parkinson’s disease (PD) in clinically uncertain cases. Previous studies showed that automatic classification of 123I‑FP‑CIT SPECT images (marketed as DaTSCAN) is feasible by using machine learning algorithms. However, these studies lacked sizable use of data from routine clinical practice. This study aims to contribute to the discussion whether artificial intelligence (AI) can be applied in clinical practice. Moreover, we investigated the need for hospital specific training data.Methods: A convolutional neural network (CNN) named DaTNet-3 was designed and trained to classify DaTSCAN images as either normal or supportive of a dopaminergic deficit. Both a multi-site data set (n = 2412) from the Parkinson’s Progression Marker Initiative (PPMI) and an in-house data set containing clinical images (n = 932) obtained in routine practice at the St Antonius hospital (STA) were used for training and testing. STA images were labeled based on interpretation by nuclear medicine physicians. To investigate whether indeterminate scans effects classification accuracy, a threshold was applied on the output probability.Results: DaTNet-3 trained with STA data reached an accuracy of 89.0% in correctly identifying images of the clinical STA test set as either normal or with decreased striatal DAT binding (98.5% on the PPMI test set). When thresholded, accuracy increased to 95.7%. This increase was not observed when trained with PPMI data, indicating the incorrect images were confidently classified as the incorrect class.Conclusion: Based on results of DaTNet-3 we conclude that automatic interpretation of DaTSCAN images with AI is feasible and robust. Further, we conclude DaTNet-3 performs slightly better when it is trained with hospital specific data. This difference increased when output probability was thresholded. Therefore we conclude that the usability of a data set increases if it contains indeterminate images.","",""
8,"Fabian Horst, D. Slijepcevic, S. Lapuschkin, Anna-Maria Raberger, M. Zeppelzauer, W. Samek, C. Breiteneder, W. Schöllhorn, B. Horsak","On the Understanding and Interpretation of Machine Learning Predictions in Clinical Gait Analysis Using Explainable Artificial Intelligence",2019,"","","","",50,"2022-07-13 09:37:36","","","","",,,,,8,2.67,1,9,3,"Systems incorporating Artificial Intelligence (AI) and machine learning (ML) techniques are increasingly used to guide decision-making in the healthcare sector. While AI-based systems provide powerful and promising results with regard to their classification and prediction accuracy (e.g., in differentiating between different disorders in human gait), most share a central limitation, namely their black-box character. Understanding which features classification models learn, whether they are meaningful and consequently whether their decisions are trustworthy is difficult and often impossible to comprehend. This severely hampers their applicability as decisionsupport systems in clinical practice. There is a strong need for AI-based systems to provide transparency and justification of predictions, which are necessary also for ethical and legal compliance. As a consequence, in recent years the field of explainable AI (XAI) has gained increasing importance. XAI focuses on the development of methods that enhance transparency and interpretability of complex ML models, such as Deep (Convolutional) Neural Networks. The primary aim of this article is to investigate whether XAI methods can enhance transparency, explainability and interpretability of predictions in automated clinical gait classification. We utilize a dataset comprising bilateral three-dimensional ground reaction force measurements from 132 patients with different lower-body gait disorders and 62 healthy controls. In our experiments, 1 ar X iv :1 91 2. 07 73 7v 1 [ cs .L G ] 1 6 D ec 2 01 9 Horst and Slijepcevic et al. Explainable AI in Clinical Gait Analysis we included several gait classification tasks, employed a representative set of classification methods, and a well-established XAI method – Layer-wise Relevance Propagation (LRP) – to explain decisions at the signal (input) level. The classification results are analyzed, compared and interpreted in terms of classification accuracy and relevance of input values for specific decisions. The decomposed input relevance information are evaluated from a statistical (using Statistical Parameter Mapping) and clinical (by an expert) viewpoint. There are three dimensions in our comparison: (i) different classification tasks, (ii) different classification methods, and (iii) data normalization. The presented approach exemplifies how XAI can be used to understand and interpret state-of-the-art ML models trained for gait classification tasks, and shows that the features that are considered relevant for machine learning models can be attributed to meaningful and clinically relevant biomechanical gait characteristics.","",""
5,"T. Mahmood, Muhammad Owais, Kyoung Jun Noh, Hyo Sik Yoon, J. Koo, A. Haider, H. Sultan, K. Park","Accurate Segmentation of Nuclear Regions with Multi-Organ Histopathology Images Using Artificial Intelligence for Cancer Diagnosis in Personalized Medicine",2021,"","","","",51,"2022-07-13 09:37:36","","10.3390/jpm11060515","","",,,,,5,5.00,1,8,1,"Accurate nuclear segmentation in histopathology images plays a key role in digital pathology. It is considered a prerequisite for the determination of cell phenotype, nuclear morphometrics, cell classification, and the grading and prognosis of cancer. However, it is a very challenging task because of the different types of nuclei, large intraclass variations, and diverse cell morphologies. Consequently, the manual inspection of such images under high-resolution microscopes is tedious and time-consuming. Alternatively, artificial intelligence (AI)-based automated techniques, which are fast and robust, and require less human effort, can be used. Recently, several AI-based nuclear segmentation techniques have been proposed. They have shown a significant performance improvement for this task, but there is room for further improvement. Thus, we propose an AI-based nuclear segmentation technique in which we adopt a new nuclear segmentation network empowered by residual skip connections to address this issue. Experiments were performed on two publicly available datasets: (1) The Cancer Genome Atlas (TCGA), and (2) Triple-Negative Breast Cancer (TNBC). The results show that our proposed technique achieves an aggregated Jaccard index (AJI) of 0.6794, Dice coefficient of 0.8084, and F1-measure of 0.8547 on TCGA dataset, and an AJI of 0.7332, Dice coefficient of 0.8441, precision of 0.8352, recall of 0.8306, and F1-measure of 0.8329 on the TNBC dataset. These values are higher than those of the state-of-the-art methods.","",""
9,"P. Narkhede, Rahee Walambe, Shruti Mandaokar, Pulkit Chandel, K. Kotecha, G. Ghinea","Gas Detection and Identification Using Multimodal Artificial Intelligence Based Sensor Fusion",2021,"","","","",52,"2022-07-13 09:37:36","","10.3390/asi4010003","","",,,,,9,9.00,2,6,1,"With the rapid industrialization and technological advancements, innovative engineering technologies which are cost effective, faster and easier to implement are essential. One such area of concern is the rising number of accidents happening due to gas leaks at coal mines, chemical industries, home appliances etc. In this paper we propose a novel approach to detect and identify the gaseous emissions using the multimodal AI fusion techniques. Most of the gases and their fumes are colorless, odorless, and tasteless, thereby challenging our normal human senses. Sensing based on a single sensor may not be accurate, and sensor fusion is essential for robust and reliable detection in several real-world applications. We manually collected 6400 gas samples (1600 samples per class for four classes) using two specific sensors: the 7-semiconductor gas sensors array, and a thermal camera. The early fusion method of multimodal AI, is applied The network architecture consists of a feature extraction module for individual modality, which is then fused using a merged layer followed by a dense layer, which provides a single output for identifying the gas. We obtained the testing accuracy of 96% (for fused model) as opposed to individual model accuracies of 82% (based on Gas Sensor data using LSTM) and 93% (based on thermal images data using CNN model). Results demonstrate that the fusion of multiple sensors and modalities outperforms the outcome of a single sensor.","",""
2,"Neha Gupta, S. Gupta, Rajesh K. Pathak, Vanita Jain, P. Rashidi, J. Suri","Human activity recognition in artificial intelligence framework: a narrative review",2022,"","","","",53,"2022-07-13 09:37:36","","10.1007/s10462-021-10116-x","","",,,,,2,2.00,0,6,1,"","",""
2,"Chiara Longoni, Andrey Fradkin, Luca Cian, Gordon Pennycook","News from Artificial Intelligence is Believed Less",2021,"","","","",54,"2022-07-13 09:37:36","","10.2139/SSRN.3787064","","",,,,,2,2.00,1,4,1,"Artificial Intelligence (AI) algorithms are now able to produce text virtually indistinguishable from text written by humans across a variety of domains. A key question, then, is whether people believe content from AI as much as content from humans. Trust in the (human generated) news media has been decreasing over time and AI is viewed as lacking human desires, and emotions, suggesting that AI news may be viewed as more accurate. Contrary to this, two preregistered experiments conducted on representative U.S. samples (combined N = 4,034) showed that people rated news produced by AI as being less accurate than news produced by humans. When news items were tagged as produced by AI (compared to a human), people were more likely to incorrectly rate them as inaccurate when they were actually true, and more likely to correctly rate them as inaccurate when they were indeed false. These results were robust to experimental paradigm (separate and joint evaluations), news item (actual veracity, age), and several respondent characteristics (e.g., political orientation). This effect is particularly important given the increasing use of AI algorithms in news production, and the associated ethical and governance pressures to disclose their use.","",""
9,"J. Harrison, J. Gilbertson, M. Hanna, N. Olson, J. Seheult, James M. Sorace, M. Stram","Introduction to Artificial Intelligence and Machine Learning for Pathology.",2021,"","","","",55,"2022-07-13 09:37:36","","10.5858/arpa.2020-0541-CP","","",,,,,9,9.00,1,7,1,"CONTEXT.— Recent developments in machine learning have stimulated intense interest in software that may augment or replace human experts. Machine learning may impact pathology practice by offering new capabilities in analysis, interpretation, and outcomes prediction using images and other data. The principles of operation and management of machine learning systems are unfamiliar to pathologists, who anticipate a need for additional education to be effective as expert users and managers of the new tools.   OBJECTIVE.— To provide a background on machine learning for practicing pathologists, including an overview of algorithms, model development, and performance evaluation; to examine the current status of machine learning in pathology and consider possible roles and requirements for pathologists in local deployment and management of machine learning systems; and to highlight existing challenges and gaps in deployment methodology and regulation.   DATA SOURCES.— Sources include the biomedical and engineering literature, white papers from professional organizations, government reports, electronic resources, and authors' experience in machine learning. References were chosen when possible for accessibility to practicing pathologists without specialized training in mathematics, statistics, or software development.   CONCLUSIONS.— Machine learning offers an array of techniques that in recent published results show substantial promise. Data suggest that human experts working with machine learning tools outperform humans or machines separately, but the optimal form for this combination in pathology has not been established. Significant questions related to the generalizability of machine learning systems, local site verification, and performance monitoring remain to be resolved before a consensus on best practices and a regulatory environment can be established.","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",56,"2022-07-13 09:37:36","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
45,"Tom Kamiel Magda Vercauteren, M. Unberath, N. Padoy, N. Navab","CAI4CAI: The Rise of Contextual Artificial Intelligence in Computer-Assisted Interventions",2019,"","","","",57,"2022-07-13 09:37:36","","10.1109/JPROC.2019.2946993","","",,,,,45,15.00,11,4,3,"Data-driven computational approaches have evolved to enable extraction of information from medical images with reliability, accuracy, and speed, which is already transforming their interpretation and exploitation in clinical practice. While similar benefits are longed for in the field of interventional imaging, this ambition is challenged by a much higher heterogeneity. Clinical workflows within interventional suites and operating theaters are extremely complex and typically rely on poorly integrated intraoperative devices, sensors, and support infrastructures. Taking stock of some of the most exciting developments in machine learning and artificial intelligence for computer-assisted interventions, we highlight the crucial need to take the context and human factors into account in order to address these challenges. Contextual artificial intelligence for computer-assisted intervention (CAI4CAI) arises as an emerging opportunity feeding into the broader field of surgical data science. Central challenges being addressed in CAI4CAI include how to integrate the ensemble of prior knowledge and instantaneous sensory information from experts, sensors, and actuators; how to create and communicate a faithful and actionable shared representation of the surgery among a mixed human–AI actor team; and how to design interventional systems and associated cognitive shared control schemes for online uncertainty-aware collaborative decision-making ultimately producing more precise and reliable interventions.","",""
0,"Karan Jaju, H. Thakkar","Impact of Artificial Intelligence and Internet of Things in Effective Handling of Coronavirus Crisis",2021,"","","","",58,"2022-07-13 09:37:36","","10.1007/978-981-16-2786-6_12","","",,,,,0,0.00,0,2,1,"","",""
0,"Michael B Rüegsegger, M. Sommer","Deep Self-optimizing Artificial Intelligence for Tactical Analysis, Training and Optimization",2021,"","","","",59,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,2,1,"The increasing complexity of modern multi-domain conflicts has made their tactical and strategic understanding and the identification of appropriate courses of action challenging endeavours. Modelling and simulation as part of concept development and experimentation (CD&E) provide new insight at higher speed and lower cost than what physical manoeuvres can achieve. Amongst other, human-machine teaming through computer games is a powerful means of simulating defence scenarios at various abstraction levels. However, conventional human-machine interaction is time-consuming and restricted to pre-designed scenarios, e.g., in terms of pre-programmed conditional computer actions. If one side of the game could be taken by Artificial Intelligence (AI), this would increase the diversity of explored courses of actions and lead to a more robust and comprehensive analysis. If the AI plays both sides, this allows employing the Data Farming methodology and creating and analysing a database of a large number of investigated scenarios. To achieve a high degree of variability and generalization capability of the investigated scenarios, we employ combined Reinforcement Learning and search algorithms, which have demonstrated super-human performance in various complex planning problems. Such AI systems avoid the reliance on training data, human experience and predictions by learning tactics and strategy through exploration and self-optimization. In this contribution, we present the benefits and challenges of applying a Neural-Network-based Monte Carlo Tree Search algorithm for strategic planning and training in air-defence scenarios and virtual war-gaming with systems that are available currently or potentially in the future to the Swiss Armed Forces.","",""
32,"S. Gonem, W. Janssens, N. Das, M. Topalovic","Applications of artificial intelligence and machine learning in respiratory medicine",2020,"","","","",60,"2022-07-13 09:37:36","","10.1136/thoraxjnl-2020-214556","","",,,,,32,16.00,8,4,2,"The past 5 years have seen an explosion of interest in the use of artificial intelligence (AI) and machine learning techniques in medicine. This has been driven by the development of deep neural networks (DNNs)—complex networks residing in silico but loosely modelled on the human brain—that can process complex input data such as a chest radiograph image and output a classification such as ‘normal’ or ‘abnormal’. DNNs are ‘trained’ using large banks of images or other input data that have been assigned the correct labels. DNNs have shown the potential to equal or even surpass the accuracy of human experts in pattern recognition tasks such as interpreting medical images or biosignals. Within respiratory medicine, the main applications of AI and machine learning thus far have been the interpretation of thoracic imaging, lung pathology slides and physiological data such as pulmonary function tests. This article surveys progress in this area over the past 5 years, as well as highlighting the current limitations of AI and machine learning and the potential for future developments.","",""
2,"A. Koeppe, F. Bamer, M. Selzer, B. Nestler, B. Markert","Explainable artificial intelligence for mechanics: physics-informing neural networks for constitutive models",2021,"","","","",61,"2022-07-13 09:37:36","","","","",,,,,2,2.00,0,5,1,"(Artificial) neural networks have become increasingly popular in mechanics as means to accelerate computations with model order reduction techniques and as universal models for a wide variety of materials. However, the major disadvantage of neural networks remains: their numerous parameters are challenging to interpret and explain. Thus, neural networks are often labeled as black boxes, and their results often elude human interpretation. In mechanics, the new and active field of physicsinformed neural networks attempts to mitigate this disadvantage by designing deep neural networks on the basis of mechanical knowledge. By using this a priori knowledge, deeper and more complex neural networks became feasible, since the mechanical assumptions could be explained. However, the internal reasoning and explanation of neural network parameters remain mysterious. Complementary to the physics-informed approach, we propose a first step towards a physicsinforming approach, which explains neural networks trained on mechanical data a posteriori. This novel explainable artificial intelligence approach aims at elucidating the black box of neural networks and their high-dimensional representations. Therein, the principal component analysis decorrelates the distributed representations in cell states of RNNs and allows the comparison to known and fundamental functions. The novel approach is supported by a systematic hyperparameter search strategy that identifies the best neural network architectures and training parameters. The findings of three case studies on fundamental constitutive models (hyperelasticity, elastoplasticity, and viscoelasticity) imply that the proposed strategy can help identify numerical and analytical closed-form solutions to characterize new materials.","",""
3,"T. Kaur, Anirudra Diwakar, Kirandeep, Pranav Mirpuri, M. Tripathi, P. Chandra, T. Gandhi","Artificial Intelligence in Epilepsy",2021,"","","","",62,"2022-07-13 09:37:36","","10.4103/0028-3886.317233","","",,,,,3,3.00,0,7,1,"Background: The study of seizure patterns in electroencephalography (EEG) requires several years of intensive training. In addition, inadequate training and human error may lead to misinterpretation and incorrect diagnosis. Artificial intelligence (AI)-based automated seizure detection systems hold an exciting potential to create paradigms for proper diagnosis and interpretation. AI holds the promise to transform healthcare into a system where machines and humans can work together to provide an accurate, timely diagnosis, and treatment to the patients. Objective: This article presents a brief overview of research on the use of AI systems for pattern recognition in EEG for clinical diagnosis. Material and Methods: The article begins with the need for understanding nonstationary signals such as EEG and simplifying their complexity for accurate pattern recognition in medical diagnosis. It also explains the core concepts of AI, machine learning (ML), and deep learning (DL) methods. Results and Conclusions: In this present context of epilepsy diagnosis, AI may work in two ways; first by creating visual representations (e.g., color-coded paradigms), which allow persons with limited training to make a diagnosis. The second is by directly explaining a complete automated analysis, which of course requires more complex paradigms than the previous one. We also clarify that AI is not about replacing doctors and strongly emphasize the need for domain knowledge in building robust AI models that can work in real-time scenarios rendering good detection accuracy in a minimum amount of time.","",""
1,"B. Hameed, Gayathri Prerepa, Vathsala Patil, Pranav Shekhar, Syed Zahid Raza, Hadis Karimi, R. Paul, Nithesh Naik, S. Modi, G. Vigneswaran, Bhavan Prasad Rai, P. Chłosta, B. Somani","Engineering and clinical use of artificial intelligence (AI) with machine learning and data science advancements: radiology leading the way for future",2021,"","","","",63,"2022-07-13 09:37:36","","10.1177/17562872211044880","","",,,,,1,1.00,0,13,1,"Over the years, many clinical and engineering methods have been adapted for testing and screening for the presence of diseases. The most commonly used methods for diagnosis and analysis are computed tomography (CT) and X-ray imaging. Manual interpretation of these images is the current gold standard but can be subject to human error, is tedious, and is time-consuming. To improve efficiency and productivity, incorporating machine learning (ML) and deep learning (DL) algorithms could expedite the process. This article aims to review the role of artificial intelligence (AI) and its contribution to data science as well as various learning algorithms in radiology. We will analyze and explore the potential applications in image interpretation and radiological advances for AI. Furthermore, we will discuss the usage, methodology implemented, future of these concepts in radiology, and their limitations and challenges.","",""
1,"V. Pai, R. Pai","Artificial intelligence in dermatology and healthcare: An overview.",2021,"","","","",64,"2022-07-13 09:37:36","","10.25259/IJDVL_518_19","","",,,,,1,1.00,1,2,1,"Many aspects of our life are affected by technology. One of the most discussed advancements of modern technologies is artificial intelligence. It involves computational methods which in some way mimic the human thought process. Just like other branches, the medical field also has come under the ambit of artificial intelligence. Almost every field in medicine has been touched by its effect in one way or the other. Prominent among them are medical diagnosis, medical statistics, robotics, and human biology. Medical imaging is one of the foremost specialties with artificial intelligence applications, wherein deep learning methods like artificial neural networks are commonly used. artificial intelligence application in dermatology was initially restricted to the analysis of melanoma and pigmentary skin lesions, has now expanded and covers many dermatoses. Though the applications of artificial intelligenceare ever increasing, large data requirements, interpretation of data and ethical concerns are some of its limitations in the present day.","",""
2,"Lamija Hafizović, Aldijana Čaušević, Amar Deumic, Lemana Spahic Becirovic, L. G. Pokvic, A. Badnjević","The Use of Artificial Intelligence in Diagnostic Medical Imaging: Systematic Literature Review",2021,"","","","",65,"2022-07-13 09:37:36","","10.1109/BIBE52308.2021.9635307","","",,,,,2,2.00,0,6,1,"Diagnostic medical imaging and the interpretation of the imaging results pose a great challenge for the medical profession as the final conclusions are highly susceptible to human error and subjectivity. The necessity for standardization of interpretation of medical images is very necessary to bypass these problems. The only way of achieving this is using a methodology which excludes the human eye and employs artificial intelligence. However, another challenge is selecting the most suitable AI algorithm fit for the challenging task of imaging results interpretation. This study was conducted following PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines published in 2020. Research was done using PubMed, ScienceDirect and Google Scholar databases where the key inclusion criteria were language, journal credibility, open access to full-text publications and the most recent papers. In order to focus on only the most recent research, only the papers published in the last 5 years were evaluated. The search through PubMed, ScienceDirect and Google Scholar has yielded 81, 205, and 520 papers respectively. Out of this number of papers, 26 of them have met all of the inclusion criteria and were included in the research. The observed accuracies of the models and the overall rising interest in the topic denote that this field is rapidly growing and has a great potential to be applied in daily medical practice in the future.","",""
1,"H. Whitney, M. Giger","Artificial Intelligence in Medical Imaging",2021,"","","","",66,"2022-07-13 09:37:36","","10.1063/9780735423473_007","","",,,,,1,1.00,1,2,1,"Artificial intelligence (AI) in cancer image interpretation continues to evolve with complementary advances in image acquisition systems, imaging protocols, and machine learning tools, as well as expanding clinical tasks. AI can be defined as having computers simulate the conduction of human intelligence tasks. Advances in computers, in terms of both computing power and memory capacity, have led to a rapid increase in assessing the potential use of AI in various tasks in medical imaging, going beyond the initial use in computer-aided detection (CADe) to include diagnosis, prognosis, response to therapy, and risk assessment, as well as in cancer discovery. AI methods are being developed for CADe and computer-aided diagnosis (CADx), for computer-aided triaging (CADt), and sometimes for use as autonomous readers, often with the need for consideration for effect on radiologists’ perception/cognitive performance and workflow. While the prospects of AI in medical image interpretation are abundant and promising, they bring along challenges and limitations. This chapter focuses on the role of AI in medical image interpretation.","",""
2,"S. Haymond, C. McCudden","Rise of the Machines: Artificial Intelligence and the Clinical Laboratory.",2021,"","","","",67,"2022-07-13 09:37:36","","10.1093/jalm/jfab075","","",,,,,2,2.00,1,2,1,"BACKGROUND Artificial intelligence (AI) is rapidly being developed and implemented to augment and automate decision-making across healthcare systems. Being an essential part of these systems, laboratories will see significant growth in AI applications for the foreseeable future.   CONTENT In laboratory medicine, AI can be used for operational decision-making and automating or augmenting human-based workflows. Specific applications include instrument automation, error detection, forecasting, result interpretation, test utilization, genomics, and image analysis. If not doing so today, clinical laboratories will be using AI routinely in the future, therefore, laboratory experts should understand their potential role in this new area and the opportunities for AI technologies. The roles of laboratorians range from passive provision of data to fuel algorithms to developing entirely new algorithms, with subject matter expertise as a perfect fit in the middle. The technical development of algorithms is only a part of the overall picture, where the type, availability, and quality of data are at least as important. Implementation of AI algorithms also offers technical and usability challenges that need to be understood to be successful. Finally, as AI algorithms continue to become available, it is important to understand how to evaluate their validity and utility in the real world.   SUMMARY This review provides an overview of what AI is, examples of how it is currently being used in laboratory medicine, different ways for laboratorians to get involved in algorithm development, and key considerations for AI algorithm implementation and critical evaluation.","",""
1,"M. Dorobantu","Cognitive Vulnerability, Artificial Intelligence, and the Image of God in Humans",2021,"","","","",68,"2022-07-13 09:37:36","","10.1080/23312521.2020.1867025","","",,,,,1,1.00,1,1,1,"Abstract Recent progress in artificial intelligence (AI) opens up the possibility that one day machines could do anything that a human being can do, raising thus serious questions regarding human distinctiveness. For theological anthropology, the prospect of human-level AI brings a fresh opportunity to clarify the definition of the image of God. Comparing human and artificial intelligence leads to replacing the Aristotelian-like interpretation of the image of God as rationality with a relational model. Instead of regarding our cognitive biases as vulnerabilities, they should be seen as instrumental in bringing about our unique type of intelligence, one marked by relationality.","",""
2,"Rishikesh Bamdale, Shreejeet Sahay, V. Khandekar","Natural Human Robot Interaction Using Artificial Intelligence: A Survey",2019,"","","","",69,"2022-07-13 09:37:36","","10.1109/IEMECONX.2019.8877044","","",,,,,2,0.67,1,3,3,"In the era of Artificial Intelligence and robotics, it’s imperative to have a friendly system to communicate with robots so they can play a very crucial role in every-day human life. Human Robot Interaction is the foremost system in robotics today to verbally communicate with a robot in a natural way. The major struggle of the interactive system not only lies in how to teach robots to speak but also in helping to make them understand the meanings and real-world around us. This article reviews the current novel and inventive technologies to have a perfect and robust interactive system, also the importance of natural communication along with the evolution of robots since an early age. The process of language understanding has its large significance in human-robot communication with the rising technology of Artificial Intelligence. Reinforcement Learning also will play a bigger role in understanding the natural language for robots. This paper is concluded by discussing various pitfalls, advantages and future scopes of different technical aspects of Human Robot Interaction, with the hope to have the absolute interactive robots in near future, that humans have always dreamed of.","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",70,"2022-07-13 09:37:36","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
0,"Kai Jiang, Xi Lu","The Influence of Speech Translation Technology on Interpreter’s Career Prospects in the Era of Artificial Intelligence",2021,"","","","",71,"2022-07-13 09:37:36","","10.1088/1742-6596/1802/4/042074","","",,,,,0,0.00,0,2,1,"As the advancements in artificial intelligence, discussions on whether machine translation will replace human translation are found in the media and the public, but scholars have rarely explored this in research. This paper first reviews the history and recent progress in speech translation technology, and analyzes its merits and limitations. Then, in view of the history and features of the interpreting profession, the paper discusses the influence of speech translation technology on interpreter’s career prospects. The author holds that even if future speech translation technology is highly sophisticated, it still cannot completely replace human interpreters. Artificial intelligence is considered as both a challenge and an opportunity for the translation industry. The future trends in interpretation will be mainly human-led and machine-aided. After analyzing the trends and challenges to the interpreting profession, the paper proposes suggestions to interpretation teaching, hoping to give reference to interpretation teachers, learners and researchers.","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",72,"2022-07-13 09:37:36","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
1,"C. Bormann, M. Kanakasabapathy, Prudhvi Thirumalaraju, I. Dimitriadis, I. Souter, K. Hammer, H. Shafiee","O-125 Development of an artificial intelligence embryo witnessing system to accurately track and identify patient specific embryos in a human IVF laboratory",2021,"","","","",73,"2022-07-13 09:37:36","","10.1093/humrep/deab126.050","","",,,,,1,1.00,0,7,1,"      Can convolutional neural networks (CNN) be used as a witnessing system to accurately track and identify patient specific embryos at the cleavage stage of development?        We developed the first artificial intelligence driven witnessing system to accurately track cleavage and blastocyst stage embryos in a human ART laboratory.        There are reports of human errors in embryo tracking that have led to the births of children with different genetic makeup than their birth parents. Clinical practices rely on manual identification, barcodes or radio-frequency identification technology to track embryos. These systems are designed to track culture dishes but are unable to monitor developing embryos within the dish to help ensure an error-free patient match. Previously, we developed an AI witnessing system to track blastocysts with 100% accuracy. The goal of this study was to determine whether an AI witnessing system could be developed that accurately tracks cleavage stage embryos.        A pre-developed deep neural network technology was first trained and tested on 4944 embryos images. The algorithm processed embryo images for each patient and produced a unique key that was associated with the patient ID at 60 hpi, which formed our library. When the algorithm evaluated embryos at 64 hpi it generated another key that was matched with the patient’s unique key available in the library.        A total of 3068 embryos from 412 patients were examined by the CNN at both 60 hpi and 64 hpi. These timepoints were chosen as they reflect the time our laboratory evaluates Day 3 embryos (60 hpi) and the time we move them to another dish and prepare them for transfer (64 hpi). The patient cohorts ranged from 3-12 embryos per patient.        The accuracy of the CNN in correctly matching the patient identification with the patient embryo cohort was 100% (CI: 99.1% to 100.0%, n = 412).        Limitations of this study include that all embryos were imaged under identical conditions and within the same EmbryoScope. Additionally, this study only examined fresh Day 3 embryos cultured over a span of 4 hours. Future studies should include images of fresh and frozen/thawed embryos captured using different imaging systems.        This study describes the first artificial intelligence-based approach for cleavage stage embryo tracking and patient specimen identification in the IVF laboratory. This technology offers a robust witnessing step based on unique morphological features that are specific to each individual embryo.        This work was partially supported by the Brigham Precision Medicine Developmental Award (Brigham Precision Medicine Program, Brigham and Women’s Hospital), Partners Innovation Discovery Grant (Partners Healthcare), and R01AI118502, and R01AI138800. ","",""
2,"Morteza Esmaeili, R. Vettukattil, H. Banitalebi, Nina R. Krogh, J. Geitung","Explainable Artificial Intelligence for Human-Machine Interaction in Brain Tumor Localization",2021,"","","","",74,"2022-07-13 09:37:36","","10.3390/jpm11111213","","",,,,,2,2.00,0,5,1,"Primary malignancies in adult brains are globally fatal. Computer vision, especially recent developments in artificial intelligence (AI), have created opportunities to automatically characterize and diagnose tumor lesions in the brain. AI approaches have provided scores of unprecedented accuracy in different image analysis tasks, including differentiating tumor-containing brains from healthy brains. AI models, however, perform as a black box, concealing the rational interpretations that are an essential step towards translating AI imaging tools into clinical routine. An explainable AI approach aims to visualize the high-level features of trained models or integrate into the training process. This study aims to evaluate the performance of selected deep-learning algorithms on localizing tumor lesions and distinguishing the lesion from healthy regions in magnetic resonance imaging contrasts. Despite a significant correlation between classification and lesion localization accuracy (R = 0.46, p = 0.005), the known AI algorithms, examined in this study, classify some tumor brains based on other non-relevant features. The results suggest that explainable AI approaches can develop an intuition for model interpretability and may play an important role in the performance evaluation of deep learning models. Developing explainable AI approaches will be an essential tool to improve human–machine interactions and assist in the selection of optimal training methods.","",""
1,"W. Monroe, F. Skidmore, David G. Odaibo, M. Tanik","HihO: accelerating artificial intelligence interpretability for medical imaging in IoT applications using hierarchical occlusion",2020,"","","","",75,"2022-07-13 09:37:36","","10.1007/S00521-020-05379-4","","",,,,,1,0.50,0,4,2,"","",""
2,"Thomas Garvin, Scott Kimbleton","Artificial intelligence as ally in hazard analysis",2021,"","","","",76,"2022-07-13 09:37:36","","10.1002/prs.12243","","",,,,,2,2.00,1,2,1,"Hazard analysis techniques have been around for many years, and have proven effective in the prevention of incidents and no doubt the saving of lives. Process hazard analysis (PHA) is now fairly robust and regulated, focused on overarching risks associated with the safe handling of hazardous materials and approaches to engineer‐out such risks. Occupational hazard analysis (OHA) is keenly focused on human activity, and personal protection in hazardous working conditions. Both approaches are critical ‐ but are often carried out separately, by different parts of an organization, which could result in an incomplete picture of the full set of operational risks in the field. Developing a holistic picture of both past and present dangers calls for a deep exploration of evidence. HAZOPs, PHA's, incident records and investigations provide expert analysis of hazards and mitigating strategies. Near‐miss reports and safety observations add a large amount of information as well; the reporting frequency of these “leading indicators” can be both a blessing and a curse, as time and available resources constrain the ability to analyze and detect hazard signals within. As important as analyzing the historical record is for lessons learned, the more recent observations could indicate new hazards or highlight concerning trends. These could feed valuable “real time” information back to operations and maintenance teams to improve risk assessments and task planning. Enter artificial intelligence (AI) as a means to analyze the large amount of written hazard analyses, reports and observations to quickly extract insights around hazardous conditions, activities, incident causes and risk mitigation measures. Trained to understand concepts and contexts in both process and personal safety, AI can provide a natural‐language information exploration environment for scanning thousands of documents in seconds and present common themes and related records. Not unlike us humans, AI learns from the past, informs the present and can help reduce risks in the future.","",""
21,"B. Stoel","Use of artificial intelligence in imaging in rheumatology – current status and future perspectives",2020,"","","","",77,"2022-07-13 09:37:36","","10.1136/rmdopen-2019-001063","","",,,,,21,10.50,21,1,2,"After decades of basic research with many setbacks, artificial intelligence (AI) has recently obtained significant breakthroughs, enabling computer programs to outperform human interpretation of medical images in very specific areas. After this shock wave that probably exceeds the impact of the first AI victory of defeating the world chess champion in 1997, some reflection may be appropriate on the consequences for clinical imaging in rheumatology. In this narrative review, a short explanation is given about the various AI techniques, including ‘deep learning’, and how these have been applied to rheumatological imaging, focussing on rheumatoid arthritis and systemic sclerosis as examples. By discussing the principle limitations of AI and deep learning, this review aims to give insight into possible future perspectives of AI applications in rheumatology.","",""
3,"B. Schneider, P. Asprion, F. Grimberg","Human-centered Artificial Intelligence: A Multidimensional Approach towards Real World Evidence",2019,"","","","",78,"2022-07-13 09:37:36","","10.5220/0007715503810390","","",,,,,3,1.00,1,3,3,"This study indicates the significance of a human-centered perspective in the analysis and interpretation of Real World Data. As an exemplary use-case, the construct of perceived ‘Health-related Quality of Life’ is chosen to show, firstly, the significance of Real World Data and, secondly, the associated ‘Real World Evidence’. We settled on an iterative methodology and used hermeneutics for a detailed literature analysis to outline the relevance and the need for a forward-thinking approach to deal with Real World Evidence in the life science and health care industry. The novelty of the study is its focus on a human-centered artificial intelligence, which can be achieved by using ‘System Dynamics’ modelling techniques. The outcome – a human-centered ‘Indicator Set’ can be combined with results from data-driven, AI-based analytics. With this multidimensional approach, human intelligence and artificial intelligence can be intertwined towards an enriched Real World Evidence. The developed approach considers three perspectives – the elementary, the algorithmic and – as novelty – the human-centered evidence. As conclusion, we claim that Real World Data are more valuable and applicable to achieve patient-centricity and personalization if the human-centered perspective is considered ‘by design’.","",""
21,"Shantani Kannan, K. Subbaram, Sheeza Ali, H. Kannan","The Role of Artificial Intelligence and Machine Learning Techniques: Race for COVID-19 Vaccine",2020,"","","","",79,"2022-07-13 09:37:36","","10.5812/archcid.103232","","",,,,,21,10.50,5,4,2,"Context: In the healthcare system, Artificial Intelligence (AI) is emerging as a productive tool. There are instances where AI has done marvels in the diagnosis of various health conditions and the interpretation of complex medical disorders. Although AI is far from human intelligence, it can be used as an effective tool to study the SARS-CoV-2 and its capabilities, virulence, and genome. The progress of the pandemic can be tracked, and the patients can be monitored, thereby speeding up the research for the treatment of COVID-19. In this review article, we highlighted the importance of AI and Machine learning (ML) techniques that can speed up the path to the discovery of a possible cure for COVID-19. We also deal with the interactions between viromics and AI, which can hopefully find a solution to this pandemic. Evidence Acquisition: A review of different articles was conducted using the following databases: MEDLINE/PubMed, SCOPUS, Web of Science, ScienceDirect, and Google Scholar for recent studies regarding the use of AI, seeking the spread of different infectious diseases using relevant MeSH subheadings. Results: After a thorough screening of different articles, 30 articles were considered, and key information was obtained from them. Finally, the scope was broadened to obtain more information. Our findings indicated that AI/ML is a promising approach to drug development. Conclusions: The field of AI has enormous potential to predict the changes that may take place in the environment. If this technology is applied to situations of a pandemic such as COVID-19, breakthroughs could potentially pave the way for new vaccines and antiviral drugs.","",""
2,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, C. Williams, M. Bates, R. Laragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (ai-LAMP) for Rapid and Reliable Detection of SARS-CoV-2",2020,"","","","",80,"2022-07-13 09:37:36","","10.1101/2020.07.08.20148999","","",,,,,2,1.00,0,24,2,"Until vaccines and effective therapeutics become available, the practical way to transit safely out of the current lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of result, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms, and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. The system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
2,"S. Rahman, Oly Katari, D. Pawde, Gopi Sumanth Bhaskar Boddeda, A. Goswami, S. Mutheneni, T. Shunmugaperumal","Application of Design of Experiments® Approach-Driven Artificial Intelligence and Machine Learning for Systematic Optimization of Reverse Phase High Performance Liquid Chromatography Method to Analyze Simultaneously Two Drugs (Cyclosporin A and Etodolac) in Solution, Human Plasma, Nanocapsules, and ",2021,"","","","",81,"2022-07-13 09:37:36","","10.1208/s12249-021-02026-6","","",,,,,2,2.00,0,7,1,"The objectives of current investigation are (1) to find out wavelength of maximum absorbance (λmax) for combined cyclosporin A and etodolac solution followed by selection of mobile phase suitable for the RP-HPLC method, (2) to define analytical target profile and critical analytical attributes (CAAs) for the analytical quality by design, (3) to screen critical method parameters with the help of full factorial design followed by optimization with face-centered central composite design (CCD) approach-driven artificial neural network (ANN)-linked with the Levenberg-Marquardt (LM) algorithm for finding the RP-HPLC conditions, (4) to perform validation of analytical procedures (trueness, linearity, precision, robustness, specificity and sensitivity) using combined drug solution, and (5) to determine drug entrapment efficiency value in dual drug-loaded nanocapsules/emulsions, percentage recovery value in human plasma spiked with two drugs and solution state stability analysis at different stress conditions for substantiating the double-stage systematically optimized RP-HPLC method conditions. Through isobestic point and scouting step, 205 nm and ACN:H2O mixture (74:26) were selected respectively as the λmax and mobile phase. The ANN topology (3:10:4) indicating the input, hidden and output layers were generated by taking the 20 trials produced from the face-centered CCD model. The ANN-linked LM model produced minimal differences between predicted and observed values of output parameters (or CAAs), low mean squared error and higher correlation coefficient values in comparison to the respective values produced by face-centered CCD model. The optimized RP-HPLC method could be applied to analyze two drugs concurrently in different formulations, human plasma and solution state stability checking.","",""
18,"Zhen Zhao, Y. Pi, Lisha Jiang, Yongzhao Xiang, Jianan Wei, Pei Yang, Wenjie Zhang, Xiao Zhong, K. Zhou, Yuhao Li, Lin Li, Yi Zhang, H. Cai","Deep neural network based artificial intelligence assisted diagnosis of bone scintigraphy for cancer bone metastasis",2020,"","","","",82,"2022-07-13 09:37:36","","10.1038/s41598-020-74135-4","","",,,,,18,9.00,2,13,2,"","",""
15,"M. Jiménez Pérez, R. Grande","Application of artificial intelligence in the diagnosis and treatment of hepatocellular carcinoma: A review",2020,"","","","",83,"2022-07-13 09:37:36","","10.3748/wjg.v26.i37.5617","","",,,,,15,7.50,8,2,2,"Although artificial intelligence (AI) was initially developed many years ago, it has experienced spectacular advances over the last 10 years for application in the field of medicine, and is now used for diagnostic, therapeutic and prognostic purposes in almost all fields. Its application in the area of hepatology is especially relevant for the study of hepatocellular carcinoma (HCC), as this is a very common tumor, with particular radiological characteristics that allow its diagnosis without the need for a histological study. However, the interpretation and analysis of the resulting images is not always easy, in addition to which the images vary during the course of the disease, and prognosis and treatment response can be conditioned by multiple factors. The vast amount of data available lend themselves to study and analysis by AI in its various branches, such as deep-learning (DL) and machine learning (ML), which play a fundamental role in decision-making as well as overcoming the constraints involved in human evaluation. ML is a form of AI based on automated learning from a set of previously provided data and training in algorithms to organize and recognize patterns. DL is a more extensive form of learning that attempts to simulate the working of the human brain, using a lot more data and more complex algorithms. This review specifies the type of AI used by the various authors. However, well-designed prospective studies are needed in order to avoid as far as possible any bias that may later affect the interpretability of the images and thereby limit the acceptance and application of these models in clinical practice. In addition, professionals now need to understand the true usefulness of these techniques, as well as their associated strengths and limitations.","",""
12,"C. Ho, Joseph Ali, K. Caals","Ensuring trustworthy use of artificial intelligence and big data analytics in health insurance",2020,"","","","",84,"2022-07-13 09:37:36","","10.2471/BLT.19.234732","","",,,,,12,6.00,4,3,2,"Abstract Technological advances in big data (large amounts of highly varied data from many different sources that may be processed rapidly), data sciences and artificial intelligence can improve health-system functions and promote personalized care and public good. However, these technologies will not replace the fundamental components of the health system, such as ethical leadership and governance, or avoid the need for a robust ethical and regulatory environment. In this paper, we discuss what a robust ethical and regulatory environment might look like for big data analytics in health insurance, and describe examples of safeguards and participatory mechanisms that should be established. First, a clear and effective data governance framework is critical. Legal standards need to be enacted and insurers should be encouraged and given incentives to adopt a human-centred approach in the design and use of big data analytics and artificial intelligence. Second, a clear and accountable process is necessary to explain what information can be used and how it can be used. Third, people whose data may be used should be empowered through their active involvement in determining how their personal data may be managed and governed. Fourth, insurers and governance bodies, including regulators and policy-makers, need to work together to ensure that the big data analytics based on artificial intelligence that are developed are transparent and accurate. Unless an enabling ethical environment is in place, the use of such analytics will likely contribute to the proliferation of unconnected data systems, worsen existing inequalities, and erode trustworthiness and trust.","",""
167,"Max Tegmark","Life 3.0: Being Human in the Age of Artificial Intelligence",2017,"","","","",85,"2022-07-13 09:37:36","","","","",,,,,167,33.40,167,1,5,"New York Times Best Seller How will Artificial Intelligence affect crime, war, justice, jobs, society and our very sense of being human? The rise of AI has the potential to transform our future more than any other technologyand theres nobody better qualified or situated to explore that future than Max Tegmark, an MIT professor whos helped mainstream research on how to keep AI beneficial. How can we grow our prosperity through automation without leaving people lacking income or purpose? What career advice should we give todays kids? How can we make future AI systems more robust, so that they do what we want without crashing, malfunctioning or getting hacked? Should we fear an arms race in lethal autonomous weapons? Will machines eventually outsmart us at all tasks, replacing humans on the job market and perhaps altogether? Will AI help life flourish like never before or give us more power than we can handle? What sort of future do you want? This book empowers you to join what may be the most important conversation of our time. It doesnt shy away from the full range of viewpoints or from the most controversial issuesfrom superintelligence to meaning, consciousness and the ultimate physical limits on life in the cosmos.","",""
47,"L. Faes, B. Geerts, Xiaoxuan Liu, L. Morgan, P. Watkinson, P. McCulloch","DECIDE-AI: new reporting guidelines to bridge the development-to-implementation gap in clinical artificial intelligence.",2021,"","","","",86,"2022-07-13 09:37:36","","10.1038/s41591-021-01229-5","","",,,,,47,47.00,8,6,1,"","",""
8,"John T. O’Brien, Cassidy Nelson","Assessing the Risks Posed by the Convergence of Artificial Intelligence and Biotechnology.",2020,"","","","",87,"2022-07-13 09:37:36","","10.1089/hs.2019.0122","","",,,,,8,4.00,4,2,2,"Rapid developments are currently taking place in the fields of artificial intelligence (AI) and biotechnology, and applications arising from the convergence of these 2 fields are likely to offer immense opportunities that could greatly benefit human health and biosecurity. The combination of AI and biotechnology could potentially lead to breakthroughs in precision medicine, improved biosurveillance, and discovery of novel medical countermeasures as well as facilitate a more effective public health emergency response. However, as is the case with many preceding transformative technologies, new opportunities often present new risks in parallel. Understanding the current and emerging risks at the intersection of AI and biotechnology is crucial for health security specialists and unlikely to be achieved by examining either field in isolation. Uncertainties multiply as technologies merge, showcasing the need to identify robust assessment frameworks that could adequately analyze the risk landscape emerging at the convergence of these 2 domains.This paper explores the criteria needed to assess risks associated with Artificial intelligence and biotechnology and evaluates 3 previously published risk assessment frameworks. After highlighting their strengths and limitations and applying to relevant Artificial intelligence and biotechnology examples, the authors suggest a hybrid framework with recommendations for future approaches to risk assessment for convergent technologies.","",""
7,"Jingguang Han, Yuyun Huang, Shaofeng Liu, Kieran Towey","Artificial intelligence for anti-money laundering: a review and extension",2020,"","","","",88,"2022-07-13 09:37:36","","10.1007/s42521-020-00023-1","","",,,,,7,3.50,2,4,2,"","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",89,"2022-07-13 09:37:36","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",90,"2022-07-13 09:37:36","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
19,"B. Verheij","Artificial intelligence as law",2020,"","","","",91,"2022-07-13 09:37:36","","10.1007/s10506-020-09266-0","","",,,,,19,9.50,19,1,2,"","",""
6,"T. Sammour, S. Bedrikovetski","Radiomics for Diagnosing Lateral Pelvic Lymph Nodes in Rectal Cancer: Artificial Intelligence Enabling Precision Medicine?",2020,"","","","",92,"2022-07-13 09:37:36","","10.1245/s10434-020-08978-6","","",,,,,6,3.00,3,2,2,"","",""
10,"A. Lin, Márton Kolossváry, I. Išgum, P. Maurovich-Horvat, P. Slomka, D. Dey","Artificial intelligence: improving the efficiency of cardiovascular imaging",2020,"","","","",93,"2022-07-13 09:37:36","","10.1080/17434440.2020.1777855","","",,,,,10,5.00,2,6,2,"ABSTRACT Introduction Artificial intelligence (AI) describes the use of computational techniques to mimic human intelligence. In healthcare, this typically involves large medical datasets being used to predict a diagnosis, identify new disease genotypes or phenotypes, or guide treatment strategies. Noninvasive imaging remains a cornerstone for the diagnosis, risk stratification, and management of patients with cardiovascular disease. AI can facilitate every stage of the imaging process, from acquisition and reconstruction, to segmentation, measurement, interpretation, and subsequent clinical pathways. Areas covered In this paper, we review state-of-the-art AI techniques and their current applications in cardiac imaging, and discuss the future role of AI as a precision medicine tool. Expert opinion Cardiovascular medicine is primed for scalable AI applications which can interpret vast amounts of clinical and imaging data in greater depth than ever before. AI-augmented medical systems have the potential to improve workflow and provide reproducible and objective quantitative results which can inform clinical decisions. In the foreseeable future, AI may work in the background of cardiac image analysis software and routine clinical reporting, automatically collecting data and enabling real-time diagnosis and risk stratification.","",""
9,"X. Tian","Application of Artificial Intelligence in Computer Network Technology",2020,"","","","",94,"2022-07-13 09:37:36","","","","",,,,,9,4.50,9,1,2,"with the deepening of science and technology, the original capabilities of computer network technology, such as data operation and word meaning interpretation, have been unable to meet the actual needs of modern users. It has become an inevitable choice for computer network technology to adapt to the development of the times to improve its humanization and intelligence level. Artificial intelligence enables computers to replace human beings to complete more complex work, which can save working time and improve working efficiency. At the same time, it can also promote people to enjoy more intelligent services, realize the innovation and development of science and technology, and promote the long-term sustainable development of society. Therefore, this paper expounds the application of artificial intelligence in computer network technology, and helps people to better understand this measure, providing necessary foundation for the further development of artificial intelligence in the future.","",""
1,"N. Corrêa, N. D. Oliveira","Dynamic Models Applied to Value Learning in Artificial Intelligence",2020,"","","","",95,"2022-07-13 09:37:36","","10.13140/RG.2.2.35369.01126/2","","",,,,,1,0.50,1,2,2,"Experts in Artificial Intelligence (AI) development predict that advances in the development of intelligent systems and agents will reshape vital areas in our society. Nevertheless, if such an advance is not made prudently and critically-reflexively, it can result in negative outcomes for humanity. For this reason, several researchers in the area are trying to develop a robust, beneficial, and safe concept of AI for the preservation of humanity and the environment. Currently, several of the open problems in the field of AI research arise from the difficulty of avoiding unwanted behaviors of intelligent agents and systems, and at the same time specifying what we want such systems to do, especially when we look for the possibility of intelligent agents acting in several domains over the long term. It is of utmost importance that artificial intelligent agents have their values aligned with human values, given the fact that we cannot expect an AI to develop human moral values simply because of its intelligence, as discussed in the Orthogonality Thesis. Perhaps this difficulty comes from the way we are addressing the problem of expressing objectives, values, and ends, using representational cognitive methods. A solution to this problem would be the dynamic approach proposed by Dreyfus, whose phenomenological philosophy shows that the human experience of being-in-the-world in several aspects is not well represented by the symbolic or connectionist cognitive method, especially in regards to the question of learning values. A possible approach to this problem would be to use theoretical models such as SED (situated embodied dynamics) to address the values learning problem in AI.","",""
1,"Alicia Lai","Artificial Intelligence, LLC: Corporate Personhood as Tort Reform",2020,"","","","",96,"2022-07-13 09:37:36","","10.2139/ssrn.3677360","","",,,,,1,0.50,1,1,2,"Our legal system has long tried to fit the square peg of artificial intelligence (AI) technologies into the round hole of the current tort regime, overlooking the inability of traditional liability schemes to address the nuances of how AI technology creates harms. The current tort regime deals out rough justice—using strict liability for some AI products and using the negligence rule for other AI services—both of which are insufficiently tailored to achieve public policy objectives.    Under a strict liability regime where manufacturers are always held liable for the faults of their technology regardless of knowledge or precautionary measures, firms are incentivized to play it safe and stifle innovation. But even with this cautionary stance, the goals of strict liability cannot be met due to the unique nature of AI technology: its mistakes are merely “efficient errors”—they appropriately surpass the human baseline, they are game theory problems intended for a jury, they are necessary to train a robust system, or they are harmless but misclassified.    Under a negligence liability regime where the onus falls entirely on consumers to prove the element of causation, victimized consumers are left without sufficient recourse or compensation. Many critiques have been leveled against the “black-box” nature of algorithms.    This paper proposes a new framework to regulate artificial intelligence technologies: bestowing corporate personhood to AI systems. First, the corporate personality trait of “limited liability” strikes an optimal balance in determining liability—it would both compensate victims (for instance, through obligations to carry insurance and a straightforward burden of causation) while holding manufacturers responsible only when the infraction is egregious (for instance, through veil-piercing). Second, corporate personhood is “divisible”—meaning not all corporate personality traits need to be granted—which circumvents many of the philosophical criticisms of giving AI the complete set of rights of full legal personhood.","",""
1,"Udo Schlegel, E. Cakmak, D. Keim","ModelSpeX: Model Specification Using Explainable Artificial Intelligence Methods",2020,"","","","",97,"2022-07-13 09:37:36","","10.2312/MLVIS.20201100","","",,,,,1,0.50,0,3,2,"Explainable artificial intelligence (XAI) methods aim to reveal the non-transparent decision-making mechanisms of black-box models. The evaluation of insight generated by such XAI methods remains challenging as the applied techniques depend on many factors (e.g., parameters and human interpretation). We propose ModelSpeX, a visual analytics workflow to interactively extract human-centered rule-sets to generate model specifications from black-box models (e.g., neural networks). The workflow enables to reason about the underlying problem, to extract decision rule sets, and to evaluate the suitability of the model for a particular task. An exemplary usage scenario walks an analyst trough the steps of the workflow to show the applicability.","",""
7,"J. Espinoza, Le Thanh Dong","Artificial Intelligence Tools for Refining Lung Cancer Screening",2020,"","","","",98,"2022-07-13 09:37:36","","10.3390/jcm9123860","","",,,,,7,3.50,4,2,2,"Nearly one-quarter of all cancer deaths worldwide are due to lung cancer, making this disease the leading cause of cancer death among both men and women. The most important determinant of survival in lung cancer is the disease stage at diagnosis, thus developing an effective screening method for early diagnosis has been a long-term goal in lung cancer care. In the last decade, and based on the results of large clinical trials, lung cancer screening programs using low-dose computer tomography (LDCT) in high-risk individuals have been implemented in some clinical settings, however, this method has various limitations, especially a high false-positive rate which eventually results in a number of unnecessary diagnostic and therapeutic interventions among the screened subjects. By using complex algorithms and software, artificial intelligence (AI) is capable to emulate human cognition in the analysis, interpretation, and comprehension of complicated data and currently, it is being successfully applied in various healthcare settings. Taking advantage of the ability of AI to quantify information from images, and its superior capability in recognizing complex patterns in images compared to humans, AI has the potential to aid clinicians in the interpretation of LDCT images obtained in the setting of lung cancer screening. In the last decade, several AI models aimed to improve lung cancer detection have been reported. Some algorithms performed equal or even outperformed experienced radiologists in distinguishing benign from malign lung nodules and some of those models improved diagnostic accuracy and decreased the false-positive rate. Here, we discuss recent publications in which AI algorithms are utilized to assess chest computer tomography (CT) scans imaging obtaining in the setting of lung cancer screening.","",""
7,"R. Trasolini, M. Byrne","Artificial intelligence and deep learning for small bowel capsule endoscopy",2020,"","","","",99,"2022-07-13 09:37:36","","10.1111/den.13896","","",,,,,7,3.50,4,2,2,"Capsule endoscopy is ideally suited to artificial intelligence‐based interpretation given its reliance on pattern recognition in still images. Time saving viewing modes and lesion detection features currently available rely on machine learning algorithms, a form of artificial intelligence. Current software necessitates close human supervision given poor sensitivity relative to an expert reader. However, with the advent of deep learning, artificial intelligence is becoming increasingly reliable and will be increasingly relied upon. We review the major advances in artificial intelligence for capsule endoscopy in recent publications and briefly review artificial intelligence development for historical understanding. Importantly, recent advancements in artificial intelligence have not yet been incorporated into practice and it is immature to judge the potential of this technology based on current platforms. Remaining regulatory and standardization hurdles are being overcome and artificial intelligence‐based clinical applications are likely to proliferate rapidly.","",""
0,"Shanqi Pang Dr, Yongmei Li Prof","Artificial Intelligence Techniques for Cyber Security Applications",2020,"","","","",100,"2022-07-13 09:37:36","","10.46532/ijaict-2020021","","",,,,,0,0.00,0,2,2,"Considering the enhancement in technology, criminals have been using cyberspace in order to commit many crimes. Therefore, it should be noted that cybercrimes are exposed to a number of threats and intrusions if not safeguarded well. Human and physical intervention tend not to be very adequate for the protection and tracking of such infrastructure, that is why there should be the establishment of multifaceted cyber defense networks, which are flexible, robust, and adjustable in order sense a massive collection of invasion and creation of real-time choices. Nevertheless, significant number of bio-related computing techniques of AI (artificial intelligence) tend to be increasing hence a significant role is played in detecting and preventing cybercrime. The main aim of this paper is outlining the actual advancement that have been made possible due to the application of AI methods for the fight against cybercrimes, in order to reveal how the methods are efficient in sensing and preventing cyber invasions, also providing a brief overview of the future works. Keywords— Computational intelligence, Artificial Intelligence, Intrusion detection and prevention systems, Cyber crime","",""
0,"K. Shrivastav, N. Taneja, P. Arambam, Vandana Bhatia, S. Batra, Harpreet Singh, E. Abed, P. Ranjan, Rajiv Janardhanan∗h","An Artificial Intelligence Enabled Multimedia Tool for Rapid Screening of Cervical Cancer",2020,"","","","",101,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,9,2,"Cervical cancer is a major public health challenge. Further mitigation of cervical cancer can greatly benefit from development of innovative and disruptive technologies for its rapid screening and early detection. The primary objective of this study is to contribute to this aim through large scale screening by development of Artificial Intelligence enabled Intelligent Systems as they can support human cancer experts in making more precise and timely diagnosis. Our current study is focused on development of a robust and interactive algorithm for analysis of colposcope-derived images analysis and a diagnostic tool/scale namely the OMThe Onco-Meter. This tool was trained and tested on 300 InEmail addresses: kdshrivastav@amity.edu (Kumar Dron Shrivastav), ntaneja@amity.edu (Neha Taneja), priyadarshini@batrahospitaldelhi.org (Priyadarshini Arambam), vbhatia2@amity.edu (Vandana Bhatia), shelly.batra@opasha.org (Shelly Batra), crbhmrc1@batrahospitaldelhi.org (Shelly Batra), hsingh@bmi.icmr.org.in (Harpreet Singh), abed@isr.umd.edu (Eyad H. Abed), ranjan.p@srmap.edu.in (Priya Ranjan), rjanardhanan@amity.edu (Rajiv Janardhanan∗) Preprint submitted to The Lancet Digital Health June 1, 2020 dian subjects/patients yielding 77% accuracy with a sensitivity of 83.56% and a specificity of 59.25%. OM-The Oncometer is capable of classifying cervigrams into cervical dysplasia, carcinoma in− situ (CIS) and invasive cancer(IC). Programming language R has been used to implement and compute earth mover distances (EMD) to characterize different diseases labels associated with cervical cancer, computationally. Deployment of automated tools will facilitate early diagnosis in a noninvasive manner leading to a timely clinical intervention for cervical cancer patients upon detection at a Primary Health Care (PHC).The tool developed in this study will aid clinicians to design timely intervention strategies aimed at improving the clinical prognosis of patients.","",""
6,"Andreas Holzinger, R. Goebel, M. Mengel, Heimo Müller, Yuzuru Tanaka","Artificial Intelligence and Machine Learning for Digital Pathology: State-of-the-Art and Future Challenges",2020,"","","","",102,"2022-07-13 09:37:36","","10.1007/978-3-030-50402-1","","",,,,,6,3.00,1,5,2,"","",""
3,"Baseer Ahmad, Judy E. Kim, E. Rahimy","Fundamentals of artificial intelligence for ophthalmologists.",2020,"","","","",103,"2022-07-13 09:37:36","","10.1097/ICU.0000000000000679","","",,,,,3,1.50,1,3,2,"PURPOSE OF REVIEW As artificial intelligence continues to develop new applications in ophthalmic image recognition, we provide here an introduction for ophthalmologists and a primer on the mechanisms of deep learning systems.   RECENT FINDINGS Deep learning has lent itself to the automated interpretation of various retinal imaging modalities, including fundus photography and optical coherence tomography. Convolutional neural networks (CNN) represent the primary class of deep neural networks applied to these image analyses. These have been configured to aid in the detection of diabetes retinopathy, AMD, retinal detachment, glaucoma, and ROP, among other ocular disorders. Predictive models for retinal disease prognosis and treatment are also being validated.   SUMMARY Deep learning systems have begun to demonstrate a reliable level of diagnostic accuracy equal or better to human graders for narrow image recognition tasks. However, challenges regarding the use of deep learning systems in ophthalmology remain. These include trust of unsupervised learning systems and the limited ability to recognize broad ranges of disorders.","",""
4,"P. Regitnig, Heimo Müller, Andreas Holzinger","Expectations of Artificial Intelligence for Pathology",2020,"","","","",104,"2022-07-13 09:37:36","","10.1007/978-3-030-50402-1_1","","",,,,,4,2.00,1,3,2,"","",""
2,"R. Stidham","Artificial Intelligence for Understanding Imaging, Text, and Data in Gastroenterology.",2020,"","","","",105,"2022-07-13 09:37:36","","","","",,,,,2,1.00,2,1,2,"Artificial intelligence (AI) could change the practice of gastroenterology through its ability to both acquire and analyze information with speed, reproducibility, and, potentially, insight that may exceed that of human medical specialists. AI is powered by computational methods that allow machines to replicate clinical pattern recognition used by gastroenterology specialists to interpret endoscopic or cross-sectional images; understand the meaning and intent of medical documents; and merge different types of data to infer a diagnosis, prognosis, or expected outcome. Ongoing research is studying the use of AI for automated interpretation of text from colonoscopy and clinical documents for improved quality and patient phenotyping as well as enhanced detection and descriptions of polyps and other endoscopic lesions, and for predicting the probability of future therapeutic response early in a treatment course. This article introduces emerging technologies of natural language processing, machine vision, and machine learning for data analytics, and describes current and future applications in gastroenterology.","",""
1,"H. K. Ha","Editorial for “Deep‐Learning‐Based Artificial Intelligence for PI‐RADS Classification to Assist Multiparametric Prostate MRI Interpretation: A Development Study”",2020,"","","","",106,"2022-07-13 09:37:36","","10.1002/jmri.27254","","",,,,,1,0.50,1,1,2,"Many methodological changes for diagnosing prostate cancer, including prostate-specific antigen, digital rectal examination, prostate ultrasonography, and magnetic resonance imaging (MRI), have evolved over the past decades, of which multiparametric (mp)MRI is clinically considered the most useful diagnostic modality to detect clinically significant prostate cancer. Accordingly, the European and American Urologic Association recommend MRI before biopsy, regardless of whether a previous prostate biopsy is conducted or not. However, before the introduction of the Prostate Imaging-Reporting and Data System (PI-RADS), the implementation and interpretation of MRI was inconsistent among institutions, and these problems began to be resolved with the introduction of PI-RADS to establish standardization in prostate mpMRI acquisition, interpretation, and reporting in 2012. In 2019, we reported the promising data of diagnostic accuracy of mpMRI with the final pathology findings for radical prostatectomy specimens in detection of prostate cancer. In this study, the sensitivity, specificity, and negative predictive value of mpMRI with PI-RADS was 75.5%, 77.0%, and 79.8% for clinically significant cancer, and 75.7%, 77.7%, and 79.5%, for pathological index tumors, respectively. Based on a meta-analysis of 21 studies (3857 patients) concerning the diagnostic performance of PI-RADS, Woo et al reported a pooled sensitivity and specificity of 0.89 (95% confidence interval [CI] 0.86–0.92) and 0.73 (95% CI 0.60–0.83), respectively. However, some studies have reported relatively poor correlation between the prostate cancer detection rate in PI-RADS 5 lesions (86.9%) and only 39.1% for category 4 lesions. This difference seems to be due to the interreader reading, which can be inferred from single-center studies and experienced radiologists generally report higher interreader agreement than multi-institution results with radiologists having variable experience levels. Recently, an interesting study suggested that even experienced radiologists showed only moderate reproducibility. This heterogeneity in the current studies result from mainly human interpretation because image acquisition and tissue confirmation are somewhat standardized now. In this issue of JMRI, Sanford et al report on the clinical application of deep-learning-based artificial intelligence (AI) for PI-RADS classifications to assist mpMRI. They introduced a deep-learning-based image classification AI system that assigns a PI-RADS score to a lesion detected and segmented by a radiologist and showed that the cancer detection rate of deep-learning-based AI was similar to an expert radiologist in classification of PI-RADS. There are some limitations to this study. First, the agreement of the AI system with the expert radiologist was only moderate (kappa 0.40), even if the expert’s analysis is not perfect. Another limitation is they did not compare the AI results with the whole-prostate mapping, because sample error should always be considered when a prostate biopsy was done. Recently, AI-based techniques have been established by examining a large number of medical images (called “radiomics”) as a possible alternative to traditional “human” interpretation and many applications of AI-based methods have been published for cancer diagnostics. However, the optimal use of AI in clinical practice, especially for detection of prostate cancer, is still ongoing. In order for AI to achieve a clear field of diagnosis, a well-organized, prospective study with a large number of patients in collaboration with radiologists, pathologists, and urologists is required.","",""
423,"Andreas Holzinger, G. Langs, H. Denk, K. Zatloukal, Heimo Müller","Causability and explainability of artificial intelligence in medicine",2019,"","","","",107,"2022-07-13 09:37:36","","10.1002/widm.1312","","",,,,,423,141.00,85,5,3,"Explainable artificial intelligence (AI) is attracting much interest in medicine. Technically, the problem of explainability is as old as AI itself and classic AI represented comprehensible retraceable approaches. However, their weakness was in dealing with uncertainties of the real world. Through the introduction of probabilistic learning, applications became increasingly successful, but increasingly opaque. Explainable AI deals with the implementation of transparency and traceability of statistical black‐box machine learning methods, particularly deep learning (DL). We argue that there is a need to go beyond explainable AI. To reach a level of explainable medicine we need causability. In the same way that usability encompasses measurements for the quality of use, causability encompasses measurements for the quality of explanations. In this article, we provide some necessary definitions to discriminate between explainability and causability as well as a use‐case of DL interpretation and of human explanation in histopathology. The main contribution of this article is the notion of causability, which is differentiated from explainability in that causability is a property of a person, while explainability is a property of a system","",""
19,"P. Sengupta, D. Adjeroh","Will Artificial Intelligence Replace the Human Echocardiographer?: Clinical Considerations",2018,"","","","",108,"2022-07-13 09:37:36","","10.1161/CIRCULATIONAHA.118.037095","","",,,,,19,4.75,10,2,4,"An older population with an increased prevalence of cardiovascular disease and an aging workforce are engendering a state of healthcare crisis in cardiology.1 Most cardiologists now face an unprecedented time crunch as they rush through their appointments to perform and interpret more and more procedures. The need to multitask creates exhaustion leading to burnout and frequent reporting errors.2 The recent interest in using artificial intelligence techniques, such as machine learning, may offer a solution to reduce physician workload including repetitive and tedious tasks involved in diagnosing and analyzing patient data and imaging. To this end, the study by Zhang and colleagues3 in this issue of Circulation adds to the growing enthusiasm for developing a machine learning algorithm that automates several facets of echocardiography measurement and interpretation. Zhang and colleagues used a deep learning model that has enjoyed spectacular success in addressing computer vision problems including image classification, face recognition, robot navigation, and driverless cars to name a few. Although traditional machine learning workflow includes an initial stage of feature engineering and selection from the data for classification, deep learning methods attempt to learn the important features directly from the raw image data (with minimal preprocessing). Zhang and colleagues applied an algorithm that has triumphed in image recognition tasks and reported a 96% accuracy for distinguishing between broad echocardiographic view classes (eg, parasternal long axis from short axis, or an apical view) and an 84% accuracy overall (including partially obscured views). These results are consistent with a recent study that applied deep learning with convolutional neural networks for view classification of echocardiograms.4 However, Zhang et al notably used a deeper architecture with more layers (18 versus 11), considered a larger number of echocardiography view classes (23 versus 15 views), and applied their technique to a larger data set (14 035 versus 267 echocardiographic studies). The authors also reported an overall metric of accuracy of image segmentation ranging from 72% to 90% for image segmentation. Although deep learning has been explored previously for segmenting the left ventricle,5 the work by Zhang et al was much more extensive with additional cardiac segments beyond the left ventricle and a larger data set, involving millions of images from 14 035 studies. Moreover, the authors succeeded in going a step beyond simple classification and segmentation by providing an algorithm for automated quantification of cardiac structure and function. The comparison with manually recorded measurements, however, showed wide limits of agreements emphasizing the potential real-world variability of echocardiography measurements. Independent verification from a core laboratory or the use of a gold standard like cardiac magnetic resonance was © 2018 American Heart Association, Inc.","",""
1,"I. Suleimenov, Y. Vitulyova, A. Bakirov, O. Gabrielyan","Artificial Intelligence: what is it?",2020,"","","","",109,"2022-07-13 09:37:36","","10.1145/3397125.3397141","","",,,,,1,0.50,0,4,2,"Based on the principle of dialectic symmetry formulated by the philosophy of dialectic positivism, an interpretation of the concept of ""artificial intelligence"" is proposed. This principle assumes the existence of a hierarchy of information objects, similar to the hierarchy, which reflects different levels of organization of matter (mechanical, chemical, biological, social). The construction of a hierarchy of information objects - information processing systems - allows us to interpret in the same way the essence of both artificial intelligence and the intelligence that a human being is endowed with. These are information processing systems referring to the highest levels of the specified hierarchy.","",""
14,"Derek J. Van Booven, M. Kuchakulla, Raghav Pai, F. Frech, Reshna Ramasahayam, P. Reddy, M. Parmar, R. Ramasamy, H. Arora","A Systematic Review of Artificial Intelligence in Prostate Cancer",2021,"","","","",110,"2022-07-13 09:37:36","","10.2147/RRU.S268596","","",,,,,14,14.00,2,9,1,"Abstract The diagnosis and management of prostate cancer involves the interpretation of data from multiple modalities to aid in decision making. Tools like PSA levels, MRI guided biopsies, genomic biomarkers, and Gleason grading are used to diagnose, risk stratify, and then monitor patients during respective follow-ups. Nevertheless, diagnosis tracking and subsequent risk stratification often lend itself to significant subjectivity. Artificial intelligence (AI) can allow clinicians to recognize difficult relationships and manage enormous data sets, which is a task that is both extraordinarily difficult and time consuming for humans. By using AI algorithms and reducing the level of subjectivity, it is possible to use fewer resources while improving the overall efficiency and accuracy in prostate cancer diagnosis and management. Thus, this systematic review focuses on analyzing advancements in AI-based artificial neural networks (ANN) and their current role in prostate cancer diagnosis and management.","",""
9,"J. Sung, C. Stewart, B. Freedman","Artificial intelligence in health care: preparing for the fifth Industrial Revolution",2020,"","","","",111,"2022-07-13 09:37:36","","10.5694/mja2.50755","","",,,,,9,4.50,3,3,2,"AI comprises any digital system “that mimics human reasoning capabilities, including pattern recognition, abstract reasoning and planning”.1 It includes the concept of machine learning, where machines are able to learn from experience in ways that mimic human behaviour, but with the ability to assimilate much more data and with potential for greater accuracy and speed. Machine learning is a research field that has seen recent advances due to exponential increases in computing power (a phenomenon known as Moore’s law), algorithmic coding that mimics the human cognitive process (deep learning), and access to large, linked sources of big data. The scope of AI can be specific, performing narrowly defined tasks (narrow AI) such as image interpretation, or more general, applying knowledge and skills in different contexts (general AI) such as making a diagnosis and predicting disease outcome. On the other hand, machine learning can also be designated “supervised”, in which a dataset is provided for the algorithm to evaluate its performance, or “unsupervised”, in which the machine is allowed to extract unknown potential features in developing an algorithm.","",""
2,"B. Nair, Yakov Diskin, V. Asari","Multi-modal low cost mobile indoor surveillance system on the Robust Artificial Intelligence-based Defense Electro Robot (RAIDER)",2012,"","","","",112,"2022-07-13 09:37:36","","10.1117/12.930353","","",,,,,2,0.20,1,3,10,"We present an autonomous system capable of performing security check routines. The surveillance machine, the Clearpath Husky robotic platform, is equipped with three IP cameras with different orientations for the surveillance tasks of face recognition, human activity recognition, autonomous navigation and 3D reconstruction of its environment. Combining the computer vision algorithms onto a robotic machine has given birth to the Robust Artificial Intelligencebased Defense Electro-Robot (RAIDER). The end purpose of the RAIDER is to conduct a patrolling routine on a single floor of a building several times a day. As the RAIDER travels down the corridors off-line algorithms use two of the RAIDER's side mounted cameras to perform a 3D reconstruction from monocular vision technique that updates a 3D model to the most current state of the indoor environment. Using frames from the front mounted camera, positioned at the human eye level, the system performs face recognition with real time training of unknown subjects. Human activity recognition algorithm will also be implemented in which each detected person is assigned to a set of action classes picked to classify ordinary and harmful student activities in a hallway setting.The system is designed to detect changes and irregularities within an environment as well as familiarize with regular faces and actions to distinguish potentially dangerous behavior. In this paper, we present the various algorithms and their modifications which when implemented on the RAIDER serves the purpose of indoor surveillance.","",""
3,"E. Sala, Stephan Ursprung","Artificial Intelligence in Radiology: The Computer's Helping Hand Needs Guidance.",2020,"","","","",113,"2022-07-13 09:37:36","","10.1148/ryai.2020200207","","",,,,,3,1.50,2,2,2,"A intelligence (AI) is not entirely new to the medical field. We are accustomed to applying tools that have been developed with a varying degree of human and computer input in our clinical practice. Representative examples include handcrafted diagnostic algorithms to triage patients presenting with acute illness (1), statistically derived scores for osteoporotic fracture risk assessment (2), and decision trees for the differentiation of benign and malignant ovarian masses (3). Common to all these tools is that changes to input parameters lead to predictable changes in model output, making them easy to interrogate and understand. More sophisticated, deep learning (DL)–based models employed in decision support systems have been implemented in clinical practice for the automated interpretation of electrocardiograms (4) and detection and classification of lesions on mammography (5). Although DL-based models have exciting potential to solve complex problems, their black box approach faces skepticism despite advances in interpretability and explainability (6). The recent, widespread availability of hardware and software for the development of AI solutions for medicine has inspired an exponential increase in publications. Data-rich medical specialties such as radiology have become a particular focus of rapid development. However, there are ample scope and encouraging initiatives for AI to support the delivery of care from general practice, primary care, the emergency department, and specialist diagnostics to patient self-care (7). This study by Tadavarthi and colleagues (8) has examined the market of AI-enabled image analysis solutions for radiology and provides recommendations for the evaluation of AI tools before purchase. In their market study, the authors illustrate how most solutions are focused on highvolume conditions. Unsurprisingly, many solutions focus on support for lesion detection and quantification rather than decision support for diagnosis and recommendations for management where regulatory stakes and hurdles are higher. Yet only a minority of solutions advertised at the Radiological Society of North America and Society of Imaging Informatics in Medicine annual meetings between November 2016 and June 2019 have received approval for the American or European market. This finding is indicative of a rapidly developing field where, after years of purely scientific development, the first tools start undergoing consolidation, approval, and marketing. The sole focus on solutions advertised at North American conferences risks missing tools by smaller companies with lower marketing budgets and introducing a geographic bias. Indeed, several other solutions have achieved Conformité Européenne marking or U.S. Food and Drug Administration (FDA) approval. Such approval or their equivalent in other territories is a precondition for the implementation of products, but it is by no means sufficient to identify clinically beneficial and financially viable tools. Overall, the adoption of these algorithms into clinical practice is emerging, and further work is needed to transform the scientific enthusiasm for developing advanced AI tools with a broader scope into clinically workable solutions. For tracking the ongoing market, surveys like this study (dating from November 2019) date quickly, leaving a gap for a living review and other market watchers. Tadavarthi et al contribute to a growing number of recommendations for the acquisition and adoption of AI solutions in medicine with a particular focus on radiology (9). They raise important considerations to determine whether an AI tool is a viable solution for an individual service. In addition, one might want to consider the following criteria: Artificial Intelligence in Radiology: The Computer’s Helping Hand Needs Guidance","",""
1,"A. Waheed, A. K, H. M","ASSESSING THE ROLE OF ARTIFICIAL INTELLIGENCE IN THE DESIGN OF DRUG DELIVERY SYSTEMS",2020,"","","","",114,"2022-07-13 09:37:36","","10.32553/ijmsdr.v4i12.725","","",,,,,1,0.50,0,3,2,"Over ten years, increasing the interest has been fascinated towards the appeal of intelligent retrieval (IR) technology for data interpretation and illuminate the biological or transmitted information, speed up drug invention, and pinpointing of the selective small-molecule modulator control or rare particle and projection of their behavior. To make use of biomaterials, synthetic resin, fats, along IR is upcoming for the manufacture of drug deliverables. The request of the computerized workflows and databases for quick calculation of the vast amounts of data and artificial neural networks (ANNs) for growth of the narrative proposition and treatment schemes, forecast of disease development, and judgment of the pharmacological description of drug candidates may consequently improve treatment outcomes. Target fishing (TG) by quick projection or identification of the biological quarry might be of great help for linking quarry to the new substance.AI and TF methods in union with human knowledge may indeed transform the present-day diagnostic strategies, meanwhile verifying approaches are necessary to overcome the possible challenges and make certain higher perfection. In this review, the importance of AI and TF in the growth of drugs and transport systems and the possible challenging topics have been spotlighted.","",""
1,"Giampaolo Collecchia","[Human and artificial intelligence: comparison and clash of cultures].",2018,"","","","",115,"2022-07-13 09:37:36","","10.1702/3080.30726","","",,,,,1,0.25,1,1,4,". Human and artificial intelligence: comparison and clash of cultures. Machine learning has become ubiquitous and indispensible for solving complex problems in most sciences. As patients' conditions and medical technologies become more complex, its role will continue to grow. However the risk is of over reliance on these systems: no amount of algorithmic finesse or computing power can squeeze out information that is not present. In fact, clinical data alone have relatively limited predictive power for hospital readmissions that may have more to do with social determinants of health. Combining machine-learning software with the clinical judgement and a wise interpretation of information from health care professionals will help to increase the integration between digital world and real practice.","",""
167,"C. Langlotz, Bibb Allen, B. Erickson, Jayashree Kalpathy-Cramer, K. Bigelow, T. Cook, A. Flanders, M. Lungren, D. Mendelson, J. Rudie, Ge Wang, K. Kandarpa","A Roadmap for Foundational Research on Artificial Intelligence in Medical Imaging: From the 2018 NIH/RSNA/ACR/The Academy Workshop.",2019,"","","","",116,"2022-07-13 09:37:36","","10.1148/radiol.2019190613","","",,,,,167,55.67,17,12,3,"Imaging research laboratories are rapidly creating machine learning systems that achieve expert human performance using open-source methods and tools. These artificial intelligence systems are being developed to improve medical image reconstruction, noise reduction, quality assurance, triage, segmentation, computer-aided detection, computer-aided classification, and radiogenomics. In August 2018, a meeting was held in Bethesda, Maryland, at the National Institutes of Health to discuss the current state of the art and knowledge gaps and to develop a roadmap for future research initiatives. Key research priorities include: 1, new image reconstruction methods that efficiently produce images suitable for human interpretation from source data; 2, automated image labeling and annotation methods, including information extraction from the imaging report, electronic phenotyping, and prospective structured image reporting; 3, new machine learning methods for clinical imaging data, such as tailored, pretrained model architectures, and federated machine learning methods; 4, machine learning methods that can explain the advice they provide to human users (so-called explainable artificial intelligence); and 5, validated methods for image de-identification and data sharing to facilitate wide availability of clinical imaging data sets. This research roadmap is intended to identify and prioritize these needs for academic research laboratories, funding agencies, professional societies, and industry.","",""
0,"N. Rafie, J. Jentzer, P. Noseworthy, A. Kashou","Mortality Prediction in Cardiac Intensive Care Unit Patients: A Systematic Review of Existing and Artificial Intelligence Augmented Approaches",2022,"","","","",117,"2022-07-13 09:37:36","","10.3389/frai.2022.876007","","",,,,,0,0.00,0,4,1,"The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient's clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.","",""
47,"T. Phong, Trong Trinh Phan, Indra Prakash, S. Singh, A. Shirzadi, K. Chapi, H. Ly, Lanh Si Ho, Nguyen Kim Quoc, B. Pham","Landslide susceptibility modeling using different artificial intelligence methods: a case study at Muong Lay district, Vietnam",2019,"","","","",118,"2022-07-13 09:37:36","","10.1080/10106049.2019.1665715","","",,,,,47,15.67,5,10,3,"Abstract Landslide is a natural hazard which causes huge loss of properties and human life in many places of the world. Mapping of landslide susceptibility is an important task for preventing and combating the landslides problems. Main objective of this study is to use different artificial intelligence methods namely support vector machines (SVM), artificial neural networks (ANN), logistic regression (LR), and reduced error-pruning tree (REPT) in the development of models for landslide susceptibility mapping of Muong Lay district of Vietnam. In total data of 217 landslide locations of the study area was used for the development and evaluation of the models. Nine landslide-conditioning factors were used for generating the datasets for training and validating the models. Results show that the SVM outperformed all other methods namely ANN, LR and REPT. Thus, it can be suggested that the SVM method is more useful in developing accurate and robust landslide prediction model.","",""
0,"E. Nikitos, T. Triantafillou, K. Dimitropoulos, V. Kallergi, P. Psathas, I. Erlich, A. Ben-Meir, N. Bergelson","P-271 Challenges with comparing different commercially available Artificial Intelligence (AI) systems on the same data set of time-lapse selected euploid blastocysts",2022,"","","","",119,"2022-07-13 09:37:36","","10.1093/humrep/deac107.260","","",,,,,0,0.00,0,8,1,"      To identify challenges in choosing a robust AI following comparative validation with data already pre-selected with established embryos selection tools: blastulation, morphology, time-lapse, PGTA.        Challenges included: bias; assessment against outcomes AI models were not trained on; performance metrics prioritisation; statistical methodology; continuous data cutoffs for binary clinical decision making.        AI is commercially available to be incorporated into routine practice to support embryo selection decision-making. Different clinical practices and demographics are used to train AI models, potentially impacting the prediction efficacy of the same model when used in different clinics. Fertility professionals require robust methods of validation to responsibly implement AI-based tools. Unbiased and robust frameworks for comparing AI systems in the same dataset are needed. Validating AI in a dataset of time-lapse selected euploid blastocysts using all the current methods of embryo selection currently available is the toughest assessment possible and has not previously been performed.        This study uses a retrospectively timelapse dataset collected from 2018-2021 at a single private fertility clinic. The dataset included 915 blastocysts which underwent PGTA (913 results: 381 euploids, 528 aneuploids, 4 mosaics) and 46 euploids transferred with known bhcg and ongoing clinical outcome (of which 40 resulted to live birth).  Following a prospective, comparative, observational, cohort study design, blastocysts were blindly scored using the CHLOE(FAIRTILITY) and another commercially available AI system, referred to as ‘AI-2’.        Patients aged 24-47years (average 35.4). Blastocysts selected for biopsy and transfer based on morphology and KIDScore(Vitrolife). Both AI systems were tested in the data set blindly, without any training. Correlation Regression analysis assessed correlation with KIDSCORE and relative to each AI system. Efficacy of prediction (using metrics AUC, Accuracy, Sensitivity, Specificity and Informedness) of outcomes (ploidy, biochemical and clinical pregnancy) were assessed for both AI models (CHLOEvsAI-2) by two independent statisticians to establish significance.        Regression analysis demonstrated no correlation between KIDSCORE and AI-2(r2=0.3%,p=0.5) or between CHLOE(FAIRTILITY) and AI-2(r2=0.03%,p=0.9). CHLOE(FAIRTILITY) correlated with KIDSCORE(r2=29%,p<0.001).  AI-2 was not predictive of ploidy (Euploids vs Aneuploids+mosaic: AUC=0.5,p=0.6). CHLOE(Fairtility) was predictive of ploidy(AUC=0.66, p<0.001).  Neither AI-2 or CHLOE(Fairtility) predicted which embryo the human embryologist prioritised for transfer (AI-2 vs CHLOE:accuracy:0.31vs0.49, p<0.00001). Neither AI-2 nor CHLOE(Fairtility) predicted which embryo the human embryologist prioritised for transfer (AI-2 vs CHLOE:accuracy: 0.31vs0.49, p<0.00001). There was no difference detected in efficacy of prediction of biochemical (accuracy:0.52vs0.67,NS) and ongoing clinical pregnancy (accuracy:0.53 vs 0.78,NS) by AI-2 or CHLOE. This is partly due to the low number of euploid transfers assessed (n = 46), and partly due to the fact that neither of these algorithms are trained specifically on predicting outcome of euploid transfers.  CHLOE(Fairtility) was more specific than AI-2 for predicting selection for transfer(0.44/0.80vs0.17/0.93,p<0.05/NS) and ploidy(0.54/0.77vs0.23/0.87,p<0.05/NS), and they were equally as sensitive. CHLOE(Fairtility) was more sensitive, and less specific than AI-2 for predicting biochemical pregnancy(0.36/0.81vs0.86/0.38,p<0.05) and more sensitive but equally as specific for predicting clinical pregnancy(0.33/0.88vs0.83/0.46,NS/p<0.05).  Informedness was positive for both CHLOE(Fairtility) and AI-2 in predicting all outcomes assessed. Informedness was greater for AI-2 for predicting morphology(AI-2vsCHLOE:0.16vs0.31,p<0.05), transfer(0.11vs0.24,p<0.05), ploidy(0.10vs0.31,p<0.05) and equivalent for predicting biochemical (0.23vs0.17,NS) and clinical pregnancy(0.29vs0.22,NS).        In this single clinic study, both algorithms were assessed against outcomes (live birth following transfer of time-lapse cultured euploid blastocysts) for which they were not trained on: AI-2(designed for ploidy prediction) and CHLOE(FAIRTILITY, implantation prediction of non-PGTA embryos) and no clinic data was used for training.        The only way to decide which AI model is more useful is by a direct comparison of two or more models on the same dataset with same outcomes and metrics, as recommended by TRIPOD. To date, this is the first publication comparing multiple commercial AI models on the same dataset.        NA ","",""
10,"A. C. Horta, A. Silva, C. Sargo, V. M. Gonçalves, T. C. Zangirolami, Roberto Campos Giordano","Robust artificial intelligence tool for automatic start-up of the supplementary medium feeding in recombinant E. coli cultivations",2011,"","","","",120,"2022-07-13 09:37:36","","10.1007/s00449-011-0540-0","","",,,,,10,0.91,2,6,11,"","",""
8,"Imran Ahmed, Gwanggil Jeon, F. Piccialli","From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where",2022,"","","","",121,"2022-07-13 09:37:36","","10.1109/tii.2022.3146552","","",,,,,8,8.00,3,3,1,"Nowadays, Industry 4.0 can be considered a reality, a paradigm integrating modern technologies and innovations. Artificial intelligence (AI) can be considered the leading component of the industrial transformation enabling intelligent machines to execute tasks autonomously such as self-monitoring, interpretation, diagnosis, and analysis. AI-based methodologies (especially machine learning and deep learning support manufacturers and industries in predicting their maintenance needs and reducing downtime. Explainable artificial intelligence (XAI) studies and designs approaches, algorithms and tools producing human-understandable explanations of AI-based systems information and decisions. This article presents a comprehensive survey of AI and XAI-based methods adopted in the Industry 4.0 scenario. First, we briefly discuss different technologies enabling Industry 4.0. Then, we present an in-depth investigation of the main methods used in the literature: we also provide the details of what, how, why, and where these methods have been applied for Industry 4.0. Furthermore, we illustrate the opportunities and challenges that elicit future research directions toward responsible or human-centric AI and XAI systems, essential for adopting high-stakes industry applications.","",""
1,"A. Admin, Dr.P Dr.P.Kavitha2, A. Akshaya, P. P.Shalin, R. R.Ramya","A Survey on Cyber Security Meets Artificial Intelligence: AI– Driven Cyber Security",2022,"","","","",122,"2022-07-13 09:37:36","","10.54216/jchci.020202","","",,,,,1,1.00,0,5,1,"The computerized version of human intelligence is Artificial Intelligence(AI). Artificial Intelligence systems combine large sets of data with intelligent and iterative processing algorithms in order to make predictions, based on patterns and features in the data that they analyse. With the booming technologies such as IOT and Cloud Computing, huge amounts of data are generated and collected that require cyber security protection today. There is a growing need for cyber security methods which are both robust and intelligent due to the ever-increasing complexity of cyber crimes. While data can be used to benefit business interests, it poses a number of challenges in terms of security and privacy protection. Artificial Intelligence (AI) based technologies, such as machine learning statistics, big data analysis, deep learning and so on, have been used to deal with cyber security threats. These technologies are used for intrusion detection systems, malicious software detection, and encrypted communications. In the rapidly growing field of AI driven security, scientists from multiple disciplines work together to combat cyber threats. AI models require unique cyber security defence and protection technologies. This survey provides various method, different datasets and methodologies that may be used for the proposed IA enabled cyber security technologies. This study aims to classify the AI-based cyber security solutions gathered and describe how they can help solve problems in the field of cyber security.","",""
0,"A. Sau, S. Ibrahim, A. Ahmed, B. Handa, DB Kramer, JW Waks, A. Arnold, Jph Howard, D. Mandic, N. Peters, F. Ng","Classification of organised atrial arrythmias using explainable artificial intelligence",2022,"","","","",123,"2022-07-13 09:37:36","","10.1093/europace/euac053.557","","",,,,,0,0.00,0,11,1,"      Type of funding sources: Public grant(s) – National budget only. Main funding source(s): BHF  NIHR        Accurately determining atrial arrhythmia mechanisms from a 12-lead ECG can be challenging. Given the high success rate of cavotricuspid isthmus (CTI) ablation, accurate identification of CTI-dependent typical atrial flutter (AFL) is important for treatment decisions and procedure planning. Machine learning, with convolutional neural networks (CNNs) in particular, has been used to classify arrhythmias using the 12-lead ECG with great accuracy. However, most studies use human interpretation of the ECG as the ground truth to label the arrhythmia ECGs. Therefore, these neural networks can only ever be as good as expert human interpretation. We hypothesised a convolutional neural network could be trained to match or even exceed expert human performance in classifying CTI-dependent AFL vs. non-CTI dependent atrial tachycardia (AT), when using findings from the invasive electrophysiology (EP) study as the gold standard.        Figure 1 summarises the study methodology. We trained a CNN on data from 231 patients undergoing EP studies for atrial tachyarrhythmia. A total of 13500 5-second 12-lead ECG segments were used for training. Each case was labelled CTI-dependent AFL or non-CTI dependent AT based on the findings of the EP study. The model performance was evaluated against a test set of 57 patients. A survey of electrophysiologists and cardiologists in Europe was undertaken on the same 57 ECGs.        The model had an accuracy of 86% (95% CI 0.77-0.95). The F1 score was 0.87.The AT/AFL network correctly identified AT 82% and AFL 90% of the time.  A saliency map can be used to help understand why a CNN predicted a particular outcome. This is achieved by mapping the outcome back to key areas of the input that most influenced the network in producing the classification result. Figure 2 presents the saliency mappings of an example 12-lead ECG for each class of AFL and AT. The network used the expected sections of the ECGs for diagnoses; these were the P-wave segments and not the QRS or other unexpected segments.  There were twelve respondents in the clinician survey. These respondents included nine electrophysiologists. The median accuracy was 78% (range 70-86%). The electrophysiologists had a median accuracy of 79%, (range 70-84%). Humans were more likely to incorrectly diagnose AFL as AT (on average incorrect diagnoses: 9 AFL, 1 AT). In comparison, the neural network most often incorrectly diagnosed AT as AFL (incorrect diagnoses: 5 AT, 3 AFL).        We describe the first neural network trained to differentiate CTI-dependent AFL from other atrial tachycardias. We found that our model surpassed expert human performance. Automated artificial intelligence enhanced ECG analysis could help guide treatment decisions and plan ablation procedures for patients with organised atrial arrhythmias. ","",""
10,"David A. Broniatowski","Psychological Foundations of Explainability and Interpretability in Artificial Intelligence",2021,"","","","",124,"2022-07-13 09:37:36","","10.6028/NIST.IR.8367","","",,,,,10,10.00,10,1,1,"In this paper, we make the case that interpretability and explainability are distinct requirements for machine learning systems. To make this case, we provide an overview of the literature in experimental psychology pertaining to interpretation (especially of numerical stimuli) and comprehension. We find that interpretation refers to the ability to contextualize a model’s output in a manner that relates it to the system’s designed functional purpose, and the goals, values, and preferences of end users. In contrast, explanation refers to the ability to accurately describe the mechanism, or implementation, that led to an algorithm’s output, often so that the algorithm can be improved in some way. Beyond these definitions, our review shows that humans differ from one another in systematic ways, that affect the extent to which they prefer to make decisions based on detailed explanations versus less precise interpretations. These individual differences, such as personality traits and skills, are associated with their abilities to derive meaningful interpretations from precise explanations of model output. This implies that system output should be tailored to different types of users.","",""
0,"Ethan Stahl, Steven L. Blumer","A Basic Primer of Artificial Intelligence for Radiologists",2022,"","","","",125,"2022-07-13 09:37:36","","10.1097/01.CDR.0000804996.57509.75","","",,,,,0,0.00,0,2,1,"Artificial intelligence (AI) comprises computer systems that behave in ways previously thought to require human intelligence.1 AI and related technologies are increasingly prevalent in business and society and are beginning to be applied to health care.2 Within health care, AI has increasingly influenced the field of radiology, and its role is likely only to grow in the future. Within radiology, AI has demonstrated benefits in the areas of image analysis and interpretation, various noninterpretive domains, and resident training. And yet, AI remains vaguely and incompletely understood by a great many practicing radiologists, radiology residents, and students considering a career in radiology. The purpose of this article is to describe the primary current and potential future applications of AI to the field of radiology and to define some of the key terms used in discussions of AI. This article is meant to provide readers with a clear, foundational understanding of AI in radiology and to equip radiologists with literacy and fluency in the AI lexicon.","",""
8,"R. D. Bülow, Daniel Dimitrov, P. Boor, J. Sáez-Rodríguez","How will artificial intelligence and bioinformatics change our understanding of IgA Nephropathy in the next decade?",2021,"","","","",126,"2022-07-13 09:37:36","","10.1007/s00281-021-00847-y","","",,,,,8,8.00,2,4,1,"","",""
6,"A. Allam, S. Feuerriegel, M. Rebhan, M. Krauthammer","Analyzing Patient Trajectories With Artificial Intelligence.",2021,"","","","",127,"2022-07-13 09:37:36","","10.2196/29812","","",,,,,6,6.00,2,4,1,"In digital medicine, patient data typically record health events over time (eg, through electronic health records, wearables, or other sensing technologies) and thus form unique patient trajectories. Patient trajectories are highly predictive of the future course of diseases and therefore facilitate effective care. However, digital medicine often uses only limited patient data, consisting of health events from only a single or small number of time points while ignoring additional information encoded in patient trajectories. To analyze such rich longitudinal data, new artificial intelligence (AI) solutions are needed. In this paper, we provide an overview of the recent efforts to develop trajectory-aware AI solutions and provide suggestions for future directions. Specifically, we examine the implications for developing disease models from patient trajectories along the typical workflow in AI: problem definition, data processing, modeling, evaluation, and interpretation. We conclude with a discussion of how such AI solutions will allow the field to build robust models for personalized risk scoring, subtyping, and disease pathway discovery.","",""
0,"","Big Data and Artificial Intelligence Analytics in Geosciences : Promises and Potential Last Call for 2019 Annual Meeting Proposals",2019,"","","","",128,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,0,3,"Big data and machine learning are IT methodologies that are bringing substantial changes in the analysis and interpretation of scientific data. By adding GPU processing resources to the typical equipment of a server host, it is possible to speed up queries performed on large databases and reduce training time for deep learning architectures. A recent pairing of the big data technologies, applied to old and new data, and artificial intelligence techniques has enabled a team of scientists to create an interactive virtual globe that shows a color mosaic of the seabed geology. This interactive model allows us to obtain robust reconstructions and predictions of climate changes and their impacts on the ocean environment. We suggest a possible evolution of such a model by means of the expansion of functionalities and performance improvements. We refer respectively to the implementation of isochronic layers of seabed lithologies and the addition of GPU resources to speed up the learning phase of the support vector machine (SVM) model. These additional features would allow us to establish broader correlations and extract additional information on large-scale geological phenomena. INTRODUCTION The Earth system generates continuous data, and our acquisition capacity has significantly increased over time. The growing availability of acquired geological data and the methods developed in the field of information technology make it possible to identify associations and understand patterns and trends within data (Big Data), solve difficult decision problems (artificial intelligence), and provide acceleration to data processing (GPU computing). Big Data is a term that indicates very large databases (often by order of zettabytes, i.e., billions of terabytes) that can contain huge amounts of heterogeneous, structured and unstructured data (text, numerical values, images, e-mail, GPS data, and data acquired from social networks), which can be extrapolated, analyzed, and correlated with each other. Artificial Intelligence (AI) is a branch of computer science that studies the way in which the combination of hardware and software systems can simulate typical behaviors of the human brain. One of the most important applications consists of a complex algorithm, called machine learning, which is able to learn and make decisions. GPU Parallel Computing (GPGPU) involves the processing of data by the processors present in the graphics card (GPU) and has allowed the computation, in relatively short times, of huge amounts of data with an efficiency of at least two orders of magnitude greater compared to the past. There are several cases in which these technologies have been applied both in the field of potential earthquakes (RouetLeduc et al., 2017), volcanic eruptions (Ham et al., 2012), and to solve the problems of spatial modeling in the field of the assessment of landslide susceptibility (Korup and Stolle, 2014). The following describes a mixed approach (AI and Big Data) in the field of geosciences—analyzing potentials and possible future developments. CASE STUDY: BIG DATA AND AI MAP WORLD’S OCEAN FLOOR An example of an application combining Big Data and machine learning technologies was implemented by a team of Australian scientists who created the first digital map of seabed lithologies (Dutkiewicz et al., 2015) through the analysis and cataloging of ~15,000 samples of sediments found in marine basins. Before such a map, the most recent map of oceanic lithologies was hand drawn ~40 years ago, at the beginning of ocean exploration. Since then, the map has undergone few changes, with at most six types of sediment dominant in the ocean basins. The digital map was created using an AI method consisting of the support vector machine (SVM) model. Through a crossvalidation approach, the classifier was trained by adding new data gradually so as to allow its learning. Learning the parameter values, which optimize the classifier’s performance on withheld data, is an important step in the workflow. In this way, the vast set of point data has been transformed into a continuous digital map with very high accuracy (up to 80%). The new lithological map of the seabed is very important for the interpretation of global phenomena related to the evolution of ocean basins. An example of this is diatoms, siliceous phytoplankton that live in the oceans and that through chlorophyll photosynthesis produce about one-quarter of the oxygen present in the atmosphere, contributing to reduce global terrestrial warming. At their death, these organisms precipitate through the water column, accumulating on the underlying sea floor. Satellite surveys over the years have identified places where diatomaceous activity is more productive; that is, the marine areas in which there are the maximum concentrations of chlorophyll, considering that they should also correspond to the areas of maximum accumulation of these organisms in the sea floor. Surprisingly, the digital map of the seabed has revealed that there is a decoupling between the productivity of diatoms and the corresponding accumulation areas in the sea floor. The possibility of diatom ooze formation is however favored by the low surface temperature (0.9–5.7 °C), by salinity (33.8–34 PSS), and by the high concentration of nutrients, and therefore can represent an important indicator of the oceanographic variables of the surface of the sea (Cunningham and Big Data and Artificial Intelligence Analytics in Geosciences: Promises and Potential Roberto Spina, Geologist and DCompSci, CNG (National Council of Geologists), Rome, Italy, robertospina@geologi.it GSA Today, https://www.doi.org/10.1130/GSATG372GW.1. Copyright 2019, The Geological Society of America. CC-BY-NC. Leventer, 1998). For this reason, the map will help scientists better understand how our oceans have responded and will respond to environmental changes. POTENTIAL AND FUTURE PROSPECTS Big Data and AI are having an impact on every commercial and scientific domain, and their application in the field of geosciences is making a great impact in the analysis and understanding of natural phenomena. The intensive use of CPUs required by these two technologies has stimulated the search for alternative solutions to improve performance by using a mixed CPU-GPU approach. In this way it is possible to obtain rapid results from huge databases and the acceleration of the learning process for neural networks. These techniques are the basis of deep learning, an alternative model of machine learning, which achieves a very high degree of accuracy in recognizing objects and is able to learn features automatically from data without the need to extract them manually. The joint application of Big Data– machine learning, described as a case study, allowed researchers to demonstrate the absence of correlation between diatom productivity and the corresponding diatom oozes: The accumulation of these organisms in the seabed seems rather to be linked to specific variations in sea-surface parameters. This is one of many cases where the integrated analysis of various parameters allows a different interpretation from what could be assumed by their disjoint analysis. A possible evolution is to represent, on a similar map, in addition to the current surface lithologies, those present within the lithostratigraphic succession, making geochronological correlations between chronostratigraphic units. Using surveys carried out in various parts of the world, different layers could be defined, each corresponding to a specific age expressed in millions of years, representing the ocean lithologies existing in that particular geological period. Similarly to the previous case, the transition from a punctual to a continuous display could be obtained, for each layer, by applying the existing SVM model or an even more efficient version using GPU computing. Figure 1 shows a possible switching between current ocean Figure 1. Example of a layered implementation of seabed lithology maps (modified from https://portal.gplates.org). lithologies (https://portal.gplates.org) placed below and those existing respectively 500,000 and one million years ago (above). The oldest layers were made only for demonstration purposes and reproduce an artificial lithology of the seabed. A system of this kind allows the carrying out of various operations that can be summarized as follows: • display/hide isochronous levels obtaining different instantaneous representations of the ocean basins during the geological eras; • using Big Data analytics to pair data sets (oceanographic, stratigraphic, paleontological, and micropaleontological) with one or more isochronous layers to analyze geological phenomena on a global scale (eustatic oscillations, glacial and interglacial periods...) and perform stratigraphic correlations between oceanic crustal sectors to identify evolutionary patterns. The optimization introduced by IT methods lets us perform analyses on large heterogeneous data to discover hidden models and unknown correlations that allow for more solid reconstructions and forecasts on natural phenomena that have had and will have a major impact on the ecosystems of our planet. REFERENCES CITED Cunningham, W.L., and Leventer, A., 1998, Diatom assemblages in surface sediments of the Ross Sea: Relationship to present oceanographic conditions: Antarctic Science, v. 10, p. 134–146, https://doi.org/10.1017/S0954102098000182. Dutkiewicz, A., Müller, R.D., O’Callaghan, S., and Jónasson, H., 2015, Census of seafloor sediments in the world’s ocean: Geology, v. 43, no. 9, p. 795–798, https://doi.org/10.1130/G36883.1. Ham, M.F., Iyengar, I., Hambebo, B.M., Garces, M., Deaton, J., Perttu, A., and Williams, B., 2012, A neurocomputing approach for monitoring Plinian volcanic eruptions using infrasound: Procedia Computer Science, v. 13, p. 7–17, https://doi.org/10.1016/j.procs.2012.09.109. Korup, O., and Stolle, A., 2014, Landslide prediction from","",""
0,"A. Campbell, R. Smith, B. Petersen, L. Moore, A. Khan, A. Barrie","O-125 Application of artificial intelligence using big data to devise and train a machine learning model on over 63,000 human embryos to automate time-lapse embryo annotation",2022,"","","","",129,"2022-07-13 09:37:36","","10.1093/humrep/deac105.025","","",,,,,0,0.00,0,6,1,"      Can a machine learning (ML) model, developed using modern neural network architecture produce comparable annotation data; utilisable for algorithmic outcome prediction, to manual time-lapse annotations?        The model automatically annotated unseen embryos with comparable results to manual methods, generating morphokinetic data to enable comparably predictive outputs from an embryo selection algorithm.        The application of artificial intelligence across healthcare industries, including fertility, is increasing. Several ML models are available that seek to generate or analyse embryo images and morphokinetic data, and to determine embryo viability potential. Along with photographic images, the use of time-lapse in IVF laboratories has amassed numeric data, resulting predominantly from annotated manual assessment of images over time. Embryo annotation practice is variable in quality, can be subjective and is time-consuming; commonly taking several minutes per embryo. The development of rapid, accurate automatic annotation would represent a significant time-saving as well as an increase in reproducibility and accuracy.        Multicentre quality assured annotation data from 63,383 time-lapse monitored embryos (EmbryoScope®), comprising over 400 million individual images, were used to train a ML model to automatically generate morphokinetic annotations. Data was derived from 8 UK clinics within a cohesive group between 2012-2021. Accuracy was assessed using 900 unseen embryos (with live birth outcome) by comparing the output of an established in-house, prospectively validated embryo selection model when the input was either ML-automated, or manual annotations.        Multi-focal plane images were processed on the Azure cloud (Microsoft) and resampled to 300x300 pixels. A Laplacian-based focal stacking algorithm merged frames into a single image. The model consisted of an EfficientNetB4 Convolutional Neural Network classifier to extract features and classify the stage of embryo images. A Temporal Convolutional Network  interpreted a time-series of image features; producing annotations from pronuclear fading through to blastocyst. Soft localisation loss function used QA data to integrate annotation subjectivities.        The ML model rapidly and automatically generated annotations. Efficacy and comparability of the ML model to automate reliable, utilisable annotations was demonstrated by comparison with manual annotation data and the ML model’s ability to auto-generate annotations which could be used to predict live birth by providing annotation data to an established, validated in house embryo selection model. Live birth-predictive capability was measured, and benchmarked against manual annotation, using the area under the receiver operating characteristic curve (AUC).  When tested on time-lapse images, collected from pronuclear fading to full blastulation, representing 900 previously unseen, transferred blastocysts where live birth outcomes were blinded, the in-house developed auto-annotation ML model resulted in an AUC of 0.686 compared with 0.661 for manual annotations, for live birth prediction.  Auto annotation using the developed model took only milliseconds to complete per embryo. The developed auto-annotation model, built and tested on large data, is considered suitable for productionisation with the aim of being validated and integrated into an application to support IVF laboratory practice.        Whilst this model was trained to recognise key morphokinetic events, there are other morphokinetic variables that may be useful in the prediction of live birth and further improve embryo selection, or deselection, ability. Akin to manual interpretation, some embryos may fail to be annotated or need second opinion.        There is increasing evidence supporting the application of ML to utilise big data from time-lapse imaging and fertility care generally. Whilst promising benefits to IVF clinics and patients, responsible use of data is required alongside large high-quality datasets, and rigorous validation, to ensure safe and robust applications.        N/A ","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",130,"2022-07-13 09:37:36","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
13,"Enrico W. Coiera","The Price of Artificial Intelligence",2019,"","","","",131,"2022-07-13 09:37:36","","10.1055/s-0039-1677892","","",,,,,13,4.33,13,1,3,"Summary Introduction : Whilst general artificial intelligence (AI) is yet to appear, today’s narrow AI is already good enough to transform much of healthcare over the next two decades. Objective : There is much discussion of the potential benefits of AI in healthcare and this paper reviews the cost that may need to be paid for these benefits, including changes in the way healthcare is practiced, patients are engaged, medical records are created, and work is reimbursed. Results : Whilst AI will be applied to classic pattern recognition tasks like diagnosis or treatment recommendation, it is likely to be as disruptive to clinical work as it is to care delivery. Digital scribe systems that use AI to automatically create electronic health records promise great efficiency for clinicians but may lead to potentially very different types of clinical records and workflows. In disciplines like radiology, AI is likely to see image interpretation become an automated process with diminishing human engagement. Primary care is also being disrupted by AI-enabled services that automate triage, along with services such as telemedical consultations. This altered future may necessarily see an economic change where clinicians are increasingly reimbursed for value, and AI is reimbursed at a much lower cost for volume. Conclusion : AI is likely to be associated with some of the biggest changes we will see in healthcare in our lifetime. To fully engage with this change brings promise of the greatest reward. To not engage is to pay the highest price.","",""
13,"R. Iezzi, S. Goldberg, B. Merlino, A. Posa, V. Valentini, R. Manfredi","Artificial Intelligence in Interventional Radiology: A Literature Review and Future Perspectives",2019,"","","","",132,"2022-07-13 09:37:36","","10.1155/2019/6153041","","",,,,,13,4.33,2,6,3,"The term “artificial intelligence” (AI) includes computational algorithms that can perform tasks considered typical of human intelligence, with partial to complete autonomy, to produce new beneficial outputs from specific inputs. The development of AI is largely based on the introduction of artificial neural networks (ANN) that allowed the introduction of the concepts of “computational learning models,” machine learning (ML) and deep learning (DL). AI applications appear promising for radiology scenarios potentially improving lesion detection, segmentation, and interpretation with a recent application also for interventional radiology (IR) practice, including the ability of AI to offer prognostic information to both patients and physicians about interventional oncology procedures. This article integrates evidence-reported literature and experience-based perceptions to assist not only residents and fellows who are training in interventional radiology but also practicing colleagues who are approaching to locoregional mini-invasive treatments.","",""
4,"C. Mallio, C. Quattrocchi, B. Beomonte Zobel, P. Parizel","Artificial intelligence, chest radiographs, and radiology trainees: a powerful combination to enhance the future of radiologists?",2021,"","","","",133,"2022-07-13 09:37:36","","10.21037/qims-20-1306","","",,,,,4,4.00,1,4,1,"Quant Imaging Med Surg 2021;11(5):2204-2207 | http://dx.doi.org/10.21037/qims-20-1306 Work overload has become a major challenge for radiologists. The increasing demands upon radiologists’ time, expertise and energy depend not only on the absolute number of imaging examinations to be performed and reported (i.e., number of patients), but also on the progressively growing complexity of imaging datasets, in terms of the number of images to be analyzed, as well as the quality of information to be processed, especially in the case of advanced imaging examinations that require post-processing and detailed interpretation (1-3). Artificial intelligence (AI) is a breakthrough innovation involving computer-based algorithms tailored to analyze complex datasets (4,5). Moreover, AI is emerging as a potential game changer in many fields. In medical imaging for instance, AI showed promising results for lesion detection and quantification over a wide spectrum of clinical conditions, as well as speeding up workflows, improving accuracy, addressing resource scarcity, and reducing the costs of care (4-7). The most promising subset of AI is the so-called deep learning algorithm, in which the term “deep” is due to the artificial neural network architecture composed by multiple layers (8,9). To be effective as representative learning applications, deep learning algorithms require large amounts of imaging data for training. These models, that are able to automatically learn, and then label, features on archetypal images, have been shown to robustly mirror or even outperform humans in task-specific applications in some cases? (8-10). AI and deep learning are currently being tested for imaging processing in several anatomical regions and various clinical scenarios, including disorders of the chest (7,8). In this context, we read with great interest the recently published paper by Wu et al. (7), investigating the performance of AI model and human third-year radiology residents in interpreting chest radiographs. The novel deep learning AI algorithm that they tested was extensively trained with a large image database (i.e., 342,126 frontal chest radiographs), acquired at the emergency departments (ED) and urgent care settings in multiple hospitals. Anteroposterior (AP) and postero-anterior (PA) images were used to train the model, despite the comparison AI vs. human radiology residents was based on AP images only. Interestingly, the major results of the study showed no significant difference between the performance of the AI algorithm and human radiology residents in terms of sensitivity (P=0.66); however, specificity [reported for AI 0.980 (95% CI, 0.980–0.981)] and positive predictive value [reported for AI 0.730 (95% CI, 0.718–0.742)] showed statistically significant greater results for the AI algorithm (both with P<0.001). This work, based on the “humble” but impactful chest radiograph, which represents the most commonly performed imaging examination, is of seminal importance at least for three good reasons (7). Firstly, the authors demonstrated Editorial Commentary","",""
5,"M. E. Laino, Angela Ammirabile, A. Posa, Pierandrea Cancian, Sherif Shalaby, V. Savevski, E. Neri","The Applications of Artificial Intelligence in Chest Imaging of COVID-19 Patients: A Literature Review",2021,"","","","",134,"2022-07-13 09:37:36","","10.3390/diagnostics11081317","","",,,,,5,5.00,1,7,1,"Diagnostic imaging is regarded as fundamental in the clinical work-up of patients with a suspected or confirmed COVID-19 infection. Recent progress has been made in diagnostic imaging with the integration of artificial intelligence (AI) and machine learning (ML) algorisms leading to an increase in the accuracy of exam interpretation and to the extraction of prognostic information useful in the decision-making process. Considering the ever expanding imaging data generated amid this pandemic, COVID-19 has catalyzed the rapid expansion in the application of AI to combat disease. In this context, many recent studies have explored the role of AI in each of the presumed applications for COVID-19 infection chest imaging, suggesting that implementing AI applications for chest imaging can be a great asset for fast and precise disease screening, identification and characterization. However, various biases should be overcome in the development of further ML-based algorithms to give them sufficient robustness and reproducibility for their integration into clinical practice. As a result, in this literature review, we will focus on the application of AI in chest imaging, in particular, deep learning, radiomics and advanced imaging as quantitative CT.","",""
5,"Y. Yoon, Sekeun Kim, Hyuk-Jae Chang","Artificial Intelligence and Echocardiography",2021,"","","","",135,"2022-07-13 09:37:36","","10.4250/jcvi.2021.0039","","",,,,,5,5.00,2,3,1,"Artificial intelligence (AI) is evolving in the field of diagnostic medical imaging, including echocardiography. Although the dynamic nature of echocardiography presents challenges beyond those of static images from X-ray, computed tomography, magnetic resonance, and radioisotope imaging, AI has influenced all steps of echocardiography, from image acquisition to automatic measurement and interpretation. Considering that echocardiography often is affected by inter-observer variability and shows a strong dependence on the level of experience, AI could be extremely advantageous in minimizing observer variation and providing reproducible measures, enabling accurate diagnosis. Currently, most reported AI applications in echocardiographic measurement have focused on improved image acquisition and automation of repetitive and tedious tasks; however, the role of AI applications should not be limited to conventional processes. Rather, AI could provide clinically important insights from subtle and non-specific data, such as changes in myocardial texture in patients with myocardial disease. Recent initiatives to develop large echocardiographic databases can facilitate development of AI applications. The ultimate goal of applying AI to echocardiography is automation of the entire process of echocardiogram analysis. Once automatic analysis becomes reliable, workflows in clinical echocardiographic will change radically. The human expert will remain the master controlling the overall diagnostic process, will not be replaced by AI, and will obtain significant support from AI systems to guide acquisition, perform measurements, and integrate and compare data on request.","",""
1,"Robin L. Zebrowski, Eli B. McGraw","Autonomy and Openness in Human and Machine Systems: Participatory Sense-Making and Artificial Minds",2021,"","","","",136,"2022-07-13 09:37:36","","10.1142/s2705078521500181","","",,,,,1,1.00,1,2,1,"Within artificial intelligence (AI) and machine consciousness research, social cognition as a whole is often ignored. When it is addressed, it is often thought of as one application of more traditional forms of cognition. However, while theoretical approaches to AI have been fairly stagnant in recent years, social cognition research has progressed in productive new ways, specifically through enactive approaches. Using participatory sense-making (PSM) as an approach, we rethink conceptions of autonomy and openness in AI and enactivism, shifting the focus away from living systems to allow incorporation of artificial systems into social forms of sense-making. PSM provides an entire level of analysis through an overlooked autonomous system produced via social interaction that can be both measured and modeled in order to instantiate and examine more robust artificial cognitive systems.","",""
13,"K. Schaefer, Jean Oh, Derya Aksaray, D. Barber","Integrating Context into Artificial Intelligence: Research from the Robotics Collaborative Technology Alliance",2019,"","","","",137,"2022-07-13 09:37:36","","10.1609/aimag.v40i3.2865","","",,,,,13,4.33,3,4,3,"Applying context to a situation, task, or system state provides meaning and advances understanding that can affect future decisions or actions. Although people are naturally good at perceiving contextual understanding and inferring missing pieces of information using various alternative sources, this process is difficult for AI systems or robots, especially in high-uncertainty and unstructured operations. Integration of context-driven AI is important for future robotic capabilities to support the development of situation awareness, calibrate appropriate trust, and improve team performance in collaborative human-robot teams. This article highlights advances in context-driven AI for human-robot teaming by the Army Research Laboratory’s Robotics Collaborative Technology Alliance. Avenues of research discussed include how context enables robots to fill in the gaps to make effective decisions more quickly, supports more robust behaviors, and augments robot communications to suit the needs of the team under a variety of environments and team organizations and across missions.","",""
1,"R. Houshyar, Justin Glavis-Bloom, T. Bui, Chantal Chahine, M. Bardis, A. Ushinsky, Hanna Liu, Param Bhatter, Elliott Lebby, D. Fujimoto, William A. Grant, Karen Tran-Harding, J. Landman, D. Chow, P. Chang","Outcomes of Artificial Intelligence Volumetric Assessment of Kidneys and Renal Tumors for Preoperative Assessment of Nephron Sparing Interventions.",2021,"","","","",138,"2022-07-13 09:37:36","","10.1089/end.2020.1125","","",,,,,1,1.00,0,15,1,"Background Renal cell carcinoma is the most common kidney cancer and the 13th most common cause of cancer death worldwide. Partial nephrectomy and percutaneous ablation, increasingly utilized to treat small renal masses and preserve renal parenchyma, require precise preoperative imaging interpretation. We sought to develop and evaluate a convolutional neural network (CNN), a type of deep learning artificial intelligence, to act as a surgical planning aid by determining renal tumor and kidney volumes via segmentation on single-phase computed tomography (CT). Materials and Methods After institutional review board approval, the CT images of 319 patients were retrospectively analyzed. Two distinct CNNs were developed for (1) bounding cube localization of the right and left hemi-abdomen and (2) segmentation of the renal parenchyma and tumor within each bounding cube. Training was performed on a randomly selected cohort of 269 patients. CNN performance was evaluated on a separate cohort of 50 patients using Sorensen-Dice coefficients (which measures the spatial overlap between the manually segmented and neural network derived segmentations) and Pearson correlation coefficients. Experiments were run on a GPU-optimized workstation with a single NVIDIA GeForce GTX Titan X (12GB, Maxwell architecture). Results Median Dice coefficients for kidney and tumor segmentation were 0.970 and 0.816, respectively; Pearson correlation coefficients between CNN-generated and human-annotated estimates for kidney and tumor volume were 0.998 and 0.993 (p < 0.001), respectively. End-to-end trained CNNs were able to perform renal parenchyma and tumor segmentation on a new test case in an average of 5.6 seconds. Conclusions Initial experience with automated deep learning artificial intelligence demonstrates that it is capable of rapidly and accurately segmenting kidneys and renal tumors on single-phase contrast-enhanced CT scans and calculating tumor and renal volumes.","",""
2,"Anjan Gudigar, Sneha Nayak, Jyothi Samanth, U. Raghavendra, A. A. J., P. Barua, Md Nazmul Hasan, E. Ciaccio, R. Tan, U. Rajendra Acharya","Recent Trends in Artificial Intelligence-Assisted Coronary Atherosclerotic Plaque Characterization",2021,"","","","",139,"2022-07-13 09:37:36","","10.3390/ijerph181910003","","",,,,,2,2.00,0,10,1,"Coronary artery disease is a major cause of morbidity and mortality worldwide. Its underlying histopathology is the atherosclerotic plaque, which comprises lipid, fibrous and—when chronic—calcium components. Intravascular ultrasound (IVUS) and intravascular optical coherence tomography (IVOCT) performed during invasive coronary angiography are reference standards for characterizing the atherosclerotic plaque. Fine image spatial resolution attainable with contemporary coronary computed tomographic angiography (CCTA) has enabled noninvasive plaque assessment, including identifying features associated with vulnerable plaques known to presage acute coronary events. Manual interpretation of IVUS, IVOCT and CCTA images demands scarce physician expertise and high time cost. This has motivated recent research into and development of artificial intelligence (AI)-assisted methods for image processing, feature extraction, plaque identification and characterization. We performed parallel searches of the medical and technical literature from 1995 to 2021 focusing respectively on human plaque characterization using various imaging modalities and the use of AI-assisted computer aided diagnosis (CAD) to detect and classify atherosclerotic plaques, including their composition and the presence of high-risk features denoting vulnerable plaques. A total of 122 publications were selected for evaluation and the analysis was summarized in terms of data sources, methods—machine versus deep learning—and performance metrics. Trends in AI-assisted plaque characterization are detailed and prospective research challenges discussed. Future directions for the development of accurate and efficient CAD systems to characterize plaque noninvasively using CCTA are proposed.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",140,"2022-07-13 09:37:36","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
0,"T. Kronivets, Ye Tymoshenko, O. Diachenko, N. Ivanchenko, S. Iasechko","Artificial Intelligence as A Key Element of Digital Education",2021,"","","","",141,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,5,1,"Summary The article proposes a typology of the goals of using AI systems, understanding education (education as a system, education as a process, education as a result) and corresponding to significant trends in the development of education (increasing flexibility and decentralization of the global education system, personalization of the education process, digital fixation of competence-based educational outcomes). The article describes that in relation to the systemic aspect of education, AI technologies will be able to bring education management closer to the use of methods based on a significant amount of qualitative data and contribute to the formation of evidence-based educational policy. It is shown that problems with the interpretation of the decision-making model in administration directly affect the assessment of the effectiveness of artificial intelligence support for managerial decisions in the educational sphere. It is shown that the process of teaching and upbringing can be personalized and individualized with the support of AI through the formation of individual educational programs content, by the educational environment; methodological support of training courses; increasing the motivation and involvement of students. The transformation of models of interaction between educational subjects is ambiguous in terms of the impact on the autonomy and responsibility of the subjects, on the results of socialization and upbringing, on the labor intensity and transparency of the educational process, including in the light of the prospects for the emergence of ""human-AI"" systems as a trained agent. In the effective aspect of education, it was revealed that AI is attractive as a tool for monitoring and recording educational achievements and expended resources, capable of clarifying the links between educational activities and results.","",""
0,"B. Kotiv, Igor A. Budko, Igor A. Ivanov, I. U. Trosko","Artificial intelligence using for medical diagnosis via implementation of expert systems",2021,"","","","",142,"2022-07-13 09:37:36","","10.17816/brmma63657","","",,,,,0,0.00,0,4,1,"Modern biomedical technologies development affords to provide the doctor with colossal amount of information about patients organism condition. However, the opportunity of using this data for medical diagnosis fully now is a distantive perspective only. The reason is a humans limited ability in assessment and interpretation this data arrays. The solution seems in artificial intelligence and expert systems wide introduction to medicine. Currently, almost all authors consider various options for constructing artificial neural networks as a way to implement artificial intelligence. This approach, which goes back to the fundamental theorem of A.N. Kolmogorov, the works of V.I. Arnold and Hecht-Nielsen [3], demonstrates excellent capabilities in a number of pattern recognition problems, which are reduced to revealing hidden details against the background of input noises. Much less often is mentioned such a method of modeling formal thinking as expert systems, which arose in the 1960s and then went into the shadows. Since the inception of cybernetics, computer programmers have tried to reproduce the mechanism of human thinking, that is, the task was to teach the computer to ""think"". The first known results in the field of creating and using intelligent systems were laid by the work of Norbert Wiener and G.S. Altshuller. At the same time, the creation of intelligent systems was reduced to the development of programs that solve problems using a variety of heuristic methods based on the property of human thinking to generalize.","",""
24,"P. Iftikhar, Marcela Kuijpers, Azadeh Khayyat, Aqsa Iftikhar, Maribel DeGouvia De Sa","Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice",2020,"","","","",143,"2022-07-13 09:37:36","","10.7759/cureus.7124","","",,,,,24,12.00,5,5,2,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians. Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating AI systems into their daily practice. AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. AI systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required.","",""
27,"E. Mekov, M. Miravitlles, R. Petkov","Artificial intelligence and machine learning in respiratory medicine",2020,"","","","",144,"2022-07-13 09:37:36","","10.1080/17476348.2020.1743181","","",,,,,27,13.50,9,3,2,"ABSTRACT Introduction The application of artificial intelligence (AI) and machine learning (ML) in medicine and in particular in respiratory medicine is an increasingly relevant topic. Areas covered We aimed to identify and describe the studies published on the use of AI and ML in the field of respiratory diseases. The string ‘(((pulmonary) OR respiratory)) AND ((artificial intelligence) OR machine learning)’ was used in PubMed as a search strategy. The majority of studies identified corresponded to the area of chronic obstructive pulmonary disease (COPD), in particular to COPD and chest computed tomography scans, interpretation of pulmonary function tests, exacerbations and treatment. Another field of interest is the application of AI and ML to the diagnosis of interstitial lung disease, and a few other studies were identified on the fields of mechanical ventilation, interpretation of images on chest X-ray and diagnosis of bronchial asthma. Expert opinion ML may help to make clinical decisions but will not replace the physician completely. Human errors in medicine are associated with large financial losses, and many of them could be prevented with the help of AI and ML. AI is particularly useful in the absence of conclusive evidence of decision-making.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",145,"2022-07-13 09:37:36","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",146,"2022-07-13 09:37:36","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
5,"J. Espinoza, C. Dupont, Aubrie O’Rourke, S. Beyhan, Pavel Morales, A. Spoering, Kirsten J Meyer, A. Chan, Yongwook Choi, W. Nierman, K. Lewis, K. Nelson","Predicting antimicrobial mechanism-of-action from transcriptomes: A generalizable explainable artificial intelligence approach",2021,"","","","",147,"2022-07-13 09:37:36","","10.1371/journal.pcbi.1008857","","",,,,,5,5.00,1,12,1,"To better combat the expansion of antibiotic resistance in pathogens, new compounds, particularly those with novel mechanisms-of-action [MOA], represent a major research priority in biomedical science. However, rediscovery of known antibiotics demonstrates a need for approaches that accurately identify potential novelty with higher throughput and reduced labor. Here we describe an explainable artificial intelligence classification methodology that emphasizes prediction performance and human interpretability by using a Hierarchical Ensemble of Classifiers model optimized with a novel feature selection algorithm called Clairvoyance; collectively referred to as a CoHEC model. We evaluated our methods using whole transcriptome responses from Escherichia coli challenged with 41 known antibiotics and 9 crude extracts while depositing 122 transcriptomes unique to this study. Our CoHEC model can properly predict the primary MOA of previously unobserved compounds in both purified forms and crude extracts at an accuracy above 99%, while also correctly identifying darobactin, a newly discovered antibiotic, as having a novel MOA. In addition, we deploy our methods on a recent E. coli transcriptomics dataset from a different strain and a Mycobacterium smegmatis metabolomics timeseries dataset showcasing exceptionally high performance; improving upon the performance metrics of the original publications. We not only provide insight into the biological interpretation of our model but also that the concept of MOA is a non-discrete heuristic with diverse effects for different compounds within the same MOA, suggesting substantial antibiotic diversity awaiting discovery within existing MOA.","",""
4,"Jack Zhang, Naveenjyote Boora, Sarah Melendez, Abhilash Rakkunedeth Hareendranathan, J. Jaremko","Diagnostic Accuracy of 3D Ultrasound and Artificial Intelligence for Detection of Pediatric Wrist Injuries",2021,"","","","",148,"2022-07-13 09:37:36","","10.3390/children8060431","","",,,,,4,4.00,1,5,1,"Wrist trauma is common in children, typically requiring radiography for diagnosis and treatment planning. However, many children do not have fractures and are unnecessarily exposed to radiation. Ultrasound performed at bedside could detect fractures prior to radiography. Modern tools including three-dimensional ultrasound (3DUS) and artificial intelligence (AI) have not yet been applied to this task. Our purpose was to assess (1) feasibility, reliability, and accuracy of 3DUS for detection of pediatric wrist fractures, and (2) accuracy of automated fracture detection via AI from 3DUS sweeps. Children presenting to an emergency department with unilateral upper extremity injury to the wrist region were scanned on both the affected and unaffected limb. Radiographs of the symptomatic limb were obtained for comparison. Ultrasound scans were read by three individuals to determine reliability. An AI network was trained and compared against the human readers. Thirty participants were enrolled, resulting in scans from fifty-five wrists. Readers had a combined sensitivity of 1.00 and specificity of 0.90 for fractures. AI interpretation was indistinguishable from human interpretation, with all fractures detected in the test set of 36 images (sensitivity = 1.0). The high sensitivity of 3D ultrasound and automated AI ultrasound interpretation suggests that ultrasound could potentially rule out fractures in the emergency department.","",""
4,"José Daniel López-Cabrera, R. Orozco-Morales, Jorge Armando Portal-Díaz, Orlando Lovelle-Enríquez, M. Pérez-Díaz","Current limitations to identify covid-19 using artificial intelligence with chest x-ray imaging (part ii). The shortcut learning problem",2021,"","","","",149,"2022-07-13 09:37:36","","10.1007/s12553-021-00609-8","","",,,,,4,4.00,1,5,1,"","",""
4,"D. Herman, D. Rhoads, W. Schulz, T. Durant","Artificial Intelligence and Mapping a New Direction in Laboratory Medicine: A Review.",2021,"","","","",150,"2022-07-13 09:37:36","","10.1093/clinchem/hvab165","","",,,,,4,4.00,1,4,1,"BACKGROUND Modern artificial intelligence (AI) and machine learning (ML) methods are now capable of completing tasks with performance characteristics that are comparable to those of expert human operators. As a result, many areas throughout healthcare are incorporating these technologies, including in vitro diagnostics and, more broadly, laboratory medicine. However, there are limited literature reviews of the landscape, likely future, and challenges of the application of AI/ML in laboratory medicine.   CONTENT In this review, we begin with a brief introduction to AI and its subfield of ML. The ensuing sections describe ML systems that are currently in clinical laboratory practice or are being proposed for such use in recent literature, ML systems that use laboratory data outside the clinical laboratory, challenges to the adoption of ML, and future opportunities for ML in laboratory medicine.   SUMMARY AI and ML have and will continue to influence the practice and scope of laboratory medicine dramatically. This has been made possible by advancements in modern computing and the widespread digitization of health information. These technologies are being rapidly developed and described, but in comparison, their implementation thus far has been modest. To spur the implementation of reliable and sophisticated ML-based technologies, we need to establish best practices further and improve our information system and communication infrastructure. The participation of the clinical laboratory community is essential to ensure that laboratory data are sufficiently available and incorporated conscientiously into robust, safe, and clinically effective ML-supported clinical diagnostics.","",""
7,"David K. Spencer, Stephen Duncan, Adam Taliaferro","Operationalizing artificial intelligence for multi-domain operations: a first look",2019,"","","","",151,"2022-07-13 09:37:36","","10.1117/12.2524227","","",,,,,7,2.33,2,3,3,"Artificial Intelligence / Machine Learning (AI/ML) is a foundational requirement for Multi-Domain Operations (MDO). To solve some of MDO’s most critical problems, for example, penetrating and dis-integrating an adversary’s antiaccess/area denial (A2/AD) systems, the future force requires the ability to converge capabilities from across multiple domains at speeds and scales beyond human cognitive abilities. This requires robust, interoperable AI/ML that operates across multiple layers: from optimizing technologies and platforms, to fusing data from multiple sources, to transferring knowledge across joint functions to accomplish critical MDO tactical tasks. This paper provides an overview of ongoing work from the Unified Quest Future Study Plan and other events with the Army’s Futures and Concepts Center to operationalize AI/ML to address MDO problems with this layered approach. It includes insights and required AI/ML capabilities determined with subject matter experts from various organizations at these learning events over the past two years, as well as vignettes that illustrate how AI/ML can be operationalized to enable successful Multi-Domain Operations against a near peer adversary.","",""
2,"Neil R. Hogan, Ethan Q Davidge, Gabriela Corabian","On the Ethics and Practicalities of Artificial Intelligence, Risk Assessment, and Race.",2021,"","","","",152,"2022-07-13 09:37:36","","10.29158/JAAPL.200116-20","","",,,,,2,2.00,1,3,1,"Artificial intelligence (AI) has been put forth as a potential means of improving and expediting violence risk assessment in forensic psychiatry. Furthermore, it has been proffered as a means of mitigating bias by replacing subjective human judgements with unadulterated data-driven predictions. A recent ethics analysis of AI-informed violence risk assessment enumerated some potential benefits, ethics concerns, and recommendations for further discussion. The current review builds on this previous work by highlighting additional important practical and ethics considerations. These include extant technology for violence risk assessment, paradigmatic concerns with the application of AI to risk assessment and management, and empirical evidence of racial bias in the criminal justice system. Emphasis is given to problems of informed consent, maleficence (e.g., the known iatrogenic effects of overly punitive sanctions), and justice (particularly racial justice). AI appears well suited to certain medical applications, such as the interpretation of diagnostic images, and may well surpass human judgement in accuracy or efficiency with respect to some important tasks. Caution is necessary, however, when applying AI to processes like violence risk assessment that do not conform clearly to simple classification paradigms.","",""
2,"P. Kumar","Special issue on Artificial Intelligence in Engineering Education",2021,"","","","",153,"2022-07-13 09:37:36","","10.1002/cae.22398","","",,,,,2,2.00,2,1,1,"Artificial intelligence (AI) can be defined as the intelligence exhibited by machines and computers in accomplishing desired tasks in a similar way to how normal human beings think and act. Hence AI is also termed machine intelligence. For a computational system to be artificially intelligent, the system should possess the ability to understand the surrounding environment, make proper assumptions, and based on the circumstances make judicious decisions that maximize the possibilities of accomplishing goals most of the time. These AI‐enabled devices are also called Intelligent Agents. These intelligent agents use some mapping functions also termed cognitive functions, which take these environmental parameters and contextual information as inputs along with the goal to be accomplished and manipulate the right means to accomplish the targeted goal. AI can also be considered inter‐ disciplinary as it involves several other disciplines such as Machine Learning, Computer Vision, Cognitive Science, Neural Networks, Data Mining, Natural Language Processing (NLP), robotics, and mathematics. All these disciplines are related, and thereby intelligent agents are trained to understand and adapt to the surrounding environment according to the context. The use of AI spans across several applications such as Human–Computer Interaction (HCI) based smart agent development, devising smart surveillance solutions using computer vision, creating robust and stable decision making systems that can understand, evaluate, manipulate, analyze, and predict several novel patterns by processing large volumes of application data, development of multilingual systems that uses NLP to understand the language features used across the context and aid decision making and so on. Also, since its inception as an academic discipline in the 1950s, AI has grown leaps and bounds as a discipline, and its applications have stretched across several domains such as Retail and Business solutions, Manufacturing and Logistics, Automobiles, Business Analytics and Market predictions, Healthcare, Security Systems, and Education. One of the key emerging areas where extensive efforts are spent towards developing smart applications and agents is the educational domain. Gone are the days where the educational system was completely driven by humans, and the growth of AI‐enabled intelligent agents has set the tone by replacing most human work with that of smart agents. Educational systems use AI‐based agents to study the behavior of students and suggest suitable courses for them. Smart agents are nowadays deployed in classrooms for complete classroom monitoring that includes tracking attendance, monitoring classroom activities, student and staff behavior monitoring, and so on. Similarly, smart agents are deployed to scan through the contents available online and suggest suitable content to students according to the course and also according to the different levels of understanding of student fraternity. Also, computer vision‐based smart agents are deployed to study the state of mind of students when they undergo different courses and provide insightful information about their likeness towards a subject or course. This agent‐based information serves as useful information in deciding the teaching methodology and also framing of course contents. Also, smart systems play a vital role in analyzing student results and providing insightful information about student performance. Thus, it is imperative that AI has become an indispensable force to reckon with in the future forward across the educational domain. However, the major drawback in these artificially intelligent systems is that they are not always accurate with decision making and at times predict otherwise. Also, training the AI‐based agent to understand the contextual paradigm and surrounding environment is a challenge. This special issue on “Artificial Intelligence In Education” is focused on drawing original studies related to the development and refinement of smart agents that can be applied across the educational domain.","",""
1,"T. Pillay","Artificial intelligence in pathology and laboratory medicine",2021,"","","","",154,"2022-07-13 09:37:36","","10.1136/jclinpath-2021-207682","","",,,,,1,1.00,1,1,1,"Increased healthcare demand has placed pressure on laboratory medicine to improve turnover and optimise efficiency using digitalisation, automation and artificial intelligence (AI). This will bring new challenges for the clinical laboratory. Laboratorians need to understand the utility of AI, its limitations and implementation. The management of big data requires ready access and accurate and contextual analysis. AI uses complex algorithms and data from medical and laboratory data to mimic human analysis and this requires accurate and reliable data. The role of AI in laboratory medicine is rapidly expanding owing to recognition of its potential to improve detection, laboratory workflows, decision support and reduce costs and increase efficiency. In this thematic issue on AI, we have attempted to present an overview of the uses of AI in laboratory medicine and advances in the digitalisation of pathology. Rakha et al from the University of Nottingham and Google Health provide an erudite overview of current and future applications of AI in pathology. The applications of AI in pathology range from prognostic/predictive applications to workflow and diagnostic applications to education as well as to the integration of other investigative data derived from genomics and radiology. It is clear that the trend of rapid deployment of AI will continue, but they highlight the gap between the translation process of discovery to clinical application, which they attribute to the fact that research and the clinical environment are often widely separated. The articles in this issue go to some length to highlight the areas of current and future applications in pathology. One area where digitalisation has progressed rapidly is in whole slide imaging. This allows slides to be transferred between locations. The value of digital neuropathology is illustrated in the paper in this issue by Williams and coauthors at the University of Leeds. This has also progressed towards the use of AI for interpretation of digital slides. There will be increased application of AI algorithms in the digital diagnostic workflow according to Stathonikos et al. The increased adoption of digital pathology allows the use of AI algorithms to facilitate automatic triaging and quality control along with assisted reading of whole slide images. There will be increased utilisation of diagnostic, prognostic and predictive algorithms based on AIdrive image analysis. Evans and coauthors describe the provision of highquality and costeffective histopathology to underserviced, remote areas, for example, in rural Canada, has been enabled by the application of digital pathology. Whole slide imaging has also found use in distant teaching as shown by that between the University of Toronto and the University of the West Indies. Immunohistochemistry is a technique that plays a crucial role in histopathology and traditionally the sections have been quantified visually by pathologists. This takes time and is subjective. Computer analysis offers the opportunity of standardised, quantifiable and highly reproducible scoring. The publication on ovarian cancer by Gentles et al illustrates this point elegantly and proves that automated scoring is reliable and superior to manual scoring and offers the reproducibility needed for highthroughput diagnostic applications. It is clear that cancer diagnosis will be one of the major growth areas for AI applications as with cancer being the leading cause of death and the most important obstacle to increased life expectancy. Deeplearning platforms for H&E analysis of slide are more sensitive to variations that escape the human eye and can offer improved fine tuning of disease prediction and prognostication and advancement of the goals of personalised and precision medicine. The review by Fitzgerald and coauthors examines how improved therapeutic stratification can be achieved in breast and prostate cancer using biomarkers and AI algorithms. They conclude that AI and machine learning will enhance precision oncology and ease the burden of pathologists and improve the capacity for reviewing high priority cases as well improve the quality and precision of diagnosis for patients. Bone marrow slide analysis will also benefit from machine learning and Baranova et al illustrate this with an open source learning tool for plasma cells. The quantitation of bone marrow plasma cell percentage is an important component of the diagnostic criteria for multiple myeloma. Using an open source digital pathology tool, QuPath, CD138positive bone marrow plasma cells were quantified. This was found to improve the speed and accuracy of cell counting. Big data analysis is a domain where the power of AI comes to the fore. This is particularly evident in chemical pathology where Punchoo et al provide a detailed overview of the applications of machine learning in the chemical pathology laboratory. Machine learning can be applied to diverse chemical pathology laboratory processes including clinical decision support, detection of errors, analysis of gels and discovery of biomarkers. Machine learning analysis offers the promise of rapid and standardised interpretation for digitised gel images in serum protein electrophoresis. The future is certainly bright and laboratorians and clinicians will need to be educated in the principles of machine learning in the framework of the appropriate regulatory and ethical frameworks.","",""
1,"Sara R. Jordan","Challenges of Artificial Intelligence Review in a Soft Law Environment",2021,"","","","",155,"2022-07-13 09:37:36","","10.1109/MTS.2021.3123743","","",,,,,1,1.00,1,1,1,"<bold>If artificial intelligence (AI)</bold> lives up to the claims of journalists, futurists, and tech companies, then AI stands to disrupt the landscape of human cognition, social order, and political power. Within a week’s span, AI can be discussed in both positive and utopian terms as well as in negative, even apocalyptic, terms. On the positive side, AI is described as an extraordinarily confident and capable F-16 pilot <xref ref-type=""bibr"" rid=""ref2"">[2]</xref>, a panoptic gastroenterologist who misses no part of a colonoscopy <xref ref-type=""bibr"" rid=""ref3"">[3]</xref>, the all-seeing solution to mapping climate change affected regions <xref ref-type=""bibr"" rid=""ref4"">[4]</xref>, and a smartphone application able to show your body with 12% less fat and give dieting advice to achieve that goal <xref ref-type=""bibr"" rid=""ref5"">[5]</xref>. Conversely, in a similar one-week period, AI is described as a tool for the surveillance of a minority population <xref ref-type=""bibr"" rid=""ref6"">[6]</xref>, a technique for identifying the whereabouts of political protestors or dissidents <xref ref-type=""bibr"" rid=""ref7"">[7]</xref>, a rogue system that delivers arbitrary scores on high-stakes examinations <xref ref-type=""bibr"" rid=""ref8"">[8]</xref>, and a harbinger of decline for reasoning, resilience, and emotional intelligence <xref ref-type=""bibr"" rid=""ref9"">[9]</xref>. Each of these assertions rests on the interpretation of both basic and applied AI research that may or may not be deployed into the production environment of normal human lives.","",""
11,"Jeong Beom Kim","Implementation of Artificial Intelligence System and Traditional System: A Comparative Study",2019,"","","","",156,"2022-07-13 09:37:36","","10.33168/jsms.2019.0309","","",,,,,11,3.67,11,1,3,"The main purpose of this paper is to study about efficient AI project implementation as a case study. For the purpose of successful AI implementation, the project plan should be complete and robust with long term view. The implementation plan includes top management decision, organization and human resource, infra structure for AI system, end user support, and company strategy. The biggest benefits of AI systems are cost reduction, quality improvement, and faster response time. The goal of this study is to provide AI system team members with successful AI project implementation guidelines compared with traditional ones as recommendation.","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",157,"2022-07-13 09:37:36","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
5,"M. Hossain, Rachit Sharma, A. Sultana, S. Tasnim, Farah Faizah","Globalising artificial intelligence for improved clinical practice.",2019,"","","","",158,"2022-07-13 09:37:36","","10.20529/ijme.2019.074","","",,,,,5,1.67,1,5,3,"Artificial intelligence (AI) technologies are facilitating the work of modern healthcare organisations to leverage the power of big data in clinical practice. In most cases, AI-based systems improve clinical decision-making using multiple layers of information and pre-specified algorithms. In addition, recent AI technologies like machine learning can learn from existing data and perform predictive operations resulting in a robust performance in clinical settings. Such innovations are likely to serve the healthcare industry by minimising human error, savings costs, and maximising informed decision-making. However, critical challenges may affect the applications of AI in clinical settings, which include the effects on patient-provider communication, safety and efficacy of health services, and humane aspects of caregiving.","",""
2,"D. Silva, Zhibo Pang, Evgeny Osipov, V. Vyatkin","Guest Editorial: Special Section on Developments in Artificial Intelligence for Industrial Informatics",2019,"","","","",159,"2022-07-13 09:37:36","","10.1109/TII.2019.2913769","","",,,,,2,0.67,1,4,3,"The emergence of artificial intelligence (AI), empowered by robust computing infrastructure and abundance of data, maintains potential for radical transformation of human society, essentially a third phase in evolution. Numerous research endeavor, policy development, and thought-leadership are presently in progress aimed at discovering data-driven intelligent decision-making solutions for smart cities, smart grids, smart homes, and informed citizens as well as addressing potential risks posed by AI workplace automation. Joining this broad effort, this Special Section contributes six research articles that consolidate recent developments in AI for industrial informatics.","",""
4,"Wenjie Ling, Guishen Yu, Zhaofeng Li","Lower Limb Exercise Rehabilitation Assessment Based on Artificial Intelligence and Medical Big Data",2019,"","","","",160,"2022-07-13 09:37:36","","10.1109/ACCESS.2019.2939006","","",,,,,4,1.33,1,3,3,"This paper firstly compares the common virtual reality technology production methods, determines the reasonable lower limb rehabilitation exercise modeling method, establishes a more accurate human lower limb musculoskeletal rehabilitation posture mechanism model, analyzes the passive movement work mode of lower limb rehabilitation exercise, and simulates the changes of human musculoskeletal changes during passive movement of lower limb rehabilitation which exercise robots were analyzed. Secondly, the research is on robust controller for omni-directional mobile lower limb rehabilitation based on artificial intelligence and medical big data. The error dynamic model of omni-directional moving lower limb rehabilitation exercise system is established, and the technical problems of standard design, dissipative and gain are analyzed. By constructing the storage function and using the inverse push method, the nonlinear robust controller for omnidirectional moving lower limb rehabilitation motion is designed. The stability of this control law is proved based on Lyapunov’s theorem. Finally, an experimental study on the omni-directional moving lower limb rehabilitation exercise system and rehabilitation evaluation system. Seven human gait and online detection methods for rehabilitation exercise were proposed. The simulation study on the omni-directional moving lower limb rehabilitation robot using nonlinear robust controller is carried out to verify the effectiveness and correctness of the lower limb exercise rehabilitation method.","",""
9,"Cecilia S Lee, Aaron Y. Lee","How Artificial Intelligence Can Transform Randomized Controlled Trials",2020,"","","","",161,"2022-07-13 09:37:36","","10.1167/tvst.9.2.9","","",,,,,9,4.50,5,2,2,"With the advent of deep learning (DL), the application of artificial intelligence (AI) and big data in healthcare has started transforming the way we approach medicine including clinical trials.1,2 The randomized controlled trial (RCT) has been traditionally accepted as the most robust method of assessing the risks and benefits of any intervention.3 However, the undertaking of an RCT is not always feasible due to the rarity of the disease, or time and costs that would impinge on the healthcare system. AI is an academic discipline founded in 1956.4 Machine learning (ML) is a subfield of AI that can learn complex relationships or patterns from data and make accurate decisions.5 DL or deep artificial networks are a relatively new subfield of ML that takes advantage of powerful computational processing capacity provided by Graphic Processing Units and exponentially increasing datasets from medical records, images, multi-omics, and other “Big Data”.6 By feeding an enormous amount of data in training, a DL algorithm allows the model to alter its internal parameters between each neuronal layer to increase its performance. Applications of AI, DL in particular, have been successful in ophthalmic imaging research,7–10 and the application of AI in RCTs may become reality in the near future. Common pitfalls of unsuccessful RCTs include poor patient selection, inadequate randomization with residual confounders, insufficient sample size, and poor selection of end points.11 With well-curated large datasets that incorporate clinical and multimodal imaging, AI models can be trained to select the potential study participants without relying on costly manual review to predict the natural history of each study participants with advanced statistical methods, and to assess study end points in a data-driven method. Given these advantages, the application of AI has potentials for more efficient execution and greater statistical power than what would be expected from traditional RCTs. First, ML models can drastically improve the patient selection process, thus lowering the burden of individual screening and need for large sample sizes. Recruiting the patients who meet precise selection criteria is crucial to avoid potential confounders or misclassifications. ML can combine multimodal data, such as imaging, laboratory, and other complex -omics data, to screen and select patients who match complex inclusion criteria, which can improve the recruitment efficiency. This is one of the areas in which the American Academy of Ophthalmology’s Intelligent Research in Sight (IRIS) data will be utilized for RCT recruitment (personal communication, Flora Lum, MD). In addition to the efficient selection process, having a sufficient sample size to enable detection of statistically significant differences between groups is critical. Many RCTs require a large sample size because the effect of the treatment in question is small.12 AI has the potential in selecting “the ideal”patients for RCTs, who are “fast progressors” of the disease based on the AI’s predictive algorithm. Thus, the expected effect size will be large and required sample size will be small resulting in a much shorter duration of RCTs. Selecting the “fast progressors” alone will limit the generalizability of the trial results; however, it may expedite the development of novel therapies, in particular for rare diseases. Second, AI-generated end points have the potential to minimize measurement errors and analyze the data without human-imposed biases. Furthermore, algorithms may enable more sensitive quantification of key study end points than how they are traditionally measured. For example, central macular","",""
29,"Brandon Malone, Boris Simovski, Clément Moliné, Jun Cheng, Marius Gheorghe, Hugues Fontenelle, Ioannis Vardaxis, Simen Tennøe, Jenny-Ann Malmberg, R. Stratford, T. Clancy","Artificial intelligence predicts the immunogenic landscape of SARS-CoV-2 leading to universal blueprints for vaccine designs",2020,"","","","",162,"2022-07-13 09:37:36","","10.1038/s41598-020-78758-5","","",,,,,29,14.50,3,11,2,"","",""
0,"Aabid Ali","Artificial Intelligence",2021,"","","","",163,"2022-07-13 09:37:36","","10.1017/9781009036719.007","","",,,,,0,0.00,0,1,1,"Artificial Intelligence may be defined as intelligence displayed by machines, systems or agents or by entities other than living beings. Apparently, the term seems simple but the definition bears deeper connotations. The terms intelligence and creativity have long been the prerogatives associated with the humans or have been the privileges enjoyed by them since the dawn of the creation. The views ‘creativity is computation’ or ‘cognition is computation’ and ‘mind as machine’ has offset the traditional theories, assumptions and interpretations held so far in the philosophy and theory of mind. AI’s push to impart intelligence to non-human entities to enable them to behave intelligently and creatively or as Boden would put it “to make computers do the sort of things that minds can do” (Boden 1) has challenged the very traditional fabric of our perception and comprehension, conception and construction related to our learning and living dispensations.","",""
0,"R. Hariharan, P. He, C. Hickman, J. Chambost, C. Jacques, M. Hentschke, B. Cunegatto, C. Dutra, A. Drakeley, Q. Zhan, R. Miller, G. Verheyen, M. Rosselot, S. Loubersac, K. Kelley","P–165 Using Artificial Intelligence to Classify Embryo Shape: An International Perspective",2021,"","","","",164,"2022-07-13 09:37:36","","10.1093/humrep/deab130.164","","",,,,,0,0.00,0,15,1,"      Is a pre-trained machine learning algorithm able to accurately detect cellular arrangement in 4-cell embryos from a different continent?        Artificial Intelligence (AI) analysis of 4-cell embryo classification is transferable across clinics globally with 79% accuracy.        Previous studies observing four-cell human embryo configurations have demonstrated that non-tetrahedral embryos (embryos in which cells make contact with fewer than 3 other cells) are associated with compromised blastulation and implantation potential. Previous research by this study group has indicated the efficacy of AI models in classification of tetrahedral and non-tetrahedral embryos with 87% accuracy, with a database comprising 2 clinics both from the same country (Brazil). This study aims to evaluate the transferability and robustness of this model on blind test data from a different country (France).        The study was a retrospective cohort analysis in which 909 4-cell embryo images (“tetrahedral”, n = 749; “non-tetrahedral”, n = 160) were collected from 3 clinics (2 Brazilian, 1 French). All embryos were captured at the central focal plane using Embryoscope™ time-lapse incubators. The training data consisted solely of embryo images captured in Brazil (586 tetrahedral; 87 non-tetrahedral) and the test data consisted exclusively of embryo images captured in France (163 tetrahedral; 72 non-tetrahedral).        The embryo images were labelled as either “tetrahedral” or “non-tetrahedral” at their respective clinics. Annotations were then validated by three operators. A ResNet–50 neural network model pretrained on ImageNet was fine-tuned on the training dataset to predict the correct annotation for each image. We used the cross entropy loss function and the RMSprop optimiser (lr = 1e–5). Simple data augmentations (flips and rotations) were used during the training process to help counteract class imbalances.        Our model was capable of classifying embryos in the blind French test set with 79% accuracy when trained with the Brazilian data. The model had sensitivity of 91% and 51% for tetrahedral and non-tetrahedral embryos respectively; precision was 81% and 73%; F1 score was 86% and 60%; and AUC was 0.61 and 0.64. This represents a 10% decrease in accuracy compared to when the model both trained and tested on different data from the same clinics.        Although strict inclusion and exclusion criteria were used, inter-operator variability may affect the pre-processing stage of the algorithm. Moreover, as only one focal plane was used, ambiguous cases were interpoloated and further annotated. Analysing embryos at multiple focal planes may prove crucial in improving the accuracy of the model.  Wider implications of the findings: Though the use of machine learning models in the analysis of embryo imagery has grown in recent years, there has been concern over their robustness and transferability. While previous results have demonstrated the utility of locally-trained models, our results highlight the potential for models to be implemented across different clinics.        Not applicable ","",""
0,"Dr. Payal K. Chandel, Siddharth Shahi","Converging Paths of Neuropsychology, Positivism and Artificial Intelligence",2021,"","","","",165,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,2,1,"There have been enormous debate upon Artificial Intelligence being a friend or foe to humankind. But a statement by Yann LeCun in which he said – “ Our intelligence is what makes us human, and AI is an extension of that quality” has very clearly pointed out that the concept of Artificial Intelligence is for the up gradation of human race and not for its end. In this paper an effort has been made to understand how Neuropsychology, Positivism and Artificial Intelligence work for a similar objective which is enhancement of human life, with so much difference within the mechanisms of these three disciplines. For this, we studied and explored a no. of articles associated with all these three domains and examined their working in order to gain a better understanding. We scrutinized some specific aspects and analyzed their behaviour in these three fields. From the review of studies it is pretty evident that AI does train the systems that can mimic human brain, carry out almost every function that a human brain does, and thus the concept of AI goes parallel to Neuropsychology, Neuroscience and the theory of Positivism which is about learning by sensation and interpretation from the environment.","",""
0,"C. D. Wagter, Federico Paredes-Vall'es, N. Sheth, G. D. Croon","The Artificial Intelligence behind the winning entry to the 2019 AI Robotic Racing Competition",2021,"","","","",166,"2022-07-13 09:37:36","","10.55417/fr.2022042","","",,,,,0,0.00,0,4,1,"Robotics is the next frontier in the progress of Artificial Intelligence (AI), as the real world in which robots operate represents an enormous, complex, continuous state space with inherent realtime requirements. One extreme challenge in robotics is currently formed by autonomous drone racing. Human drone racers can fly through complex tracks at speeds of up to 190 km/h. Achieving similar speeds with autonomous drones signifies tackling fundamental problems in AI under extreme restrictions in terms of resources. In this article, we present the winning solution of the first AI Robotic Racing (AIRR) Circuit, a competition consisting of four races in which all participating teams used the same drone, to which they had limited access. The core of our approach is inspired by how human pilots combine noisy observations of the race gates with their mental model of the drone’s dynamics to achieve fast control. Our approach has a large focus on gate detection with an efficient deep neural segmentation network and active vision. Further, we make contributions to robust state estimation and risk-based control. This allowed us to reach speeds of 9.2m/s in the last race, unrivaled by previous autonomous drone race competitions. Although our solution was the fastest and most robust, it still lost against one of the best human pilots, Gab707. The presented approach indicates a promising direction to close the gap with human drone pilots, forming an important step in bringing AI to the real world.","",""
0,"I. Mohammed","ARTIFICIAL INTELLIGENCE: THE KEY TO SELF-DRIVING IDENTITY GOVERNANCE",2021,"","","","",167,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,1,1,"The main goal of this article is to examine how artificial intelligence is playing an increasingly important role in advancing identity governance. The speed of global digital change is accelerating, and businesses are under increasing pressure to guarantee that their technology can keep up with the times. Today's headlines often include stories about high-profile data leakage, which have a significant impact on a company's image and financial health [1]. The moment has come for businesses to invest in AIpowered identity security to remain abreast of security and compliance risks. Information technology, a shifting workforce, and an onslaught of compliance regulations have brought an unprecedented number of users, points of access, apps, and data, to the point that IT departments are struggling to stay up [1]. A human-centric approach to identity security can only scale so far, and with it comes inaccuracy in risk identification. Security requirements are becoming more complicated, decentralized, and integrated with business operations, owing to new methods of working enabled by cloud technology [2]. This implies that robust identity governance and access control are more critical than ever. In this paper, we examine the current status of the information technology environment and explain how artificial intelligence will help companies address their present issues relating to identity governance.","",""
0,"P. Bombicz","Artificial Intelligence and Machine Learning in Crystallography Editorial for Crystallography Reviews, Issue 2 of Volume27, 2021",2021,"","","","",168,"2022-07-13 09:37:36","","10.1080/0889311x.2021.2000094","","",,,,,0,0.00,0,1,1,"“Everythingwe love about civilization is a product of intelligence, so amplifying our human intelligence with artificial intelligence has the potential of helping civilization flourish like never before – as long as wemanage to keep the technology beneficial.” saidMax Tegmark, President of the Future of Life Institute [1]. There is half a century of evolution behind artificial intelligence (AI) and machine learning (ML). The exponentially developing technology can do a good job at narrow tasks for example in mathematics, modelling climate change, internet searches, facial recognition, speech recognition, driving autonomous cars, customer service, playing chess, or Facebook uses algorithms to block content that breaks its rules. It can be applied in automated stock trading, it is offered for the commercial sectors, solving business problems for public and private sectors. Science fiction often portrays artificial intelligence with human-like characteristics, which emerges conversations about the impact on society and around the ethics of AI. Artificial General or Super Intelligence is a theoretical form of AI, where it would have a self-aware consciousness that had the ability to solve problems surpassing the intelligence and capacity of the human brain. An example isHAL, the rogue computer assistant in 2001: A Space Odyssey. Back to reality, algorithms cannot understand the essence of humans: emotion, morality, culture, since these abilities cannot be expressed in mathematical equations. Artificial Intelligence enables problem-solving by the combination of computer science and robust datasets. Machine learning is the subfields of artificial intelligence. Deep learning refers to a neural network, which comprise of multiple hidden layers between the input and output layers. Machine learning and deep learning differs in the way how their algorithms learn.Machine learning ismore dependent on human intervention, what determines the hierarchy of features. A deep learning-based systemwould be able to achieve the same task in a much shorter time. MelanieVollmar andGwyndaf Evans from theDiamondLight Source Ltd., and from the Rosalind Franklin Institute, respectively, both in Harwell Science and Innovation Campus, Didcot, UK, review the “Machine learning applications in macromolecular X-ray crystallography” in Issue 2 of Volume 27 of Crystallography Reviews. We can quickly understand why introducing Artificial Intelligence is somuch investigated and needed at the Diamond Light Source reading the facts: throughout 2020 user access to MX beamlines was almost exclusively remote, in the 11 months from June 2020 over 33,000 data sets were measured, typically less than 3minutes being used for each crystal sample, the yearly quantities of measured data reach many Petabyte. We may learn from the article that AI can contribute to the question of crystallisability, to the detection of the presence of crystals in crystallisation trials, to forecast of experimental data and data analysis outcome, to have real-time","",""
0,"Nikolaos Siafakas","Do We Need a Hippocratic Oath for Artificial Intelligence Scientists?",2022,"","","","",169,"2022-07-13 09:37:36","","10.1609/aimag.v42i4.15090","","",,,,,0,0.00,0,1,1,"Artificial intelligence (AI) has been beneficial for humanity, improving many human activities. However, there are now significant dangers that may increase when AI reaches a human level of intelligence or superintelligence. It is paramount to focus on ensuring that AI is designed in a manner that is robustly beneficial for humans. The ethics and personal responsibilities of AI scientists could play an important role in continuing the constructive use of AI in the future. Lessons can be learnt from the long and successful history of medical ethics. Therefore, a Hippocratic Oath for AI scientists may increase awareness of the potential lethal threats of AI, enhance efforts to develop safe and beneficial AI to prevent corrupt practices and manipulations and invigorate ethical codes. The Hippocratic Oath in medicine, using simple universal principles, is a basis of human ethics, and in an analogous way, the proposed oath for AI scientists could enhance morality beyond biological consciousness and spread ethics across the universe.","",""
0,"I. Sivanarayana, J. Chandra, A. Rani","NEURAL COMPUTING IN ARTIFICIAL INTELLIGENCE – A REVIEW",2021,"","","","",170,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,3,1,"This paper presents a new perspective of Artificial Intelligence (AI). Although, number of attempts has been made to make an artifact intelligent, including evolution theory, neural network etc and a number of problems have been solved using these concepts but each of this theory covers only some aspect of human intelligence. Still there is a large gap between artificial intelligence agent and human being. In this paper, we outline the technical issues that need to be addressed in order to meet this challenge, including usability, robustness, and scale. At the same time it adds the power of two well knows Artificial Intelligence techniques viz. Neural Computing .The paper gives an idea of an artifact which is supposed to match the intelligence and behavior of a human being. Paper also discusses some natural phenomenon and how they can be confirmed by the revised definition of artificial intelligence. The paper does not claim that existing definition of artificial intelligence has some faults. The paper just augments the existing definition by some other features that can make it more close to natural intelligence. The features augmented are naturally inspired similarly as AI, Neural Network and genetics all are naturally inspired. Index Terms Neural Computing, Intelligence.","",""
2,"J. Hernández-Orallo, B. S. Loe, L. Cheke, Fernando Martínez-Plumed, Seán Ó hÉigeartaigh","General intelligence disentangled via a generality metric for natural and artificial intelligence",2021,"","","","",171,"2022-07-13 09:37:36","","10.1038/s41598-021-01997-7","","",,,,,2,2.00,0,5,1,"","",""
1,"H. Yamakawa","Peacekeeping Conditions for an Artificial Intelligence Society",2019,"","","","",172,"2022-07-13 09:37:36","","10.3390/BDCC3020034","","",,,,,1,0.33,1,1,3,"In a human society with emergent technology, the destructive actions of some pose a danger to the survival of all of humankind, increasing the need to maintain peace by overcoming universal conflicts. However, human society has not yet achieved complete global peacekeeping. Fortunately, a new possibility for peacekeeping among human societies using the appropriate interventions of an advanced system will be available in the near future. To achieve this goal, an artificial intelligence (AI) system must operate continuously and stably (condition 1) and have an intervention method for maintaining peace among human societies based on a common value (condition 2). However, as a premise, it is necessary to have a minimum common value upon which all of human society can agree (condition 3). In this study, an AI system to achieve condition 1 was investigated. This system was designed as a group of distributed intelligent agents (IAs) to ensure robust and rapid operation. Even if common goals are shared among all IAs, each autonomous IA acts on each local value to adapt quickly to each environment that it faces. Thus, conflicts between IAs are inevitable, and this situation sometimes interferes with the achievement of commonly shared goals. Even so, they can maintain peace within their own societies if all the dispersed IAs think that all other IAs aim for socially acceptable goals. However, communication channel problems, comprehension problems, and computational complexity problems are barriers to realization. This problem can be overcome by introducing an appropriate goal-management system in the case of computer-based IAs. Then, an IA society could achieve its goals peacefully, efficiently, and consistently. Therefore, condition 1 will be achievable. In contrast, humans are restricted by their biological nature and tend to interact with others similar to themselves, so the eradication of conflicts is more difficult.","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",173,"2022-07-13 09:37:36","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
3,"M. Iqbal","Active Surveillance for COVID-19 through artificial intelligence using concept of real-time speech-recognition mobile application to analyse cough sound.",2020,"","","","",174,"2022-07-13 09:37:36","","10.31219/osf.io/cev6x","","",,,,,3,1.50,3,1,2,"In view of recent coronavirus (SARS-CoV2) outbreak, we propose a novel model of active surveillance for COVID-19 through artificial intelligence. Both past and recent events of viral disease outbreaks have shown us that we do not have effective methods to screen the whole population and efforts are failing to stop the pandemics. Moreover, at this stage, social distancing and home quarantine are only measures to stop the spread of COVID-19 infection. The purpose of our project is to introduce a robust method of using speech-recognition techniques through a mobile application in analysing cough sounds of suspected people, who previously were healthy, suffering from a respiratory ailment and actively monitor the progress of their symptoms in real-time. The mobile application will give feedback to the app users on a routine basis and advise to take medication and necessary precautions to avoid spreading of the infection. The app will also notify the local healthcare facilities about sick users or vice-versa if their symptoms deteriorates. A feedback will be sent to an app-centre notifying the number of both new and old sick users appeared in a particular region. With the data compiled at the app-centre, we will also be able to trace the disease spread patterns, categorise the regions in three levels- mild, moderate and severe based on the number of sick users and deploy the resources accordingly to stop the transmission hence, preventing unnecessary use of both human and medical resources to stop the infection in redundant regions.","",""
3,"J. Banja","Obviously You, Maybe You, Artificial You: Exploring the Impact of Artificial Intelligence Technologies on Consciousness and Personal Identity",2020,"","","","",175,"2022-07-13 09:37:36","","10.1080/21507740.2020.1740349","","",,,,,3,1.50,3,1,2,"In the acknowledgements section of her 2019 book Artificial You, Susan Schneider relates that “This book was a delight to write.” (Schneider 2019, 153) It shows. The book is a delight to read. Artificial You is relatively short and, thankfully, without a lot of neurophilosophical jargon. Its primary objective is to present a multi-faceted exploration of how artificial intelligence (AI) and its related technologies might challenge our understanding of consciousness and our moral attitudes toward nonhumans, maybe-humans, and post humans. The first chapters of Schneider’s book explore what it would mean for an AI model to be conscious. Schneider’s initial response is the familiar: Consciousness means “it feels like something to be you.” (16) I’ve always found that characterization too obscure. Consider the robust conversation around whether slime molds are conscious (Skiles 2019). Slime molds don’t possess anything resembling the molecular constitution of neurons and neural networks, but they exhibit astonishingly intelligent-like, acutely adaptive responses to their environments. Whether they are conscious is baffling on two counts: It seems doubtful that they have a feeling of being aware, so they have no awareness of what it’s like to be them. But even if they did, how could humans know it? And if we could know it, what ethical platforms would we use to assess whether that awareness would be morally significant? Some microbiologists claim that slime molds have rudimentary consciousness while a “feeling like something to be you” implies a self-awareness that only certain higher vertebrates possess. My graduate days spent studying Husserl led me to understand consciousness as awareness of something, whose sophistication or acuity exists on a continuum—from a slime mold’s awareness of nutrients in its biomolecular environments to the exhausting self-awareness of a Kierkegaard or Henry James. But leaving the matter of “feeling like something to be you” unanswered allows Schneider a certain latitude in exploring the intersection of AI or advanced technologies with human cognition and identity. Thus, she asks early in the book: If humans choose to enhance themselves with advanced hardware like brain microchips that can dramatically improve memory or thinking, is there a point at which the accumulation of those enhancements would fracture our sense of identity and transcend our “humanness”? This problem is especially interesting if we consider the transhumanist aspiration of uploading one’s consciousness onto a computer. Schneider makes the provocative observation that a human consciousness previously subserved by human neurons but now uploaded into a computer whose mechanical substrate consists of transistorized parts no longer seems a human consciousness. When I upload my consciousness to a computer, what does consciousness “become”? Furthermore, if an essential aspect of human consciousness is my awareness of myself, especially understanding (or feeling) myself as patterns of neural events that enable and integrate memory, behaviors, cognitions and the like, then transmogrifying those neurological patterns into entirely new, artificial ones that a computer can run casts enormous doubt on whether they have retained their essential “humanness.” Again, when I upload my consciousness to a computer, what does it become? Do I remain me? Does it matter? Schneider argues that it certainly does matter as nothing short of the deepest moral questions humanity can pose to itself are at stake. Of course, a computer can be programed to relate what it feels like to be it. But how would we evaluate the moral status of a sophisticated, future AI whose cognitive and","",""
149,"Tarek R. Besold, A. Garcez, Sebastian Bader, H. Bowman, Pedro M. Domingos, P. Hitzler, Kai-Uwe Kühnberger, L. Lamb, Daniel Lowd, P. Lima, L. Penning, Gadi Pinkas, Hoifung Poon, Gerson Zaverucha","Neural-Symbolic Learning and Reasoning: A Survey and Interpretation",2017,"","","","",176,"2022-07-13 09:37:36","","10.3233/faia210348","","",,,,,149,29.80,15,14,5,"The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.","",""
7,"G. Porenta","Is There Value for Artificial Intelligence Applications in Molecular Imaging and Nuclear Medicine?",2019,"","","","",177,"2022-07-13 09:37:36","","10.2967/jnumed.119.227702","","",,,,,7,2.33,7,1,3,"Core competencies in molecular imaging and nuclear medicine include imaging with radioactive isotopes, pattern recognition, image interpretation, and report communication. In diagnostic imaging, nuclear medicine physicians communicate with referring physicians to establish indications for imaging studies, perform or supervise imaging procedures to obtain high-quality images, interpret images to compile medical reports, and communicate results to inform patients and their referring doctors. In many of these tasks, computers already are indispensable tools that enable or assist the work of physicians. How does artificial intelligence (AI) fit into this workflow (Fig. 1)? There is no universal definition of AI (1), but in the context of practical applications, AI can be considered a scientific discipline that uses computers to perform tasks usually requiring human cognition. Research topics on AI include pattern recognition, natural language processing, machine learning, problem solving, and knowledge representation. Thus, AI techniques apply to many core competencies in metabolic imaging and nuclear medicine, and this has led to an enormous interest and even hype about AI in medical imaging (2). AI applications at present dominate the technical exhibitions of international imaging conferences such as the 2019 European Congress of Radiology (https://ecronline.myesr.org/ecr2019/) and are prominently featured in the product portfolios of most commercial companies of medical imaging technology. AI applications have enabled a multibillion-dollar business model for the large Internet companies penetrating the consumer market in many ways, including Internet searches, social networks, or smartphone software. In consumer markets, value is measured by the willingness of a consumer to use or pay for a product. Therefore, the value of AI applications in consumer markets depends not on an intrinsic objective value but the perception of the customer. This value concept is well illustrated by a quote attributed to Charles Revson, the founder of a cosmetics company: ‘‘In the factory we make cosmetics, in the store we sell hope.’’ However, in medicine the business model and the value concept of a consumer market do not apply. Hope is essential when taking care of patients, but hope cannot serve as the foundation for medical decision making and patient stratification. Several decades ago, patients with extrasystoles after a myocardial infarction were commonly treated with antiarrhythmic drugs in the hope of preventing arrhythmic death. A large, randomized multicenter trial uncovered this hope as a deadly illusion and established that the antiarrhythmic therapy in fact increased arrhythmic mortality and caused premature death in thousands of patients. From this trial and others that were able to scientifically disprove suggested or assumed benefits based on hope and hype, rigorous and often laborious scientific methods have emerged that permit establishing, grading, or disproving the value of diagnostic and therapeutic procedures. For patients, value is generated if quality of life is improved, morbidity is reduced, or preventable mortality is eliminated. It is difficult or impossible for both patients and physicians to directly assess the value of medical products, interventions, or technology. Thus, science is essential to firmly guide patient care. International guidelines compiled by professional societies assess the value of diagnostic and therapeutic methods based on scientific evidence and, for each method, clearly state the class of recommendation for a particular use with an associated level of evidence. This science-based model of grading value for patient care has been universally adopted in the medical community. Currently, there is little scientific evidence for the value of AI applications in medical imaging. Several AI applications have received Food and Drug Administration approval (3), but this does not imply that AI applications at present are relevant for medical practice or that their value has been firmly established. Most AI applications are built from 3 essential components: complex computer algorithms, extensive computing resources, and large data sets. Algorithms and computing facilities are easily available at little or no cost. Many powerful AI algorithms are published as opensource code, such as TensorFlow (https://www.tensorflow.org) and Core ML (https://developer.apple.com/machine-learning/). Extensive computing power is offered instantaneously on demand through the large Internet companies. Recently, even smartphones have been equipped with high-power computing hardware, including neural network chips that enable intensive AI applications, such as facial identification or speech recognition. In contrast, large data sets are more difficult to collect and thus are the most critical component when building AI applications. Data are more important than hardware or software in determining the success of AI applications (4). Even highly complex AI algorithms cannot compensate for incomplete, inadequate, or low-quality data collection. Thus, the characteristics and validity of data sets need to be firmly established and made fully transparent when AI applications are investigated for a proposed clinical purpose. Collaborative efforts are frequently required to compile the large data sets, which need to include many thousands of data entries. Recently, the Mozilla Common Voice project (https://voice. mozilla.org/en) has published an open-source multilanguage data set of voice recordings from 40,000 people in 18 languages to foster and enable research in natural language processing. If AI applications are to be applied successfully in medical imaging, Received Mar. 18, 2019; revision accepted Apr. 3, 2019. For correspondence or reprints contact: Gerold Porenta, Ambulatorium Döbling, Heiligenstädterstrasse 62-64, 1190 Vienna, Austria. E-mail: gerold@porenta.com Published online May 3, 2019. COPYRIGHT© 2019 by the Society of Nuclear Medicine and Molecular Imaging. DOI: 10.2967/jnumed.119.227702","",""
11,"A. Ran, Jian Shi, Amanda K Ngai, Wai-Yin Chan, Poemen P. Chan, A. Young, Hon-Wah Yung, C. Tham, C. Cheung","Artificial intelligence deep learning algorithm for discriminating ungradable optical coherence tomography three-dimensional volumetric optic disc scans",2019,"","","","",178,"2022-07-13 09:37:36","","10.1117/1.NPh.6.4.041110","","",,,,,11,3.67,1,9,3,"Abstract. Spectral-domain optical coherence tomography (SDOCT) is a noncontact and noninvasive imaging technology offering three-dimensional (3-D), objective, and quantitative assessment of optic nerve head (ONH) in human eyes in vivo. The image quality of SDOCT scans is crucial for an accurate and reliable interpretation of ONH structure and for further detection of diseases. Traditionally, signal strength (SS) is used as an index to include or exclude SDOCT scans for further analysis. However, it is insufficient to assess other image quality issues such as off-centration, out of registration, missing data, motion artifacts, mirror artifacts, or blurriness, which require specialized knowledge in SDOCT for such assessment. We proposed a deep learning system (DLS) as an automated tool for filtering out ungradable SDOCT volumes. In total, 5599 SDOCT ONH volumes were collected for training (80%) and primary validation (20%). Other 711 and 298 volumes from two independent datasets, respectively, were used for external validation. An SDOCT volume was labeled as ungradable when SS was <5 or when any artifacts influenced the measurement circle or >25  %   of the peripheral area. Artifacts included (1) off-centration, (2) out of registration, (3) missing signal, (4) motion artifacts, (5) mirror artifacts, and (6) blurriness. An SDOCT volume was labeled as gradable when SS was ≥5, and there was an absence of any artifacts or artifacts only influenced <25  %   peripheral area but not the retinal nerve fiber layer calculation circle. We developed and validated a 3-D DLS based on squeeze-and-excitation ResNeXt blocks and experimented with different training strategies. The area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and accuracy were calculated to evaluate the performance. Heatmaps were generated by gradient-weighted class activation map. Our findings show that the presented DLS achieved a good performance in both primary and external validations, which could potentially increase the efficiency and accuracy of SDOCT volumetric scans quality control by filtering out ungradable ones automatically.","",""
0,"Bartłomiej Szlachta","Artificial intelligence in iris recognition",2019,"","","","",179,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,1,3,"Containing many characteristic points, human iris is unique for each person. This gives an opportunity to successfully implement people authentication by iris images in many life areas, for example to secure sensitive data. The most difficult part of iris recognition is to extract the iris characteristic points and to compare them with those extracted from other iris image. During our research, selected artificial intelligence methods such as Speeded Up Robust Features and Soft sets has been analysed in regard of recognizing people by their iris image. As a result, three application concepts has been described and proposed. Two of them have been also implemented and tested on thousand of iris images. The results have been presented and compared in order to find the most suitable method for iris recognition. Moreover, possible concepts future improvements have been described in order to allow recognition effectiveness improvement.","",""
0,"Pooja Gundagurti","Artificial Intelligence and its associated application in medical field",2019,"","","","",180,"2022-07-13 09:37:36","","","","",,,,,0,0.00,0,1,3,"Prediction is a crucial facet within the medical domain. This paper encourages the utilization of Artificial Intelligence for prediction in medical life as technological support. There's a powerful impact upon all activities because of health, and human consultants should have the power to choose the adequate treatment which is able to be the evolution of the patient throughout the treatment. Since the mechanisms of AI have many advantages that are appropriate for this, it assists human intelligence in decision-making/prediction. The preciseness of mathematics and also the power of current technologies are the two robust qualities used in the system when they are combined to produce positive options as a result.","",""
0,"Yaxin Peng, S. Du, T. Zeng","Preface: Special Issue on Optimization Models and Algorithms in Artificial Intelligence",2019,"","","","",181,"2022-07-13 09:37:36","","10.1007/s40305-019-00278-5","","",,,,,0,0.00,0,3,3,"","",""
2,"King-Ho Leung","The Picture of Artificial Intelligence and the Secularization of Thought",2019,"","","","",182,"2022-07-13 09:37:36","","10.1080/1462317X.2019.1605725","","",,,,,2,0.67,2,1,3,"ABSTRACT This article offers a critical interpretation of Artificial Intelligence (AI) as a philosophical notion which exemplifies a secular conception of thinking. One way in which AI notably differs from the conventional understanding of “thinking” is that, according to AI, “intelligence” or “thinking” does not necessarily require “life” as a precondition: that it is possible to have “thinking without life.” Building on Charles Taylor’s critical account of secularity as well as Hubert Dreyfus’ influential critique of AI, this article offers a theological analysis of AI’s “lifeless” picture of thinking in relation to the Augustinian conception of God as “Life itself.” Following this critical theological analysis, this article argues that AI’s notion of thinking promotes a societal privilege of certain rationalistic or calculative ways of thought over more existential or spiritual ways of thinking, and thereby fosters a secularization or de-spiritualization of thinking as an ethical human practice.","",""
2,"Jacques Biot","How will clinical practice be impacted by artificial intelligence?",2019,"","","","",183,"2022-07-13 09:37:36","","10.1684/ejd.2019.3536","","",,,,,2,0.67,2,1,3,"Currently, artificial intelligence (AI) heavily impacts all human activities, including medicine, where needs for data analysis and interpretation are high and where technology opens new perspectives. Considering that current treatments do not always cure all patients and may even harm certain of them, we have to recognize that AI may fill a great medical need, potentially supporting physicians’ efforts to refine diagnosis and to improve the relevance of the clinical diagnosis for each patient. As in other industries, this challenge implies changes in the repartition of medical and paramedical tasks. As repetitive tasks will disappear in the wake of automation, health care providers will ultimately regain truly an opportunity to focus on medicine, thereby ensuring an individual and holistic approach to each patient.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",184,"2022-07-13 09:37:36","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
14,"K. Kusunose","Steps to use artificial intelligence in echocardiography",2020,"","","","",185,"2022-07-13 09:37:36","","10.1007/s12574-020-00496-4","","",,,,,14,7.00,14,1,2,"","",""
0,"H. Mcgrath, Colin Flanagan, Liaoyuan Zeng, Yiming Lei","Future of Artificial Intelligence in Anesthetics and Pain Management",2019,"","","","",186,"2022-07-13 09:37:36","","10.4236/jbm.2019.711010","","",,,,,0,0.00,0,4,3,"The potential of the second wave of Artificial Intelligence (AI) to change our lives beyond recognition is both exciting and challenging. AI has been around for over three decades, and this new approach of artificial intelligence, due to enhancements in technology, both software, and hardware, has resulted in the fact that human decision-making is considered inferior and erratic in many fields: none more so than medicine. Machine learning algorithms with access to large data sets can be trained to outperform clinicians in many respects. AI’s effectiveness in accurate diagnosis of various medical conditions and medical image interpretation is well documented. Modern AI technology has the potential to transform medicine to a level never seen before in terms of efficiency and accuracy; but is also potentially highly disruptive, creating insecurity and allowing the transfer of expert domain knowledge to machines.  Anesthetics is a complex medical discipline and assuming AI can easily replace experienced and knowledgeable medical practitioners is a very unrealistic expectation. AI can be used in anesthetics to develop, in some respects, more advanced clinical decision support tools based on machine learning. This paper focuses on the complexity of both AI developments, deep learning, neural networks, etc. and opportunities of AI in anesthetics for the future. It will review current advances in AI tools and hardware technologies as well as outlining how these can be used in the field of anesthetics.","",""
0,"E. Shekhovtsova","The topic of artificial intelligence in the anti-utopian novel by Alexander Zinoviev, “The Global Humane”: author's warnings and predictions",2019,"","","","",187,"2022-07-13 09:37:36","","10.18254/s258770110007540-6","","",,,,,0,0.00,0,1,3,"The paper considers the philosophical problems associated with the topic of artificial intelligence, raised by Alexander Zinoviev in his anti-utopia “Global humane”. An attempt is made to philosophical interpretation of the author’s meanings and assessment of the prognostic potentials of the book. The examples of anti-utopian plots examine the probability of primitivization of human intelligence in the era of a new sociopolitical and anthropological reality.","",""
0,"Yuejuan Jing, Jiangtao Wang","Design and Implementation of Work Evaluation Monitoring System under Artificial Intelligence Condition",2019,"","","","",188,"2022-07-13 09:37:36","","10.25236/IJNDES.19301","","",,,,,0,0.00,0,2,3,"At this stage, the development of science and technology in China is extremely fast, and the research of computer artificial intelligence technology is the best interpretation of human wisdom. The algorithm research of artificial intelligence technology continues to penetrate into various aspects. Work evaluation is a kind of human resource management technology and method to determine the relative value of positions. It shows a certain degree of scientificity and objectivity in post evaluation and salary rating. It is widely used in enterprises, but there are also many problems in its use. This paper expounds the related concepts of artificial intelligence technology and job evaluation, and then analyzes the current situation and existing problems in the evaluation of enterprise work in the context of artificial intelligence, and proposes the design and implementation of the work evaluation monitoring system, which is more for the enterprise in practice. Provide a reference for good operational evaluation.","",""
7,"E. Loginov, V. Grigoriev, A. Shkuta, V. Bortalevich, D. Sorokin","The use of artificial intelligence’s elements to block the manifestations of individuals’ behavioral activity going beyond the quasi-stable states",2019,"","","","",189,"2022-07-13 09:37:36","","10.1088/1757-899X/516/1/012028","","",,,,,7,2.33,1,5,3,"The monitoring of the metastable states of individuals as a bifurcation point of development of intellectual dynamics of behavioural activity allows us to identify a set of characteristics of coherent-resonant clusters of manifestations of biophysical factors and information-cognitive nature. Conscious changes in the functioning modes of brain and human nervous system can be achieved by electromagnetic influence or purely informational influence as well as by the combined effect of both these factors. The arrangement of complex processes of informational influence is required to penetrate to the level of conscious (semantic) and unconscious (mental, emotional, meditative) interpretation of events when it is necessary to ensure sufficiently stable cognitive-behavioural stereotypes of individuals and their groups. Convergent informational and electromagnetic effects facilitate the effect on the brain, including the use of neuro-linguistic programming for this element with correction or even a complete change of the reflexive matrix (matrix of key reflexive reactions) with a corresponding change and fixation of the personality-style in the personality events to block the release of behavioural activity of individuals beyond quasi-stable states.","",""
19,"P. Mathur, S. Srivastava, Xiaowei Xu, J. Mehta","Artificial Intelligence, Machine Learning, and Cardiovascular Disease",2020,"","","","",190,"2022-07-13 09:37:36","","10.1177/1179546820927404","","",,,,,19,9.50,5,4,2,"Artificial intelligence (AI)-based applications have found widespread applications in many fields of science, technology, and medicine. The use of enhanced computing power of machines in clinical medicine and diagnostics has been under exploration since the 1960s. More recently, with the advent of advances in computing, algorithms enabling machine learning, especially deep learning networks that mimic the human brain in function, there has been renewed interest to use them in clinical medicine. In cardiovascular medicine, AI-based systems have found new applications in cardiovascular imaging, cardiovascular risk prediction, and newer drug targets. This article aims to describe different AI applications including machine learning and deep learning and their applications in cardiovascular medicine. AI-based applications have enhanced our understanding of different phenotypes of heart failure and congenital heart disease. These applications have led to newer treatment strategies for different types of cardiovascular diseases, newer approach to cardiovascular drug therapy and postmarketing survey of prescription drugs. However, there are several challenges in the clinical use of AI-based applications and interpretation of the results including data privacy, poorly selected/outdated data, selection bias, and unintentional continuance of historical biases/stereotypes in the data which can lead to erroneous conclusions. Still, AI is a transformative technology and has immense potential in health care.","",""
30,"Xinqin Liao, Wei‐ming Song, X. Zhang, Chaoqun Yan, Tianliang Li, Hongliang Ren, Cunzhi Liu, Yongtian Wang, Yuanjin Zheng","A bioinspired analogous nerve towards artificial intelligence",2020,"","","","",191,"2022-07-13 09:37:36","","10.1038/s41467-019-14214-x","","",,,,,30,15.00,3,9,2,"","",""
2,"Á. Alberich-Bayarri, A. Pastor, Rafael López González, Fabio García Castro","How to Develop Artificial Intelligence Applications",2019,"","","","",192,"2022-07-13 09:37:36","","10.1007/978-3-319-94878-2_5","","",,,,,2,0.67,1,4,3,"","",""
3,"Pu Yanan, Yan Jilong, Zhang Heng","Using Artificial Intelligence to Achieve Auxiliary Training of Table Tennis Based on Inertial Perception Data",2021,"","","","",193,"2022-07-13 09:37:36","","10.3390/s21196685","","",,,,,3,3.00,1,3,1,"Compared with optical sensors, wearable inertial sensors have many advantages such as low cost, small size, more comprehensive application range, no space restrictions and occlusion, better protection of user privacy, and more suitable for sports applications. This article aims to solve irregular actions that table tennis enthusiasts do not know in actual situations. We use wearable inertial sensors to obtain human table tennis action data of professional table tennis players and non-professional table tennis players, and extract the features from them. Finally, we propose a new method based on multi-dimensional feature fusion convolutional neural network and fine-grained evaluation of human table tennis actions. Realize ping-pong action recognition and evaluation, and then achieve the purpose of auxiliary training. The experimental results prove that our proposed multi-dimensional feature fusion convolutional neural network has an average recognition rate that is 0.17 and 0.16 higher than that of CNN and Inception-CNN on the nine-axis non-professional test set, which proves that we can better distinguish different human table tennis actions and have a more robust generalization performance. Therefore, on this basis, we have better realized the enthusiast of table tennis the purpose of the action for auxiliary training.","",""
1,"B. A.","Informational Linguistics: Computer, Internet, Artificial Intelligence and Language",2019,"","","","",194,"2022-07-13 09:37:36","","","","",,,,,1,0.33,1,1,3,"Modern technological progress is clearly mediated via the informational and communicational conceptualizations, which are first of all of language nature. Interdependence and syncretism of human cognitive activity create unlimited demand for knowledge interpretation of certain semantic format – information. Informational Linguistics is a discipline, dedicated to the interdisciplinary investigation of the specifics of communication contents.","",""
2,"Karanjeet Choudhary, G. S. Gaba, R. Miglani, Lavish Kansal, Pardeep Kumar","Artificial intelligence and machine learning aided blockchain systems to address security vulnerabilities and threats in the industrial Internet of things",2021,"","","","",195,"2022-07-13 09:37:36","","10.1049/PBTE094E_CH13","","",,,,,2,2.00,0,5,1,"Advent of digital sensors and machines led to a significant acceleration in industrial evolution. The desire to automate industrial processes with minimum human intervention paved the way for the onset of a new era of technological nomenclature called the industrial Internet of things (IIoT). A remarkable feature of IIoT is its underlying architecture which allows the managers/engineers/supervisors to remotely operate and access the performance of their machines. Industries ranging from healthcare, finance, logistics, and power have witnessed a major performance increment and quality stabilization by transforming themselves into an IIoT empowered smart environment. However, this transformation has brought with itself a whole new set of challenges with cybersecurity being the paramount. The vulnerabilities like bugs and broken processes can lead to a serious compromise or even collapse of security mechanisms of IIoT networks. Such a situation will have a devastating impact on the financial health, reputation, and credibility of companies. After an extensive review of existing technologies, we believe that blockchain, artificial intelligence (AI), and machine learning (ML) can complement each other in building a revolutionary deterrent to negate malicious activities that in any form intend to harm the system. While, blockchain offers public/private/consortium relationships, ML and AI, on the other hand, follow the principle of supervised/ unsupervised/reinforcement learning and reactive/memory approaches, respectively. Based on the distributed ledger system, blockchain mechanisms can be aided with self-learning algorithms which will update and strengthen the database by learning each time the system suffers new forms of network attacks and intrusions. This process of learning will help build a robust system which can learn to optimize its deterrence procedures against different forms of attacks. It is due to these overwhelming benefits, blockchain, AI, and ML find applications in smart logistics, predictive maintenance, autonomous vehicles, intelligent manufacturing, and smart grid maintenance.","",""
2,"D. Edwards, Ciara McEnteggart, Y. Barnes-Holmes","A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",2022,"","","","",196,"2022-07-13 09:37:36","","10.3389/fpsyg.2022.745306","","",,,,,2,2.00,1,3,1,"Psychology has benefited from an enormous wealth of knowledge about processes of cognition in relation to how the brain organizes information. Within the categorization literature, this behavior is often explained through theories of memory construction called exemplar theory and prototype theory which are typically based on similarity or rule functions as explanations of how categories emerge. Although these theories work well at modeling highly controlled stimuli in laboratory settings, they often perform less well outside of these settings, such as explaining the emergence of background knowledge processes. In order to explain background knowledge, we present a non-similarity-based post-Skinnerian theory of human language called Relational Frame Theory (RFT) which is rooted in a philosophical world view called functional contextualism (FC). This theory offers a very different interpretation of how categories emerge through the functions of behavior and through contextual cues, which may be of some benefit to existing categorization theories. Specifically, RFT may be able to offer a novel explanation of how background knowledge arises, and we provide some mathematical considerations in order to identify a formal model. Finally, we discuss much of this work within the broader context of general semantic knowledge and artificial intelligence research.","",""
7,"R. Y. Goh, L. Lee, H. Seow, Kathiresan Gopal","Hybrid Harmony Search–Artificial Intelligence Models in Credit Scoring",2020,"","","","",197,"2022-07-13 09:37:36","","10.3390/e22090989","","",,,,,7,3.50,2,4,2,"Credit scoring is an important tool used by financial institutions to correctly identify defaulters and non-defaulters. Support Vector Machines (SVM) and Random Forest (RF) are the Artificial Intelligence techniques that have been attracting interest due to their flexibility to account for various data patterns. Both are black-box models which are sensitive to hyperparameter settings. Feature selection can be performed on SVM to enable explanation with the reduced features, whereas feature importance computed by RF can be used for model explanation. The benefits of accuracy and interpretation allow for significant improvement in the area of credit risk and credit scoring. This paper proposes the use of Harmony Search (HS), to form a hybrid HS-SVM to perform feature selection and hyperparameter tuning simultaneously, and a hybrid HS-RF to tune the hyperparameters. A Modified HS (MHS) is also proposed with the main objective to achieve comparable results as the standard HS with a shorter computational time. MHS consists of four main modifications in the standard HS: (i) Elitism selection during memory consideration instead of random selection, (ii) dynamic exploration and exploitation operators in place of the original static operators, (iii) a self-adjusted bandwidth operator, and (iv) inclusion of additional termination criteria to reach faster convergence. Along with parallel computing, MHS effectively reduces the computational time of the proposed hybrid models. The proposed hybrid models are compared with standard statistical models across three different datasets commonly used in credit scoring studies. The computational results show that MHS-RF is most robust in terms of model performance, model explainability and computational time.","",""
6,"T. York, Heloise Jenney, G. Jones","Clinician and computer: a study on patient perceptions of artificial intelligence in skeletal radiography",2020,"","","","",198,"2022-07-13 09:37:36","","10.1136/bmjhci-2020-100233","","",,,,,6,3.00,2,3,2,"Background Up to half of all musculoskeletal injuries are investigated with plain radiographs. However, high rates of image interpretation error mean that novel solutions such as artificial intelligence (AI) are being explored. Objectives To determine patient confidence in clinician-led radiograph interpretation, the perception of AI-assisted interpretation and management, and to identify factors which might influence these views. Methods A novel questionnaire was distributed to patients attending fracture clinic in a large inner-city teaching hospital. Categorical and Likert scale questions were used to assess participant demographics, daily electronics use, pain score and perceptions towards AI used to assist in interpretation of their radiographs, and guide management. Results 216 questionnaires were included (M=126, F=90). Significantly higher confidence in clinician rather than AI-assisted interpretation was observed (clinician=9.20, SD=1.27 vs AI=7.06, SD=2.13), 95.4% reported favouring clinician over AI-performed interpretation in the event of disagreement. Small positive correlations were observed between younger age/educational achievement and confidence in AI-assistance. Students demonstrated similarly increased confidence (8.43, SD 1.80), and were over-represented in the minority who indicated a preference for AI-assessment over their clinicians (50%). Conclusions Participant’s held the clinician’s assessment in the highest regard and expressed a clear preference for it over the hypothetical AI assessment. However, robust confidence scores for the role of AI-assistance in interpreting skeletal imaging suggest patients view the technology favourably. Findings indicate that younger, more educated patients are potentially more comfortable with a role for AI-assistance however further research is needed to overcome the small number of responses on which these observations are based.","",""
6,"N. Gahungu, Robert Trueick, S. Bhat, P. Sengupta, G. Dwivedi","Current Challenges and Recent Updates in Artificial Intelligence and Echocardiography",2020,"","","","",199,"2022-07-13 09:37:36","","10.1007/s12410-020-9529-x","","",,,,,6,3.00,1,5,2,"","",""
13,"Shen Li, Zigui Wang, L. Visser, E. Wisner, Hao Cheng","Pilot study: Application of artificial intelligence for detecting left atrial enlargement on canine thoracic radiographs",2020,"","","","",200,"2022-07-13 09:37:36","","10.1111/vru.12901","","",,,,,13,6.50,3,5,2,"Abstract Although deep learning has been explored extensively for computer‐aided medical imaging diagnosis in human medicine, very little has been done in veterinary medicine. The goal of this retrospective, pilot project was to apply the deep learning artificial intelligence technique using thoracic radiographs for detection of canine left atrial enlargement and compare results with those of veterinary radiologist interpretations. Seven hundred ninety‐two right lateral radiographs from canine patients with thoracic radiographs and contemporaneous echocardiograms were used to train, validate, and test a convolutional neural network algorithm. The accuracy, sensitivity, and specificity for determination of left atrial enlargement were then compared with those of board‐certified veterinary radiologists as recorded on radiology reports. The accuracy, sensitivity, and specificity were 82.71%, 68.42%, and 87.09%, respectively, using an accuracy driven variant of the convolutional neural network algorithm and 79.01%, 73.68%, and 80.64%, respectively, using a sensitivity driven variant. By comparison, accuracy, sensitivity, and specificity achieved by board‐certified veterinary radiologists was 82.71%, 68.42%, and 87.09%, respectively. Although overall accuracy of the accuracy driven convolutional neural network algorithm and veterinary radiologists was identical, concordance between the two approaches was 85.19%. This study documents proof‐of‐concept for application of deep learning techniques for computer‐aided diagnosis in veterinary medicine.","",""
