Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
0,"Joe Hays, S. Ramamoorthy, Christian Tetzlaff","Editorial: Robust Artificial Intelligence for Neurorobotics",2021,"","","","",1,"2022-07-13 09:34:13","","10.3389/fnbot.2021.809903","","",,,,,0,0.00,0,3,1,"Neural computing is a powerful paradigm that has revolutionized machine learning. Building from early roots in the study of adaptive behavior and attempts to understand information processing in parallel and distributed neural architectures, modern neural networks have convincingly demonstrated successes in numerous areas—transforming the practice of computer vision, natural language processing, and even computational biology. Applications in robotics bring stringent constraints on size, weight and power constraints (SWaP), which challenge the developers of these technologies in new ways. Indeed, these requirements take us back to the roots of the field of neural computing, forcing us to ask how it could be that the human brain achieves with as little as 12 watts of power what seems to require entire server farms with state of the art computational and numerical methods. Likewise, even lowly insects demonstrate a degree of adaptivity and resilience that still defy easy explanation or computational replication. In this Research Topic, we have compiled the latest research addressing several aspects of these broadly defined challenge questions. As illustrated in Figure 1, the articles are organized into four prevailing themes: Sense, Think, Act, and Tools.","",""
0,"Rih-Teng Wu","Development and Application of Big Data Analytics and Artificial Intelligence for Structural Health Monitoring and Metamaterial Design",2020,"","","","",2,"2022-07-13 09:34:13","","10.25394/PGS.12858245.V1","","",,,,,0,0.00,0,1,2,"Recent advances in sensor technologies and data acquisition platforms have led to the era of Big Data. The rapid growth of artificial intelligence (AI), computing power and machine learning (ML) algorithms allow Big Data to be processed within affordable time constraints. This opens abundant opportunities to develop novel and efficient approaches to enhance the sustainability and resilience of Smart Cities. This work, by starting with a review of the state-of-the-art data fusion and ML techniques, focuses on the development of advanced solutions to structural health monitoring (SHM) and metamaterial design and discovery strategies. A deep convolutional neural network (CNN) based approach that is more robust against noisy data is proposed to perform structural response estimation and system identification. To efficiently detect surface defects using mobile devices with limited training data, an approach that incorporates network pruning into transfer learning is introduced for crack and corrosion detection. For metamaterial design, a reinforcement learning (RL) and a neural network based approach are proposed to reduce the computation efforts for the design of periodic and non-periodic metamaterials, respectively. Lastly, a physics-constrained deep auto-encoder (DAE) based approach is proposed to design the geometry of wave scatterers that satisfy user-defined downstream acoustic 2D wave fields. The robustness of the proposed approaches as well as their limitations are demonstrated and discussed through experimental data or/and numerical simulations. A roadmap for future works that may benefit the SHM and material design research communities is presented at the end of this dissertation.","",""
2,"Rozhin Eskandarpour, A. Khodaei, Aleksi Paaso, N. M. Abdullah","Artificial Intelligence Assisted Power Grid Hardening in Response to Extreme Weather Events",2018,"","","","",3,"2022-07-13 09:34:13","","","","",,,,,2,0.50,1,4,4,"In this paper, an artificial intelligence based grid hardening model is proposed with the objective of improving power grid resilience in response to extreme weather events. At first, a machine learning model is proposed to predict the component states (either operational or outage) in response to the extreme event. Then, these predictions are fed into a hardening model, which determines strategic locations for placement of distributed generation (DG) units. In contrast to existing literature in hardening and resilience enhancement, this paper co-optimizes grid economic and resilience objectives by considering the intricate dependencies of the two. The numerical simulations on the standard IEEE 118-bus test system illustrate the merits and applicability of the proposed hardening model. The results indicate that the proposed hardening model through decentralized and distributed local energy resources can produce a more robust solution that can protect the system significantly against multiple component outages due to an extreme event.","",""
1,"J. C. Bedoya, Yubo Wang, Chen-Ching Liu","Distribution System Resilience Under Asynchronous Information Using Deep Reinforcement Learning",2021,"","","","",4,"2022-07-13 09:34:13","","10.1109/TPWRS.2021.3056543","","",,,,,1,1.00,0,3,1,"Resilience of a distribution system can be enhanced by efficient restoration of critical load following a major outage. Existing models include optimization approaches that consider available information without incorporating the inherent asynchrony of data arrival during execution of the restoration plan. Failure to consider the asynchronous nature of information arrival can lead to underutilization of critical resources. Moreover, analytical models become computationally inefficient for large scale systems. On the other hand, artificial intelligence (AI)-based tools have demonstrated efficient results for power system applications. In this paper, it is proposed a Reinforcement Learning (RL) model that learns how to efficiently restore a distribution system after a major outage. The proposed approach is based on a Monte Carlo Tree Search to expedite the training process. The proposed model strategy provides a robust decision-making tool for asynchronous and partial information scenarios. The results, validated with the IEEE 13-bus test feeder and IEEE 8500-node distribution test feeder, demonstrate the effectiveness and scalability of the proposed method.","",""
1,"Muhammad Abdullah Hanif, M. Shafique","Dependable Deep Learning: Towards Cost-Efficient Resilience of Deep Neural Network Accelerators against Soft Errors and Permanent Faults",2020,"","","","",5,"2022-07-13 09:34:13","","10.1109/IOLTS50870.2020.9159734","","",,,,,1,0.50,1,2,2,"Deep Learning has enabled machines to learn computational models (i.e., Deep Neural Networks – DNNs) that can perform certain complex tasks with claims to be close to human-level precision. This state-of-the-art performance offered by DNNs in many Artificial Intelligence (AI) applications has paved their way to being used in several safety-critical applications where even a single failure can lead to catastrophic results. Therefore, improving the robustness of these models to hardware-induced faults (such as soft errors, aging, and manufacturing defects) is of significant importance to avoid any disastrous event. Traditional redundancy-based fault mitigation techniques cannot be employed in a wide of applications due to their high overheads, which, when coupled with the compute-intensive nature of DNNs, lead to undesirable resource consumption. In this article, we present an overview of different low-cost fault-mitigation techniques that exploit the intrinsic characteristics of DNNs to limit their overheads. We discuss how each technique can contribute to the overall resilience of a DNN-based system, and how they can be integrated together to offer resilience against multiple diverse hardware-induced reliability threats. Towards the end, we highlight several key future directions that are envisioned to help in achieving highly dependable DL-based systems.","",""
1,"S. Mileiko, R. Shafik, A. Yakovlev, J. Edwards","A Pulse Width Modulation based Power-elastic and Robust Mixed-signal Perceptron Design",2019,"","","","",6,"2022-07-13 09:34:13","","10.23919/DATE.2019.8714806","","",,,,,1,0.33,0,4,3,"Neural networks are exerting burgeoning influence in emerging artificial intelligence applications at the micro-edge, such as sensing systems and image processing. As many of these systems are typically self-powered, their circuits are expected to be resilient and efficient in the presence of continuous power variations caused by the harvesters. In this paper, we propose a novel mixed-signal (i.e. analogue/digital) approach of designing a power-elastic perceptron using the principle of pulse width modulation (PWM). Fundamental to the design are a number of parallel inverters that transcode the input-weight pairs based on the principle of PWM duty cycle. Since PWM-based inverters are typically agnostic to amplitude and frequency variations, the perceptron shows a high degree of power elasticity and robustness under these variations. We show extensive design analysis in Cadence Analog Design Environment tool using a 3 x 3 perceptron circuit as a case study to demonstrate the resilience in the presence of parameric variations.","",""
3,"J. Xia, Zhe Li, Sidong Zeng, L. Zou, D. She, Dandong Cheng","Perspectives on eco-water security and sustainable development in the Yangtze River Basin",2021,"","","","",7,"2022-07-13 09:34:13","","10.1186/s40562-021-00187-7","","",,,,,3,3.00,1,6,1,"","",""
1,"Anuj Tambwekar, Anirudh Maiya, S. Dhavala, Snehanshu Saha","Estimation and Applications of Quantiles in Deep Binary Classification",2021,"","","","",8,"2022-07-13 09:34:13","","10.1109/tai.2021.3115078","","",,,,,1,1.00,0,4,1,"Conditional quantiles obtained via regression are used as a robust alternative to classical conditional means in econometrics and statistics, as they can capture the uncertainty in a prediction, and model tail behaviors, while making very few distributional assumptions. In this work, we extend the notion of conditional quantiles to the binary classification setting—allowing us to quantify the uncertainty in the predictions, increase resilience to label noise, and provide new insights into the functions learnt by the models. We accomplish this by defining a new loss called binary quantile regression loss. We compute the Lipschitz constant of the proposed loss and show that its curvature is bounded under some regularity conditions. These properties are later used to characterize the error rates of the learning algorithms and to accelerate the training regime with using Lipschitz adaptive learning rates. We leverage the estimated quantiles to obtain individualized confidence scores that provide an accurate measure of a prediction being misclassified. We aggregate these scores to provide two additional metrics, namely, confidence score and retention rate, which can be used to withhold decisions and increase model accuracy. We also study the robustness of the proposed nonparametric binary quantile classification framework, and finally, we demonstrate that quantiles aid in explainability as they can be used to obtain several univariate summary statistics that can be directly applied to existing explanation tools.","",""
0,"Di Wang, Hongying Zhang, Yanhua Shao","End-to-End Matching Network for Invariant Local Features",2021,"","","","",9,"2022-07-13 09:34:13","","10.1109/PRAI53619.2021.9551071","","",,,,,0,0.00,0,3,1,"The accurate estimation of the pose is the critical step of visual localization. Aiming at the problem that the current feature tasks cannot cope well with the end-to-end framework of scene transformation and feature extraction, an end-to-end matching network integrating feature point extraction, descriptor construction, and local feature matching is proposed. The feature points extraction based on the neural network is used with descriptor construction to form a joint training network, which obtains local features with a robust viewpoint and illumination changes. Introduce Attentional Graph Neural Networks (AGNN) to enhance the connection of local features of image pairs. The experimental results show that the proposed method can achieve end-to-end local feature matching tasks and meet the requirements of the front-end of the visual localization system for environmental resilience. Compared with classical algorithms, homography estimation, matching precision, and recall have a better performance.","",""
0,"Zhe Liu, M. Yang, W. Yan","A Framework for Image Encryption on Frequency Domain",2021,"","","","",10,"2022-07-13 09:34:13","","10.4018/978-1-5225-6313-6.CH010","","",,,,,0,0.00,0,3,1,"In this chapter, the authors propose an improved image encryption algorithm based on digital watermarking. The algorithm combines discrete wavelet transform (DWT), discrete cosine transform (DCT), and singular value decomposition (SVD) together in a DWT-DCT-SVD framework to improve the robust watermarking technique. The secret image is embedded into both high-frequency and low-frequency sub-bands of the host image; this makes it difficult to be attacked in all the sub-bands. To reduce the size of a secret key, the authors use a logistic map to generate random images so as to replace the host images. They tested the algorithm by using five types of attacks and the results indicate that the proposed algorithm has higher robustness than traditional chaotic scrambling method and the DRPE method. It shows strong resilience against the five types of attacks as well as statistical attacks.","",""
0,"C. Sample, S. Loo, M. Bishop","Resilient Data : An Interdisciplinary Approach",2020,"","","","",11,"2022-07-13 09:34:13","","10.1109/RWS50334.2020.9241268","","",,,,,0,0.00,0,3,2,"Cybersecurity continues the migration toward data-informed solutions and the quality of the data is gaining in importance. Data accuracy is foundational to the trustworthiness required of artificial intelligence solutions. Trustworthy data must be accurate, robust, resistant and resilient to unauthorized modifications, going beyond traditional security solutions that perform data integrity checking. Cyber-physical systems present unique challenges with physical outcomes.Cyber-physical systems present unique challenges in achieving trustworthy data. The combination of security data and safety data is unique. Capturing both sets of data and determining the accuracy of that data requires an interdisciplinary approach. This effort describes the merging of information theory and information security constructs along with physical systems data. Knowledge is needed in control systems engineering, cybersecurity and information theory. As training data that informs decisions and feeds artificial intelligence algorithms accuracy and resilience are important.Resilient data is trustworthy data that represents a research challenge offering an opportunity to apply lessons learned from information disorders into the broader cybersecurity environment including the cyber-physical systems that power much of the US critical infrastructure. Creating resilient data, for use as training data requires data be examined in ways that have not historically been a part of traditional cybersecurity analysis. This effort describes a proposed method of contextually evaluating cyber-physical systems security data in order to determine the accuracy of the data and in the event of tampering, reconstitute the data to the last known trustworthy state.","",""
0,"C. Bergin, M. Horgan","Past, present and future of medical education in Ireland",2020,"","","","",12,"2022-07-13 09:34:13","","10.29060/taps.2020-5-2/gp1084","","",,,,,0,0.00,0,2,2,"Medical education and training has evolved over the centuries. Ireland has a long history of leading on aspects of training that remain relevant today, focussing on the apprenticeship model coupled with a robust modern medical education framework. The practice of medicine is changing rapidly driven by expanding knowledge, advances in technology and use of artificial intelligence, demographic shifts and the expectations of patients and society. Medical training and education need to adapt to ensure that our current knowledge and future medical workforce is prepared for modern-day patient-centric practice. Ireland has emerged as a world leader in medical device technology, pharmaceutical research and development and social media technology support which offer the opportunity for the future of medical training. Knowledge, emotional intelligence, critical thinking, compassion, resilience and leadership are key attributes to which we as a profession aspire. There is an opportunity to leverage Ireland’s global position in technology and finance to train our modern-day medical workforce whilst retaining the attributes of the compassionate practice of the art of medicine. This paper explores the past, present and future of medical education and training in Ireland.","",""
6,"Xueyuan She, Yun Long, S. Mukhopadhyay","Improving Robustness of ReRAM-based Spiking Neural Network Accelerator with Stochastic Spike-timing-dependent-plasticity",2019,"","","","",13,"2022-07-13 09:34:13","","10.1109/IJCNN.2019.8851825","","",,,,,6,2.00,2,3,3,"Spike-timing-dependent-plasticity (STDP) is an unsupervised learning algorithm for spiking neural network (SNN), which promises to achieve deeper understanding of human brain and more powerful artificial intelligence. While conventional computing system fails to simulate SNN efficiently, process-inmemory (PIM) based on devices such as ReRAM can be used in designing fast and efficient STDP based SNN accelerators, as it operates in high resemblance with biological neural network. However, the real-life implementation of such design still suffers from impact of input noise and device variation. In this work, we present a novel stochastic STDP algorithm that uses spiking frequency information to dynamically adjust synaptic behavior. The algorithm is tested in pattern recognition task with noisy input and shows accuracy improvement over deterministic STDP. In addition, we show that the new algorithm can be used for designing a robust ReRAM based SNN accelerator that has strong resilience to device variation.","",""
5,"Tianxiang Wang, Zhonglong Zheng, Changbing Tang, Hao Peng","Aggregation rules based on stochastic gradient descent in Byzantine consensus",2019,"","","","",14,"2022-07-13 09:34:13","","10.1109/ITAIC.2019.8785560","","",,,,,5,1.67,1,4,3,"With the development of the data, block chain technology has gradually become the focus of the world. In block chain’s consensus algorithm, the typical Byzantine problem is often mentioned. In this paper, the Trimmed mean aggregation rule is proposed based on the stochastic gradient descent method to solve the Byzantine problem. We introduce the concept of Byzantine resilience and proves that the aggregation rule satisfies the Byzantine resilience condition, and the aggregation rule has O(dnlogn) complexity. Finally, in our experiment, we compare various aggregation rules and demonstrate that the Trimmed mean aggregation rules are robust.","",""
24,"Hoda Mehrpouyan, B. Haley, A. Dong, I. Tumer, C. Hoyle","Resiliency analysis for complex engineered system design",2015,"","","","",15,"2022-07-13 09:34:13","","10.1017/S0890060414000663","","",,,,,24,3.43,5,5,7,"Abstract Resilience is a key driver in the design of systems that must operate in an uncertain operating environment, and it is a key metric to assess the capacity for systems to perform within the specified performance envelop despite disturbances to their operating environment. This paper describes a graph spectral approach to calculate the resilience of complex engineered systems. The resilience of the design architecture of complex engineered systems is deduced from graph spectra. This is calculated from adjacency matrix representations of the physical connections between components in complex engineered systems. Furthermore, we propose a new method to identify the most vulnerable components in the design and design architectures that are robust to transmission of failures. Nonlinear dynamical system and epidemic spreading models are used to compare the failure propagation mean time transformation. Using these metrics, we present a case study based on the Advanced Diagnostics and Prognostics Testbed, which is an electrical power system developed at NASA Ames as a subsystem for the ramp system of an infantry fighting vehicle.","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",16,"2022-07-13 09:34:13","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
23,"M. Alomar, M. Hameed, M. Alsaadi","Multi hours ahead prediction of surface ozone gas concentration: Robust artificial intelligence approach",2020,"","","","",17,"2022-07-13 09:34:13","","10.1016/j.apr.2020.06.024","","",,,,,23,11.50,8,3,2,"","",""
27,"Amine Belhadi, Venkatesh Mani, Sachin S. Kamble, S. A. R. Khan, Surabhi Verma","Artificial intelligence-driven innovation for enhancing supply chain resilience and performance under the effect of supply chain dynamism: an empirical investigation",2021,"","","","",18,"2022-07-13 09:34:13","","10.1007/s10479-021-03956-x","","",,,,,27,27.00,5,5,1,"","",""
10,"M. Alomar, M. Hameed, N. Al‐Ansari, M. Alsaadi","Data-Driven Model for the Prediction of Total Dissolved Gas: Robust Artificial Intelligence Approach",2020,"","","","",19,"2022-07-13 09:34:13","","10.1155/2020/6618842","","",,,,,10,5.00,3,4,2,"Saturated total dissolved gas (TDG) is recently considered as a serious issue in the environmental engineering field since it stands behind the reasons for increasing the mortality rates of fish and aquatic organisms. The accurate and more reliable prediction of TDG has a very significant role in preserving the diversity of aquatic organisms and reducing the phenomenon of fish deaths. Herein, two machine learning approaches called support vector regression (SVR) and extreme learning machine (ELM) have been applied to predict the saturated TDG% at USGS 14150000 and USGS 14181500 stations which are located in the USA. For the USGS 14150000 station, the recorded samples from 13 October 2016 to 14 March 2019 (75%) were used for training set, and the rest from 15 March 2019 to 13 October 2019 (25%) were used for testing requirements. Similarly, for USGS 14181500 station, the hourly data samples which covered the period from 9 June 2017 till 11 March 2019 were used for calibrating the models and from 12 March 2019 until 9 October 2019 were used for testing the predictive models. Eight input combinations based on different parameters have been established as well as nine statistical performance measures have been used for evaluating the accuracy of adopted models, for instance, not limited, correlation of determination (        R      2        ), mean absolute relative error (MAE), and uncertainty at 95% (        U      95        ). The obtained results of the study for both stations revealed that the ELM managed efficiently to estimate the TDG in comparison to SVR technique. For USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.986 (0.986), MAE of 0.316 (0.441), and         U      95        of 3.592 (3.869). Lastly, for USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.991 (0.991), MAE of 0.338 (0.396), and         U      95        of 0.832 (0.837). In addition, ELM’s training process computational time is stated to be much shorter than that of SVM. The results also showed that the temperature parameter was the most significant variable that influenced TDG relative to the other parameters. Overall, the proposed model (ELM) proved to be an appropriate and efficient computer-assisted technology for saturated TDG modeling that will contribute to the basic knowledge of environmental considerations.","",""
14,"S. Modgil, R. Singh, C. Hannibal","Artificial intelligence for supply chain resilience: learning from Covid-19",2021,"","","","",20,"2022-07-13 09:34:13","","10.1108/ijlm-02-2021-0094","","",,,,,14,14.00,5,3,1,"PurposeMany supply chains have faced disruption during Covid-19. Artificial intelligence (AI) is one mechanism that can be used to improve supply chain resilience by developing business continuity capabilities. This study examines how firms employ AI and consider the opportunities for AI to enhance supply chain resilience by developing visibility, risk, sourcing and distribution capabilities.Design/methodology/approachThe authors have gathered rich data by conducting semistructured interviews with 35 experts from the e-commerce supply chain. The authors have adopted a systematic approach of coding using open, axial and selective methods to map and identify the themes that represent the critical elements of AI-enabled supply chain resilience.FindingsThe results of the study highlight the emergence of five critical areas where AI can contribute to enhanced supply chain resilience; (1) transparency, (2) ensuring last-mile delivery, (3) offering personalized solutions to both upstream and downstream supply chain stakeholders, (4) minimizing the impact of disruption and (5) facilitating an agile procurement strategy.Research limitations/implicationsThe study offers interesting implications for bridging the theory–practice gap by drawing on contemporary empirical data to demonstrate how enhancing dynamic capabilities via AI technologies further strengthens supply chain resilience. The study also offers suggestions for utilizing the findings and proposes a framework to strengthen supply chain resilience through AI.Originality/valueThe study presents the dynamic capabilities for supply chain resilience through the employment of AI. AI can contribute to readying supply chains to reduce their risk of disruption through enhanced resilience.","",""
13,"Amine Belhadi, Sachin S. Kamble, S. Fosso Wamba, M. Queiroz","Building supply-chain resilience: an artificial intelligence-based technique and decision-making framework",2021,"","","","",21,"2022-07-13 09:34:13","","10.1080/00207543.2021.1950935","","",,,,,13,13.00,3,4,1,"Artificial Intelligence (AI) offers a promising solution for building and promoting more resilient supply chains. However, the literature is highly dispersed regarding the application of AI in supp...","",""
120,"Hoang Nguyen, X. Bui","Predicting Blast-Induced Air Overpressure: A Robust Artificial Intelligence System Based on Artificial Neural Networks and Random Forest",2018,"","","","",22,"2022-07-13 09:34:13","","10.1007/s11053-018-9424-1","","",,,,,120,30.00,60,2,4,"","",""
0,"Bushra Rasheed, M. Usama, Asmara Safdar","Robust Artificial Intelligence Approach to Stabilize and Control Propeller Driven Hybrid UGV",2022,"","","","",23,"2022-07-13 09:34:13","","10.1109/ICAI55435.2022.9773375","","",,,,,0,0.00,0,3,1,"Hybrid Unmanned Ground Vehicle (HUGV) can drive on any terrain including walls and fly as well, using the multi directional thrust force of propellers. In the era of industrial revolution, hybrid UGVs need to be autonomous with intelligent decision making capabilities. During wall climbing of hybrid UGVs, stability is essential and depends on real time feedback from multiple sensors. To increase stability and control, it is proposed that PID control loops should be replaced by AI based algorithms that reduce the decision time and mathematical complexity. For autonomous movement in any terrain using the proposed model, intelligent UGVs can map and localize simultaneously.They can make intelligent decisions about mode of movement i.e. driving on ground or wall, steering on ground or wall, flying and maneuvering by using real time sensor readings. Integration of the proposed AI models with HUGV can be applied to many areas which are hard for humans to access, for instance; inspection of large structures, bio & nuclear hazard environments, planetary exploration & magnetic fields detection.","",""
7,"F. Morales-Rodríguez, Juan Pedro Martínez-Ramón, Inmaculada Méndez, C. Ruiz-Esteban","Stress, Coping, and Resilience Before and After COVID-19: A Predictive Model Based on Artificial Intelligence in the University Environment",2021,"","","","",24,"2022-07-13 09:34:13","","10.3389/fpsyg.2021.647964","","",,,,,7,7.00,2,4,1,"The COVID-19 global health emergency has greatly impacted the educational field. Faced with unprecedented stress situations, professors, students, and families have employed various coping and resilience strategies throughout the confinement period. High and persistent stress levels are associated with other pathologies; hence, their detection and prevention are needed. Consequently, this study aimed to design a predictive model of stress in the educational field based on artificial intelligence that included certain sociodemographic variables, coping strategies, and resilience capacity, and to study the relationship between them. The non-probabilistic snowball sampling method was used, involving 337 people (73% women) from the university education community in south-eastern Spain. The Perceived Stress Scale, Stress Management Questionnaire, and Brief Resilience Scale were administered. The Statistical Package for the Social Sciences (version 24) was used to design the architecture of artificial neural networks. The results found that stress levels could be predicted by the synaptic weights of coping strategies and timing of the epidemic (before and after the implementation of isolation measures), with a predictive capacity of over 80% found in the neural network model. Additionally, direct and significant associations were identified between the use of certain coping strategies, stress levels, and resilience. The conclusions of this research are essential for effective stress detection, and therefore, early intervention in the field of educational psychology, by discussing the influence of resilience or lack thereof on the prediction of stress levels. Identifying the variables that maintain a greater predictive power in stress levels is an effective strategy to design more adjusted prevention programs and to anticipate the needs of the community.","",""
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",25,"2022-07-13 09:34:13","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
7,"M. Hosseini, M. Parvania","Artificial intelligence for resilience enhancement of power distribution systems",2021,"","","","",26,"2022-07-13 09:34:13","","10.1016/j.tej.2020.106880","","",,,,,7,7.00,4,2,1,"","",""
19,"Thomas G. Dietterich","Robust artificial intelligence and robust human organizations",2018,"","","","",27,"2022-07-13 09:34:13","","10.1007/s11704-018-8900-4","","",,,,,19,4.75,19,1,4,"","",""
59,"Jinha Jung, M. Maeda, Anjin Chang, Mahendra Bhandari, Akash Ashapure, Juan Landivar-Bowles","The potential of remote sensing and artificial intelligence as tools to improve the resilience of agriculture production systems.",2020,"","","","",28,"2022-07-13 09:34:13","","10.1016/j.copbio.2020.09.003","","",,,,,59,29.50,10,6,2,"","",""
3,"Vijay Singh, P. Chaudhary, Jyoti Taunk, C. Singh, Deepti Singh, R. S. Tomar, M. Aski, N. Konjengbam, Ranjeet Sharan Raje, Sanjay Singh, R. S. Sengar, R. Yadav, M. Pal","Fab Advances in Fabaceae for Abiotic Stress Resilience: From ‘Omics’ to Artificial Intelligence",2021,"","","","",29,"2022-07-13 09:34:13","","10.3390/ijms221910535","","",,,,,3,3.00,0,13,1,"Legumes are a better source of proteins and are richer in diverse micronutrients over the nutritional profile of widely consumed cereals. However, when exposed to a diverse range of abiotic stresses, their overall productivity and quality are hugely impacted. Our limited understanding of genetic determinants and novel variants associated with the abiotic stress response in food legume crops restricts its amelioration. Therefore, it is imperative to understand different molecular approaches in food legume crops that can be utilized in crop improvement programs to minimize the economic loss. ‘Omics’-based molecular breeding provides better opportunities over conventional breeding for diversifying the natural germplasm together with improving yield and quality parameters. Due to molecular advancements, the technique is now equipped with novel ‘omics’ approaches such as ionomics, epigenomics, fluxomics, RNomics, glycomics, glycoproteomics, phosphoproteomics, lipidomics, regulomics, and secretomics. Pan-omics—which utilizes the molecular bases of the stress response to identify genes (genomics), mRNAs (transcriptomics), proteins (proteomics), and biomolecules (metabolomics) associated with stress regulation—has been widely used for abiotic stress amelioration in food legume crops. Integration of pan-omics with novel omics approaches will fast-track legume breeding programs. Moreover, artificial intelligence (AI)-based algorithms can be utilized for simulating crop yield under changing environments, which can help in predicting the genetic gain beforehand. Application of machine learning (ML) in quantitative trait loci (QTL) mining will further help in determining the genetic determinants of abiotic stress tolerance in pulses.","",""
12,"S. Abir, S. Islam, A. Anwar, A. Mahmood, A. Oo","Building Resilience against COVID-19 Pandemic Using Artificial Intelligence, Machine Learning, and IoT: A Survey of Recent Progress",2020,"","","","",30,"2022-07-13 09:34:13","","10.3390/iot1020028","","",,,,,12,6.00,2,5,2,"Coronavirus disease 2019 (COVID-19) has significantly impacted the entire world today and stalled off regular human activities in such an unprecedented way that it will have an unforgettable footprint on the history of mankind. Different countries have adopted numerous measures to build resilience against this life-threatening disease. However, the highly contagious nature of this pandemic has challenged the traditional healthcare and treatment practices. Thus, artificial intelligence (AI) and machine learning (ML) open up new mechanisms for effective healthcare during this pandemic. AI and ML can be useful for medicine development, designing efficient diagnosis strategies and producing predictions of the disease spread. These applications are highly dependent on real-time monitoring of the patients and effective coordination of the information, where the Internet of Things (IoT) plays a key role. IoT can also help with applications such as automated drug delivery, responding to patient queries, and tracking the causes of disease spread. This paper represents a comprehensive analysis of the potential AI, ML, and IoT technologies for defending against the COVID-19 pandemic. The existing and potential applications of AI, ML, and IoT, along with a detailed analysis of the enabling tools and techniques are outlined. A critical discussion on the risks and limitations of the aforementioned technologies are also included.","",""
10,"Z. Xu-Monette, Hongwei H Zhang, Feng Zhu, A. Tzankov, G. Bhagat, C. Visco, K. Dybkaer, A. Chiu, W. Tam, Y. Zu, E. Hsi, Hua You, J. Huh, M. Ponzoni, A. Ferreri, M. Møller, B. Parsons, J. V. van Krieken, M. Piris, J. Winter, F. Hagemeister, B. Shahbaba, I. De Dios, Hong Zhang, Yong Li, Bing Xu, M. Albitar, K. Young","A refined cell-of-origin classifier with targeted NGS and artificial intelligence shows robust predictive value in DLBCL.",2020,"","","","",31,"2022-07-13 09:34:13","","10.1182/bloodadvances.2020001949","","",,,,,10,5.00,1,28,2,"Diffuse large B-cell lymphoma (DLBCL) is a heterogeneous entity of B-cell lymphoma. Cell-of-origin (COO) classification of DLBCL is required in routine practice by the World Health Organization classification for biological and therapeutic insights. Genetic subtypes uncovered recently are based on distinct genetic alterations in DLBCL, which are different from the COO subtypes defined by gene expression signatures of normal B cells retained in DLBCL. We hypothesize that classifiers incorporating both genome-wide gene-expression and pathogenetic variables can improve the therapeutic significance of DLBCL classification. To develop such refined classifiers, we performed targeted RNA sequencing (RNA-Seq) with a commercially available next-generation sequencing (NGS) platform in a large cohort of 418 DLBCLs. Genetic and transcriptional data obtained by RNA-Seq in a single run were explored by state-of-the-art artificial intelligence (AI) to develop a NGS-COO classifier for COO assignment and NGS survival models for clinical outcome prediction. The NGS-COO model built through applying AI in the training set was robust, showing high concordance with COO classification by either Affymetrix GeneChip microarray or the NanoString Lymph2Cx assay in 2 validation sets. Although the NGS-COO model was not trained for clinical outcome, the activated B-cell-like compared with the germinal-center B-cell-like subtype had significantly poorer survival. The NGS survival models stratified 30% high-risk patients in the validation set with poor survival as in the training set. These results demonstrate that targeted RNA-Seq coupled with AI deep learning techniques provides reproducible, efficient, and affordable assays for clinical application. The clinical grade assays and NGS models integrating both genetic and transcriptional factors developed in this study may eventually support precision medicine in DLBCL.","",""
7,"Meng-Leong How, Y. Chan, S. Cheah","Predictive Insights for Improving the Resilience of Global Food Security Using Artificial Intelligence",2020,"","","","",32,"2022-07-13 09:34:13","","10.3390/su12156272","","",,,,,7,3.50,2,3,2,"Unabated pressures on food systems affect food security on a global scale. A human-centric artificial intelligence-based probabilistic approach is used in this paper to perform a unified analysis of data from the Global Food Security Index (GFSI). The significance of this intuitive probabilistic reasoning approach for predictive forecasting lies in its simplicity and user-friendliness to people who may not be trained in classical computer science or in software programming. In this approach, predictive modeling using a counterfactual probabilistic reasoning analysis of the GFSI dataset can be utilized to reveal the interplay and tensions between the variables that underlie food affordability, food availability, food quality and safety, and the resilience of natural resources. Exemplars are provided in this paper to illustrate how computational simulations can be used to produce forecasts of good and bad conditions in food security using multi-variant optimizations. The forecast of these future scenarios is useful for informing policy makers and stakeholders across domain verticals, so they can make decisions that are favorable to global food security.","",""
12,"Ahmed Imteaj, M. Amini, J. Mohammadi","Leveraging Decentralized Artificial Intelligence to Enhance Resilience of Energy Networks",2019,"","","","",33,"2022-07-13 09:34:13","","10.1109/PESGM41954.2020.9281763","","",,,,,12,4.00,4,3,3,"This paper reintroduces the notion of resilience in the context of recent issues originated from climate change triggered events including severe hurricanes and wildfires. A recent example is PG&E’s forced power outage to contain wildfire risk which led to widespread power disruption. This paper focuses on answering two questions: who is responsible for resilience? and how to quantify the monetary value of resilience? To this end, we first provide preliminary definitions of resilience for power systems. We then investigate the role of natural hazards, especially wildfire, on power system resilience. Finally, we will propose a decentralized strategy for a resilient management system using distributed storage and demand response resources. Our proposed high fidelity model provides utilities, operators, and policymakers with a clearer picture for strategic decision making and preventive decisions.","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",34,"2022-07-13 09:34:13","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
35,"S. Saravi, R. Kalawsky, D. Joannou, M. Rivas Casado, G. Fu, F. Meng","Use of Artificial Intelligence to Improve Resilience and Preparedness Against Adverse Flood Events",2019,"","","","",35,"2022-07-13 09:34:13","","10.3390/W11050973","","",,,,,35,11.67,6,6,3,"The main focus of this paper is the novel use of Artificial Intelligence (AI) in natural disaster, more specifically flooding, to improve flood resilience and preparedness. Different types of flood have varying consequences and are followed by a specific pattern. For example, a flash flood can be a result of snow or ice melt and can occur in specific geographic places and certain season. The motivation behind this research has been raised from the Building Resilience into Risk Management (BRIM) project, looking at resilience in water systems. This research uses the application of the state-of-the-art techniques i.e., AI, more specifically Machin Learning (ML) approaches on big data, collected from previous flood events to learn from the past to extract patterns and information and understand flood behaviours in order to improve resilience, prevent damage, and save lives. In this paper, various ML models have been developed and evaluated for classifying floods, i.e., flash flood, lakeshore flood, etc. using current information i.e., weather forecast in different locations. The analytical results show that the Random Forest technique provides the highest accuracy of classification, followed by J48 decision tree and Lazy methods. The classification results can lead to better decision-making on what measures can be taken for prevention and preparedness and thus improve flood resilience.","",""
3,"Y. Maruyama","The Conditions of Artificial General Intelligence: Logic, Autonomy, Resilience, Integrity, Morality, Emotion, Embodiment, and Embeddedness",2020,"","","","",36,"2022-07-13 09:34:13","","10.1007/978-3-030-52152-3_25","","",,,,,3,1.50,3,1,2,"","",""
44,"A. Goli, H. Zare, R. Tavakkoli-Moghaddam, A. Sadeghieh","Hybrid artificial intelligence and robust optimization for a multi-objective product portfolio problem Case study: The dairy products industry",2019,"","","","",37,"2022-07-13 09:34:13","","10.1016/j.cie.2019.106090","","",,,,,44,14.67,11,4,3,"","",""
26,"P. Radanliev, D. D. Roure, M. V. Kleek, Omar Santos, U. Ani","Artificial intelligence in cyber physical systems",2019,"","","","",38,"2022-07-13 09:34:13","","10.1007/s00146-020-01049-0","","",,,,,26,8.67,5,5,3,"","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",39,"2022-07-13 09:34:13","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",40,"2022-07-13 09:34:13","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
0,"Bahman Zohuri, Masoud Moghaddam, Farhang Mossavar-Rahmani","Business Resilience System Integrated Artificial Intelligence System",2022,"","","","",41,"2022-07-13 09:34:13","","10.47485/2767-3901.1019","","",,,,,0,0.00,0,3,1,"By definition, “Business Resilience” is the ability for an organization to quickly adapt to an unexpected disruption(s) and prevent any ongoing workflow(s) to come to a halt and yet maintaining continuous business operations and safeguarding people, resources, assets, and overall barns equity. By the same talking, a Business Resilience System (BRS) is a combination of intelligent software and hardware combined in an integrated system. Such an integrated combination of Business Resilience System goes a step beyond Disaster Recovery (DR) by offering post-disaster strategies to avoid costly downtime, shore up vulnerability and maintain business operations in the face of additional, unexpected breaches of the daily operation of workflow in any enterprise or organization. With recent technical progress in Artificial Intelligence (AI) augmented with Machine Learning (ML) and Deep Learning sub-systems, they present an Artificial Intelligence System (AIS) and now integrating these two systems of BRS and AIS, one can offer the most intelligent system that an organization or an enterprise can own, in order to have the best possible solution in place to have the best possible technique of predication and consequently prevention and adverse events based on collective historical data within Deep Learning of Artificial Intelligence. In this paper we are present and introduce each of these systems i.e., BRS and AIS and how they can be beneficial to each other by their integration as a holistic system along with their sub-stems of Software, Hardware, Machine Learning and Deep Learning.","",""
11,"A. Holzinger, M. Dehmer, F. Emmert‐Streib, N. Díaz-Rodríguez, R. Cucchiara, Isabelle Augenstein, J. Ser, W. Samek, I. Jurisica","Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trustworthy medical artificial intelligence",2021,"","","","",42,"2022-07-13 09:34:13","","10.1016/j.inffus.2021.10.007","","",,,,,11,11.00,1,9,1,"","",""
0,"Zhong Zheng, G. Zhang, Yun Lin, Yanfang Pan, Yandong He","The Role of Artificial Intelligence Technology in Improving the Resilience of Supply Chain During COVID-19",2022,"","","","",43,"2022-07-13 09:34:13","","10.1007/978-3-030-92537-6_21","","",,,,,0,0.00,0,5,1,"","",""
10,"O. Omitaomu, Haoran Niu","Artificial Intelligence Techniques in Smart Grid: A Survey",2021,"","","","",44,"2022-07-13 09:34:13","","10.3390/SMARTCITIES4020029","","",,,,,10,10.00,5,2,1,"The smart grid is enabling the collection of massive amounts of high-dimensional and multi-type data about the electric power grid operations, by integrating advanced metering infrastructure, control technologies, and communication technologies. However, the traditional modeling, optimization, and control technologies have many limitations in processing the data; thus, the applications of artificial intelligence (AI) techniques in the smart grid are becoming more apparent. This survey presents a structured review of the existing research into some common AI techniques applied to load forecasting, power grid stability assessment, faults detection, and security problems in the smart grid and power systems. It also provides further research challenges for applying AI technologies to realize truly smart grid systems. Finally, this survey presents opportunities of applying AI to smart grid problems. The paper concludes that the applications of AI techniques can enhance and improve the reliability and resilience of smart grid systems.","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",45,"2022-07-13 09:34:13","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
2,"B. Nair, Yakov Diskin, V. Asari","Multi-modal low cost mobile indoor surveillance system on the Robust Artificial Intelligence-based Defense Electro Robot (RAIDER)",2012,"","","","",46,"2022-07-13 09:34:13","","10.1117/12.930353","","",,,,,2,0.20,1,3,10,"We present an autonomous system capable of performing security check routines. The surveillance machine, the Clearpath Husky robotic platform, is equipped with three IP cameras with different orientations for the surveillance tasks of face recognition, human activity recognition, autonomous navigation and 3D reconstruction of its environment. Combining the computer vision algorithms onto a robotic machine has given birth to the Robust Artificial Intelligencebased Defense Electro-Robot (RAIDER). The end purpose of the RAIDER is to conduct a patrolling routine on a single floor of a building several times a day. As the RAIDER travels down the corridors off-line algorithms use two of the RAIDER's side mounted cameras to perform a 3D reconstruction from monocular vision technique that updates a 3D model to the most current state of the indoor environment. Using frames from the front mounted camera, positioned at the human eye level, the system performs face recognition with real time training of unknown subjects. Human activity recognition algorithm will also be implemented in which each detected person is assigned to a set of action classes picked to classify ordinary and harmful student activities in a hallway setting.The system is designed to detect changes and irregularities within an environment as well as familiarize with regular faces and actions to distinguish potentially dangerous behavior. In this paper, we present the various algorithms and their modifications which when implemented on the RAIDER serves the purpose of indoor surveillance.","",""
462,"Stuart J. Russell, Dan Dewey, Max Tegmark","Research Priorities for Robust and Beneficial Artificial Intelligence",2015,"","","","",47,"2022-07-13 09:34:13","","10.1609/aimag.v36i4.2577","","",,,,,462,66.00,154,3,7,"Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls. This article gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial.","",""
9,"Seunghyeon Kim, Yeon-Hee Lee, Yung-kyun Noh, F. Park, Q-Schick Auh","Age-group determination of living individuals using first molar images based on artificial intelligence",2021,"","","","",48,"2022-07-13 09:34:13","","10.1038/s41598-020-80182-8","","",,,,,9,9.00,2,5,1,"","",""
2,"Francesco Ciampi, Giacomo Marzi, Riccardo Rialti","Artificial Intelligence, Big Data, Strategic Flexibility, Agility, And Organizational Resilience: A Conceptual Framework Based On Existing Literature",2018,"","","","",49,"2022-07-13 09:34:13","","","","",,,,,2,0.50,1,3,4,"In today’s economically turbulent times, it is imperative that organizations remain flexible and resilient in order to adapt themselves to an ever-changing environment. To facilitate this, organizations should rely upon pliant structures of information, whilst simultaneously continuing to incorporate more rigid infrastructures in order to allow for the collection and analysis of large amounts of both internal and external data. This juxtaposition gives rise to the need for a trade-off. While academic literature has stressed that information systems may represent a burden for organizations pursuing strategic agility, flexibility, and organizational resilience, this paper highlights the ways in which Analytical, Automatic, Adaptive, and Agile information systems - or Big Data Analytics (BDA) capable information systems - may be helpful. In particular, this paper proposes BDA capable information systems, tied with artificial intelligence capabilities, as a trade-off solution. Alongside this, it also proposes some further implications of the topic for scholars and practitioners.","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",50,"2022-07-13 09:34:13","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",51,"2022-07-13 09:34:13","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
10,"A. C. Horta, A. Silva, C. Sargo, V. M. Gonçalves, T. C. Zangirolami, Roberto Campos Giordano","Robust artificial intelligence tool for automatic start-up of the supplementary medium feeding in recombinant E. coli cultivations",2011,"","","","",52,"2022-07-13 09:34:13","","10.1007/s00449-011-0540-0","","",,,,,10,0.91,2,6,11,"","",""
8,"Linbo Liu, Mingcheng Bi, Yunhua Wang, Junfeng Liu, Xiwen Jiang, Zhongbin Xu, Xingcai Zhang","Artificial intelligence-powered microfluidics for nanomedicine and materials synthesis.",2021,"","","","",53,"2022-07-13 09:34:13","","10.1039/d1nr06195j","","",,,,,8,8.00,1,7,1,"Artificial intelligence (AI) is an emerging technology with great potential, and its robust calculation and analysis capabilities are unmatched by traditional calculation tools. With the promotion of deep learning and open-source platforms, the threshold of AI has also become lower. Combining artificial intelligence with traditional fields to create new fields of high research and application value has become a trend. AI has been involved in many disciplines, such as medicine, materials, energy, and economics. The development of AI requires the support of many kinds of data, and microfluidic systems can often mine object data on a large scale to support AI. Due to the excellent synergy between the two technologies, excellent research results have emerged in many fields. In this review, we briefly review AI and microfluidics and introduce some applications of their combination, mainly in nanomedicine and material synthesis. Finally, we discuss the development trend of the combination of the two technologies.","",""
7,"N. Ullah, I. Sami, Md. Shahariar Chowdhury, K. Techato, H. Alkhammash","Artificial Intelligence Integrated Fractional Order Control of Doubly Fed Induction Generator-Based Wind Energy System",2021,"","","","",54,"2022-07-13 09:34:13","","10.1109/ACCESS.2020.3048420","","",,,,,7,7.00,1,5,1,"This paper proposes an artificial intelligence integrated (AI) fractional order robust control for a DFIG based wind energy conversion system. To reduce the chattering phenomena in the excitation signal, fuzzy system is employed for the adaptive adjustment of the discontinuous control gain while preserving the robustness of the closed-loop system. The stability of the closed loop system with fuzzy fractional order robust control (FFORC) is ensured using fractional order Lyapunov system. The proposed FFORC control scheme is tested using processor in the loop (PIL) experiment.MATLAB/Simulink environment is used to emulate DFIG based wind energy system and a Texas Instrument (TI) DSP320F37D processor is used for interfacing the proposed control scheme with the emulated DFIG model in Simulink environment. System performance under the proposed FFORC scheme is compared with classical sliding mode control(SMC).The experimental results justifies the superiority of the proposed FFORC control scheme under all test conditions.Under ideal condition and with the proposed FFORC control scheme, the speed tracking error is approximately zero while with SMC method the peak tracking error is 0.4 radian/s. Similarly the active and reactive powers tracking is smooth with the proposed control system, while with SMC method the reactive power oscillates on both sides of the reference and it reaches 0.01 kVAR on positive side and −0.01kVAR on the negative side of the plot.Under parameters variation, system with FFORC control scheme offers minimum steady state error which is about 0.01 radian/s, while in case of SMC with saturation function a peak value of 0.6 radian/s is recorded. In case of SMC with sgn function, the speed tracking error is around 0.1 radian/s.Moreover the proposed FFORC scheme exhibits minimum chattering.","",""
4,"O. L. Saldanha, P. Quirke, N. West, J. James, M. Loughrey, H. Grabsch, M. Salto‐Tellez, E. Alwers, Didem Cifci, Narmin Ghaffari Laleh, T. Seibel, Richard Gray, G. Hutchins, H. Brenner, T. Yuan, T. Brinker, J. Chang-Claude, Firas Khader, A. Schuppert, T. Luedde, S. Foersch, H. Muti, C. Trautwein, M. Hoffmeister, D. Truhn, J. Kather","Swarm learning for decentralized artificial intelligence in cancer histopathology",2021,"","","","",55,"2022-07-13 09:34:13","","10.1038/s41591-022-01768-5","","",,,,,4,4.00,0,26,1,"","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",56,"2022-07-13 09:34:13","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
96,"Eduardo H. B. Maia, L. Assis, Tiago Alves de Oliveira, Alisson Marques da Silva, A. Taranto","Structure-Based Virtual Screening: From Classical to Artificial Intelligence",2020,"","","","",57,"2022-07-13 09:34:13","","10.3389/fchem.2020.00343","","",,,,,96,48.00,19,5,2,"The drug development process is a major challenge in the pharmaceutical industry since it takes a substantial amount of time and money to move through all the phases of developing of a new drug. One extensively used method to minimize the cost and time for the drug development process is computer-aided drug design (CADD). CADD allows better focusing on experiments, which can reduce the time and cost involved in researching new drugs. In this context, structure-based virtual screening (SBVS) is robust and useful and is one of the most promising in silico techniques for drug design. SBVS attempts to predict the best interaction mode between two molecules to form a stable complex, and it uses scoring functions to estimate the force of non-covalent interactions between a ligand and molecular target. Thus, scoring functions are the main reason for the success or failure of SBVS software. Many software programs are used to perform SBVS, and since they use different algorithms, it is possible to obtain different results from different software using the same input. In the last decade, a new technique of SBVS called consensus virtual screening (CVS) has been used in some studies to increase the accuracy of SBVS and to reduce the false positives obtained in these experiments. An indispensable condition to be able to utilize SBVS is the availability of a 3D structure of the target protein. Some virtual databases, such as the Protein Data Bank, have been created to store the 3D structures of molecules. However, sometimes it is not possible to experimentally obtain the 3D structure. In this situation, the homology modeling methodology allows the prediction of the 3D structure of a protein from its amino acid sequence. This review presents an overview of the challenges involved in the use of CADD to perform SBVS, the areas where CADD tools support SBVS, a comparison between the most commonly used tools, and the techniques currently used in an attempt to reduce the time and cost in the drug development process. Finally, the final considerations demonstrate the importance of using SBVS in the drug development process.","",""
7,"Yulei Wu","Robust Learning-Enabled Intelligence for the Internet of Things: A Survey From the Perspectives of Noisy Data and Adversarial Examples",2021,"","","","",58,"2022-07-13 09:34:13","","10.1109/JIOT.2020.3018691","","",,,,,7,7.00,7,1,1,"The Internet of Things (IoT) has been widely adopted in a range of verticals, e.g., automation, health, energy, and manufacturing. Many of the applications in these sectors, such as self-driving cars and remote surgery, are critical and high stakes applications, calling for advanced machine learning (ML) models for data analytics. Essentially, the training and testing data that are collected by massive IoT devices may contain noise (e.g., abnormal data, incorrect labels, and incomplete information) and adversarial examples. This requires high robustness of ML models to make reliable decisions for IoT applications. The research of robust ML has received tremendous attention from both academia and industry in recent years. This article will investigate the state of the art and representative works of robust ML models that can enable high resilience and reliability of IoT intelligence. Two aspects of robustness will be focused on, i.e., when the training data of ML models contain noises and adversarial examples, which may typically happen in many real-world IoT scenarios. In addition, the reliability of both neural networks and reinforcement learning framework will be investigated. Both of these two ML paradigms have been widely used in handling data in IoT scenarios. The potential research challenges and open issues will be discussed to provide future research directions.","",""
4,"Shivam Mehta, Y. Suhail, J. Nelson, M. Upadhyay","Artificial Intelligence for radiographic image analysis",2021,"","","","",59,"2022-07-13 09:34:13","","10.1053/J.SODO.2021.05.007","","",,,,,4,4.00,1,4,1,"Abstract Automated identification of landmarks on lateral cephalogram and cone-beam computed tomography (CBCT) scans can save time for the clinicians and act as a second set of eyes for analysis of radiographic images in diagnosis and treatment planning. Several machine-learning techniques have been utilized for this purpose with varying accuracies. However, high degree of variability in the clinical presentation of orthodontic patients, limitations of the algorithms, lack of labelled data, high compute power, etc. are some drawbacks that have limited robust clinical application of such techniques. In recent years, artificial neural networks like deep learning and more specifically deep neural networks are making significant inroads in the true adoption of this technology. YOLOv3 and Single Shot Multibox Detector are some of the deep learning algorithms that have shown promising results. This paper is a theoretical review of the evolution of these technologies and the current state of the art in orthodontic image analysis.","",""
7,"Arwin Datumaya Wahyudi Sumari, A. S. Ahmad, Cognitive Artificial","The application of cognitive artificial intelligence within C4ISR framework for national resilience",2017,"","","","",60,"2022-07-13 09:34:13","","10.1109/ACDTJ.2017.8259600","","",,,,,7,1.40,2,3,5,"Cognitive Artificial Intelligence (CAI) is a new perspective in Artificial Intelligence (AI) which is aimed to emulate how human brain works in generating knowledge. Human becomes intelligent because of knowledge which grows over time in his brain. With comprehensive knowledge, he can understand the world (environment) and is able to make decision and or action on it. On the other hand, strategic decision which impacts to the continuance of having a nation and having state is a critical and crucial matter, and it should be done in precise and quick manner especially in the case of contingency and faced to mutiple-data multiple-decision-alternative problems. The most precise decision has to be based on the knowledge from extracted comprehensive information. In this paper we show you the application of CAI for National Security with Knowledge-Growing System (KGS) as the engine of decision making system. We apply the CAI to a framework called Cognitive Command, Control, Communications, Computers, Intelligence, Surveillance and Reconnaissance (C4ISR) with examples taken from a simulated of real-life case in the Defense-Security domain.","",""
2,"D. Silvestro, S. Goria, T. Sterner, A. Antonelli","Optimising biodiversity protection through artificial intelligence",2021,"","","","",61,"2022-07-13 09:34:13","","10.1101/2021.04.13.439752","","",,,,,2,2.00,1,4,1,"Over a million species face extinction, carrying with them untold options for food, medicine, fibre, shelter, ecological resilience, aesthetic and cultural values. There is therefore an urgent need to design conservation policies that maximise the protection of biodiversity and its contributions to people, within the constraints of limited budgets. Here we present a novel framework for spatial conservation prioritisation that combines simulation models, reinforcement learning and ground validation to identify optimal policies. Our methodology, CAPTAIN (Conservation Area Prioritisation Through Artificial Intelligence Networks), quantifies the trade-off between the costs and benefits of area and biodiversity protection, allowing the exploration of multiple biodiversity metrics. Under a fixed budget, our model protects substantially more species from extinction than the random or naively targeted protection of areas. CAPTAIN also outperforms the most widely used software for spatial conservation prioritisation (Marxan) in 97% of cases and reduces species loss by an average of 40% under simulations, besides yielding prioritisation maps at substantially higher spatial resolution using empirical data. We find that regular biodiversity monitoring, even if simple and with a degree of inaccuracy – characteristic of citizen science surveys – substantially improves biodiversity outcomes. Given the complexity of people–nature interactions and wealth of associated data, artificial intelligence holds great promise for improving the conservation of biological and ecosystem values in a rapidly changing and resource-limited world.","",""
1,"Oliver Eigner, Sebastian Eresheim, Peter Kieseberg, Lukas Daniel Klausner, Martin Pirker, Torsten Priebe, S. Tjoa, F. Marulli, F. Mercaldo","Towards Resilient Artificial Intelligence: Survey and Research Issues",2021,"","","","",62,"2022-07-13 09:34:13","","10.1109/CSR51186.2021.9527986","","",,,,,1,1.00,0,9,1,"Artificial intelligence (AI) systems are becoming critical components of today’s IT landscapes. Their resilience against attacks and other environmental influences needs to be ensured just like for other IT assets. Considering the particular nature of AI, and machine learning (ML) in particular, this paper provides an overview of the emerging field of resilient AI and presents research issues the authors identify as potential future work.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",63,"2022-07-13 09:34:13","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
29,"Ajay-Vikram Singh, Daniel Rosenkranz, M. Ansari, Rishabh Singh, Anurag Kanase, Shubham Pratap Singh, Blair Johnston, J. Tentschert, P. Laux, A. Luch","Artificial Intelligence and Machine Learning Empower Advanced Biomedical Material Design to Toxicity Prediction",2020,"","","","",64,"2022-07-13 09:34:13","","10.1002/aisy.202000084","","",,,,,29,14.50,3,10,2,"Materials at the nanoscale exhibit specific physicochemical interactions with their environment. Therefore, evaluating their toxic potential is a primary requirement for regulatory purposes and for the safer development of nanomedicines. In this review, to aid the understanding of nano–bio interactions from environmental and health and safety perspectives, the potential, reality, challenges, and future advances that artificial intelligence (AI) and machine learning (ML) present are described. Herein, AI and ML algorithms that assist in the reporting of the minimum information required for biomaterial characterization and aid in the development and establishment of standard operating procedures are focused. ML tools and ab initio simulations adopted to improve the reproducibility of data for robust quantitative comparisons and to facilitate in silico modeling and meta‐analyses leading to a substantial contribution to safe‐by‐design development in nanotoxicology/nanomedicine are mainly focused. In addition, future opportunities and challenges in the application of ML in nanoinformatics, which is particularly well‐suited for the clinical translation of nanotherapeutics, are highlighted. This comprehensive review is believed that it will promote an unprecedented involvement of AI research in improvements in the field of nanotoxicology and nanomedicine.","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",65,"2022-07-13 09:34:13","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
20,"L. McCoy, Sujay Nagaraj, F. Morgado, V. Harish, Sunit Das, L. Celi","What do medical students actually need to know about artificial intelligence?",2020,"","","","",66,"2022-07-13 09:34:13","","10.1038/s41746-020-0294-7","","",,,,,20,10.00,3,6,2,"","",""
28,"H. Alami, L. Rivard, P. Lehoux, S. Hoffman, Stephanie B. M. Cadeddu, Mathilde Savoldelli, M. A. Samri, M. A. Ag Ahmed, R. Fleet, J. Fortin","Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",2020,"","","","",67,"2022-07-13 09:34:13","","10.1186/s12992-020-00584-1","","",,,,,28,14.00,3,10,2,"","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",68,"2022-07-13 09:34:13","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
23,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, Craig Williams, Jayde Whittingham-Dowd, E. Shaw, Matt D. Hodges, L. Butler, M. Bates, R. L. La Ragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (AI-LAMP) for Rapid Detection of SARS-CoV-2",2020,"","","","",69,"2022-07-13 09:34:13","","10.3390/v12090972","","",,,,,23,11.50,2,28,2,"Until vaccines and effective therapeutics become available, the practical solution to transit safely out of the current coronavirus disease 19 (CoVID-19) lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of results, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected NHS patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. Therefore, this system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
25,"D. Schiff","Out of the laboratory and into the classroom: the future of artificial intelligence in education",2020,"","","","",70,"2022-07-13 09:34:13","","10.1007/s00146-020-01033-8","","",,,,,25,12.50,25,1,2,"","",""
23,"A. Șerban, M. Lytras","Artificial Intelligence for Smart Renewable Energy Sector in Europe—Smart Energy Infrastructures for Next Generation Smart Cities",2020,"","","","",71,"2022-07-13 09:34:13","","10.1109/ACCESS.2020.2990123","","",,,,,23,11.50,12,2,2,"One of the most challenging areas of Future Smart Cities Research is the Smart Energy domain. Critical issues related to optimization, provision of smart customizable networks and sophisticated computational techniques and methods enabled by artificial intelligence and machine learning need further investigation. The renewable energy (RE) is a powerful resource for the future global development in the context of climate change and resources depletion. Artificial intelligence (AI) implies new rules of organizing the activities in order to respond to these new requirements. It is necessary to improve the design of the energy infrastructure, the deployment and production of RE in order to face the multiple challenges that will affect the sector’s growth and resilience.. In this research work we exploit the recent developments on the AI adoption for RE sector in European Union (EU). In this respect, we analysed (i) the efficiency of the transformation processes of the RE within the energy chain from Gross Inland Consumption to Final Energy Consumption, (ii) its implications on the structure of renewable energy by source (solar, wind, biomass etc.), (iii) the labour productivity in RE sector compared to the economy as a whole and its correlation with investments level, (iv) the implication of the adoption of AI for RE towards Future Smart Cities Research. The main contribution of this research is the development of a framework for understanding the contribution of AI in the RE sector in Europe. Another bold contribution of this work is the discussion of the implications for Future Smart Cities Research and future research directions.","",""
23,"P. Radanliev, D. de Roure, Rob Walton, M. Van Kleek, Rafael Mantilla Montalvo, L. Maddox, Omar Santos, P. Burnap, Eirini Anthi","Artificial intelligence and machine learning in dynamic cyber risk analytics at the edge",2020,"","","","",72,"2022-07-13 09:34:13","","10.1007/s42452-020-03559-4","","",,,,,23,11.50,3,9,2,"","",""
37,"H.J. Yu, S. Cho, M. Kim, Won Hwa Kim, J.W. Kim, J. Choi","Automated Skeletal Classification with Lateral Cephalometry Based on Artificial Intelligence",2020,"","","","",73,"2022-07-13 09:34:13","","10.1177/0022034520901715","","",,,,,37,18.50,6,6,2,"Lateral cephalometry has been widely used for skeletal classification in orthodontic diagnosis and treatment planning. However, this conventional system, requiring manual tracing of individual landmarks, contains possible errors of inter- and intravariability and is highly time-consuming. This study aims to provide an accurate and robust skeletal diagnostic system by incorporating a convolutional neural network (CNN) into a 1-step, end-to-end diagnostic system with lateral cephalograms. A multimodal CNN model was constructed on the basis of 5,890 lateral cephalograms and demographic data as an input. The model was optimized with transfer learning and data augmentation techniques. Diagnostic performance was evaluated with statistical analysis. The proposed system exhibited >90% sensitivity, specificity, and accuracy for vertical and sagittal skeletal diagnosis. Clinical performance of the vertical classification showed the highest accuracy at 96.40 (95% CI, 93.06 to 98.39; model III). The receiver operating characteristic curve and the area under the curve both demonstrated the excellent performance of the system, with a mean area under the curve >95%. The heat maps of cephalograms were also provided for deeper understanding of the quality of the learned model by visually representing the region of the cephalogram that is most informative in distinguishing skeletal classes. In addition, we present broad applicability of this system through subtasks. The proposed CNN-incorporated system showed potential for skeletal orthodontic diagnosis without the need for intermediary steps requiring complicated diagnostic procedures.","",""
0,"N. Komendantova, L. Ekenberg, W. Amann, M. Danielson, V. Koulolias","Chapter 10 The Adequacy of Artificial Intelligence Tools to Combat Misinformation",2021,"","","","",74,"2022-07-13 09:34:13","","10.1007/978-3-030-70370-7_10","","",,,,,0,0.00,0,5,1,"","",""
1,"Sandhya Aneja, Nagender Aneja, Pg Emeroylariffion Abas, A. G. Naim","IAES International Journal of Artificial Intelligence (IJ-AI)",2021,"","","","",75,"2022-07-13 09:34:13","","","","",,,,,1,1.00,0,4,1,"Received Aug 22, 2021 Revised May 20, 2022 Accepted Jun 6, 2022 Despite substantial advances in network architecture performance, the susceptibility of adversarial attacks makes deep learning challenging to implement in safety-critical applications. This paper proposes a data-centric approach to addressing this problem. A nonlocal denoising method with different luminance values has been used to generate adversarial examples from the Modified National Institute of Standards and Technology database (MNIST) and Canadian Institute for Advanced Research (CIFAR-10) data sets. Under perturbation, the method provided absolute accuracy improvements of up to 9.3% in the MNIST data set and 13% in the CIFAR10 data set. Training using transformed images with higher luminance values increases the robustness of the classifier. We have shown that transfer learning is disadvantageous for adversarial machine learning. The results indicate that simple adversarial examples can improve resilience and make deep learning easier to apply in various applications.","",""
20,"Dimitra Samara, Ioannis Magnisalis, Vassilios Peristeras","Artificial intelligence and big data in tourism: a systematic literature review",2020,"","","","",76,"2022-07-13 09:34:13","","10.1108/jhtt-12-2018-0118","","",,,,,20,10.00,7,3,2,"This paper aims to research, identify and discuss the benefits and overall role of big data and artificial intelligence (BDAI) in the tourism sector, as this is depicted in recent literature.,A systematic literature review was conducted under the McKinsey’s Global Institute (Talwar and Koury, 2017) methodological perspective that identifies the four ways (i.e. project, produce, promote and provide) in which BDAI creates value. The authors enhanced this analysis methodology by depicting relevant challenges as well.,The findings imply that BDAI create value for the tourism sector through appropriately identified disseminations. The benefits of adopting BDAI strategies include increased efficiency, productivity and profitability for tourism suppliers combined with an extremely rich and personalized experience for travellers. The authors conclude that challenges can be bypassed by adopting a BDAI strategy. Such an adoption will stand critical for the competitiveness and resilience of existing established and new players in the tourism sector.,Besides identifying the benefits that BDAI brings in the tourism sector, the research proposes a guidebook to overcome challenges when introducing such new technologies. The exploration of the BDAI literature brings important implication for managers, academicians and consumers. This is the first systematic review in an area and contributes to the broader e-commerce marketing, retailing and e-tourism research.,本论文旨在研究、指出、和讨论大数据和人工智能（BDAI）在旅游业中的优势和整体作用。这些方面也在近文献中有所提到。,本论文采用系统综述方式, 在McKinsey’s Global Institute方法论的指导下, 确认BDAI可以在四种方面（预测、产出、提高、以及提供）创造价值。我们也通过阐述相关挑战来增强这个分析方法。,本论文结果显示BDAI通过适当的传播方式来为旅游业中创造价值。采用BDAI战略的好处包括：对旅游提供商带来高效、多产、盈利, 以及对旅游者们带来极度丰富和个性化的旅游体验。我们还总结了采取BDAI战略带来的诸多挑战。采用BDAI战略对旅游业中现有和新参与者的竞争力和弹性起到至关重要的作用。,除了指出了旅游业中BDAI带来的优势, 本论文还提出了一个指南, 来指导当新科技被引进时如何克服挑战。本论文通过对BDAI文献的梳理, 其文献综述结果对经理、学者、和消费者都有重要的启示作用。本论文是首篇在BDAI领域的系统综述, 对拓展电子商务营销、零售、和电子旅游科研有着重大贡献。","",""
27,"Omar Alshorman, Muhammad Irfan, N. Saad, D. Zhen, Noman Haider, A. Głowacz, Ahmad M. Alshorman","A Review of Artificial Intelligence Methods for Condition Monitoring and Fault Diagnosis of Rolling Element Bearings for Induction Motor",2020,"","","","",77,"2022-07-13 09:34:13","","10.1155/2020/8843759","","",,,,,27,13.50,4,7,2,"The fault detection and diagnosis (FDD) along with condition monitoring (CM) and of rotating machinery (RM) have critical importance for early diagnosis to prevent severe damage of infrastructure in industrial environments. Importantly, valuable industrial equipment needs continuous monitoring to enhance the safety, reliability, and availability and to decrease the cost of maintenance of modern industrial systems and applications. However, induction motor (IM) has been extensively used in several industrial processes because it is cheap, reliable, and robust. Rolling bearings are considered to be the main component of IM. Undoubtedly, any failure of this basic component can lead to a serious breakdown of IM and for whole industrial system. Thus, many current methods based on different techniques are employed as a fault prognosis and diagnosis of rolling elements bearing of IM. Moreover, these techniques include signal/image processing, intelligent diagnostics, data fusion, data mining, and expert systems for time and frequency as well as time-frequency domains. Artificial intelligence (AI) techniques have proven their significance in every field of digital technology. Industrial machines, automation, and processes are the net frontiers of AI adaptation. There are quite developed literatures that have been approaching the issues using signals and data processing techniques. However, the key contribution of this work is to present an extensive review of CM and FDD of the IM, especially for rolling elements bearings, based on artificial intelligent (AI) methods. This study highlights the advantages and performance limitations of each method. Finally, challenges and future trends are also highlighted.","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",78,"2022-07-13 09:34:13","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",79,"2022-07-13 09:34:13","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
43,"Stuart J. Russell, Thomas G. Dietterich, Eric Horvitz, B. Selman, F. Rossi, D. Hassabis, S. Legg, Mustafa Suleyman, D. George, D. Phoenix","Letter to the Editor: Research Priorities for Robust and Beneficial Artificial Intelligence: An Open Letter",2015,"","","","",80,"2022-07-13 09:34:13","","10.1609/aimag.v36i4.2621","","",,,,,43,6.14,4,10,7,"Artificial intelligence (AI) research has explored a variety of problems and approaches since its inception, but for the last 20 years or so has been focused on the problems surrounding the construction of intelligent agents — systems that perceive and act in some environment. In this context, ""intelligence"" is related to statistical and economic notions of rationality — colloquially, the ability to make good decisions, plans, or inferences. The adoption of probabilistic and decision-theoretic representations and statistical learning methods has led to a large degree of integration and cross-fertilization among AI, machine learning, statistics, control theory, neuroscience, and other fields. The establishment of shared theoretical frameworks, combined with the availability of data and processing power, has yielded remarkable successes in various component tasks such as speech recognition, image classification, autonomous vehicles, machine translation, legged locomotion, and question-answering systems. As capabilities in these areas and others cross the threshold from laboratory research to economically valuable technologies, a virtuous cycle takes hold whereby even small improvements in performance are worth large sums of money, prompting greater investments in research. There is now a broad consensus that AI research is progressing steadily, and that its impact on society is likely to increase. The potential benefits are huge, since everything that civilization has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable. Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls. The progress in AI research makes it timely to focus research not only on making AI more capable, but also on maximizing the societal benefit of AI. Such considerations motivated the AAAI 2008–09 Presidential Panel on Long-Term AI Futures and other projects on AI impacts, and constitute a significant expansion of the field of AI itself, which up to now has focused largely on techniques that are neutral with respect to purpose. We recommend expanded research aimed at ensuring that increasingly capable AI systems are robust and beneficial: our AI systems must do what we want them to do. The attached research priorities document [see page X] gives many examples of such research directions that can help maximize the societal benefit of AI. This research is by necessity interdisciplinary, because it involves both society and AI. It ranges from economics, law and philosophy to computer security, formal methods and, of course, various branches of AI itself. In summary, we believe that research on how to make AI systems robust and beneficial is both important and timely, and that there are concrete research directions that can be pursued today.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",81,"2022-07-13 09:34:13","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
18,"Ahmed Gowida, Salaheldin Elkatatny, Saad F. K. Al-Afnan, A. Abdulraheem","New Computational Artificial Intelligence Models for Generating Synthetic Formation Bulk Density Logs While Drilling",2020,"","","","",82,"2022-07-13 09:34:13","","10.3390/su12020686","","",,,,,18,9.00,5,4,2,"Synthetic well log generation using artificial intelligence tools is a robust solution for situations in which logging data are not available or are partially lost. Formation bulk density (RHOB) logging data greatly assist in identifying downhole formations. These data are measured in the field while drilling by using a density log tool in the form of either a logging while drilling (LWD) technique or (more often) by wireline logging after the formations are drilled. This is due to operational limitations during the drilling process. Therefore, the objective of this study was to develop a predictive tool for estimating RHOB while drilling using an adaptive network-based fuzzy interference system (ANFIS), functional network (FN), and support vector machine (SVM). The proposed model uses the mechanical drilling constraints as feeding input parameters, and the conventional RHOB log data as an output parameter. These mechanical drilling parameters are usually measured while drilling, and their responses vary with different formations. A dataset of 2400 actual datapoints, obtained from a horizontal well in the Middle East, were used to build the proposed models. The obtained dataset was divided into a 70/30 ratio for model training and testing, respectively. The optimized ANFIS-based model outperformed the FN- and SVM-based models with a correlation coefficient (R) of 0.93, and average absolute percentage error (AAPE) of 0.81% between the predicted and measured RHOB values. These results demonstrate the reliability of the developed ANFIS model for predicting RHOB while drilling, based on the mechanical drilling parameters. Subsequently, the ANFIS-based model was validated using unseen data from another well within the same field. The validation process yielded an AAPE of 0.97% between the predicted and actual RHOB values, which confirmed the robustness of the developed model as an effective predictive tool for RHOB.","",""
13,"Mohammad Rasheed Khan, Zeeshan Tariq, A. Abdulraheem","Application of Artificial Intelligence to Estimate Oil Flow Rate in Gas-Lift Wells",2020,"","","","",83,"2022-07-13 09:34:13","","10.1007/s11053-020-09675-7","","",,,,,13,6.50,4,3,2,"","",""
14,"G. Coskuner, Majeed S Jassim, M. Zontul, Seda Karateke","Application of artificial intelligence neural network modeling to predict the generation of domestic, commercial and construction wastes",2020,"","","","",84,"2022-07-13 09:34:13","","10.1177/0734242X20935181","","",,,,,14,7.00,4,4,2,"Reliable prediction of municipal solid waste (MSW) generation rates is a significant element of planning and implementation of sustainable solid waste management strategies. In this study, the multi-layer perceptron artificial neural network (MLP-ANN) is applied to verify the prediction of annual generation rates of domestic, commercial and construction and demolition (C&D) wastes from the year 1997 to 2016 in Askar Landfill site in the Kingdom of Bahrain. The proposed robust predictive models incorporated selected explanatory variables to reflect the influence of social, demographical, economic, geographical and touristic factors upon waste generation rates (WGRs). The Mean Squared Error (MSE) and coefficient of determination (R2) are used as performance indicators to evaluate effectiveness of the developed models. MLP-ANN models exhibited strong accuracy in predictions with high R2 and low MSE values. The R2 values for domestic, commercial and C&D wastes are 0.95, 0.99 and 0.91, respectively. Our results show that the developed MLP-ANN models are effective for the prediction of WGRs from different sources and could be considered as a cost-effective approach for planning integrated MSW management systems.","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",85,"2022-07-13 09:34:13","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
11,"Rebekah H. Gensure, M. Chiang, J. P. Campbell","Artificial intelligence for retinopathy of prematurity.",2020,"","","","",86,"2022-07-13 09:34:13","","10.1097/ICU.0000000000000680","","",,,,,11,5.50,4,3,2,"PURPOSE OF REVIEW In this article, we review the current state of artificial intelligence applications in retinopathy of prematurity (ROP) and provide insight on challenges as well as strategies for bringing these algorithms to the bedside.   RECENT FINDINGS In the past few years, there has been a dramatic shift from machine learning approaches based on feature extraction to 'deep' convolutional neural networks for artificial intelligence applications. Several artificial intelligence for ROP approaches have demonstrated adequate proof-of-concept performance in research studies. The next steps are to determine whether these algorithms are robust to variable clinical and technical parameters in practice. Integration of artificial intelligence into ROP screening and treatment is limited by generalizability of the algorithms to maintain performance on unseen data and integration of artificial intelligence technology into new or existing clinical workflows.   SUMMARY Real-world implementation of artificial intelligence for ROP diagnosis will require massive efforts targeted at developing standards for data acquisition, true external validation, and demonstration of feasibility. We must now focus on ethical, technical, clinical, regulatory, and financial considerations to bring this technology to the infant bedside to realize the promise offered by this technology to reduce preventable blindness from ROP.","",""
10,"Xiaohang Wu, Lixue Liu, Lanqin Zhao, Chong Guo, Ruiyang Li, Ting Wang, Xiaonan Yang, Peichen Xie, Yizhi Liu, Haotian Lin","Application of artificial intelligence in anterior segment ophthalmic diseases: diversity and standardization.",2020,"","","","",87,"2022-07-13 09:34:13","","10.21037/ATM-20-976","","",,,,,10,5.00,1,10,2,"Artificial intelligence (AI) based on machine learning (ML) and deep learning (DL) techniques has gained tremendous global interest in this era. Recent studies have demonstrated the potential of AI systems to provide improved capability in various tasks, especially in image recognition field. As an image-centric subspecialty, ophthalmology has become one of the frontiers of AI research. Trained on optical coherence tomography, slit-lamp images and even ordinary eye images, AI can achieve robust performance in the detection of glaucoma, corneal arcus and cataracts. Moreover, AI models based on other forms of data also performed satisfactorily. Nevertheless, several challenges with AI application in ophthalmology have also arisen, including standardization of data sets, validation and applicability of AI models, and ethical issues. In this review, we provided a summary of the state-of-the-art AI application in anterior segment ophthalmic diseases, potential challenges in clinical implementation and our prospects.","",""
0,"Yusen Xie, Ting Sun, Xinglong Cui, Shuixin Deng, Lei Deng, Baohua Chen","Fast-robust book information extraction system for automated intelligence library",2021,"","","","",88,"2022-07-13 09:34:13","","10.1109/AIID51893.2021.9456499","","",,,,,0,0.00,0,6,1,"At present, in the large-scale book management scene, book sorting, daily maintenance and book retrieval are very common, but the book information is complicated and the efficiency of relying on manual management is extremely poor. Although there have been many self-service book systems based on optics or vision, they are mostly based on traditional computer vision algorithms such as boundary extraction. Due to the fact that there are more artificial experience thresholds, some shortcomings such as low detection accuracy, poor robustness, and inability to systematically deploy on a large scale, which lack of insufficient intelligence. Therefore, we proposed a book information extraction algorithm based on object detection and optical character recognition (OCR) that is suitable for multiple book information recognition, multiple book image angles and multiple book postures. It can be applied to scenes such as book sorting, bookshelf management and book retrieval. The system we designed includes the classification of book covers and back covers, the classification of books upright and inverted, the detection of book pages side and spine side, the recognition of book pricing. In terms of accuracy, the classification accuracy of the front cover and the back cover is 99.9%, the upright classification accuracy of book front covers is 98.8%, the back cover reaches 99.9%, the accuracy of book price recognition get 94.5%, and the book spine/page side detection mAP reaches 99.6%; in terms of detection speed, Yolov5 detection model was improved and the statistical-based pre-pruning strategy was adopted, support by our algorithm the system reaches 2.09 FPS in book price recognition, which improves the detection speed to meet actual needs.","",""
8,"Jun Zhu, Hang Su, Bo Zhang","Toward the third generation of artificial intelligence",2020,"","","","",89,"2022-07-13 09:34:13","","10.1360/ssi-2020-0204","","",,,,,8,4.00,3,3,2,"There have been two competing paradigms of artificial intelligence (AI) development since 1956, i.e., symbolism and connectionism (or subsymbolism). Both started at the same time, but symbolism had dominated AI development until the end of the 1980s. Connectionism began to develop in the 1990s and reached its climax at the beginning of this century, and it is likely to displace symbolism. Today, it seems that the two paradigms only simulate the human mind (or brain) in different ways and have their own advantages. True human intelligence cannot be achieved by relying on only one paradigm. Both are necessary to establish a new, explainable, and robust AI theory and method and develop safe, trustworthy, reliable, and extensible AI technology. To this end, it is imperative to combine the two paradigms, and the present article will illustrate this idea. For the sake of description, symbolism, connectionism, and the newly developed paradigm are termed as first-, second-, and third-generation AIs.","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",90,"2022-07-13 09:34:13","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
7,"Ashley Kras, L. Celi, John B. Miller","Accelerating ophthalmic artificial intelligence research: the role of an open access data repository.",2020,"","","","",91,"2022-07-13 09:34:13","","10.1097/ICU.0000000000000678","","",,,,,7,3.50,2,3,2,"PURPOSE OF REVIEW Artificial intelligence has already provided multiple clinically relevant applications in ophthalmology. Yet, the explosion of nonstandardized reporting of high-performing algorithms are rendered useless without robust and streamlined implementation guidelines. The development of protocols and checklists will accelerate the translation of research publications to impact on patient care.   RECENT FINDINGS Beyond technological scepticism, we lack uniformity in analysing algorithmic performance generalizability, and benchmarking impacts across clinical settings. No regulatory guardrails have been set to minimize bias or optimize interpretability; no consensus clinical acceptability thresholds or systematized postdeployment monitoring has been set. Moreover, stakeholders with misaligned incentives deepen the landscape complexity especially when it comes to the requisite data integration and harmonization to advance the field. Therefore, despite increasing algorithmic accuracy and commoditization, the infamous 'implementation gap' persists. Open clinical data repositories have been shown to rapidly accelerate research, minimize redundancies and disseminate the expertise and knowledge required to overcome existing barriers. Drawing upon the longstanding success of existing governance frameworks and robust data use and sharing agreements, the ophthalmic community has tremendous opportunity in ushering artificial intelligence into medicine. By collaboratively building a powerful resource of open, anonymized multimodal ophthalmic data, the next generation of clinicians can advance data-driven eye care in unprecedented ways.   SUMMARY This piece demonstrates that with readily accessible data, immense progress can be achieved clinically and methodologically to realize artificial intelligence's impact on clinical care. Exponentially progressive network effects can be seen by consolidating, curating and distributing data amongst both clinicians and data scientists.","",""
6,"E. Loukis, M. Maragoudakis, Niki Kyriakou","Artificial intelligence-based public sector data analytics for economic crisis policymaking",2020,"","","","",92,"2022-07-13 09:34:13","","10.1108/tg-11-2019-0113","","",,,,,6,3.00,2,3,2," Purpose Public sector has started exploiting artificial intelligence (AI) techniques, however, mainly for operational but much less for tactical or level tasks. The purpose of this study is to exploit AI for the highest strategic-level task of government: to develop an AI-based public sector data analytics methodology for supporting policymaking for one of the most serious and large-scale challenges that governments repeatedly face, the economic crises that lead to economic recessions (though the proposed methodology is of much more general applicability).   Design/methodology/approach A public sector data analytics methodology has been developed, which enables the exploitation of existing public and private sector data, through advanced processing of them using a big data-oriented AI technique, “all-relevant” feature selection, to identify characteristics of firms as well as their external environment that affect (positively or negatively) their resilience to economic crisis.   Findings A first application of the proposed public sector data analytics methodology has been conducted, using Greek firms’ data concerning the economic crisis period 2009–2014, which has led to interesting conclusions and insights, revealing factors affecting the extent of sales revenue decrease in Greek firms during the above crisis period and providing a first validation of the methodology used in this study.   Research limitations/implications This paper contributes to the advancement of two emerging highly important, for the society, but minimally researched, digital government research domains: public sector data analytics (and especially policy analytics) and government exploitation of AI. It exploits an AI feature selection algorithm, the Boruta “all-relevant” variables identification algorithm, which has been minimally exploited in the past for public sector data analytics, to support the design of public policies for addressing one of the most serious and large-scale economic challenges that governments repeatedly face: the economic crises.   Practical implications The proposed methodology allows the identification of characteristics of firms as well as their external environment that affect positively or negatively their resilience to economic crisis. This enables a better understanding of the kinds of firms that are more strongly hit by the crisis, which is quite useful for the design of public policies for supporting them; and at the same time reveals firms’ practices, resources, capabilities, etc. that enhance their ability to cope with economic crisis, to design policies for promoting them through educational and support activities.   Social implications This methodology can be very useful for the design of more effective public policies for reducing the negative impacts of economic crises on firms, and therefore mitigating their negative consequences for the society, such as unemployment, poverty and social exclusion.   Originality/value This study develops a novel approach to the exploitation of public and private sector data, based on a minimally exploited, for such purposes, AI technique (“all-relevant” feature selection), to support the design of public policies for addressing one of the most threatening disruptions that modern economies and societies repeatedly face, the economic crises. ","",""
2,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, C. Williams, M. Bates, R. Laragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (ai-LAMP) for Rapid and Reliable Detection of SARS-CoV-2",2020,"","","","",93,"2022-07-13 09:34:13","","10.1101/2020.07.08.20148999","","",,,,,2,1.00,0,24,2,"Until vaccines and effective therapeutics become available, the practical way to transit safely out of the current lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of result, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms, and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. The system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",94,"2022-07-13 09:34:13","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
3,"B. Unhelkar, T. Gonsalves","Enhancing Artificial Intelligence Decision Making Frameworks to Support Leadership During Business Disruptions",2020,"","","","",95,"2022-07-13 09:34:13","","10.1109/MITP.2020.3031312","","",,,,,3,1.50,2,2,2,"Resilience is an organization's end-to-end capability to handle disruptions and recover postdisruption. This resilience depends on an organization's ability to predict disruptions and the preparedness of the leadership to handle them. Predictability and preparedness are functions of data science in the data-driven world of today's digital business. Artificial Intelligence (AI) within data science is poised to play a crucial role in making sense of data, predicting disruptions, and assisting the leaders with business continuity. AI's deep learning engine (DLE) is a tool that learns from past decisions and subsequent consequences. This article discusses enhancing the DLE with human experience resulting in a business disruption prediction framework.","",""
5,"M. Iqbal, Md. Faiz Iqbal Faiz","Active Surveillance for COVID-19 Through Artificial Intelligence Using Real-Time Speech-Recognition Mobile Application",2020,"","","","",96,"2022-07-13 09:34:13","","10.1109/ICCE-Taiwan49838.2020.9258276","","",,,,,5,2.50,3,2,2,"We propose a novel model of active surveillance for COVID-19 through artificial intelligence. Both past and recent events of viral disease outbreaks have shown us that we do not have effective methods to screen the whole population, and efforts are failing to stop the pandemics. Moreover, at this stage, social distancing and home quarantine are only measures to prevent the spread of COVID-19 infection. The purpose of our project is to introduce a robust method of using speech-recognition techniques through a mobile application in analyzing cough sounds of suspected people who previously were healthy, suffering from a respiratory ailment, and actively monitor the progress of their symptoms in real-time.","",""
2,"Dr. Uma Devi, Maria Tresita, V. Paul","Artificial Intelligence: Pertinence in Supply Chain and Logistics Management",2020,"","","","",97,"2022-07-13 09:34:13","","","","",,,,,2,1.00,1,3,2,"-Artificial Intelligence (AI) is the revolutionary invention of human intelligence. Artificial Intelligence is nothing but the duplication of human in which machines are programmed to rationally think and behave like humans developed for very many purposes including business decision making, problem-solving, business data analysis and interpretation and information management. The application of AI in business endeavours decides the competitive advantage, market leadership, robust operating efficiency of corporates and other business houses. Exploiting the application of AI in the manufacturing and distribution process enables the organisations to reach the pinnacle in their business graph. Businesses are operating in the international market which is highly multifaceted and challenging to serve the world as a sole market for their products, services and their products and without the integration of technology into their business processes, they cannot assure the sustainable growth. The management of the process of transforming the raw materials into the final product is called Supply Chain Management (SCM) and the effective movement and storage of goods, services and information are called Logistics Management (LM). This article analyses the applications of Artificial Intelligence in Supply Chain and Logistics Management (SC&LM) Keywords--Artificial Intelligence, Supply Chain Management, Logistics Management, Supply Chain Profitability","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",98,"2022-07-13 09:34:13","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",99,"2022-07-13 09:34:13","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
1,"L. Goldberg, Emma Quail","Leverage Utility Management and Artificial Intelligence in Today's COVID‐19 World",2020,"","","","",100,"2022-07-13 09:34:13","","10.1002/opfl.1425","","",,,,,1,0.50,1,2,2,"An Illinois water utility's ability to optimize water distribution network monitoring through artificial intelligence and automation gives it operational resilience to meet current and future challenges","",""
1,"P. Cook, Felicity O'Neill","Artificial Intelligence in Agribusiness is Growing in Emerging Markets",2020,"","","","",101,"2022-07-13 09:34:13","","10.1596/34304","","",,,,,1,0.50,1,2,2,"Business models utilizing artificial intelligence can help meet rising global demand for food and support a more inclusive and sustainable food system by: (1) enhancing the resilience of farming methods; (2) reducing the cost of quality inputs and services to underserved farmers; and (3) improving market access to facilitate smallholder farmer integration into regional and global supply chains. Although nascent in emerging economies, applications for artificial intelligence in agribusiness will proliferate as farmers’ access to the Internet and adoption of smart devices increases across low-income countries.","",""
4,"Bahman Zohuri","From Business Intelligence to Artificial Intelligence",2020,"","","","",102,"2022-07-13 09:34:13","","10.32474/MAMS.2020.02.000137","","",,,,,4,2.00,4,1,2,"With today’s growing information and overloading of its volume based on tremendous size of data growing to the level of big data, Business Intelligence (BI) is not enough to handle any day-to-day business operation of any enterprises. It is becoming tremendously difficult to analyze the huge amounts of data that contain the information and makes it very strenuous and inconvenient to introduce an appropriate methodology of decision-making fast enough to the point that it can be, considered as real time, a methodology that we used to call it BI. The demand for real time processing information and related data both structured and unstructured is on the rise and consequently makes it harder and harder to implement correct decision making at enterprise level that was driven by BI, in order to keep the organization robust and resilient against either man made threats or natural disasters. With smart malware in modern computation world and necessity for Internet-of-Things (IoT), we are in need of a better intelligence system that today we know it as Artificial Intelligence (AI). AI with its two other subset that are called Machine Learning (ML) and Deep Learning (DL), we have a better chance against any cyber-attack and makes our day-to-day operation within our organization a more robust one as well makes our decision making as stakeholder more trust worthy one as well.","",""
5,"Lindong Zhao, Xuguang Zhang, Jianxin Chen, Liang Zhou","Physical Layer Security in the Age of Artificial Intelligence and Edge Computing",2020,"","","","",103,"2022-07-13 09:34:13","","10.1109/MWC.001.2000044","","",,,,,5,2.50,1,4,2,"Physical layer security (PLS) is emerging as an attractive security paradigm to complement or even replace complex cryptography. Although information-theoretical transmission optimization and physical-layer key generation have been thoroughly researched, there still exist many critical issues to be tackled before PLS is extensively applied. In this article, we investigate the prospect for exploiting artificial intelligent (AI) and edge computing (EC) to facilitate the practical application of PLS. First, two outstanding challenges facing PLS designers are identified by analyzing the fundamental assumptions regarding eavesdroppers and wireless channels. Accordingly, two enhancement schemes are designed by reaping the benefits offered by AI and EC. Specifically, a novel secure resource management framework is developed to enhance the adaptability of an optimization-based PLS paradigm, and a robust physical-layer key generation method is designed to cope with reciprocity failure. Finally, we discuss a coordinated defense architecture with multi-layer, multi-domain, and multi-dimension, which is expected to exploit the compatibility and complementarity of the existing PLS methods.","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",104,"2022-07-13 09:34:13","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
13,"M. Ghasemi, A. Nassef, M. Al-Dhaifallah, Hegazy Rezk","Performance improvement of microbial fuel cell through artificial intelligence",2020,"","","","",105,"2022-07-13 09:34:13","","10.1002/er.5484","","",,,,,13,6.50,3,4,2,"The current work introduces an enhancement in the performance of the microbial fuel cell through estimating the optimal set of controlling parameters. The maximization of both power density (PD) and the percentage of chemical oxygen demand (COD) removal were considered as the enhancement in the cell's performance. Three main parameters in terms of performance as well as commercialization are the system's inputs; the Pt which takes the range of 0.1‐0.5 mg/cm2, the degree of sulphonation in sulfonated‐poly‐ether‐ether‐ketone that changes in the range of 20‐80%, and the rate of aeration of cathode which varies between 10 and 150 mL/min. From the experimental dataset, two robust adaptive neuro‐fuzzy inference system models based on the fuzzy logic technique have been constructed. The comparisons between the models' outputs and the experimental data showed well‐fitting in both training and testing datasets. The mean squared errors of the PD model, for testing and whole datasets, were found 2.575 and 0.909 while for the COD model it showed 19.242 and 6.791, respectively. Then, based on the two fuzzy models, a Particle Swarm Optimization algorithm has been used to determine the best parameters that maximize both of the PD and the COD removal of the cell. The optimization process was utilized for single and multi‐object optimization processes. In the single optimization, the resulting maximums of the PD and the COD removal were found 62.844 (mW/m2) and 99.99 (%), respectively. Whereas, in the multi‐object optimization, the values of 61.787 (mW/m2) and 96.21 (%) were reached as the maximums for the PD and COD, respectively. This implies that, in both cases of optimization processes, the adopted methodology can efficiently enhance the microbial fuel cell performances than the previous work.","",""
17,"Shengjie Xu, Y. Qian, R. Hu","Data-Driven Edge Intelligence for Robust Network Anomaly Detection",2020,"","","","",106,"2022-07-13 09:34:13","","10.1109/TNSE.2019.2936466","","",,,,,17,8.50,6,3,2,"The advancement of networking platforms for assured online services requires robust and effective network intelligence systems against anomalous events and malicious threats. With the rapid development of modern communication technologies, artificial intelligence, and the revolution of computing devices, cloud computing empowered network intelligence will inevitably become a core platform for various smart applications. While cloud computing provides strong and powerful computation, storage, and networking services to detect and defend cyber threats, edge computing on the other hand will deliver more benefits in specific yet potential critical areas. In this paper, we present a study on the data-driven edge intelligence for robust network anomaly detection. We first highlight the main motivations for edge intelligence, and then propose an intelligence system empowered by edge computing for network anomaly detection. We further propose a scheme on the data-driven robust network anomaly detection. In the proposed scheme, four phases are designed to incorporate with data-driven approaches to train a learning model which is able to detect and identify a network anomaly in a robust way. In the performance evaluations with data experiments, we demonstrate that the proposed scheme achieves the robustness of trained model and the efficiency on the detection of specific anomalies.","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",107,"2022-07-13 09:34:13","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
20,"Hong Zhang, Hoang Nguyen, X. Bui, B. Pradhan, P. Asteris, R. Costache, J. Aryal","A generalized artificial intelligence model for estimating the friction angle of clays in evaluating slope stability using a deep neural network and Harris Hawks optimization algorithm",2021,"","","","",108,"2022-07-13 09:34:13","","10.1007/S00366-020-01272-9","","",,,,,20,20.00,3,7,1,"","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",109,"2022-07-13 09:34:13","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
15,"S. Ebrahimian, Fatemeh Homayounieh, M. Rockenbach, Preetham Putha, T. Raj, I. Dayan, B. Bizzo, Varun Buch, Dufan Wu, Kyungsang Kim, Quanzheng Li, S. Digumarthy, M. Kalra","Artificial intelligence matches subjective severity assessment of pneumonia for prediction of patient outcome and need for mechanical ventilation: a cohort study",2021,"","","","",110,"2022-07-13 09:34:13","","10.1038/s41598-020-79470-0","","",,,,,15,15.00,2,13,1,"","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",111,"2022-07-13 09:34:13","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
17,"Mosleh Hmoud Al-Adhaileh, Fawaz Waselallah Alsaade","Modelling and Prediction of Water Quality by Using Artificial Intelligence",2021,"","","","",112,"2022-07-13 09:34:13","","10.3390/SU13084259","","",,,,,17,17.00,9,2,1,"Artificial intelligence methods can remarkably reduce costs for water supply and sanitation systems and help ensure compliance with the quality of drinking and wastewater treatment. Therefore, modelling and predicting water quality to control water pollution has been widely researched. The novelty of the proposed system is presented to develop an efficient operation of monitoring drinking water to ensure a sustainable and friendly green environment. In this work, the adaptive neuro-fuzzy inference system (ANFIS) algorithm was developed to predict the water quality index (WQI). Feed-forward neural network (FFNN) and K-nearest neighbors were applied to classify water quality. The dataset has eight significant parameters, but seven parameters were considered to show significant values. The proposed methodology was developed based on these statistical parameters. Prediction results demonstrated that the ANFIS model was superior for the prediction of WQI values. Nevertheless, the FFNN algorithm achieved the highest accuracy (100%) for water quality classification (WQC). Furthermore, the ANFIS model accurately predicted WQI, and the FFNN model showed superior robustness in classifying the WQC. In addition, the ANFIS model showed accuracy during the testing phase, with a regression coefficient of 96.17% for predicting WQI, and the FFNN model achieved the highest accuracy (100%) for WQC. This proposed method, using advanced artificial intelligence, can aid in water treatment and management.","",""
5,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: A Sensible Artificial Intelligence That Plays with Handicap and Targets High Scores in 9×9 Go",2020,"","","","",113,"2022-07-13 09:34:13","","10.3233/FAIA200119","","",,,,,5,2.50,1,6,2,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9×9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",114,"2022-07-13 09:34:13","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
15,"J. Janet, Chenru Duan, A. Nandy, Fang Liu, H. Kulik","Navigating Transition-Metal Chemical Space: Artificial Intelligence for First-Principles Design.",2021,"","","","",115,"2022-07-13 09:34:13","","10.1021/acs.accounts.0c00686","","",,,,,15,15.00,3,5,1,"ConspectusThe variability of chemical bonding in open-shell transition-metal complexes not only motivates their study as functional materials and catalysts but also challenges conventional computational modeling tools. Here, tailoring ligand chemistry can alter preferred spin or oxidation states as well as electronic structure properties and reactivity, creating vast regions of chemical space to explore when designing new materials atom by atom. Although first-principles density functional theory (DFT) remains the workhorse of computational chemistry in mechanism deduction and property prediction, it is of limited use here. DFT is both far too computationally costly for widespread exploration of transition-metal chemical space and also prone to inaccuracies that limit its predictive performance for localized d electrons in transition-metal complexes. These challenges starkly contrast with the well-trodden regions of small-organic-molecule chemical space, where the analytical forms of molecular mechanics force fields and semiempirical theories have for decades accelerated the discovery of new molecules, accurate DFT functional performance has been demonstrated, and gold-standard methods from correlated wavefunction theory can predict experimental results to chemical accuracy.The combined promise of transition-metal chemical space exploration and lack of established tools has mandated a distinct approach. In this Account, we outline the path we charted in exploration of transition-metal chemical space starting from the first machine learning (ML) models (i.e., artificial neural network and kernel ridge regression) and representations for the prediction of open-shell transition-metal complex properties. The distinct importance of the immediate coordination environment of the metal center as well as the lack of low-level methods to accurately predict structural properties in this coordination environment first motivated and then benefited from these ML models and representations. Once developed, the recipe for prediction of geometric, spin state, and redox potential properties was straightforwardly extended to a diverse range of other properties, including in catalysis, computational ""feasibility"", and the gas separation properties of periodic metal-organic frameworks. Interpretation of selected features most important for model prediction revealed new ways to encapsulate design rules and confirmed that models were robustly mapping essential structure-property relationships. Encountering the special challenge of ensuring that good model performance could generalize to new discovery targets motivated investigation of how to best carry out model uncertainty quantification. Distance-based approaches, whether in model latent space or in carefully engineered feature space, provided intuitive measures of the domain of applicability. With all of these pieces together, ML can be harnessed as an engine to tackle the large-scale exploration of transition-metal chemical space needed to satisfy multiple objectives using efficient global optimization methods. In practical terms, bringing these artificial intelligence tools to bear on the problems of transition-metal chemical space exploration has resulted in ML-model assessments of large, multimillion compound spaces in minutes and validated new design leads in weeks instead of decades.","",""
99,"R. Colling, Helen Pitman, K. Oien, N. Rajpoot, P. Macklin, D. Snead, Tony Sackville, C. Verrill","Artificial intelligence in digital pathology: a roadmap to routine use in clinical practice",2019,"","","","",116,"2022-07-13 09:34:13","","10.1002/path.5310","","",,,,,99,33.00,12,8,3,"The use of artificial intelligence will transform clinical practice over the next decade and the early impact of this will likely be the integration of image analysis and machine learning into routine histopathology. In the UK and around the world, a digital revolution is transforming the reporting practice of diagnostic histopathology and this has sparked a proliferation of image analysis software tools. While this is an exciting development that could discover novel predictive clinical information and potentially address international pathology workforce shortages, there is a clear need for a robust and evidence‐based framework in which to develop these new tools in a collaborative manner that meets regulatory approval. With these issues in mind, the NCRI Cellular Molecular Pathology (CM‐Path) initiative and the British In Vitro Diagnostics Association (BIVDA) have set out a roadmap to help academia, industry, and clinicians develop new software tools to the point of approved clinical use. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.","",""
85,"A. Grzybowski, Piotr Brona, Gilbert Lim, P. Ruamviboonsuk, G. Tan, M. Abràmoff, D. Ting","Artificial intelligence for diabetic retinopathy screening: a review",2019,"","","","",117,"2022-07-13 09:34:13","","10.1038/s41433-019-0566-0","","",,,,,85,28.33,12,7,3,"","",""
73,"Valentina Bellemo, Gilbert Lim, T. Rim, G. Tan, C. Cheung, S. Sadda, M. He, A. Tufail, M. Lee, W. Hsu, D. Ting","Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application",2019,"","","","",118,"2022-07-13 09:34:13","","10.1007/s11892-019-1189-3","","",,,,,73,24.33,7,11,3,"","",""
67,"Yonghui Shang, Hoang Nguyen, X. Bui, Quang-Hieu Tran, H. Moayedi","A Novel Artificial Intelligence Approach to Predict Blast-Induced Ground Vibration in Open-Pit Mines Based on the Firefly Algorithm and Artificial Neural Network",2019,"","","","",119,"2022-07-13 09:34:13","","10.1007/s11053-019-09503-7","","",,,,,67,22.33,13,5,3,"","",""
51,"Xiaohang Wu, Yelin Huang, Zhenzhen Liu, Weiyi Lai, Erping Long, Kai Zhang, Jiewei Jiang, Duoru Lin, Kexin Chen, Tongyong Yu, Dongxuan Wu, Cong Li, Yanyi Chen, Minjie Zou, Chuan Chen, Yi Zhu, Chong Guo, Xiayin Zhang, Ruixin Wang, Yahan Yang, Yifan Xiang, Lijian Chen, Congxin Liu, J. Xiong, Z. Ge, Ding-ding Wang, Guihua Xu, Shao-lin Du, Chi Xiao, Jianghao Wu, Ke Zhu, Dan-yao Nie, Fan Xu, Jian Lv, Weirong Chen, Yizhi Liu, Haotian Lin","Universal artificial intelligence platform for collaborative management of cataracts",2019,"","","","",120,"2022-07-13 09:34:13","","10.1136/bjophthalmol-2019-314729","","",,,,,51,17.00,5,37,3,"Purpose To establish and validate a universal artificial intelligence (AI) platform for collaborative management of cataracts involving multilevel clinical scenarios and explored an AI-based medical referral pattern to improve collaborative efficiency and resource coverage. Methods The training and validation datasets were derived from the Chinese Medical Alliance for Artificial Intelligence, covering multilevel healthcare facilities and capture modes. The datasets were labelled using a three-step strategy: (1) capture mode recognition; (2) cataract diagnosis as a normal lens, cataract or a postoperative eye and (3) detection of referable cataracts with respect to aetiology and severity. Moreover, we integrated the cataract AI agent with a real-world multilevel referral pattern involving self-monitoring at home, primary healthcare and specialised hospital services. Results The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance in three-step tasks: (1) capture mode recognition (area under the curve (AUC) 99.28%–99.71%), (2) cataract diagnosis (normal lens, cataract or postoperative eye with AUCs of 99.82%, 99.96% and 99.93% for mydriatic-slit lamp mode and AUCs >99% for other capture modes) and (3) detection of referable cataracts (AUCs >91% in all tests). In the real-world tertiary referral pattern, the agent suggested 30.3% of people be ‘referred’, substantially increasing the ophthalmologist-to-population service ratio by 10.2-fold compared with the traditional pattern. Conclusions The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance and effective service for cataracts. The context of our AI-based medical referral pattern will be extended to other common disease conditions and resource-intensive situations.","",""
47,"T. Phong, Trong Trinh Phan, Indra Prakash, S. Singh, A. Shirzadi, K. Chapi, H. Ly, Lanh Si Ho, Nguyen Kim Quoc, B. Pham","Landslide susceptibility modeling using different artificial intelligence methods: a case study at Muong Lay district, Vietnam",2019,"","","","",121,"2022-07-13 09:34:13","","10.1080/10106049.2019.1665715","","",,,,,47,15.67,5,10,3,"Abstract Landslide is a natural hazard which causes huge loss of properties and human life in many places of the world. Mapping of landslide susceptibility is an important task for preventing and combating the landslides problems. Main objective of this study is to use different artificial intelligence methods namely support vector machines (SVM), artificial neural networks (ANN), logistic regression (LR), and reduced error-pruning tree (REPT) in the development of models for landslide susceptibility mapping of Muong Lay district of Vietnam. In total data of 217 landslide locations of the study area was used for the development and evaluation of the models. Nine landslide-conditioning factors were used for generating the datasets for training and validating the models. Results show that the SVM outperformed all other methods namely ANN, LR and REPT. Thus, it can be suggested that the SVM method is more useful in developing accurate and robust landslide prediction model.","",""
48,"Liang Tan, Keping Yu, Fang Ming, Xiaofan Cheng, Gautam Srivastava","Secure and Resilient Artificial Intelligence of Things: A HoneyNet Approach for Threat Detection and Situational Awareness",2022,"","","","",122,"2022-07-13 09:34:13","","10.1109/MCE.2021.3081874","","",,,,,48,48.00,10,5,1,"Artificial Intelligence of Things (AIoT) is emerging as the future of Industry 4.0 and will be widely applied in consumer, commercial, and industrial fields. In AIoT, intelligent objects (smart devices), smart gateways, and edge/cloud nodes are subject to a large number of security threats and attacks. However, the traditional network security approaches are not fully suitable for AIoT. To address this issue, this article proposes a HoneyNet approach that includes both threat detection and situational awareness to enhance the security and resilience of AIoT. We first design a HoneyNet based on Docker technology that collects data to detect adversaries and monitor their attack behaviors. The collected data are then converted into images and used as samples to train a deep learning model. Finally, the trained model is deployed in AIoT to perform threat detection and provide situational awareness. To validate our scheme, we conduct HoneyNet deployment and model training on the SiteWhere AIoT platform and construct a simulation environment on this platform for threat detection and situational awareness. The experimental results demonstrate the feasibility and effectiveness of our solution.","",""
32,"Matt Taddy","The Technological Elements of Artificial Intelligence",2018,"","","","",123,"2022-07-13 09:34:13","","10.3386/W24301","","",,,,,32,8.00,32,1,4,"We have seen in the past decade a sharp increase in the extent that companies use data to optimize their businesses. Variously called the `Big Data' or `Data Science' revolution, this has been characterized by massive amounts of data, including unstructured and nontraditional data like text and images, and the use of fast and flexible Machine Learning (ML) algorithms in analysis. With recent improvements in Deep Neural Networks (DNNs) and related methods, application of high-performance ML algorithms has become more automatic and robust to different data scenarios. That has led to the rapid rise of an Artificial Intelligence (AI) that works by combining many ML algorithms together – each targeting a straightforward prediction task – to solve complex problems. We will define a framework for thinking about the ingredients of this new ML-driven AI. Having an understanding of the pieces that make up these systems and how they fit together is important for those who will be building businesses around this technology. Those studying the economics of AI can use these definitions to remove ambiguity from the conversation on AI's projected productivity impacts and data requirements. Finally, this framework should help clarify the role for AI in the practice of modern business analytics and economic measurement.","",""
32,"Jun-Ho Huh, Yeong-Seok Seo","Understanding Edge Computing: Engineering Evolution With Artificial Intelligence",2019,"","","","",124,"2022-07-13 09:34:13","","10.1109/ACCESS.2019.2945338","","",,,,,32,10.67,16,2,3,"The key to the explosion of the Internet of Things and the ability to collect, analyze, and provide big data in the cloud is edge computing, which is a new computing paradigm in which data is processed from edges. Edge Computing has been attracting attention as one of the top 10 strategic technology trends in the past two years and has innovative potential. It provides shorter response times, lower bandwidth costs, and more robust data safety and privacy protection than cloud computing. In particular, artificial intelligence technologies are rapidly incorporating edge computing. In this paper, we introduce the concepts, backgrounds, and pros and cons of edge computing, explain how it operates and its structure hierarchically with artificial intelligence concepts, list examples of its applications in various fields, and finally suggest some improvements and discuss the challenges of its application in three representative technological fields. We intend to clarify various analyses and opinions regarding edge computing and artificial intelligence.","",""
0,"","A Novel Approach to Adopt Explainable Artificial Intelligence in X-ray Image Classification",2022,"","","","",125,"2022-07-13 09:34:13","","10.33140/amlai.03.01.01","","",,,,,0,0.00,0,0,1,"Robust “Blackbox” algorithms such as Convolutional Neural Networks (CNNs) are known for making high prediction performance. However, the ability to explain and interpret these algorithms still require innovation in the understanding of influential and, more importantly, explainable features that directly or indirectly impact the performance of predictivity. In view of the above needs, this study proposes an interaction- based methodology – Influence Score (I-score) – to screen out the noisy and non-informative variables in the images hence it nourishes an environment with explainable and interpretable features that are directly associated to feature predictivity. We apply the proposed method on a real-world application in Pneumonia Chest X-ray Image data set and produced state- of-the-art results. We demonstrate how to apply the proposed approach for more general big data problems by improving the explain ability and interpretability without sacrificing the prediction performance. The contribution of this paper opens a novel angle that moves the community closer to the future pipelines of XAI problems.","",""
6,"Dina M. El-Sherif, Mohamed Abouzid, Mohamed Tarek Elzarif, Alhassan Ali Ahmed, Ashwag Albakri, Mohammed M. Alshehri","Telehealth and Artificial Intelligence Insights into Healthcare during the COVID-19 Pandemic",2022,"","","","",126,"2022-07-13 09:34:13","","10.3390/healthcare10020385","","",,,,,6,6.00,1,6,1,"Soon after the coronavirus disease 2019 pandemic was proclaimed, digital health services were widely adopted to respond to this public health emergency, including comprehensive monitoring technologies, telehealth, creative diagnostic, and therapeutic decision-making methods. The World Health Organization suggested that artificial intelligence might be a valuable way of dealing with the crisis. Artificial intelligence is an essential technology of the fourth industrial revolution that is a critical nonmedical intervention for overcoming the present global health crisis, developing next-generation pandemic preparation, and regaining resilience. While artificial intelligence has much potential, it raises fundamental privacy, transparency, and safety concerns. This study seeks to address these issues and looks forward to an intelligent healthcare future based on best practices and lessons learned by employing telehealth and artificial intelligence during the COVID-19 pandemic.","",""
5,"P. Radanliev, D. D. Roure, R. Nicolescu, M. Huth, Omar Santos","Digital twins: artificial intelligence and the IoT cyber-physical systems in Industry 4.0",2021,"","","","",127,"2022-07-13 09:34:13","","10.1007/S41315-021-00180-5","","",,,,,5,5.00,1,5,1,"","",""
22,"Rushikesh S. Joshi, Alexander F. Haddad, Darryl Lau, C. Ames","Artificial Intelligence for Adult Spinal Deformity",2019,"","","","",128,"2022-07-13 09:34:13","","10.14245/ns.1938414.207","","",,,,,22,7.33,6,4,3,"Adult spinal deformity (ASD) is a complex disease that significantly affects the lives of many patients. Surgical correction has proven to be effective in achieving improvement of spinopelvic parameters as well as improving quality of life (QoL) for these patients. However, given the relatively high complication risk associated with ASD correction, it is of paramount importance to develop robust prognostic tools for predicting risk profile and outcomes. Historically, statistical models such as linear and logistic regression models were used to identify preoperative factors associated with postoperative outcomes. While these tools were useful for looking at simple associations, they represent generalizations across large populations, with little applicability to individual patients. More recently, predictive analytics utilizing artificial intelligence (AI) through machine learning for comprehensive processing of large amounts of data have become available for surgeons to implement. The use of these computational techniques has given surgeons the ability to leverage far more accurate and individualized predictive tools to better inform individual patients regarding predicted outcomes after ASD correction surgery. Applications range from predicting QoL measures to predicting the risk of major complications, hospital readmission, and reoperation rates. In addition, AI has been used to create a novel classification system for ASD patients, which will help surgeons identify distinct patient subpopulations with unique risk-benefit profiles. Overall, these tools will help surgeons tailor their clinical practice to address patients’ individual needs and create an opportunity for personalized medicine within spine surgery.","",""
21,"D. Ting, M. Ang, J. Mehta, D. Ting","Artificial intelligence-assisted telemedicine platform for cataract screening and management: a potential model of care for global eye health",2019,"","","","",129,"2022-07-13 09:34:13","","10.1136/bjophthalmol-2019-315025","","",,,,,21,7.00,5,4,3,"Artificial intelligence (AI) is the fourth industrial revolution.1 Deep learning is a robust machine learning technique that uses convolutional neural network to perform multilevel data abstraction without the need for manual feature engineering.2 In ophthalmology, many studies showed comparable, if not better, diagnostic performance in using AI to screen, diagnose, predict and monitor various eye conditions on fundus photographs and optical coherence tomography,3 4 including diabetic retinopathy (DR),5 age-related macular degeneration,6 glaucoma,7 retinopathy of prematurity (ROP).8   To date, many countries have reported well-established telemedicine programme to screen for DR and ROP,9–12 but limited for cataracts. Cataract is the leading cause of reversible blindness, affecting approximately 12.6 million (3.4–28.7 million) worldwide.13 14 The prevalence of cataract-related visual impairment also varies between high-income and low-income countries, with the latter having poorer access to tertiary care.13 In this issue, Wu et al 15 reported an AI-integrated telemedicine platform to screen and refer patients with cataract. This article consists of two parts: (1) the first part focusing on the AI system in detection of three tasks (capture mode, cataract diagnosis and referable cataract) and (2) the second part describing how these AI algorithms could be integrated in the telemedicine platform for real-world operational use. In this study, the referable cases were defined as: (1) grade 3 and grade 4 nuclear sclerotic …","",""
16,"K. Denecke, E. Gabarron, R. Grainger, S. Konstantinidis, A. Lau, O. Rivera-Romero, T. Miron-Shatz, M. Merolli","Artificial Intelligence for Participatory Health: Applications, Impact, and Future Implications",2019,"","","","",130,"2022-07-13 09:34:13","","10.1055/s-0039-1677902","","",,,,,16,5.33,2,8,3,"Summary Objective : Artificial intelligence (AI) provides people and professionals working in the field of participatory health informatics an opportunity to derive robust insights from a variety of online sources. The objective of this paper is to identify current state of the art and application areas of AI in the context of participatory health. Methods : A search was conducted across seven databases (PubMed, Embase, CINAHL, PsychInfo, ACM Digital Library, IEEExplore, and SCOPUS), covering articles published since 2013. Additionally, clinical trials involving AI in participatory health contexts registered at clinicaltrials.gov were collected and analyzed. Results : Twenty-two articles and 12 trials were selected for review. The most common application of AI in participatory health was the secondary analysis of social media data: self-reported data including patient experiences with healthcare facilities, reports of adverse drug reactions, safety and efficacy concerns about over-the-counter medications, and other perspectives on medications. Other application areas included determining which online forum threads required moderator assistance, identifying users who were likely to drop out from a forum, extracting terms used in an online forum to learn its vocabulary, highlighting contextual information that is missing from online questions and answers, and paraphrasing technical medical terms for consumers. Conclusions : While AI for supporting participatory health is still in its infancy, there are a number of important research priorities that should be considered for the advancement of the field. Further research evaluating the impact of AI in participatory health informatics on the psychosocial wellbeing of individuals would help in facilitating the wider acceptance of AI into the healthcare ecosystem.","",""
0,"N. Rafie, J. Jentzer, P. Noseworthy, A. Kashou","Mortality Prediction in Cardiac Intensive Care Unit Patients: A Systematic Review of Existing and Artificial Intelligence Augmented Approaches",2022,"","","","",131,"2022-07-13 09:34:13","","10.3389/frai.2022.876007","","",,,,,0,0.00,0,4,1,"The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient's clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.","",""
19,"Y. Ong, Abhishek Gupta","AIR5: Five Pillars of Artificial Intelligence Research",2018,"","","","",132,"2022-07-13 09:34:13","","10.1109/TETCI.2019.2928344","","",,,,,19,4.75,10,2,4,"In this paper, we provide an overview of what we consider to be some of the most pressing research questions currently facing the fields of <italic>artificial and computational intelligence</italic> (AI and CI). While AI spans a range of methods that enable machines to learn from data and operate autonomously, CI serves as a means to this end by finding its niche in algorithms that are inspired by complex natural phenomena (including the working of the brain). In this paper, we demarcate the key issues surrounding these fields using five unique <italic>Rs</italic>, namely, <italic>rationalizability</italic>, <italic>resilience</italic>, <italic>reproducibility</italic>, <italic>realism</italic>, and <italic>responsibility</italic>. Notably, just as <italic>air</italic> serves as the basic element of biological life, the term AIR<sub>5</sub>—cumulatively referring to the five aforementioned <italic>Rs</italic>—is introduced herein to mark some of the basic elements of artificial life, <italic>for sustainable AI and CI</italic>. A brief summary of each of the <italic>Rs</italic> is presented, highlighting their relevance as pillars of future research in this arena.","",""
19,"E. O. Kontis, T. Papadopoulos, M. Syed, E. Guillo‐Sansano, G. Burt, G. Papagiannis","Artificial-Intelligence Method for the Derivation of Generic Aggregated Dynamic Equivalent Models",2019,"","","","",133,"2022-07-13 09:34:13","","10.1109/TPWRS.2019.2894185","","",,,,,19,6.33,3,6,3,"Aggregated equivalent models for the dynamic analysis of active distribution networks (ADNs) can be efficiently developed using dynamic responses recorded through field measurements. However, equivalent model parameters are highly affected from the time-varying composition of power system loads and the stochastic behavior of distributed generators. Thus, equivalent models, developed through in situ measurements, are valid only for the operating conditions from which they have been derived. To overcome this issue, in this paper, a new method is proposed for the derivation of generic aggregated dynamic equivalent models, i.e., for equivalent models that can be used for the dynamic analysis of a wide range of network conditions. The method incorporates clustering and artificial neural network techniques to derive robust sets of parameters for a variable-order dynamic equivalent model. The effectiveness of the proposed method is evaluated using measurements recorded on a laboratory-scale ADN, while its performance is compared with a conventional technique. The corresponding results reveal the applicability of the proposed approach for the analysis and simulation of a wide range of distinct network conditions.","",""
10,"Zihao Chen, Long Hu, Baoting Zhang, Aiping Lu, Yaofeng Wang, Yuanyuan Yu, Ge Zhang","Artificial Intelligence in Aptamer–Target Binding Prediction",2021,"","","","",134,"2022-07-13 09:34:13","","10.3390/ijms22073605","","",,,,,10,10.00,1,7,1,"Aptamers are short single-stranded DNA, RNA, or synthetic Xeno nucleic acids (XNA) molecules that can interact with corresponding targets with high affinity. Owing to their unique features, including low cost of production, easy chemical modification, high thermal stability, reproducibility, as well as low levels of immunogenicity and toxicity, aptamers can be used as an alternative to antibodies in diagnostics and therapeutics. Systematic evolution of ligands by exponential enrichment (SELEX), an experimental approach for aptamer screening, allows the selection and identification of in vitro aptamers with high affinity and specificity. However, the SELEX process is time consuming and characterization of the representative aptamer candidates from SELEX is rather laborious. Artificial intelligence (AI) could help to rapidly identify the potential aptamer candidates from a vast number of sequences. This review discusses the advancements of AI pipelines/methods, including structure-based and machine/deep learning-based methods, for predicting the binding ability of aptamers to targets. Structure-based methods are the most used in computer-aided drug design. For this part, we review the secondary and tertiary structure prediction methods for aptamers, molecular docking, as well as molecular dynamic simulation methods for aptamer–target binding. We also performed analysis to compare the accuracy of different secondary and tertiary structure prediction methods for aptamers. On the other hand, advanced machine-/deep-learning models have witnessed successes in predicting the binding abilities between targets and ligands in drug discovery and thus potentially offer a robust and accurate approach to predict the binding between aptamers and targets. The research utilizing machine-/deep-learning techniques for prediction of aptamer–target binding is limited currently. Therefore, perspectives for models, algorithms, and implementation strategies of machine/deep learning-based methods are discussed. This review could facilitate the development and application of high-throughput and less laborious in silico methods in aptamer selection and characterization.","",""
10,"Shun Zhang, Muye Li, Mengnan Jian, Yajun Zhao, Feifei Gao","AIRIS: Artificial intelligence enhanced signal processing in reconfigurable intelligent surface communications",2021,"","","","",135,"2022-07-13 09:34:13","","10.23919/JCC.2021.07.013","","",,,,,10,10.00,2,5,1,"Reconfigurable intelligent surface (RIS) is an emerging meta-surface that can provide additional communications links through reflecting the signals, and has been recognized as a strong candidate of 6G mobile communications systems. Meanwhile, it has been recently admitted that implementing artificial intelligence (AI) into RIS communications will extensively benefit the reconfiguration capacity and enhance the robustness to complicated transmission environments. Besides the conventional model-driven approaches, AI can also deal with the existing signal processing problems in a data-driven manner via digging the inherent characteristic from the real data. Hence, AI is particularly suitable for the signal processing problems over RIS networks under unideal scenarios like modeling mismatching, insufficient resource, hardware impairment, as well as dynamical transmissions. As one of the earliest survey papers, we will introduce the merging of AI and RIS, called AIRIS, over various signal processing topics, including environmental sensing, channel acquisition, beam-forming design, and resource scheduling, etc. We will also discuss the challenges of AIRIS and present some interesting future directions.","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",136,"2022-07-13 09:34:13","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
27,"Óscar Álvarez-Machancoses, J. Fernández-Martínez","Using artificial intelligence methods to speed up drug discovery",2019,"","","","",137,"2022-07-13 09:34:13","","10.1080/17460441.2019.1621284","","",,,,,27,9.00,14,2,3,"ABSTRACT Introduction: Drug discovery is the process through which potential new compounds are identified by means of biology, chemistry, and pharmacology. Due to the high complexity of genomic data, AI techniques are increasingly needed to help reduce this and aid the adoption of optimal decisions. Phenotypic prediction is of particular use to drug discovery and precision medicine where sets of genes that predict a given phenotype are determined. Phenotypic prediction is an undetermined problem given that the number of monitored genetic probes markedly exceeds the number of collected samples (from patients). This imbalance creates ambiguity in the characterization of the biological pathways that are responsible for disease development. Areas covered: In this paper, the authors present AI methodologies that perform a robust deep sampling of altered genetic pathways to locate new therapeutic targets, assist in drug repurposing and speed up and optimize the drug selection process. Expert opinion: AI is a potential solution to a number of drug discovery problems, though one should, bear in mind that the quality of data predicts the overall quality of the prediction, as in any modeling task in data science. The use of transparent methodologies is crucial, particularly in drug repositioning/repurposing in rare diseases.","",""
0,"You Lv","Application of 3D Animation Cluster System Based on Artificial Intelligence and Machine Learning",2022,"","","","",138,"2022-07-13 09:34:13","","10.1155/2022/2904607","","",,,,,0,0.00,0,1,1,"In many living phenomena, the behavior of social animals (such as ants, fish stocks, and birds) has attracted great attention, and many theories and models have emerged to simulate the behavior of biological communities. These studies are important in theory and practice and have wide application potential in optimization methods and product design, which leads to the so-called cluster intelligence. Development of the 3D animation system can be closely combined with cluster intelligence, and the full application of cluster intelligence is conducive to continuously improve the stability of animation system design, for animation system design to bring continuous design inspiration. The purpose of the development platform is to promote the development of enterprise projects, record each stage of the animation process in 3D, form a complete industrial chain, ensure the traceability and resilience of the whole process, and provide a comprehensive and effective solution for 3D animation production.","",""
427,"D. Ting, L. Pasquale, L. Peng, J. P. Campbell, Aaron Y. Lee, R. Raman, G. Tan, L. Schmetterer, P. Keane, T. Wong","Artificial intelligence and deep learning in ophthalmology",2018,"","","","",139,"2022-07-13 09:34:13","","10.1136/bjophthalmol-2018-313173","","",,,,,427,106.75,43,10,4,"Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, DL has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with DL application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the AI ‘black-box’ algorithms. DL could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art DL systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward.","",""
0,"R. W. Albuquerque, D. L. M. Vieira, M. E. Ferreira, L. P. Soares, S. Olsen, L. S. Araujo, L. E. Vicente, J. R. Tymus, C. Balieiro, M. Matsumoto, C. Grohmann","Mapping Key Indicators of Forest Restoration in the Amazon Using a Low-Cost Drone and Artificial Intelligence",2022,"","","","",140,"2022-07-13 09:34:13","","10.3390/rs14040830","","",,,,,0,0.00,0,11,1,"Monitoring the vegetation structure and species composition of forest restoration (FR) in the Brazilian Amazon is critical to ensuring its long-term benefits. Since remotely piloted aircrafts (RPAs) associated with deep learning (DL) are becoming powerful tools for vegetation monitoring, this study aims to use DL to automatically map individual crowns of Vismia (low resilience recovery indicator), Cecropia (fast recovery indicator), and trees in general (this study refers to individual crowns of all trees regardless of species as All Trees). Since All Trees can be accurately mapped, this study also aims to propose a tree crown heterogeneity index (TCHI), which estimates species diversity based on: the heterogeneity attributes/parameters of the RPA image inside the All Trees results; and the Shannon index measured by traditional fieldwork. Regarding the DL methods, this work evaluated the accuracy of the detection of individual objects, the quality of the delineation outlines and the area distribution. Except for Vismia delineation (IoU = 0.2), DL results presented accurate values in general, as F1 and IoU were always greater than 0.7 and 0.55, respectively, while Cecropia presented the most accurate results: F1 = 0.85 and IoU = 0.77. Since All Trees results were accurate, the TCHI was obtained through regression analysis between the canopy height model (CHM) heterogeneity attributes and the field plot data. Although TCHI presented robust parameters, such as p-value < 0.05, its results are considered preliminary because more data are needed to include different FR situations. Thus, the results of this work show that low-cost RPA has great potential for monitoring FR quality in the Amazon, because Vismia, Cecropia, and All Trees can be automatically mapped. Moreover, the TCHI preliminary results showed high potential in estimating species diversity. Future studies must assess domain adaptation methods for the DL results and different FR situations to improve the TCHI range of action.","",""
0,"Sandro González-González, L. Serpa-Andrade","Development of a virtual assistant chatbot based on Artificial Intelligence to control and supervise a process of 4 tanks which are interconnected",2022,"","","","",141,"2022-07-13 09:34:13","","10.54941/ahfe1001464","","",,,,,0,0.00,0,2,1,"This article presents the gathering of works related to the usage of virtual assistants into the 4.0 industry in order to stablish the parameters and essential characteristics to define the creation of a ‘chatbot’ virtual assistant. This device should be applicable to a process of 4 tanks which are interconnected with a robust multivariable PID control with the aim of controlling and supervising this process using a mobile messaging application from a smartphone by sending key words in text messages which will be interpreted by the chatbot and this will be capable of acting depending on the message it receives; it can be either a consultation of the status of the process and the tanks which will be answered with a text message with the required information, or a command which will make it work starting or stopping the process. This system is proposed as a solution in the case of long-distance supervision and control during different processes. With this, an option to optimize the execution of actions such as security, speed, reliability of data, and resource maximization can be implemented, which leads to a better general performance of an industry","",""
17,"M. Mrówczyńska, M. Sztubecka, M. Skiba, A. Bazan-Krzywoszanska, P. Bejga","The Use of Artificial Intelligence as a Tool Supporting Sustainable Development Local Policy",2019,"","","","",142,"2022-07-13 09:34:13","","10.3390/SU11154199","","",,,,,17,5.67,3,5,3,"This paper addresses the problem of noise in spa protection areas. Its aim is to determine the delimitation of the areas that exceed a permissible noise level around the sanatorium on the example of a health resort in Inowrocław. The determination of the exceedance of permissible noise levels allows us to develop directly effective local policy tools to be included in planning documents. In order to reduce noise infiltration, it is important to define environmental priorities. Taking into account their impact on the health of users in the protection area, environmental priorities enable us to introduce additional elements to street architecture. In order to properly manage space, in accordance with the idea of sustainable development, zones of environmental sensitivity—and their socio-environmental vulnerability—have been designated for assessing damage (exceeding permissible noise in health facilities) and defining methods of building resilience (proper management). This has provided the basis for a natural balance optimized for the people living in these areas. To achieve the goal above, non-linear support vector machine (SVM) networks were used. This technique allows us to classify the linearly inseparable data and to determine the optimal separation margin. The boundaries of the areas which exceeded permissible noise levels (separation margin) were estimated on the basis of noise pollution maps, created by means of the SVM technique. Thus, the study results in establishing buffer zones where it is possible to use varied land utilization in terms of form and function, as described in the planning documents. Such an activity would limit the spread of noise.","",""
9,"Nawaf H. M. M. Shrifan, M. F. Akbar, N. Isa","Prospect of Using Artificial Intelligence for Microwave Nondestructive Testing Technique: A Review",2019,"","","","",143,"2022-07-13 09:34:13","","10.1109/ACCESS.2019.2934143","","",,,,,9,3.00,3,3,3,"The development in materials technology has produced stronger, lighter, stiffer, and more durable electrically insulating composites which are replacing metals in many applications. These composites require alternative inspection techniques because the conventional nondestructive testing (NDT) techniques such as thermography, eddy currents, ultrasonic, X-ray and magnetic particles have limitations of inspecting them. Microwave NDT technique employing open-ended rectangular waveguides (OERW) has emerged as a promising approach to detect the defects in both metal and composite materials. Despite its promising results over conventional NDT techniques, OERW microwave NDT technique has shown numerous limitations in terms of poor spatial resolution due to the stand-off distance variations, inspection area irregularities and quantitative estimation in imaging the size of defects. Microwave NDT employing OERW in conjunction with robust artificial intelligence approaches have tremendous potential and viability for evaluating composite structures for the purpose mentioned here. Artificial intelligence techniques with signal processing techniques are highly possible to enhance the efficiency and resolution of microwave NDT technique because the impact of artificial intelligence approaches is proven in various conventional NDT techniques. This paper provides a comprehensive review of NDT techniques as well as the prospect of using artificial intelligence approaches in microwave NDT technique with regards to other conventional NDT techniques.","",""
13,"K. Schaefer, Jean Oh, Derya Aksaray, D. Barber","Integrating Context into Artificial Intelligence: Research from the Robotics Collaborative Technology Alliance",2019,"","","","",144,"2022-07-13 09:34:13","","10.1609/aimag.v40i3.2865","","",,,,,13,4.33,3,4,3,"Applying context to a situation, task, or system state provides meaning and advances understanding that can affect future decisions or actions. Although people are naturally good at perceiving contextual understanding and inferring missing pieces of information using various alternative sources, this process is difficult for AI systems or robots, especially in high-uncertainty and unstructured operations. Integration of context-driven AI is important for future robotic capabilities to support the development of situation awareness, calibrate appropriate trust, and improve team performance in collaborative human-robot teams. This article highlights advances in context-driven AI for human-robot teaming by the Army Research Laboratory’s Robotics Collaborative Technology Alliance. Avenues of research discussed include how context enables robots to fill in the gaps to make effective decisions more quickly, supports more robust behaviors, and augments robot communications to suit the needs of the team under a variety of environments and team organizations and across missions.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",145,"2022-07-13 09:34:13","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",146,"2022-07-13 09:34:13","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
9,"Farheen Naz, Anil . Kumar, A. Majumdar, R. Agrawal","Is artificial intelligence an enabler of supply chain resiliency post COVID-19? An exploratory state-of-the-art review for future research",2021,"","","","",147,"2022-07-13 09:34:13","","10.1007/s12063-021-00208-w","","",,,,,9,9.00,2,4,1,"","",""
43,"Dan Liu, Fei Liu, Xiao-yan Xie, Liya Su, Ming Liu, Xiaohua Xie, M. Kuang, Guangliang Huang, Yuqi Wang, Hui Zhou, Kun Wang, Manxia Lin, Jie Tian","Accurate prediction of responses to transarterial chemoembolization for patients with hepatocellular carcinoma by using artificial intelligence in contrast-enhanced ultrasound",2020,"","","","",148,"2022-07-13 09:34:13","","10.1007/s00330-019-06553-6","","",,,,,43,21.50,4,13,2,"","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",149,"2022-07-13 09:34:13","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
7,"David K. Spencer, Stephen Duncan, Adam Taliaferro","Operationalizing artificial intelligence for multi-domain operations: a first look",2019,"","","","",150,"2022-07-13 09:34:13","","10.1117/12.2524227","","",,,,,7,2.33,2,3,3,"Artificial Intelligence / Machine Learning (AI/ML) is a foundational requirement for Multi-Domain Operations (MDO). To solve some of MDO’s most critical problems, for example, penetrating and dis-integrating an adversary’s antiaccess/area denial (A2/AD) systems, the future force requires the ability to converge capabilities from across multiple domains at speeds and scales beyond human cognitive abilities. This requires robust, interoperable AI/ML that operates across multiple layers: from optimizing technologies and platforms, to fusing data from multiple sources, to transferring knowledge across joint functions to accomplish critical MDO tactical tasks. This paper provides an overview of ongoing work from the Unified Quest Future Study Plan and other events with the Army’s Futures and Concepts Center to operationalize AI/ML to address MDO problems with this layered approach. It includes insights and required AI/ML capabilities determined with subject matter experts from various organizations at these learning events over the past two years, as well as vignettes that illustrate how AI/ML can be operationalized to enable successful Multi-Domain Operations against a near peer adversary.","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",151,"2022-07-13 09:34:13","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
0,"Alessio Carpegna, S. Carlo, A. Savino","Artificial Resilience in neuromorphic systems",2022,"","","","",152,"2022-07-13 09:34:13","","10.1145/3535044.3535062","","",,,,,0,0.00,0,3,1,"Biological beings are intrinsically resilient. This means that they are able to continue to perform a task even if they are partially damaged or if some parts of them don’t work as expected. This is true also for the human brain. The research in these last years, however, has been concentrated on Artificial Intelligence (AI), to try to emulate the capabilities of the brain to improve itself, learning from experience. Artificial Resilience (AR) is something not explored in detail yet. This four pages abstract present a Ph.D. path dedicated to the extensive study of Artificial Resilience in all its aspects. The study will target neuromorphic systems, in particular Spiking Neural Networks, an emerging type of neural network models that try to mimic the behavior of a biological brain in a faithful way. In addition to this they are in general more suitable for an hardware acceleration. The goal of the Ph.D. is to realize a complete neuromorphic accelerator, configurable and resilient, and to apply it to improve the resilience of other electronic systems. Such an accelerator will be able to target area- and power-constrained applications in mission-critical environments, providing a more efficient alternative to classical techniques like Error Correction Codes (ECC) or redundancy to improve the robustness of a complex electronic system.","",""
6,"Francisco Javier Abarca-Álvarez, F. S. Campos-Sánchez, Fernando Osuna-Pérez","Urban Shape and Built Density Metrics through the Analysis of European Urban Fabrics Using Artificial Intelligence",2019,"","","","",153,"2022-07-13 09:34:13","","10.3390/su11236622","","",,,,,6,2.00,2,3,3,"In recent decades, the concept of urban density has been considered key to the creation of sustainable urban fabrics. However, when it comes to measuring the built density, a difficulty has been observed in defining valid measurement indicators universally. With the intention of identifying the variables that allow the best characterization of the shape of urban fabrics and of obtaining the metrics of their density, a multi-variable analysis methodology from the field of artificial intelligence is proposed. The main objective of this paper was to evaluate the capacity and interest of such a methodology from standard indicators of the built density, measured at various urban scales, (i) to cluster differentiated urban profiles in a robust way by assessing the results statistically, and (ii) to obtain the metrics that characterize them with an identity. As a case study, this methodology was applied to the state of the art European urban fabrics (N = 117) by simultaneously integrating 13 regular parameters to qualify urban shape and density. It was verified that the profiles obtained were more robust than those based on a limited number of indicators, evidencing that the proposed methodology offers operational opportunities in urban management by allowing the comparison of a fabric with the identified profiles.","",""
2,"O. Ahmad, L. Lovat","Artificial intelligence for colorectal polyp detection: are we ready for prime time?",2019,"","","","",154,"2022-07-13 09:34:13","","10.21037/jmai.2019.09.02","","",,,,,2,0.67,1,2,3,"Colorectal cancer (CRC) is a leading cause of cancer-related mortality worldwide. Colonoscopy is protective against CRC through the detection and removal of neoplastic polyps. Unfortunately, the procedure is highly operator dependent with significant miss rates for polyps. Artificial intelligence (AI) and computer-aided detection software offers a promising solution by providing real-time assistance to highlight lesions that may otherwise be overlooked. Rapid advances have occurred in the field with recent prospective clinical trials demonstrating an improved adenoma detection rate (ADR) with AI assistance. Deployment in routine clinical practice is possible in the near future although further robust clinical trials are necessary and important practical challenges relating to real-world implementation must be addressed.","",""
4,"A. Samareh, Xiangyu Chang, W. Lober, H. Evans, Zhangyang Wang, Xiaoning Qian, Shuai Huang","Artificial Intelligence Methods for Surgical Site Infection: Impacts on Detection, Monitoring, and Decision Making.",2019,"","","","",155,"2022-07-13 09:34:13","","10.1089/sur.2019.150","","",,,,,4,1.33,1,7,3,"Background: There has been tremendous growth in the amount of new surgical site infection (SSI) data generated. Key challenges exist in understanding the data for robust clinical decision-support. Limitations of traditional methodologies to handle these data led to the emergence of artificial intelligence (AI). This article emphasizes the capabilities of AI to identify patterns of SSI data. Method: Artificial intelligence comprises various subfields that present potential solutions to identify patterns of SSI data. Discussions on opportunities, challenges, and limitations of applying these methods to derive accurate SSI prediction are provided. Results: Four main challenges in dealing with SSI data were defined: (1) complexities in using SSI data, (2) disease knowledge, (3) decision support, and (4) heterogeneity. The implications of some of the recent advances in AI methods to optimize clinical effectiveness were discussed. Conclusions: Artificial intelligence has the potential to provide insight in detecting and decision-support of SSI. As we turn SSI data into intelligence about the disease, we increase the possibility of improving surgical practice with the promise of a future optimized for the highest quality patient care.","",""
6,"J. Senthil Kumar, G. Sivasankar, S. Selva Nidhyananthan","An Artificial Intelligence Approach for Enhancing Trust Between Social IoT Devices in a Network",2019,"","","","",156,"2022-07-13 09:34:13","","10.1007/978-3-030-24513-9_11","","",,,,,6,2.00,2,3,3,"","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",157,"2022-07-13 09:34:13","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
6,"A. Allam, S. Feuerriegel, M. Rebhan, M. Krauthammer","Analyzing Patient Trajectories With Artificial Intelligence.",2021,"","","","",158,"2022-07-13 09:34:13","","10.2196/29812","","",,,,,6,6.00,2,4,1,"In digital medicine, patient data typically record health events over time (eg, through electronic health records, wearables, or other sensing technologies) and thus form unique patient trajectories. Patient trajectories are highly predictive of the future course of diseases and therefore facilitate effective care. However, digital medicine often uses only limited patient data, consisting of health events from only a single or small number of time points while ignoring additional information encoded in patient trajectories. To analyze such rich longitudinal data, new artificial intelligence (AI) solutions are needed. In this paper, we provide an overview of the recent efforts to develop trajectory-aware AI solutions and provide suggestions for future directions. Specifically, we examine the implications for developing disease models from patient trajectories along the typical workflow in AI: problem definition, data processing, modeling, evaluation, and interpretation. We conclude with a discussion of how such AI solutions will allow the field to build robust models for personalized risk scoring, subtyping, and disease pathway discovery.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",159,"2022-07-13 09:34:13","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
4,"J. Braun, Jochen Hausler, Wolfgang Schäfers","Artificial intelligence, news sentiment, and property market liquidity",2019,"","","","",160,"2022-07-13 09:34:13","","10.1108/jpif-08-2019-0100","","",,,,,4,1.33,1,3,3,"The purpose of this paper is to use a text-based sentiment indicator to explain variations in direct property market liquidity in the USA.,By means of an artificial neural network, market sentiment is extracted from 66,070 US real estate market news articles from the S&P Global Market Intelligence database. For training of the network, a distant supervision approach utilizing 17,822 labeled investment ideas from the crowd-sourced investment advisory platform Seeking Alpha is applied.,According to the results of autoregressive distributed lag models including contemporary and lagged sentiment as independent variables, the derived textual sentiment indicator is not only significantly linked to the depth and resilience dimensions of market liquidity (proxied by Amihud’s (2002) price impact measure), but also to the breadth dimension (proxied by transaction volume).,These results suggest an intertemporal effect of sentiment on liquidity for the direct property market. Market participants should account for this effect in terms of their investment decisions, and also when assessing and pricing liquidity risk.,This paper not only extends the literature on text-based sentiment indicators in real estate, but is also the first to apply artificial intelligence for sentiment extraction from news articles in a market liquidity setting.","",""
38,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases.",2020,"","","","",161,"2022-07-13 09:34:13","","10.1038/s41746-020-0229-3","","",,,,,38,19.00,6,6,2,"","",""
45,"Avishek Choudhury, Onur Asan","Role of Artificial Intelligence in Patient Safety Outcomes: Systematic Literature Review",2020,"","","","",162,"2022-07-13 09:34:13","","10.2196/18599","","",,,,,45,22.50,23,2,2,"Background Artificial intelligence (AI) provides opportunities to identify the health risks of patients and thus influence patient safety outcomes. Objective The purpose of this systematic literature review was to identify and analyze quantitative studies utilizing or integrating AI to address and report clinical-level patient safety outcomes. Methods We restricted our search to the PubMed, PubMed Central, and Web of Science databases to retrieve research articles published in English between January 2009 and August 2019. We focused on quantitative studies that reported positive, negative, or intermediate changes in patient safety outcomes using AI apps, specifically those based on machine-learning algorithms and natural language processing. Quantitative studies reporting only AI performance but not its influence on patient safety outcomes were excluded from further review. Results We identified 53 eligible studies, which were summarized concerning their patient safety subcategories, the most frequently used AI, and reported performance metrics. Recognized safety subcategories were clinical alarms (n=9; mainly based on decision tree models), clinical reports (n=21; based on support vector machine models), and drug safety (n=23; mainly based on decision tree models). Analysis of these 53 studies also identified two essential findings: (1) the lack of a standardized benchmark and (2) heterogeneity in AI reporting. Conclusions This systematic review indicates that AI-enabled decision support systems, when implemented correctly, can aid in enhancing patient safety by improving error detection, patient stratification, and drug management. Future work is still needed for robust validation of these systems in prospective and real-world clinical environments to understand how well AI can predict safety outcomes in health care settings.","",""
43,"M. González-Rivero, Oscar Beijbom, A. Rodriguez-Ramirez, D. Bryant, A. Ganase, Y. González-Marrero, A. Herrera-Reveles, E. Kennedy, Catherine J. S. Kim, S. Lopez-Marcano, Kathryn Markey, B. Neal, K. Osborne, C. Reyes-Nivia, E. Sampayo, Kristin Stolberg, Abbie Taylor, J. Vercelloni, Mathew Wyatt, O. Hoegh‐Guldberg","Monitoring of Coral Reefs Using Artificial Intelligence: A Feasible and Cost-Effective Approach",2020,"","","","",163,"2022-07-13 09:34:13","","10.3390/rs12030489","","",,,,,43,21.50,4,20,2,"Ecosystem monitoring is central to effective management, where rapid reporting is essential to provide timely advice. While digital imagery has greatly improved the speed of underwater data collection for monitoring benthic communities, image analysis remains a bottleneck in reporting observations. In recent years, a rapid evolution of artificial intelligence in image recognition has been evident in its broad applications in modern society, offering new opportunities for increasing the capabilities of coral reef monitoring. Here, we evaluated the performance of Deep Learning Convolutional Neural Networks for automated image analysis, using a global coral reef monitoring dataset. The study demonstrates the advantages of automated image analysis for coral reef monitoring in terms of error and repeatability of benthic abundance estimations, as well as cost and benefit. We found unbiased and high agreement between expert and automated observations (97%). Repeated surveys and comparisons against existing monitoring programs also show that automated estimation of benthic composition is equally robust in detecting change and ensuring the continuity of existing monitoring data. Using this automated approach, data analysis and reporting can be accelerated by at least 200x and at a fraction of the cost (1%). Combining commonly used underwater imagery in monitoring with automated image annotation can dramatically improve how we measure and monitor coral reefs worldwide, particularly in terms of allocating limited resources, rapid reporting and data integration within and across management areas.","",""
37,"Jincai Yang, Cheng Shen, N. Huang","Predicting or Pretending: Artificial Intelligence for Protein-Ligand Interactions Lack of Sufficiently Large and Unbiased Datasets",2020,"","","","",164,"2022-07-13 09:34:13","","10.3389/fphar.2020.00069","","",,,,,37,18.50,12,3,2,"Predicting protein-ligand interactions using artificial intelligence (AI) models has attracted great interest in recent years. However, data-driven AI models unequivocally suffer from a lack of sufficiently large and unbiased datasets. Here, we systematically investigated the data biases on the PDBbind and DUD-E datasets. We examined the model performance of atomic convolutional neural network (ACNN) on the PDBbind core set and achieved a Pearson R2 of 0.73 between experimental and predicted binding affinities. Strikingly, the ACNN models did not require learning the essential protein-ligand interactions in complex structures and achieved similar performance even on datasets containing only ligand structures or only protein structures, while data splitting based on similarity clustering (protein sequence or ligand scaffold) significantly reduced the model performance. We also identified the property and topology biases in the DUD-E dataset which led to the artificially increased enrichment performance of virtual screening. The property bias in DUD-E was reduced by enforcing the more stringent ligand property matching rules, while the topology bias still exists due to the use of molecular fingerprint similarity as a decoy selection criterion. Therefore, we believe that sufficiently large and unbiased datasets are desirable for training robust AI models to accurately predict protein-ligand interactions.","",""
37,"Z. Yaseen, Z. H. Ali, Sinan Q. Salih, N. Al‐Ansari","Prediction of Risk Delay in Construction Projects Using a Hybrid Artificial Intelligence Model",2020,"","","","",165,"2022-07-13 09:34:13","","10.3390/su12041514","","",,,,,37,18.50,9,4,2,"Project delays are the major problems tackled by the construction sector owing to the associated complexity and uncertainty in the construction activities. Artificial Intelligence (AI) models have evidenced their capacity to solve dynamic, uncertain and complex tasks. The aim of this current study is to develop a hybrid artificial intelligence model called integrative Random Forest classifier with Genetic Algorithm optimization (RF-GA) for delay problem prediction. At first, related sources and factors of delay problems are identified. A questionnaire is adopted to quantify the impact of delay sources on project performance. The developed hybrid model is trained using the collected data of the previous construction projects. The proposed RF-GA is validated against the classical version of an RF model using statistical performance measure indices. The achieved results of the developed hybrid RF-GA model revealed a good resultant performance in terms of accuracy, kappa and classification error. Based on the measured accuracy, kappa and classification error, RF-GA attained 91.67%, 87% and 8.33%, respectively. Overall, the proposed methodology indicated a robust and reliable technique for project delay prediction that is contributing to the construction project management monitoring and sustainability.","",""
7,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: a Sensible Artificial Intelligence that plays with handicap and targets high scores in 9x9 Go (extended version)",2019,"","","","",166,"2022-07-13 09:34:13","","","","",,,,,7,2.33,1,6,3,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9x9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",167,"2022-07-13 09:34:13","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
34,"Shashank Vaid, Aaron McAdie, Ran Kremer, V. Khanduja, M. Bhandari","Risk of a second wave of Covid-19 infections: using artificial intelligence to investigate stringency of physical distancing policies in North America",2020,"","","","",168,"2022-07-13 09:34:13","","10.1007/s00264-020-04653-3","","",,,,,34,17.00,7,5,2,"","",""
32,"D. Bates, A. Auerbach, Peter F. Schulam, A. Wright, S. Saria","Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence",2020,"","","","",169,"2022-07-13 09:34:13","","10.7326/M19-0872","","",,,,,32,16.00,6,5,2,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.","",""
5,"Xiaochen Zhang, Dayu Yang","Research on Music Assisted Teaching System Based on Artificial Intelligence Technology",2021,"","","","",170,"2022-07-13 09:34:13","","10.1088/1742-6596/1852/2/022032","","",,,,,5,5.00,3,2,1,"With the advent of the information age, computer technology has been greatly developed, especially the development of Artificial Intelligence(AI). And with the passage of time, AI began to involve various fields, music education is no exception. In this paper, after a detailed understanding of some research results of AI on music assisted instruction system, we mainly analyze the students’ video, audio and other related information, and save it in the database. This paper first introduces the evaluation process by using AI technology. In fact, it is necessary to find out the relationship between the influencing factors and evaluation of music assisted teaching system. Neural network(NN) is actually a model proposed by simulating the way people think in the brain. It has no strict requirements for data distribution. In terms of nonlinear data processing method, robustness and dynamics, it is very suitable to be used as a model for evaluating music assisted instruction system. Then each factor is taken as the input parameter of the NN. According to the evaluation index of music teaching, a special modeling system is designed. With the help of technical personnel, we obtained the sample data of music performance and completed the neural training. The experimental results show that the development of AI technology has broken the original situation of traditional teaching, especially the application of music system and intelligent music software based on AI in music teaching.","",""
3,"M. Padmaja, S. Shitharth, K. Prasuna, Abhay Chaturvedi, P. Kshirsagar, A. Vani","Grow of Artificial Intelligence to Challenge Security in IoT Application",2021,"","","","",171,"2022-07-13 09:34:13","","10.1007/s11277-021-08725-4","","",,,,,3,3.00,1,6,1,"","",""
3,"Feng Xiao, Jintao Ke","Pricing, management and decision-making of financial markets with artificial intelligence: introduction to the issue",2021,"","","","",172,"2022-07-13 09:34:13","","10.1186/s40854-021-00302-9","","",,,,,3,3.00,2,2,1,"","",""
1,"Sara R. Jordan","Challenges of Artificial Intelligence Review in a Soft Law Environment",2021,"","","","",173,"2022-07-13 09:34:13","","10.1109/MTS.2021.3123743","","",,,,,1,1.00,1,1,1,"<bold>If artificial intelligence (AI)</bold> lives up to the claims of journalists, futurists, and tech companies, then AI stands to disrupt the landscape of human cognition, social order, and political power. Within a week’s span, AI can be discussed in both positive and utopian terms as well as in negative, even apocalyptic, terms. On the positive side, AI is described as an extraordinarily confident and capable F-16 pilot <xref ref-type=""bibr"" rid=""ref2"">[2]</xref>, a panoptic gastroenterologist who misses no part of a colonoscopy <xref ref-type=""bibr"" rid=""ref3"">[3]</xref>, the all-seeing solution to mapping climate change affected regions <xref ref-type=""bibr"" rid=""ref4"">[4]</xref>, and a smartphone application able to show your body with 12% less fat and give dieting advice to achieve that goal <xref ref-type=""bibr"" rid=""ref5"">[5]</xref>. Conversely, in a similar one-week period, AI is described as a tool for the surveillance of a minority population <xref ref-type=""bibr"" rid=""ref6"">[6]</xref>, a technique for identifying the whereabouts of political protestors or dissidents <xref ref-type=""bibr"" rid=""ref7"">[7]</xref>, a rogue system that delivers arbitrary scores on high-stakes examinations <xref ref-type=""bibr"" rid=""ref8"">[8]</xref>, and a harbinger of decline for reasoning, resilience, and emotional intelligence <xref ref-type=""bibr"" rid=""ref9"">[9]</xref>. Each of these assertions rests on the interpretation of both basic and applied AI research that may or may not be deployed into the production environment of normal human lives.","",""
2,"C. Koo, Zheng Xiang, U. Gretzel, M. Sigala","Artificial intelligence (AI) and robotics in travel, hospitality and leisure",2021,"","","","",174,"2022-07-13 09:34:13","","10.1007/s12525-021-00494-z","","",,,,,2,2.00,1,4,1,"","",""
2,"P. W. Grimm, Maura R. Grossman, G. Cormack","Artificial Intelligence as Evidence",2021,"","","","",175,"2022-07-13 09:34:13","","","","",,,,,2,2.00,1,3,1,"This article explores issues that govern the admissibility of Artificial Intelligence (“AI”) applications in civil and criminal cases, from the perspective of a federal trial judge and two computer scientists, one of whom also is an experienced attorney. It provides a detailed yet intelligible discussion of what AI is and how it works, a history of its development, and a description of the wide variety of functions that it is designed to accomplish, stressing that AI applications are ubiquitous, both in the private and public sectors. Applications today include: health care, education, employment-related decision-making, finance, law enforcement, and the legal profession. The article underscores the importance of determining the validity of an AI application (i.e., how accurately the AI measures, classifies, or predicts what it is designed to), as well as its reliability (i.e., the consistency with which the AI produces accurate results when applied to the same or substantially similar circumstances), in deciding whether it should be admitted into evidence in civil and criminal cases. The article further discusses factors that can affect the validity and reliability of AI evidence, including bias of various types, “function creep,” lack of transparency and explainability, and the sufficiency of the objective testing of AI applications before they are released for public use. The article next provides an in-depth discussion of the evidentiary principles that govern whether AI evidence should be admitted in court cases, a topic which, at present, is not the subject of comprehensive analysis in decisional law. The focus of this discussion is on providing a step-by-step analysis of the most important issues, and the factors that affect decisions on whether to admit AI evidence. Finally, the article concludes with a discussion of practical suggestions intended to assist lawyers and judges as they are called upon to introduce, object to, or decide on whether to admit AI evidence. 1 Hon. Paul W. Grimm is a United States District Judge for the District of Maryland, and an adjunct professor at both the University of Maryland Carey School of Law and the University of Baltimore School of Law. Maura R. Grossman, J.D., Ph.D., is a Research Professor, and Gordon V. Cormack, Ph.D., is a Professor, in the David R. Cheriton School of Computer Science at the University of Waterloo. Professor Grossman is also an affiliate faculty member at the Vector Institute for Artificial Intelligence. Her work is funded, in part, by the National Sciences and Engineering Council of Canada (“NESERC”). The opinions expressed in this article are the authors’ own, and do not necessarily reflect the views of the institutions or organizations with which they are affiliated. NORTHWESTERN JOURNAL OF TECHNOLOGY AND INTELLECTUAL PROPERTY 10 INTRODUCTION .............................................................................................................. 10 I. WHAT IS “ARTIFICIAL INTELLIGENCE”? .................................................................... 14 II. WHY AI HAS COME TO THE FOREFRONT TODAY ...................................................... 17 III. THE AI TECHNOLOGY LANDSCAPE .......................................................................... 24 IV. USES OF AI IN BUSINESS AND LAW TODAY .............................................................. 32 V. ISSUES RAISED BY THE USE OF AI IN BUSINESS AND LAW TODAY ............................ 41 A. Bias ............................................................................................................... 42 B. Lack of Robust Testing for Validity and Reliability ....................................... 48 C. Failure to Monitor for Function Creep ......................................................... 51 D. Failure to Ensure Data Privacy and Data Protection .................................. 53 E. Lack of Transparency and Explainabilty ....................................................... 60 F. Lack of Accountability ................................................................................... 65 G. Lack of Resilience ......................................................................................... 72 VI. ESTABLISHING VALIDITY AND RELIABILITY ........................................................... 79 A. Testimony, Expert Testimony, or Technology? .............................................. 79 B. Benchmarks and Goodhart’s Law ................................................................. 82 VII. EVIDENTIARY PRINCIPLES THAT SHOULD BE CONSIDERED IN EVALUATING THE ADMISSIBILITY OF AI EVIDENCE IN CIVIL AND CRIMINAL TRIALS .................... 84 A. Adequacy of the Federal Rules of Evidence in Addressing the Admissibility of AI Evidence ......................................................................... 84 B. Relevance ...................................................................................................... 86 C. Authentication of AI Evidence ....................................................................... 90 D. Usefulness of the Daubert Factors in Determining Whether to Admit AI Evidence ....................................................................................................... 95 E. Practice Pointers for Lawyers and Judges .................................................... 97 CONCLUSION ............................................................................................................... 105","",""
29,"Brandon Malone, Boris Simovski, Clément Moliné, Jun Cheng, Marius Gheorghe, Hugues Fontenelle, Ioannis Vardaxis, Simen Tennøe, Jenny-Ann Malmberg, R. Stratford, T. Clancy","Artificial intelligence predicts the immunogenic landscape of SARS-CoV-2 leading to universal blueprints for vaccine designs",2020,"","","","",176,"2022-07-13 09:34:13","","10.1038/s41598-020-78758-5","","",,,,,29,14.50,3,11,2,"","",""
0,"Abdulraqeb Alhammadi, Ayman A. El-Saleh, Ibraheem Shayea","MOS Prediction for Mobile Broadband Networks Using Bayesian Artificial Intelligence",2021,"","","","",177,"2022-07-13 09:34:13","","10.1109/ICAICST53116.2021.9497834","","",,,,,0,0.00,0,3,1,"Mobile broadband (MBB) networks are growing fast with supporting high-speed internet access. Fifth-generation networks promise an enhanced MBB that offers a high-speed data rate and video streaming with ultra-low latency. Thus, monitoring the level quality of these services supported by network providers becomes essential. Mobile network operators continuously optimize their network performance to provide a better quality of service and quality of experience. Moreover, artificial intelligence has been used considerably in optimizations to efficiently meet the requirements of future mobile networks. In this paper, we propose a Bayesian network model to predict the minimum opinion score (MOS), which contributes to evaluating the network performance of video streaming services. The proposed model depends on several input data, namely, bite rate, stalling load, and round-trip time. The predicted MOS depends on prior probability distributions to generate posterior probabilities. The predicted MOS depends on these input data. Results demonstrate that the proposed model achieves a high prediction accuracy of 86%, with a mean square error of 0.34. The proposed model also has a robust performance design through various testing methods.","",""
0,"Jie Wang, Xiangyuan Zheng, Qingdong He","Artificial Intelligence Applied to Extreme Value Prediction of Non-Gaussian Processes with Bandwidth Effect and Non-monotonicity",2021,"","","","",178,"2022-07-13 09:34:13","","10.1109/ICAICA52286.2021.9498204","","",,,,,0,0.00,0,3,1,"Extreme value prediction of a short-term non-Gaussian random process like ocean waves has been a tough issue for decades. In the 1990’s Winterstein proposed a cubic Hermite transformation using skewness and kurtosis, which has been widely applied in many areas for its accuracy and robustness. However, this approach is valid for monotonic transformation and narrow-banded processes. When the bandwidth of a random process is wide, no reasonable methods are available for acquiring the extreme value. This paper therefore applies the artificial neural network and genetic algorithm to do the extreme value prediction, without seeking rigorous mathematical derivations. Not only skewness and kurtosis are used, the spectral moments up to 4th-order reflecting bandwidth effects are also adopted. The results of many random case studies show that the artificial intelligence method is more accurate than the Hermite method in most of situations, especially for non-monotonic transformations. Besides, the artificial intelligence method has a wider application range.","",""
24,"P. Iftikhar, Marcela Kuijpers, Azadeh Khayyat, Aqsa Iftikhar, Maribel DeGouvia De Sa","Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice",2020,"","","","",179,"2022-07-13 09:34:13","","10.7759/cureus.7124","","",,,,,24,12.00,5,5,2,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians. Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating AI systems into their daily practice. AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. AI systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required.","",""
27,"I. Stafford, M. Kellermann, E. Mossotto, R. M. Beattie, B. MacArthur, S. Ennis","A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases",2020,"","","","",180,"2022-07-13 09:34:13","","10.1038/s41746-020-0229-3","","",,,,,27,13.50,5,6,2,"","",""
9,"J. Chen, Jen-Ting Chang","Route Choice Behaviour Modeling using IoT Integrated Artificial Intelligence",2021,"","","","",181,"2022-07-13 09:34:13","","10.36548/JAICN.2020.4.006","","",,,,,9,9.00,5,2,1,"Automatic Vehicle Identification (AVI) data is used to identify the location of a particular vehicle in and can also be used for route choice behaviour modelling. But the use of AVI doesn’t provide accurate information on OD pair and the particular route that is chosen. This problem is addressed in this paper using a semi-supervised learning method which can be used to identify the route on prior training. As the first step, the AVI trace is segregated into observation pairs using the Maximum Likelihood Estimation and then it is further joined with GPS co-ordinates to tackle the sparse issues. As the next step, the heterogeneity and correlation between the various pairs are determined using Mixed Logit model. As the final step, a relationship between the likelihood function and route choice model is established using Maximum to log-likelihood function. Based on the observations, the results are recorded and the proposed work shows significant improvement in the accuracy in route determination. The evaluation scenario shows that the proposed work could be expanded to a larger area. Moreover, the robustness of the system is illustrated using sensitivity analysis. This work uses AVI data with respect to its behaviour in routes through high penetration.","",""
0,"Joseph Noussa-Yao, D. Heudes, P. Degoulet","Using Artificial Intelligence and Big Data-Based Documents to Optimize Medical Coding",2019,"","","","",182,"2022-07-13 09:34:13","","10.5772/INTECHOPEN.85749","","",,,,,0,0.00,0,3,3,"Clinical information systems (CISs) in some hospitals streamline the data management from data warehouses. These warehouses contain heterogeneous information from all medical specialties that offer patient care services. It is increasingly difficult to manage large volumes of data in a specific clinical context such as quality coding of medical services. The document-based not only SQL (NoSQL) model can provide an accessible, extensive, and robust coding data management framework while maintaining certain flexibility. This paper focuses on the design and implementation of a big data-coding warehouse, and it also defines the rules to convert a conceptual model of coding into a document-oriented logical model. Using that model, we implemented and analyzed a big data-coding warehouse via the MongoDB database and evaluated it using data research monoand multicriteria and then calculated the precision of our model.","",""
82,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing and Collusion",2018,"","","","",183,"2022-07-13 09:34:13","","10.2139/ssrn.3304991","","",,,,,82,20.50,21,4,4,"Pricing algorithms are increasingly replacing human decision making in real marketplaces. To inform the competition policy debate on possible consequences, we run experiments with pricing algorithms powered by Artificial Intelligence in controlled environments (computer simulations).<br><br>In particular, we study the interaction among a number of Q-learning algorithms in the context of a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. We show that the algorithms consistently learn to charge supra-competitive prices, without communicating with each other. The high prices are sustained by classical collusive strategies with a finite punishment phase followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
52,"Hamon Ronan, Junklewitz Henrik, S. Ignacio","Robustness and Explainability of Artificial Intelligence",2020,"","","","",184,"2022-07-13 09:34:13","","10.2760/57493","","",,,,,52,26.00,17,3,2,"","",""
6,"B. Mahboub, M. Bataineh, H. Alshraideh, R. Hamoudi, Laila Salameh, A. Shamayleh","Prediction of COVID-19 Hospital Length of Stay and Risk of Death Using Artificial Intelligence-Based Modeling",2021,"","","","",185,"2022-07-13 09:34:13","","10.3389/fmed.2021.592336","","",,,,,6,6.00,1,6,1,"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a highly infectious virus with overwhelming demand on healthcare systems, which require advanced predictive analytics to strategize COVID-19 management in a more effective and efficient manner. We analyzed clinical data of 2017 COVID-19 cases reported in the Dubai health authority and developed predictive models to predict the patient's length of hospital stay and risk of death. A decision tree (DT) model to predict COVID-19 length of stay was developed based on patient clinical information. The model showed very good performance with a coefficient of determination R2 of 49.8% and a median absolute deviation of 2.85 days. Furthermore, another DT-based model was constructed to predict COVID-19 risk of death. The model showed excellent performance with sensitivity and specificity of 96.5 and 87.8%, respectively, and overall prediction accuracy of 96%. Further validation using unsupervised learning methods showed similar separation patterns, and a receiver operator characteristic approach suggested stable and robust DT model performance. The results show that a high risk of death of 78.2% is indicated for intubated COVID-19 patients who have not used anticoagulant medications. Fortunately, intubated patients who are using anticoagulant and dexamethasone medications with an international normalized ratio of <1.69 have zero risk of death from COVID-19. In conclusion, we constructed artificial intelligence–based models to accurately predict the length of hospital stay and risk of death in COVID-19 cases. These smart models will arm physicians on the front line to enhance management strategies to save lives.","",""
21,"Chuan Zhang, Yeong-Luh Ueng, Christoph Studer, A. Burg","Artificial Intelligence for 5G and Beyond 5G: Implementations, Algorithms, and Optimizations",2020,"","","","",186,"2022-07-13 09:34:13","","10.1109/JETCAS.2020.3000103","","",,,,,21,10.50,5,4,2,"The communication industry is rapidly advancing towards 5G and beyond 5G (B5G) wireless technologies in order to fulfill the ever-growing needs for higher data rates and improved quality-of-service (QoS). Emerging applications require wireless connectivity with tremendously increased data rates, substantially reduced latency, and growing support for a large number of devices. These requirements pose new challenges that can no longer be efficiently addressed by conventional approaches. Artificial intelligence (AI) is considered as one of the most promising solutions to improve the performance and robustness of 5G and B5G systems, fueled by the massive amount of data generated in 5G and B5G networks and the availability of powerful data processing fabrics. As a consequence, a plethora of research on AI-based communication technologies has emerged recently, promising higher data rates and improved QoS with affordable implementation overhead. In this overview paper, we summarize the state-of-the-art of AI-based 5G and B5G techniques on the algorithm, implementation, and optimization levels. We shed light on the advantages and limitations of AI-based solutions, and we provide a summary of emerging techniques and open research problems.","",""
19,"Sandip K. Patel, Bhawana George, Vineeta Rai","Artificial Intelligence to Decode Cancer Mechanism: Beyond Patient Stratification for Precision Oncology",2020,"","","","",187,"2022-07-13 09:34:13","","10.3389/fphar.2020.01177","","",,,,,19,9.50,6,3,2,"The multitude of multi-omics data generated cost-effectively using advanced high-throughput technologies has imposed challenging domain for research in Artificial Intelligence (AI). Data curation poses a significant challenge as different parameters, instruments, and sample preparations approaches are employed for generating these big data sets. AI could reduce the fuzziness and randomness in data handling and build a platform for the data ecosystem, and thus serve as the primary choice for data mining and big data analysis to make informed decisions. However, AI implication remains intricate for researchers/clinicians lacking specific training in computational tools and informatics. Cancer is a major cause of death worldwide, accounting for an estimated 9.6 million deaths in 2018. Certain cancers, such as pancreatic and gastric cancers, are detected only after they have reached their advanced stages with frequent relapses. Cancer is one of the most complex diseases affecting a range of organs with diverse disease progression mechanisms and the effectors ranging from gene-epigenetics to a wide array of metabolites. Hence a comprehensive study, including genomics, epi-genomics, transcriptomics, proteomics, and metabolomics, along with the medical/mass-spectrometry imaging, patient clinical history, treatments provided, genetics, and disease endemicity, is essential. Cancer Moonshot℠ Research Initiatives by NIH National Cancer Institute aims to collect as much information as possible from different regions of the world and make a cancer data repository. AI could play an immense role in (a) analysis of complex and heterogeneous data sets (multi-omics and/or inter-omics), (b) data integration to provide a holistic disease molecular mechanism, (c) identification of diagnostic and prognostic markers, and (d) monitor patient’s response to drugs/treatments and recovery. AI enables precision disease management well beyond the prevalent disease stratification patterns, such as differential expression and supervised classification. This review highlights critical advances and challenges in omics data analysis, dealing with data variability from lab-to-lab, and data integration. We also describe methods used in data mining and AI methods to obtain robust results for precision medicine from “big” data. In the future, AI could be expanded to achieve ground-breaking progress in disease management.","",""
19,"E. I. Fernandez, André Satoshi Ferreira, M. Cecílio, D. S. Chéles, Rebeca Colauto Milanezi de Souza, M. Nogueira, J. C. Rocha","Artificial intelligence in the IVF laboratory: overview through the application of different types of algorithms for the classification of reproductive data",2020,"","","","",188,"2022-07-13 09:34:13","","10.1007/s10815-020-01881-9","","",,,,,19,9.50,3,7,2,"","",""
4,"D. Cabrera, R. Rubilar, Claudio Cubillos","Resilience in the Decision-Making of an Artificial Autonomous System on the Stock Market",2019,"","","","",189,"2022-07-13 09:34:13","","10.1109/ACCESS.2019.2945471","","",,,,,4,1.33,1,3,3,"This paper presents the design of a resilience mechanism for supporting investment decision-making processes performed by artificial autonomous systems. In the field of Psychology, resilience is understood as the capacity of people to overcome adversity. Resilience has been determined to be a permanent necessary element for the life of an individual. In addition, different levels of intelligence, analysis capacities, and degrees of autonomy have been progressively incorporated within information systems that are oriented to support decision-making processes, such as those for stock markets. Particularly, the inclusion of affective criteria or variables within decision-making systems represents a promising line of action. However, to the best of our knowledge, there are no proposals that suggest the inclusion of a psychological approach to resilience within an autonomous decision-making system for stock markets. Specifically, the incorporation of a psychological approach to resilience allows the autonomous system to face special difficult investment scenarios (e.g., an economic shock) and prevent the system from achieving a permanent negative performance. Thus, psychological resilience can enable an artificial autonomous system to adapt its decision-making processes according to uncertain investment environments. Our proposal conducts experiments using official data from the Standard & Poor’s 500 Index. The results are promising and are based on a second-order autoregressive model. The test results suggest that the use of a resilience mechanism within an artificial autonomous system can contain and recover the affective dimensions of the system when it faces adverse decision scenarios.","",""
30,"Xinqin Liao, Wei‐ming Song, X. Zhang, Chaoqun Yan, Tianliang Li, Hongliang Ren, Cunzhi Liu, Yongtian Wang, Yuanjin Zheng","A bioinspired analogous nerve towards artificial intelligence",2020,"","","","",190,"2022-07-13 09:34:13","","10.1038/s41467-019-14214-x","","",,,,,30,15.00,3,9,2,"","",""
3,"Juan Pedro Martínez-Ramón, F. Morales-Rodríguez, S. Pérez-López","Burnout, Resilience, and COVID-19 among Teachers: Predictive Capacity of an Artificial Neural Network",2021,"","","","",191,"2022-07-13 09:34:13","","10.3390/app11178206","","",,,,,3,3.00,1,3,1,"Emotional exhaustion, cynicism, and work inefficiency are three dimensions that define burnout syndrome among teachers. On another note, resilience can be understood as the ability to adapt to the environment and overcome adverse situations. In addition, COVID-19 has provided a threatening environment that has led to the implementation of resilience strategies to struggle with burnout and cope with the virus. The aim of this study was to analyze the relationship between resilience, burnout dimensions, and variables associated with COVID-19 through the design of an artificial neural network architecture. For this purpose, the Maslach Burnout Inventory-General Survey (MBI-GS), the Brief Resilience Coping Scale (BRCS), and a questionnaire on stress towards COVID-19 were administered to 419 teachers from secondary schools in southeastern Spain (292 females; 69.7%). The results showed that 30.8% suffered from burnout (high emotional exhaustion, high cynicism, and low professional efficacy) and that 38.7% had a high level of resilience, with an inverse relationship between both constructs. Likewise, we modelled an ANN able to predict burnout syndrome among 97.4% of teachers based on its dimensions, resilience, sociodemographic variables, and the stress generated by COVID-19. Our conclusions shed some light on the efficacy of relying on artificial intelligence in the educational field to predict the psychological situation of teachers and take early action.","",""
3,"Pu Yanan, Yan Jilong, Zhang Heng","Using Artificial Intelligence to Achieve Auxiliary Training of Table Tennis Based on Inertial Perception Data",2021,"","","","",192,"2022-07-13 09:34:13","","10.3390/s21196685","","",,,,,3,3.00,1,3,1,"Compared with optical sensors, wearable inertial sensors have many advantages such as low cost, small size, more comprehensive application range, no space restrictions and occlusion, better protection of user privacy, and more suitable for sports applications. This article aims to solve irregular actions that table tennis enthusiasts do not know in actual situations. We use wearable inertial sensors to obtain human table tennis action data of professional table tennis players and non-professional table tennis players, and extract the features from them. Finally, we propose a new method based on multi-dimensional feature fusion convolutional neural network and fine-grained evaluation of human table tennis actions. Realize ping-pong action recognition and evaluation, and then achieve the purpose of auxiliary training. The experimental results prove that our proposed multi-dimensional feature fusion convolutional neural network has an average recognition rate that is 0.17 and 0.16 higher than that of CNN and Inception-CNN on the nine-axis non-professional test set, which proves that we can better distinguish different human table tennis actions and have a more robust generalization performance. Therefore, on this basis, we have better realized the enthusiast of table tennis the purpose of the action for auxiliary training.","",""
16,"B. Koçak, Ece Ates Kus, O. Kilickesmez","How to read and review papers on machine learning and artificial intelligence in radiology: a survival guide to key methodological concepts",2020,"","","","",193,"2022-07-13 09:34:13","","10.1007/s00330-020-07324-4","","",,,,,16,8.00,5,3,2,"","",""
0,"Maria Cecilia Anggraeni, Chrysanti Anastasya Silaban, Maria Susan Anggreainy, Ervan Cahyadi","Role of Artificial Intelligence in the Management of Food Waste",2021,"","","","",194,"2022-07-13 09:34:13","","10.1109/AiDAS53897.2021.9574167","","",,,,,0,0.00,0,4,1,"Food waste is caused by a complex collection of interconnected behavior at both the supplier and customer levels. Computational and mathematical models provide various methods for simulating, diagnosing, and predicting various aspects of the dynamic food waste generation and prevention system. This paper describes three modeling methods that have been used to analyze food waste in the past. Bayesian networks and machine learning algorithms are applied to help determine how much food is discarded at the household level. Agent-Based Simulation was used to gain insight into how innovation and adoption of a particular technology can help minimize retail food waste. The first BN-ABM integrated model assesses consumer food waste levels affected by particular features and aspects, resulting in the model reaching equilibrium. Proofing that there is a need for policy interventions, including training, economic incentives, and campaigns, to obtain the resulting model transformation. These interventions are ready to be assessed by the model, but further study is needed to understand the effects of enforcing these structures on the accuracy of the BN-ABM predictive model. The second ABM model aims to determine the factors that establish the adoption of food waste reduction technology at the retail level, which is influenced by particular but not limited to economic factors, including a strong network between retailers and consumer's awareness regarding food waste reduction technology. These findings can study the effects of policy intervention regarding food waste reduction at the retail and consumer level. The third ABM model employed a general food chain network model consisting of consumers, traders, and producers to simulate the dynamic change of product flow between agents and to be able to assess the effect of agent's behavioral contrast. Resilience is measured by the ability to deal with shocks, and efficiency is the share of total food manages to be dispatched to consumers. At first glance, the simulation results seem to show a system trade-off between efficiency and resilience. Network chain structures with higher efficiency displayed more sensitivity to shocks, while networks with less efficiency show more resilience. However, there seem to be modifications in the results when applying several trading interactions and shock types. Resiliency and efficiency are affected by social aspects (trust and preference) in trading interaction between agents. An essential aspect of resilience is the agent's ability to switch links (trading partners) which shows the capability of reorganization. Insights regarding the research can be applicable when considering real-life food chain and structural reorganization to increase resilience and efficiency in meeting national food security goals.","",""
0,"E. Cambouropoulos, Maximos A. Kaliakatsos-Papakostas","Cognitive Musicology and Artificial Intelligence: Harmonic Analysis, Learning, and Generation",2021,"","","","",195,"2022-07-13 09:34:13","","10.1007/978-3-030-72116-9_10","","",,,,,0,0.00,0,2,1,"","",""
14,"M. Yazdani-Asrami, Mehran Taghipour-Gorjikolaie, Wenjuan Song, Min Zhang, W. Yuan","Prediction of Nonsinusoidal AC Loss of Superconducting Tapes Using Artificial Intelligence-Based Models",2020,"","","","",196,"2022-07-13 09:34:13","","10.1109/ACCESS.2020.3037685","","",,,,,14,7.00,3,5,2,"Current is no longer sinusoidal in modern electric networks because of widespread use of power electronic-based equipments and nonlinear loads. Usually AC loss is calculated for pure sinusoidal current, while it is no longer accurate when current is nonsinusoidal. On the other hand, efficiency of cooling system in large scale power devices is dependent on accurate estimation and prediction of the heat load caused by AC loss in design stage. Therefore, estimation of nonsinusoidal AC loss of high temperature superconducting (HTS) material would be of great interest for designers of large-scale superconducting devices. In this paper, at first nonsinusoidal AC loss of a typical HTS tape was calculated under distorted currents using H-formulation finite element method. Then, a range of artificial intelligence (AI) models were implemented to predict AC loss of a typical HTS tape. In order to find the best and more adaptive AI model for nonsinusoidal AC loss prediction, different regression models are evaluated using Support Vector Machine regression model, Generalized Linear regression model, Decision Tree regression model, Feed Forward Neural Network based model, Adaptive Neuro Fuzzy Inference System based model, and Radial Basis Function Neural Network (RBFNN) based model. In order to evaluate robustness of developed models cross-validation technique is implemented on experimental data. To compare the performance of different AI models, four prediction measures were used: Theil’s U coefficients (U_Accuracy and U_Quality), Root Mean Square Error (RMSE) and Regression value (R-value). Obtained results show that best performance belongs to RBFNN based model and then ANFIS based model. U coefficients and RMSE values are obtained less than 0.005 and R-Value is become close to one by using RBFNN based model for testing data, which indicates high accuracy prediction performance.","",""
14,"A. Burlacu, Adrian Iftene, Daniel Jugrin, I. Popa, Paula Madalina Lupu, C. Vlad, A. Covic","Using Artificial Intelligence Resources in Dialysis and Kidney Transplant Patients: A Literature Review",2020,"","","","",197,"2022-07-13 09:34:13","","10.1155/2020/9867872","","",,,,,14,7.00,2,7,2,"Background The purpose of this review is to depict current research and impact of artificial intelligence/machine learning (AI/ML) algorithms on dialysis and kidney transplantation. Published studies were presented from two points of view: What medical aspects were covered? What AI/ML algorithms have been used? Methods We searched four electronic databases or studies that used AI/ML in hemodialysis (HD), peritoneal dialysis (PD), and kidney transplantation (KT). Sixty-nine studies were split into three categories: AI/ML and HD, PD, and KT, respectively. We identified 43 trials in the first group, 8 in the second, and 18 in the third. Then, studies were classified according to the type of algorithm. Results AI and HD trials covered: (a) dialysis service management, (b) dialysis procedure, (c) anemia management, (d) hormonal/dietary issues, and (e) arteriovenous fistula assessment. PD studies were divided into (a) peritoneal technique issues, (b) infections, and (c) cardiovascular event prediction. AI in transplantation studies were allocated into (a) management systems (ML used as pretransplant organ-matching tools), (b) predicting graft rejection, (c) tacrolimus therapy modulation, and (d) dietary issues. Conclusions Although guidelines are reluctant to recommend AI implementation in daily practice, there is plenty of evidence that AI/ML algorithms can predict better than nephrologists: volumes, Kt/V, and hypotension or cardiovascular events during dialysis. Altogether, these trials report a robust impact of AI/ML on quality of life and survival in G5D/T patients. In the coming years, one would probably witness the emergence of AI/ML devices that facilitate the management of dialysis patients, thus increasing the quality of life and survival.","",""
14,"I. Tyukin, D. Higham, A. Gorban","On Adversarial Examples and Stealth Attacks in Artificial Intelligence Systems",2020,"","","","",198,"2022-07-13 09:34:13","","10.1109/IJCNN48605.2020.9207472","","",,,,,14,7.00,5,3,2,"In this work we present a formal theoretical framework for assessing and analyzing two classes of malevolent action towards generic Artificial Intelligence (AI) systems. Our results apply to general multi-class classifiers that map from an input space into a decision space, including artificial neural networks used in deep learning applications. Two classes of attacks are considered. The first class involves adversarial examples and concerns the introduction of small perturbations of the input data that cause misclassification. The second class, introduced here for the first time and named stealth attacks, involves small perturbations to the AI system itself. Here the perturbed system produces whatever output is desired by the attacker on a specific small data set, perhaps even a single input, but performs as normal on a validation set (which is unknown to the attacker).We show that in both cases, i.e., in the case of an attack based on adversarial examples and in the case of a stealth attack, the dimensionality of the AI’s decision-making space is a major contributor to the AI’s susceptibility. For attacks based on adversarial examples, a second crucial parameter is the absence of local concentrations in the data probability distribution, a property known as Smeared Absolute Continuity. According to our findings, robustness to adversarial examples requires either (a) the data distributions in the AI’s feature space to have concentrated probability density functions or (b) the dimensionality of the AI’s decision variables to be sufficiently small. We also show how to construct stealth attacks on high-dimensional AI systems that are hard to spot unless the validation set is made exponentially large.","",""
14,"E. Kotter, E. Ranschaert","Challenges and solutions for introducing artificial intelligence (AI) in daily clinical workflow",2020,"","","","",199,"2022-07-13 09:34:13","","10.1007/s00330-020-07148-2","","",,,,,14,7.00,7,2,2,"","",""
14,"Gaolei Li, K. Ota, M. Dong, Jun Wu, Jianhua Li","DeSVig: Decentralized Swift Vigilance Against Adversarial Attacks in Industrial Artificial Intelligence Systems",2020,"","","","",200,"2022-07-13 09:34:13","","10.1109/TII.2019.2951766","","",,,,,14,7.00,3,5,2,"Individually reinforcing the robustness of a single deep learning model only gives limited security guarantees especially when facing adversarial examples. In this article, we propose DeSVig, a decentralized swift vigilance framework to identify adversarial attacks in an industrial artificial intelligence systems (IAISs), which enables IAISs to correct the mistake in a few seconds. The DeSVig is highly decentralized, which improves the effectiveness of recognizing abnormal inputs. We try to overcome the challenges on ultralow latency caused by dynamics in industries using peculiarly designated mobile edge computing and generative adversarial networks. The most important advantage of our work is that it can significantly reduce the failure risks of being deceived by adversarial examples, which is critical for safety-prioritized and delay-sensitive environments. In our experiments, adversarial examples of industrial electronic components are generated by several classical attacking models. Experimental results demonstrate that the DeSVig is more robust, efficient, and scalable than some state-of-art defenses.","",""
