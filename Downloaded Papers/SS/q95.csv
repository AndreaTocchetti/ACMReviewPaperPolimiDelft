Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
5,"Cathy O'Neil, H. Gunn","Near-Term Artificial Intelligence and the Ethical Matrix",2020,"","","","",1,"2022-07-13 09:35:20","","10.1093/oso/9780190905033.003.0009","","",,,,,5,2.50,3,2,2,"This chapter takes up the issue of near-term artificial intelligence, or the algorithms that are already in place in a variety of public and private sectors, guiding decisions from advertising and to credit ratings to sentencing in the justice system. There is a pressing need to recognize and evaluate the ways that structural racism, sexism, classism, and ableism may be embedded in and amplified by these systems. The chapter proposes a framework for ethical analysis that can be used to facilitate more robust ethical reflection in AI development and implementation. It presents an ethical matrix that incorporates the language of data science as a tool that data scientists can build themselves in order to integrate ethical analysis into the design process, addressing the need for immediate analysis and accountability over the design and deployment of near-term AI.","",""
0,"Alexander Buhmann, Christian Fieseler","Tackling the Grand Challenge of Algorithmic Opacity Through Principled Robust Action",2021,"","","","",2,"2022-07-13 09:35:20","","10.5771/2747-5174-2021-1-74","","",,,,,0,0.00,0,2,1,"Organizations increasingly delegate agency to artificial intelligence. However, such systems can yield unintended negative effects as they may produce biases against users or reinforce social injustices. What pronounces them as a unique grand challenge, however, are not their potentially problematic outcomes but their fluid design. Machine learning algorithms are continuously evolving; as a result, their functioning frequently remains opaque to humans. In this article, we apply recent work on tackling grand challenges though robust action to assess the potential and obstacles of managing the challenge of algorithmic opacity. We stress that although this approach is fruitful, it can be gainfully complemented by a discussion regarding the accountability and legitimacy of solutions. In our discussion, we extend the robust action approach by linking it to a set of principles that can serve to evaluate organisational approaches of tackling grand challenges with respect to their ability to foster accountable outcomes under the intricate conditions of algorithmic opacity.","",""
1,"N. Prakash, K. Mathewson","Conceptualization and Framework of Hybrid Intelligence Systems",2020,"","","","",3,"2022-07-13 09:35:20","","","","",,,,,1,0.50,1,2,2,"As artificial intelligence (AI) systems are getting ubiquitous within our society, issues related to its fairness, accountability, and transparency are increasing rapidly. As a result, researchers are integrating humans with AI systems to build robust and reliable hybrid intelligence systems. However, a proper conceptualization of these systems does not underpin this rapid growth. This article provides a precise definition of hybrid intelligence systems as well as explains its relation with other similar concepts through our proposed framework and examples from contemporary literature. The framework breakdowns the relationship between a human and a machine in terms of the degree of coupling and the directive authority of each party. Finally, we argue that all AI systems are hybrid intelligence systems, so human factors need to be examined at every stage of such systems' lifecycle.","",""
51,"A. Garcez, L. Lamb","Neurosymbolic AI: The 3rd Wave",2020,"","","","",4,"2022-07-13 09:35:20","","","","",,,,,51,25.50,26,2,2,"Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.","",""
138,"A. Garcez, M. Gori, L. Lamb, L. Serafini, Michael Spranger, S. Tran","Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning",2019,"","","","",5,"2022-07-13 09:35:20","","","","",,,,,138,46.00,23,6,3,"Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.","",""
0,"E. Blasch, Haoran Li, Zhihao Ma, Yang Weng","The Powerful Use of AI in the Energy Sector: Intelligent Forecasting",2021,"","","","",6,"2022-07-13 09:35:20","","","","",,,,,0,0.00,0,4,1,"Artificial Intelligence (AI) techniques continue to broaden across governmental and public sectors, such as power and energy which serve as critical infrastructures for most societal operations. However, due to the requirements of reliability, accountability, and explainability, it is risky to directly apply AI-based methods to power systems because society cannot afford cascading failures and large-scale blackouts, which easily cost billions of dollars. To meet society requirements, this paper proposes a methodology to develop, deploy, and evaluate AI systems in the energy sector by: (1) understanding the power system measurements with physics, (2) designing AI algorithms to forecast the need, (3) developing robust and accountable AI methods, and (4) creating reliable measures to evaluate the performance of the AI model. The goal is to provide a high level of confidence to energy utility users. For illustration purposes, the paper uses power system event forecasting (PEF) as an example, which carefully analyzes synchrophasor patterns measured by the Phasor Measurement Units (PMUs). Such a physical understanding leads to a data-driven framework that reduces the dimensionality with physics and forecasts the event with high credibility. Specifically, for dimensionality reduction, machine learning arranges physical information from different dimensions, resulting inefficient information extraction. For event forecasting, the supervised learning model fuses the results of different models to increase the confidence. Finally, comprehensive experiments demonstrate the high accuracy, efficiency, and reliability as compared to other state-of-the-art machine learning methods.","",""
2,"A. Garcez, L. Lamb","A I ] 1 0 D ec 2 02 0 Neurosymbolic AI : The 3 rd Wave",2020,"","","","",7,"2022-07-13 09:35:20","","","","",,,,,2,1.00,1,2,2,"Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.","",""
1,"Wahiduzzaman Khan, Takudzwa Fadziso","Ethical Issues on Utilization of AI, Robotics and Automation Technologies",2020,"","","","",8,"2022-07-13 09:35:20","","10.18034/AJHAL.V7I2.521","","",,,,,1,0.50,1,2,2,"The fast technological advancements in machine intelligence and automation may also arrive with risks and some negative effects on employees, firms, and society at large. Currently, both end-users, scientists, and practitioners have acknowledged the need for machine assistance and also welcome consideration for a robust ethical strategy that will allow a safe application and usage of improved technologies. Artificial Intelligence related ethics has been presented and considered from various standpoints and views. This paper furthers on the subject. Potential ethical issues are envisaged in the area of machine end-user perceptions, privacy, accountability, and the robot/ human rights, design of ethical machines, and technological singularity. It, therefore, possesses the question. What are the current ethical issues with the use of machines? The study adopted a quantitative and qualitative approach to drawing conclusions from the thematic and descriptive analysis. The result shows that majority of the respondents were males 46 (65.7%) while 24(34.3%) were females. They are mainly literates/ Majority 49(70%) are from the private firm and come majorly from the Asian continent. The majority of the respondents view that ethical consideration is necessary for machine and automation design, the machine-human relationship should be improved. Their privacy should be instituted while they consider technology singularity as a severe issue and desire the creation of ethical machines. Following this result, the study documents policy recommendations.","",""
1,"Geoffrey Rockwell, Emily Black, Evan Selinger, Antonio Davola, Elana Seide, K. Gulson","From Shortcut to Sleight of Hand: Why the Checklist Approach in the EU Guidelines Does Not Work",2019,"","","","",9,"2022-07-13 09:35:20","","","","",,,,,1,0.33,0,6,3,"Author(s): Rockwell, Geoffrey; Black, Emily; Selinger, Evan; Davola, Antonio; Seide, Elana; Gulson, Kalervo | Abstract: In April 2019, the High-Level Expert Group on Artificial Intelligence (AI) nominated by the EU Commission presented “Ethics Guidelines for Trustworthy Artificial Intelligence,” followed in June 2019 by a second “Policy and investment recommendations” Document.The Guidelines establish three characteristics (lawful, ethical, and robust) and seven key requirements (Human agency and oversight; Technical Robustness and safety; Privacy and data governance; Transparency; Diversity, non-discrimination and fairness; Societal and environmental well-being; and Accountability) that the development of AI should follow.The Guidelines are of utmost significance for the international debate over the regulation of AI. Firstly, they aspire to set a universal standard of care for the development of AI in the future. Secondly, they have been developed within a group of experts nominated by a regulatory body, and therefore will shape the normative approach in the EU regulation of AI and in its interaction with foreign countries. As the GDPR has shown, the effect of this normative activity goes way past the European Union territory.One of the most debated aspects of the Guidelines was the need to find an objective methodology to evaluate conformity with the key requirements. For this purpose, the Expert Group drafted an “assessment checklist” in the last part of the document: the list is supposed to be incorporated into existing practices, as a way for technology developers to consider relevant ethical issues and create more “trustworthy” AI. Our group undertook a critical assessment of the proposed tool from a multidisciplinary perspective, to assess its implications and limitations for global AI development.","",""
0,"Qiang Zhang, K. Werys, E. Lukaschuk, Iulia A. Popescu, Evan Hann, S. Neubauer, Vanessa M Ferreira, Stefan K Piechnik","3 Train the Ai like a human observer: deep learning with visualisation and guidance on attention in cardiac T1 mapping",2019,"","","","",10,"2022-07-13 09:35:20","","10.1136/heartjnl-2019-BSCMR.3","","",,,,,0,0.00,0,8,3,"Background Artificial intelligence (AI) is increasingly used in diagnostic imaging. Deep convolutional neural networks (CNN) can learn from labelled datasets, and then provide independent interpretations on new cases, but often without traceability to how such conclusions were made. This ‘black box’ behaviour is not desirable for clinical applications. We propose a novel framework for visualising and guiding the AI attention, using artefact detection in cardiac T1-mapping as an example - a critical quality assurance step for clinically-robust T1 determinations. Method We utilised an AI attention visualisation framework. This serves as an ‘eye tracker’ and reveals where the neural network ‘looks’ when scoring artefacts. The technique adds an essential accountability aspect to the CNN by producing additional evidence to validate the decision-making process. Beyond simply observing the AI attention maps, we provided additional direct guidance on the attention of the CNN, instructing the machine where to look, similar to training a human operator. Results We demonstrate an application in automated T1-mapping artefact detection of the 6 AHA segments in mid-ventricular slices (figure 1a). The AI ‘eye tracker’ detected an ill-trained CNN not paying attention to myocardium (figure 1b). A well-trained CNN learned from the training data to pay attention to the 6 myocardial segments, but with distraction by other image features (red arrows, figure 1c) and inaccuracy (yellow arrows). The proposed solution is a CNN trained with additional guidance to pay attention to the correct structures and avoid distractions (figure 1d).Abstract 3 Figure 1 Attention maps as the CNN ‘eye tracker’ in detecting T1-mapping artefacts in the 6 AHA segments (a), which reveals that (b) an ill-trained CNN looked at the features not desired for the task; In comparison; (c) a well-trained CNN correctly identified the segments, but with distraction (red arrows) and low accuracy (yellow arrows); (d) CNN trained with attention guidance looked at the target myocardial segments more accurately Conclusion CNN designed with both visualisation in perception and guidance on attention to relevant anatomical structures can lead to significantly more transparent and accountable AI, therefore more reliable for clinical practice.","",""
0,"Qiang Zhang, K. Werys, E. Lukaschuk, Iulia A. Popescu, Evan Hann, S. Neubauer, Vanessa M Ferreira, Stefan K Piechnik","9 Train the Ai like a human observer: deep learning with visualisation and guidance on attention in cardiac T1 mapping",2019,"","","","",11,"2022-07-13 09:35:20","","10.1136/heartjnl-2019-BSCMR.9","","",,,,,0,0.00,0,8,3,"Background Artificial intelligence (AI) is increasingly used in diagnostic imaging. Deep convolutional neural networks (CNN) are able to learn from datasets presented to them, and then provide independent interpretations on new cases, but often without traceability of how they came to the conclusions. Such ‘black box’ behaviour is not desirable for clinical use. We propose the concepts of visualising and guiding the AI attention in an application to artefact detection in cardiac T1-mapping - a critical quality assurance step for clinically-robust T1 determinations. Method We utilise the emerging AI attention visualisation. This serves as an ‘eye tracker’ and reveals where the neural network ‘looks’ when scoring artefacts in T1 mapping, and adds an essential accountability aspect to the CNN by producing additional evidence to validate the decision making process. Beyond simply observing the perception, we developed a technique to provide direct guidance on the attention of the CNN, by telling the machine which region to look at, very similar to training a human observer. Results We demonstrate an application in automated T1 mapping artefact detection of the 6 AHA segments in mid-ventricular slices (figure 1a). The AI ‘eye tracker’ detected an ill-trained CNN paying attention to features not desired for the assigned tasks (figure 1b). A well-trained CNN learned from the training data to pay attention to the corresponding myocardial segments for detecting artefacts, but with indicating distractions leading to suboptimal accuracy (figure 1c). A CNN trained with additional guidance on attention is shown to pay the desired attention to the right structures and avoids distractions (figure 1d).Abstract 9 Figure 1 Attention visualisation and guidance in detecting T1 mapping artefacts in the 6 AHA segments (a), which reveals that (b) an ill-trained CNN looked at the features irrelevant to the tasks, (c) a well-trained CNN highlighted the segments but with distraction by other image features, and (d) with attention guidance in training the CNN highlighted the segments more accurately Conclusion CNN designed with support of attention visualisation, and trained with guidance on attention can lead to significantly more transparent and accountable AI use in clinical practice.","",""
21,"Paul M. Goldwater, T. Fogarty","Protecting the Solution: A ‘High-Tech.’ Method to Guarantee Individual Effort in Accounting Classes",2007,"","","","",12,"2022-07-13 09:35:20","","10.1080/09639280701234344","","",,,,,21,1.40,11,2,15,"Abstract Advocates of the case method in accounting education have provided strong arguments in favour of this classroom approach. However, a primary objection has been unanswered. Cases generate ‘canned’ solutions that, when passed between students, jeopardize the accountability of individual efforts and the educational value of the exercise. Although students have leveraged computer technology to exacerbate this problem, academic staff generally have not ‘fought fire with fire.’ This paper shows how computer technology, through the use of artificial intelligence, can restore the confidence that each student will work his/her own case solution and, therefore, will extract the intended educational value from the effort. With computer technology made to act intelligently, the case method in accounting classes should become more robust as a primary pedagogical device. *The authors are willing to share the data in this paper","",""
1,"Paul M. Goldwater, T. Fogarty","RESPONDING TO THE CHALLENGE OF ACADEMIC INTEGRITY IN DISTANCE LEARNING: USING EXCEL TO GUARANTEE INDIVIDUAL EFFORT",2005,"","","","",13,"2022-07-13 09:35:20","","10.48009/1_iis_2005_231-237","","",,,,,1,0.06,1,2,17,"The distance learning environment is highly dependent upon assignment-based assessment. Whereas the business academy may seem well prepared for this transition with the emergence of the case method, a primary objection has been unanswered. Cases generate ""canned"" solutions that, when passed between students, jeopardize the accountability of individual efforts and the educational value of the exercise. Although students have leveraged computer technology to exacerbate this problem, the professoriate generally has not ""fought fire with fire."" Through the use of artificial intelligence can restore the confidence that each student will work his/her own case solution and will therefore extract the intended educational purpose from the effort. With computer technology made to act intelligently, assessments given to students should become more robust as a primary pedagogical device of distance learning. One of the least recognized challenges of the distance learning environment pertains to the need to reconfigure student evaluation. This paper describes the problem and proposes a solution based on artificial intelligence concepts that is deliverable within conventional software. The ability to rapidly transfer data and to instantaneously communicate simultaneously makes distance learning possible and threatens its integrity. Much more than with the ""face-to-face"" learning environment, instructors are heavily dependent upon assignments completed under uncontrolled circumstances. While this packaging of educational material can come closer to addressing the factual richness of the setting, they may be ineffective as measures of student ability. If instructors ignore the prospect that students exchange solutions, individual evaluation is considerably compromised. In this paper, we suggest that computer technology and artificial intelligence can be better brought to bear on the production of case materials so that academic integrity can be maintained. THE NATURE OF THE PROBLEM Concern over the integrity of the solution remains a legitimate concern in the traditional educational environment. Unlike tests, instructors have little control over the actual inputs of individual students when cases are a major part of the course. When cases include expectations that students produce written solutions that are to be graded, individual accountability is at issue. Notwithstanding ethical codes to the contrary, students, in the preparation of their written responses, may ""borrow"" solutions prepared by other students. This may occur between students in the current year's class, or through more systematic means, between students taking the class in different terms. Fraternities and sororities are notorious in the maintenance of files containing solutions to cases, as well as other materials, in order to reduce the necessary effort of each","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",14,"2022-07-13 09:35:20","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
23,"M. Alomar, M. Hameed, M. Alsaadi","Multi hours ahead prediction of surface ozone gas concentration: Robust artificial intelligence approach",2020,"","","","",15,"2022-07-13 09:35:20","","10.1016/j.apr.2020.06.024","","",,,,,23,11.50,8,3,2,"","",""
10,"M. Alomar, M. Hameed, N. Al‐Ansari, M. Alsaadi","Data-Driven Model for the Prediction of Total Dissolved Gas: Robust Artificial Intelligence Approach",2020,"","","","",16,"2022-07-13 09:35:20","","10.1155/2020/6618842","","",,,,,10,5.00,3,4,2,"Saturated total dissolved gas (TDG) is recently considered as a serious issue in the environmental engineering field since it stands behind the reasons for increasing the mortality rates of fish and aquatic organisms. The accurate and more reliable prediction of TDG has a very significant role in preserving the diversity of aquatic organisms and reducing the phenomenon of fish deaths. Herein, two machine learning approaches called support vector regression (SVR) and extreme learning machine (ELM) have been applied to predict the saturated TDG% at USGS 14150000 and USGS 14181500 stations which are located in the USA. For the USGS 14150000 station, the recorded samples from 13 October 2016 to 14 March 2019 (75%) were used for training set, and the rest from 15 March 2019 to 13 October 2019 (25%) were used for testing requirements. Similarly, for USGS 14181500 station, the hourly data samples which covered the period from 9 June 2017 till 11 March 2019 were used for calibrating the models and from 12 March 2019 until 9 October 2019 were used for testing the predictive models. Eight input combinations based on different parameters have been established as well as nine statistical performance measures have been used for evaluating the accuracy of adopted models, for instance, not limited, correlation of determination (        R      2        ), mean absolute relative error (MAE), and uncertainty at 95% (        U      95        ). The obtained results of the study for both stations revealed that the ELM managed efficiently to estimate the TDG in comparison to SVR technique. For USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.986 (0.986), MAE of 0.316 (0.441), and         U      95        of 3.592 (3.869). Lastly, for USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.991 (0.991), MAE of 0.338 (0.396), and         U      95        of 0.832 (0.837). In addition, ELM’s training process computational time is stated to be much shorter than that of SVM. The results also showed that the temperature parameter was the most significant variable that influenced TDG relative to the other parameters. Overall, the proposed model (ELM) proved to be an appropriate and efficient computer-assisted technology for saturated TDG modeling that will contribute to the basic knowledge of environmental considerations.","",""
120,"Hoang Nguyen, X. Bui","Predicting Blast-Induced Air Overpressure: A Robust Artificial Intelligence System Based on Artificial Neural Networks and Random Forest",2018,"","","","",17,"2022-07-13 09:35:20","","10.1007/s11053-018-9424-1","","",,,,,120,30.00,60,2,4,"","",""
0,"Bushra Rasheed, M. Usama, Asmara Safdar","Robust Artificial Intelligence Approach to Stabilize and Control Propeller Driven Hybrid UGV",2022,"","","","",18,"2022-07-13 09:35:20","","10.1109/ICAI55435.2022.9773375","","",,,,,0,0.00,0,3,1,"Hybrid Unmanned Ground Vehicle (HUGV) can drive on any terrain including walls and fly as well, using the multi directional thrust force of propellers. In the era of industrial revolution, hybrid UGVs need to be autonomous with intelligent decision making capabilities. During wall climbing of hybrid UGVs, stability is essential and depends on real time feedback from multiple sensors. To increase stability and control, it is proposed that PID control loops should be replaced by AI based algorithms that reduce the decision time and mathematical complexity. For autonomous movement in any terrain using the proposed model, intelligent UGVs can map and localize simultaneously.They can make intelligent decisions about mode of movement i.e. driving on ground or wall, steering on ground or wall, flying and maneuvering by using real time sensor readings. Integration of the proposed AI models with HUGV can be applied to many areas which are hard for humans to access, for instance; inspection of large structures, bio & nuclear hazard environments, planetary exploration & magnetic fields detection.","",""
11,"D. Almeida, Konstantin Shmarko, Elizabeth Lomas","The ethics of facial recognition technologies, surveillance, and accountability in an age of artificial intelligence: a comparative analysis of US, EU, and UK regulatory frameworks",2021,"","","","",19,"2022-07-13 09:35:20","","10.1007/s43681-021-00077-w","","",,,,,11,11.00,4,3,1,"","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",20,"2022-07-13 09:35:20","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
81,"Thomas G. Dietterich","Steps Toward Robust Artificial Intelligence",2017,"","","","",21,"2022-07-13 09:35:20","","10.1609/aimag.v38i3.2756","","",,,,,81,16.20,81,1,5,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world","",""
1,"Ana Lucic, Maurits Bleeker, Sami Jullien, Samarth Bhargav, M. de Rijke","Teaching Fairness, Accountability, Confidentiality, and Transparency in Artificial Intelligence through the Lens of Reproducibility",2021,"","","","",22,"2022-07-13 09:35:20","","","","",,,,,1,1.00,0,5,1,"In this work we explain the setup for a technical, graduatelevel course on Fairness, Accountability, Confidentiality and Transparency in Artificial Intelligence (FACT-AI) at the University of Amsterdam, which teaches FACT-AI concepts through the lens of reproducibility. The focal point of the course is a group project based on reproducing existing FACT-AI algorithms from top AI conferences, and writing a report about their experiences. In the first iteration of the course, we created an open source repository with the code implementations from the group projects. In the second iteration, we encouraged students to submit their group projects to the Machine Learning Reproducibility Challenge, which resulted in 9 reports from our course being accepted to the challenge. We reflect on our experience teaching the course over two academic years, where one year coincided with a global pandemic, and propose guidelines for teaching FACTAI through reproducibility in graduate-level AI programs. We hope this can be a useful resource for instructors to set up similar courses at their universities in the future.","",""
6,"M. Loi, M. Spielkamp","Towards Accountability in the Use of Artificial Intelligence for Public Administrations",2021,"","","","",23,"2022-07-13 09:35:20","","10.1145/3461702.3462631","","",,,,,6,6.00,3,2,1,"We argue that the phenomena of distributed responsibility, induced acceptance, and acceptance through ignorance constitute instances of imperfect delegation when tasks are delegated to computationally-driven systems. Imperfect delegation challenges human accountability. We hold that both direct public accountability via public transparency and indirect public accountability via transparency to auditors in public organizations can be both instrumentally ethically valuable and required as a matter of deontology from the principle of democratic self-government. We analyze the regulatory content of 16 guideline documents about the use of AI in the public sector, by mapping their requirements to those of our philosophical account of accountability, and conclude that while some guidelines refer processes that amount to auditing, it seems that the debate would benefit from more clarity about the nature of the entitlement of auditors and the goals of auditing, also in order to develop ethically meaningful standards with respect to which different forms of auditing can be evaluated and compared.","",""
7,"O. H. Maghsoudi, A. Gastounioti, Christopher Scott, L. Pantalone, Fang-Fang Wu, E. Cohen, S. Winham, E. Conant, C. Vachon, D. Kontos","Deep-LIBRA: Artificial intelligence method for robust quantification of breast density with independent validation in breast cancer risk assessment",2020,"","","","",24,"2022-07-13 09:35:20","","10.1016/j.media.2021.102138","","",,,,,7,3.50,1,10,2,"","",""
19,"Thomas G. Dietterich","Robust artificial intelligence and robust human organizations",2018,"","","","",25,"2022-07-13 09:35:20","","10.1007/s11704-018-8900-4","","",,,,,19,4.75,19,1,4,"","",""
0,"G. Leoni, Francesco Bergamaschi, G. Maione","Artificial Intelligence and Local Governments: The Case of Strategic Performance Management Systems and Accountability",2021,"","","","",26,"2022-07-13 09:35:20","","10.1007/978-3-030-88972-2_10","","",,,,,0,0.00,0,3,1,"","",""
5,"M. V. D. van den Homberg, C. Gevaert, Y. Georgiadou","The Changing Face of Accountability in Humanitarianism: Using Artificial Intelligence for Anticipatory Action",2020,"","","","",27,"2022-07-13 09:35:20","","10.17645/pag.v8i4.3158","","",,,,,5,2.50,2,3,2,"Over the past two decades, humanitarian conduct has been drifting away from the classical paradigm. This drift is caused by the blurring of boundaries between development aid and humanitarianism and the increasing reliance on digital technologies and data. New humanitarianism, especially in the form of disaster risk reduction, involved government authorities in plans to strengthen their capacity to deal with disasters. Digital humanitarianism now enrolls remote data analytics: GIS capacity, local data and information management experts, and digital volunteers. It harnesses the power of artificial intelligence to strengthen humanitarian agencies and governments’ capacity to anticipate and cope better with crises. In this article, we first trace how the meaning of accountability changed from classical to new and finally to digital humanitarianism. We then describe a recent empirical case of anticipatory humanitarian action in the Philippines. The Red Cross Red Crescent movement designed an artificial intelligence algorithm to trigger the release of funds typically used for humanitarian response in advance of an impending typhoon to start up early actions to mitigate its potential impact. We highlight emerging actors and fora in the accountability relationship of anticipatory humanitarian action as well as the consequences arising from actors’ (mis)conduct. Finally, we reflect on the implications of this new form of algorithmic accountability for classical humanitarianism.","",""
10,"Z. Xu-Monette, Hongwei H Zhang, Feng Zhu, A. Tzankov, G. Bhagat, C. Visco, K. Dybkaer, A. Chiu, W. Tam, Y. Zu, E. Hsi, Hua You, J. Huh, M. Ponzoni, A. Ferreri, M. Møller, B. Parsons, J. V. van Krieken, M. Piris, J. Winter, F. Hagemeister, B. Shahbaba, I. De Dios, Hong Zhang, Yong Li, Bing Xu, M. Albitar, K. Young","A refined cell-of-origin classifier with targeted NGS and artificial intelligence shows robust predictive value in DLBCL.",2020,"","","","",28,"2022-07-13 09:35:20","","10.1182/bloodadvances.2020001949","","",,,,,10,5.00,1,28,2,"Diffuse large B-cell lymphoma (DLBCL) is a heterogeneous entity of B-cell lymphoma. Cell-of-origin (COO) classification of DLBCL is required in routine practice by the World Health Organization classification for biological and therapeutic insights. Genetic subtypes uncovered recently are based on distinct genetic alterations in DLBCL, which are different from the COO subtypes defined by gene expression signatures of normal B cells retained in DLBCL. We hypothesize that classifiers incorporating both genome-wide gene-expression and pathogenetic variables can improve the therapeutic significance of DLBCL classification. To develop such refined classifiers, we performed targeted RNA sequencing (RNA-Seq) with a commercially available next-generation sequencing (NGS) platform in a large cohort of 418 DLBCLs. Genetic and transcriptional data obtained by RNA-Seq in a single run were explored by state-of-the-art artificial intelligence (AI) to develop a NGS-COO classifier for COO assignment and NGS survival models for clinical outcome prediction. The NGS-COO model built through applying AI in the training set was robust, showing high concordance with COO classification by either Affymetrix GeneChip microarray or the NanoString Lymph2Cx assay in 2 validation sets. Although the NGS-COO model was not trained for clinical outcome, the activated B-cell-like compared with the germinal-center B-cell-like subtype had significantly poorer survival. The NGS survival models stratified 30% high-risk patients in the validation set with poor survival as in the training set. These results demonstrate that targeted RNA-Seq coupled with AI deep learning techniques provides reproducible, efficient, and affordable assays for clinical application. The clinical grade assays and NGS models integrating both genetic and transcriptional factors developed in this study may eventually support precision medicine in DLBCL.","",""
353,"Erico Tjoa, Cuntai Guan","A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI",2019,"","","","",29,"2022-07-13 09:35:20","","10.1109/TNNLS.2020.3027314","","",,,,,353,117.67,177,2,3,"Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide “obviously” interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.","",""
35,"Sonia K. Katyal","Private Accountability in an Age of Artificial Intelligence",2019,"","","","",30,"2022-07-13 09:35:20","","10.1017/9781108680844.004","","",,,,,35,11.67,35,1,3,"Author(s): Katyal, SK | Abstract: © 2019 American Statistical Association. All Rights Reserved. In this Article, I explore the impending conflict between the protection of civil rights and artificial intelligence (AI). While both areas of law have amassed rich and well-developed areas of scholarly work and doctrinal support, a growing body of scholars are interrogating the intersection between them. This Article argues that the issues surrounding algorithmic accountability demonstrate a deeper, more structural tension within a new generation of disputes regarding law and technology. As I argue, the true promise of AI does not lie in the information we reveal to one another, but rather in the questions it raises about the interaction of technology, property, and civil rights. For this reason, I argue that we are looking in the wrong place if we look only to the state to address issues of algorithmic accountability. Instead, given the state's reluctance to address the issue, we must turn to other ways to ensure more transparency and accountability that stem from private industry, rather than public regulation. The issue of algorithmic bias represents a crucial new world of civil rights concerns, one that is distinct in nature from the ones that preceded it. Since we are in a world where the activities of private corporations, rather than the state, are raising concerns about privacy, due process, and discrimination, we must focus on the role of private corporations in addressing the issue. Towards this end, I discuss a variety of tools to help eliminate the opacity of AI, including codes of conduct, impact statements, and whistleblower protection, which I argue carries the potential to encourage greater endogeneity in civil rights enforcement. Ultimately, by examining the relationship between private industry and civil rights, we can perhaps develop a new generation of forms of accountability in the process.","",""
39,"Han-wei Liu, Ching-Fu Lin, Yu-Jie Chen","Beyond State v Loomis: artificial intelligence, government algorithmization and accountability",2019,"","","","",31,"2022-07-13 09:35:20","","10.1093/IJLIT/EAZ001","","",,,,,39,13.00,13,3,3,"Developments in data analytics, computational power, and machine learning techniques have driven all branches of the government to outsource authority to machines in performing public functions — social welfare, law enforcement, and most importantly, courts. Complex statistical algorithms and artificial intelligence (AI) tools are being used to automate decision-making and are having a significant impact on individuals’ rights and obligations. Controversies have emerged regarding the opaque nature of such schemes, the unintentional bias against and harm to underrepresented populations, and the broader legal, social, and ethical ramifications. State v. Loomis, a recent case in the United States, well demonstrates how unrestrained and unchecked outsourcing of public power to machines may undermine human rights and the rule of law. With a close examination of the case, this Article unpacks the issues of the ‘legal black box’ and the ‘technical black box’ to identify the risks posed by rampant ‘algorithmization’ of government functions to due process, equal protection, and transparency. We further assess some important governance proposals and suggest ways for improving the accountability of AI-facilitated decisions. As AI systems are commonly employed in consequential settings across jurisdictions, technologically-informed governance models are needed to locate optimal institutional designs that strike a balance between the benefits and costs of algorithmization.","",""
1,"O. Jenkins, D. Lopresti, M. Mitchell","Next Wave Artificial Intelligence: Robust, Explainable, Adaptable, Ethical, and Accountable",2020,"","","","",32,"2022-07-13 09:35:20","","","","",,,,,1,0.50,0,3,2,"The history of AI has included several ""waves"" of ideas. The first wave, from the mid-1950s to the 1980s, focused on logic and symbolic hand-encoded representations of knowledge, the foundations of so-called ""expert systems"". The second wave, starting in the 1990s, focused on statistics and machine learning, in which, instead of hand-programming rules for behavior, programmers constructed ""statistical learning algorithms"" that could be trained on large datasets. In the most recent wave research in AI has largely focused on deep (i.e., many-layered) neural networks, which are loosely inspired by the brain and trained by ""deep learning"" methods. However, while deep neural networks have led to many successes and new capabilities in computer vision, speech recognition, language processing, game-playing, and robotics, their potential for broad application remains limited by several factors.  A concerning limitation is that even the most successful of today's AI systems suffer from brittleness-they can fail in unexpected ways when faced with situations that differ sufficiently from ones they have been trained on. This lack of robustness also appears in the vulnerability of AI systems to adversarial attacks, in which an adversary can subtly manipulate data in a way to guarantee a specific wrong answer or action from an AI system. AI systems also can absorb biases-based on gender, race, or other factors-from their training data and further magnify these biases in their subsequent decision-making. Taken together, these various limitations have prevented AI systems such as automatic medical diagnosis or autonomous vehicles from being sufficiently trustworthy for wide deployment. The massive proliferation of AI across society will require radically new ideas to yield technology that will not sacrifice our productivity, our quality of life, or our values.","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",33,"2022-07-13 09:35:20","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
33,"M. Busuioc","Accountable Artificial Intelligence: Holding Algorithms to Account",2020,"","","","",34,"2022-07-13 09:35:20","","10.1111/puar.13293","","",,,,,33,16.50,33,1,2,"Abstract Artificial intelligence (AI) algorithms govern in subtle yet fundamental ways the way we live and are transforming our societies. The promise of efficient, low‐cost, or “neutral” solutions harnessing the potential of big data has led public bodies to adopt algorithmic systems in the provision of public services. As AI algorithms have permeated high‐stakes aspects of our public existence—from hiring and education decisions to the governmental use of enforcement powers (policing) or liberty‐restricting decisions (bail and sentencing)—this necessarily raises important accountability questions: What accountability challenges do AI algorithmic systems bring with them, and how can we safeguard accountability in algorithmic decision‐making? Drawing on a decidedly public administration perspective, and given the current challenges that have thus far become manifest in the field, we critically reflect on and map out in a conceptually guided manner the implications of these systems, and the limitations they pose, for public accountability.","",""
11,"K. Porayska-Pomsta, Gnanathusharan Rajendran","Accountability in Human and Artificial Intelligence Decision-Making as the Basis for Diversity and Educational Inclusion",2019,"","","","",35,"2022-07-13 09:35:20","","10.1007/978-981-13-8161-4_3","","",,,,,11,3.67,6,2,3,"","",""
3,"R. Garigliano, Luisa Mich","Looking Inside the Black Box: Core Semantics Towards Accountability of Artificial Intelligence",2019,"","","","",36,"2022-07-13 09:35:20","","10.1007/978-3-030-30985-5_16","","",,,,,3,1.00,2,2,3,"","",""
44,"A. Goli, H. Zare, R. Tavakkoli-Moghaddam, A. Sadeghieh","Hybrid artificial intelligence and robust optimization for a multi-objective product portfolio problem Case study: The dairy products industry",2019,"","","","",37,"2022-07-13 09:35:20","","10.1016/j.cie.2019.106090","","",,,,,44,14.67,11,4,3,"","",""
4,"Kacper Sokol","Fairness, Accountability and Transparency in Artificial Intelligence: A Case Study of Logical Predictive Models",2019,"","","","",38,"2022-07-13 09:35:20","","10.1145/3306618.3314316","","",,,,,4,1.33,4,1,3,"Machine learning -- the part of artificial intelligence aimed at eliciting knowledge from data and automated decision making without explicit instructions -- is making great strides, with new algorithms being invented every day. These algorithms find myriads of applications, but their ubiquity often comes at the expense of limited interpretability, hidden biases and unexpected vulnerabilities. Whenever one of these factors is a priority, the learning algorithm of choice is often a method considered to be inherently interpretable, e.g. logical models such as decision trees. In my research I challenge this assumption and highlight (quite common) cases when the assumed interpretability fails to deliver. To restore interpretability of logical machine learning models (decision trees and their ensembles in particular) I propose to explain them with class-contrastive counterfactual statements, which are a very common type of explanation in human interactions, well-grounded in social science research. To evaluate transparency of such models I collate explainability desiderata that can be used to systematically assess and compare such methods as an addition to user studies. Given contrastive explanations, I investigate their influence on the model's security, in particular gaming and stealing the model. Finally, I evaluate model fairness, where I am interested in choosing the most fair model among all the models with equal performance.","",""
1,"Jeanna Neefe Matthews","Patterns and Antipatterns, Principles, and Pitfalls: Accountability and Transparency in Artificial Intelligence",2019,"","","","",39,"2022-07-13 09:35:20","","","","",,,,,1,0.33,1,1,3,"Copyright © 2020, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 82 AI MAGAZINE Increasingly, decisions that significantly impact the lives of individuals (such as decisions about hiring, housing, insurance, loans, criminal justice, or medical treatment) are being made in a partnership between human decisionmakers and artificial intelligence (AI) systems. As builders of AI systems, we know how easy it is for errors to occur. We also know how difficult it can be to push the boundaries and adapt a system developed in one context into another. As developers of AI, we know how our systems learn from people and from the past, assimilating latent biases. Understanding all of this, who better than us to insist that the systems we build support investigation and iterative improvement, so that others are empowered to help counter the limitations of AI while benefiting from its strengths?  This article discusses a set of principles for accountability and transparency in AI as well as a set of antipatterns or harmful trends too often seen in deployed systems. It provides concrete suggestions for what can be done to shift the balance away from these antipatterns and toward more positive ones. Patterns and Antipatterns, Principles, and Pitfalls: Accountability and Transparency in Artificial Intelligence","",""
29,"F. S. D. Sio, G. Mecacci","Four Responsibility Gaps with Artificial Intelligence: Why they Matter and How to Address them",2021,"","","","",40,"2022-07-13 09:35:20","","10.1007/S13347-021-00450-X","","",,,,,29,29.00,15,2,1,"","",""
16,"A. Amritphale, Ranojoy Chatterjee, Suvo Chatterjee, N. Amritphale, Ali Rahnavard, G. Awan, B. Omar, G. Fonarow","Predictors of 30-Day Unplanned Readmission After Carotid Artery Stenting Using Artificial Intelligence",2021,"","","","",41,"2022-07-13 09:35:20","","10.1007/s12325-021-01709-7","","",,,,,16,16.00,2,8,1,"","",""
1,"Ana Lucic, Maurits Bleeker, Sami Jullien, Samarth Bhargav, M. de Rijke","Reproducibility as a Mechanism for Teaching Fairness, Accountability, Confidentiality, and Transparency in Artificial Intelligence",2021,"","","","",42,"2022-07-13 09:35:20","","10.1609/aaai.v36i11.21558","","",,,,,1,1.00,0,5,1,"In this work, we explain the setup for a technical, graduate-level course on Fairness, Accountability, Confidentiality, and Transparency in Artificial Intelligence (FACT-AI) at the University of Amsterdam, which teaches FACT-AI concepts through the lens of reproducibility.  The focal point of the course is a group project based on reproducing existing FACT-AI algorithms from top AI conferences and writing a corresponding report.  In the first iteration of the course, we created an open source repository with the code implementations from the group projects.  In the second iteration, we encouraged students to submit their group projects to the Machine Learning Reproducibility Challenge, resulting in 9 reports from our course being accepted for publication in the ReScience journal.  We reflect on our experience teaching the course over two years, where one year coincided with a global pandemic, and propose guidelines for teaching FACT-AI through reproducibility in graduate-level AI study programs.  We hope this can be a useful resource for instructors who want to set up similar courses in the future.","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",43,"2022-07-13 09:35:20","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
195,"Jessica Fjeld, Nele Achten, Hannah Hilligoss, Ádám Nagy, Madhulika Srikumar","Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI",2020,"","","","",44,"2022-07-13 09:35:20","","10.2139/ssrn.3518482","","",,,,,195,97.50,39,5,2,"The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and human rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles,"" there has been little scholarly focus on understanding these efforts either individually or as contextualized within an expanding universe of principles with discernible trends.    To that end, this white paper and its associated data visualization compare the contents of thirty-six prominent AI principles documents side-by-side. This effort uncovered a growing consensus around eight key thematic trends: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. Underlying this “normative core,” our analysis examined the forty-seven individual principles that make up the themes, detailing notable similarities and differences in interpretation found across the documents. In sharing these observations, it is our hope that policymakers, advocates, scholars, and others working to maximize the benefits and minimize the harms of AI will be better positioned to build on existing efforts and to push the fractured, global conversation on the future of AI toward consensus.","",""
10,"T. Penzkofer, A. Padhani, B. Turkbey, M. Haider, H. Huisman, J. Walz, G. Salomon, I. Schoots, J. Richenberg, G. Villeirs, V. Panebianco, O. Rouvière, V. Løgager, J. Barentsz","ESUR/ESUI position paper: developing artificial intelligence for precision diagnosis of prostate cancer using magnetic resonance imaging",2021,"","","","",45,"2022-07-13 09:35:20","","10.1007/s00330-021-08021-6","","",,,,,10,10.00,1,14,1,"","",""
10,"Y. Y. Aung, D. C. Wong, D. Ting","The promise of artificial intelligence: a review of the opportunities and challenges of artificial intelligence in healthcare.",2021,"","","","",46,"2022-07-13 09:35:20","","10.1093/bmb/ldab016","","",,,,,10,10.00,3,3,1,"INTRODUCTION Artificial intelligence (AI) and machine learning (ML) are rapidly evolving fields in various sectors, including healthcare. This article reviews AI's present applications in healthcare, including its benefits, limitations and future scope.   SOURCES OF DATA A review of the English literature was conducted with search terms 'AI' or 'ML' or 'deep learning' and 'healthcare' or 'medicine' using PubMED and Google Scholar from 2000-2021.   AREAS OF AGREEMENT AI could transform physician workflow and patient care through its applications, from assisting physicians and replacing administrative tasks to augmenting medical knowledge.   AREAS OF CONTROVERSY From challenges training ML systems to unclear accountability, AI's implementation is difficult and incremental at best. Physicians also lack understanding of what AI implementation could represent.   GROWING POINTS AI can ultimately prove beneficial in healthcare, but requires meticulous governance similar to the governance of physician conduct.   AREAS TIMELY FOR DEVELOPING RESEARCH Regulatory guidelines are needed on how to safely implement and assess AI technology, alongside further research into the specific capabilities and limitations of its medical use.","",""
2,"B. Nair, Yakov Diskin, V. Asari","Multi-modal low cost mobile indoor surveillance system on the Robust Artificial Intelligence-based Defense Electro Robot (RAIDER)",2012,"","","","",47,"2022-07-13 09:35:20","","10.1117/12.930353","","",,,,,2,0.20,1,3,10,"We present an autonomous system capable of performing security check routines. The surveillance machine, the Clearpath Husky robotic platform, is equipped with three IP cameras with different orientations for the surveillance tasks of face recognition, human activity recognition, autonomous navigation and 3D reconstruction of its environment. Combining the computer vision algorithms onto a robotic machine has given birth to the Robust Artificial Intelligencebased Defense Electro-Robot (RAIDER). The end purpose of the RAIDER is to conduct a patrolling routine on a single floor of a building several times a day. As the RAIDER travels down the corridors off-line algorithms use two of the RAIDER's side mounted cameras to perform a 3D reconstruction from monocular vision technique that updates a 3D model to the most current state of the indoor environment. Using frames from the front mounted camera, positioned at the human eye level, the system performs face recognition with real time training of unknown subjects. Human activity recognition algorithm will also be implemented in which each detected person is assigned to a set of action classes picked to classify ordinary and harmful student activities in a hallway setting.The system is designed to detect changes and irregularities within an environment as well as familiarize with regular faces and actions to distinguish potentially dangerous behavior. In this paper, we present the various algorithms and their modifications which when implemented on the RAIDER serves the purpose of indoor surveillance.","",""
22,"S. Yanisky-Ravid","Generating Rembrandt: Artificial Intelligence, Copyright, and Accountability in the 3A Era — The Human-Like Authors Are Already Here — A New Model",2017,"","","","",48,"2022-07-13 09:35:20","","10.2139/ssrn.2957722","","",,,,,22,4.40,22,1,5,"Artificial intelligence (AI) systems are creative, unpredictable, independent, autonomous, rational, evolving, capable of data collection, communicative, efficient, accurate, and have free choice among alternatives. Similar to humans, AI systems can autonomously create and generate creative works. The use of AI systems in the production of works, either for personal or manufacturing purposes, has become common in the 3A era of automated, autonomous, and advanced technology. Despite this progress, there is a deep and common concern in modern society that AI technology will become uncontrollable. There is therefore a call for social and legal tools for controlling AI systems’ functions and outcomes.    This Article addresses the questions of the copyrightability of artworks generated by AI systems: ownership and accountability. The Article debates who should enjoy the benefits of copyright protection and who should be responsible for the infringement of rights and damages caused by AI systems that independently produce creative works. Subsequently, this Article presents the AI ""Multi-Player"" paradigm, arguing against the imposition of these rights and responsibilities on the AI systems themselves or on the different stakeholders, mainly the programmers who develop such systems.    Most importantly, this Article proposes the adoption of a new model of accountability for works generated by AI systems: the AI Work Made for Hire (WMFH) model, which views the AI system as a creative employee or independent contractor of the user. Under this proposed model, ownership, control, and responsibility would be imposed on the humans or legal entities that use AI systems and enjoy its benefits. This model accurately reflects the human-like features of AI systems; it is justified by the theories behind copyright protection; and it serves as a practical solution to assuage the fears behind AI systems. In addition, this model unveils the powers behind the operation of AI systems; hence, it efficiently imposes accountability on clearly identifiable persons or legal entities. Since AI systems are copyrightable algorithms, this Article reflects on the accountability for AI systems in other legal regimes, such as tort or criminal law and in various industries using these systems.","",""
462,"Stuart J. Russell, Dan Dewey, Max Tegmark","Research Priorities for Robust and Beneficial Artificial Intelligence",2015,"","","","",49,"2022-07-13 09:35:20","","10.1609/aimag.v36i4.2577","","",,,,,462,66.00,154,3,7,"Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls. This article gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial.","",""
9,"Seunghyeon Kim, Yeon-Hee Lee, Yung-kyun Noh, F. Park, Q-Schick Auh","Age-group determination of living individuals using first molar images based on artificial intelligence",2021,"","","","",50,"2022-07-13 09:35:20","","10.1038/s41598-020-80182-8","","",,,,,9,9.00,2,5,1,"","",""
5,"Lorna McGregor","Accountability for Governance Choices in Artificial Intelligence: Afterword to Eyal Benvenisti’s Foreword",2018,"","","","",51,"2022-07-13 09:35:20","","10.1093/EJIL/CHY086","","",,,,,5,1.25,5,1,4,"  A growing body of literature examines how to make the use of new and emerging technologies more transparent and explainable as a means to ensure accountability for harm to human rights. While a critical part of accountability, a predominant focus on the technology can result in the design and adaptation of accountability principles to ‘manage’ the technology instead of starting from an assessment of the governance choices actors make when integrating new and emerging technologies into their mandates. Recognition of the governance choices underpinning the introduction of new and emerging technologies is often overlooked in scholarship and practice. Yet, without explicit recognition of the role played by technology in governance, the disruptive effects of technology on (global) governance may be underplayed or even ignored. In this response, I argue that if the ‘culture of accountability’ is to adapt to the challenges posed by new and emerging technologies, the focus cannot only be technology-led. It must also be interrogative of the governance choices that are made within organizations, particularly those vested with public functions at the international and national level.","",""
9,"Nathalie A. Smuha, Emma Ahmed-Rengers, Adam Harkens, Wenlong Li, J. Maclaren, Riccardo Piselli, K. Yeung","How the EU Can Achieve Legally Trustworthy AI: A Response to the European Commission’s Proposal for an Artificial Intelligence Act",2021,"","","","",52,"2022-07-13 09:35:20","","10.2139/ssrn.3899991","","",,,,,9,9.00,1,7,1,"This document contains the response to the European Commission’s Proposal for an Artificial Intelligence Act from members of the Legal, Ethical & Accountable Digital Society (LEADS) Lab at the University of Birmingham. The Proposal seeks to give expression to the concept of ‘Lawful AI.’ This concept was mentioned, but not developed in the Commission’s High-Level Expert Group on AI’s Ethics Guidelines for Trustworthy AI (2019), which instead confined its discussion to the concepts of ‘Ethical’ and ‘Robust’ AI. After a brief introduction (Chapter 1), we set out the many aspects of the Proposal which we welcome, and stress our wholehearted support for its aim to protect fundamental rights (Chapter 2). Subsequently, we develop the concept of ‘Legally Trustworthy AI,’ arguing that it should be grounded in respect for three pillars on which contemporary liberal democratic societies are founded, namely: fundamental rights, the rule of law, and democracy (Chapter 3). Drawing on this conceptual framework, we first argue that the Proposal fails to reflect fundamental rights as claims with enhanced moral and legal status, which subjects any rights interventions to a demanding regime of scrutiny and must satisfy tests of necessity and proportionality. Moreover, the Proposal does not always accurately recognise the wrongs and harms associated with different kinds of AI systems and appropriately allocates responsibility for them. Second, the Proposal does not provide an effective framework for the enforcement of legal rights and duties, and does not ensure legal certainty and consistency, which are essential for the rule of law. Third, the Proposal neglects to ensure meaningful transparency, accountability, and rights of public participation, thereby failing to reflect adequate protection for democracy (Chapter 4). Based on these shortcomings in respecting and promoting the three pillars of Legally Trustworthy AI, we provide detailed recommendations for the Proposal’s revision (Chapter 5).","",""
9,"B. N. Manjunatha Reddy, S. K. Pramada, T. Roshni","Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin",2021,"","","","",53,"2022-07-13 09:35:20","","10.1007/s12040-020-01508-8","","",,,,,9,9.00,3,3,1,"","",""
63,"M. VerMilyea, J. Hall, S. Diakiw, A. Johnston, T. Nguyen, D. Perugini, A. Miller, A. Picou, A. P. Murphy, M. Perugini","Development of an artificial intelligence-based assessment model for prediction of embryo viability using static images captured by optical light microscopy during IVF",2020,"","","","",54,"2022-07-13 09:35:20","","10.1093/humrep/deaa013","","",,,,,63,31.50,6,10,2,"Abstract STUDY QUESTION Can an artificial intelligence (AI)-based model predict human embryo viability using images captured by optical light microscopy? SUMMARY ANSWER We have combined computer vision image processing methods and deep learning techniques to create the non-invasive Life Whisperer AI model for robust prediction of embryo viability, as measured by clinical pregnancy outcome, using single static images of Day 5 blastocysts obtained from standard optical light microscope systems. WHAT IS KNOWN ALREADY Embryo selection following IVF is a critical factor in determining the success of ensuing pregnancy. Traditional morphokinetic grading by trained embryologists can be subjective and variable, and other complementary techniques, such as time-lapse imaging, require costly equipment and have not reliably demonstrated predictive ability for the endpoint of clinical pregnancy. AI methods are being investigated as a promising means for improving embryo selection and predicting implantation and pregnancy outcomes. STUDY DESIGN, SIZE, DURATION These studies involved analysis of retrospectively collected data including standard optical light microscope images and clinical outcomes of 8886 embryos from 11 different IVF clinics, across three different countries, between 2011 and 2018. PARTICIPANTS/MATERIALS, SETTING, METHODS The AI-based model was trained using static two-dimensional optical light microscope images with known clinical pregnancy outcome as measured by fetal heartbeat to provide a confidence score for prediction of pregnancy. Predictive accuracy was determined by evaluating sensitivity, specificity and overall weighted accuracy, and was visualized using histograms of the distributions of predictions. Comparison to embryologists’ predictive accuracy was performed using a binary classification approach and a 5-band ranking comparison. MAIN RESULTS AND THE ROLE OF CHANCE The Life Whisperer AI model showed a sensitivity of 70.1% for viable embryos while maintaining a specificity of 60.5% for non-viable embryos across three independent blind test sets from different clinics. The weighted overall accuracy in each blind test set was >63%, with a combined accuracy of 64.3% across both viable and non-viable embryos, demonstrating model robustness and generalizability beyond the result expected from chance. Distributions of predictions showed clear separation of correctly and incorrectly classified embryos. Binary comparison of viable/non-viable embryo classification demonstrated an improvement of 24.7% over embryologists’ accuracy (P = 0.047, n = 2, Student’s t test), and 5-band ranking comparison demonstrated an improvement of 42.0% over embryologists (P = 0.028, n = 2, Student’s t test). LIMITATIONS, REASONS FOR CAUTION The AI model developed here is limited to analysis of Day 5 embryos; therefore, further evaluation or modification of the model is needed to incorporate information from different time points. The endpoint described is clinical pregnancy as measured by fetal heartbeat, and this does not indicate the probability of live birth. The current investigation was performed with retrospectively collected data, and hence it will be of importance to collect data prospectively to assess real-world use of the AI model. WIDER IMPLICATIONS OF THE FINDINGS These studies demonstrated an improved predictive ability for evaluation of embryo viability when compared with embryologists’ traditional morphokinetic grading methods. The superior accuracy of the Life Whisperer AI model could lead to improved pregnancy success rates in IVF when used in a clinical setting. It could also potentially assist in standardization of embryo selection methods across multiple clinical environments, while eliminating the need for complex time-lapse imaging equipment. Finally, the cloud-based software application used to apply the Life Whisperer AI model in clinical practice makes it broadly applicable and globally scalable to IVF clinics worldwide. STUDY FUNDING/COMPETING INTEREST(S) Life Whisperer Diagnostics, Pty Ltd is a wholly owned subsidiary of the parent company, Presagen Pty Ltd. Funding for the study was provided by Presagen with grant funding received from the South Australian Government: Research, Commercialisation and Startup Fund (RCSF). ‘In kind’ support and embryology expertise to guide algorithm development were provided by Ovation Fertility. J.M.M.H., D.P. and M.P. are co-owners of Life Whisperer and Presagen. Presagen has filed a provisional patent for the technology described in this manuscript (52985P pending). A.P.M. owns stock in Life Whisperer, and S.M.D., A.J., T.N. and A.P.M. are employees of Life Whisperer.","",""
10,"A. C. Horta, A. Silva, C. Sargo, V. M. Gonçalves, T. C. Zangirolami, Roberto Campos Giordano","Robust artificial intelligence tool for automatic start-up of the supplementary medium feeding in recombinant E. coli cultivations",2011,"","","","",55,"2022-07-13 09:35:20","","10.1007/s00449-011-0540-0","","",,,,,10,0.91,2,6,11,"","",""
63,"Oscar Rodríguez-Espíndola, Soumyadeb Chowdhury, A. Beltagui, P. Albores","The potential of emergent disruptive technologies for humanitarian supply chains: the integration of blockchain, Artificial Intelligence and 3D printing",2020,"","","","",56,"2022-07-13 09:35:20","","10.1080/00207543.2020.1761565","","",,,,,63,31.50,16,4,2,"The growing importance of humanitarian operations has created an imperative to overcome the complications currently recorded in the field. Challenges such as delays, congestion, poor communication and lack of accountability may represent opportunities to test the reported advantages of emergent disruptive technologies. Meanwhile, the literature on humanitarian supply chains looks at isolated applications of technology and lacks a framework for understanding challenges and solutions, a gap that this article aims to fill. Using a case study based on the flood of Tabasco of 2007 in Mexico, this research identifies solutions based on the use of emergent disruptive technologies. Furthermore, this article argues that the integration of different technologies is essential to deliver real benefits to the humanitarian supply chain. As a result, it proposes a framework to improve the flow of information, products and financial resources in humanitarian supply chains integrating three emergent disruptive technologies; Artificial Intelligence, Blockchain and 3D Printing. The analysis presented shows the potential of the framework to reduce congestion in the supply chain, enhance simultaneous collaboration of different stakeholders, decrease lead times, increase transparency, traceability and accountability of material and financial resources, and allow victims to get involved in the fulfilment of their own needs.","",""
7,"N. Ullah, I. Sami, Md. Shahariar Chowdhury, K. Techato, H. Alkhammash","Artificial Intelligence Integrated Fractional Order Control of Doubly Fed Induction Generator-Based Wind Energy System",2021,"","","","",57,"2022-07-13 09:35:20","","10.1109/ACCESS.2020.3048420","","",,,,,7,7.00,1,5,1,"This paper proposes an artificial intelligence integrated (AI) fractional order robust control for a DFIG based wind energy conversion system. To reduce the chattering phenomena in the excitation signal, fuzzy system is employed for the adaptive adjustment of the discontinuous control gain while preserving the robustness of the closed-loop system. The stability of the closed loop system with fuzzy fractional order robust control (FFORC) is ensured using fractional order Lyapunov system. The proposed FFORC control scheme is tested using processor in the loop (PIL) experiment.MATLAB/Simulink environment is used to emulate DFIG based wind energy system and a Texas Instrument (TI) DSP320F37D processor is used for interfacing the proposed control scheme with the emulated DFIG model in Simulink environment. System performance under the proposed FFORC scheme is compared with classical sliding mode control(SMC).The experimental results justifies the superiority of the proposed FFORC control scheme under all test conditions.Under ideal condition and with the proposed FFORC control scheme, the speed tracking error is approximately zero while with SMC method the peak tracking error is 0.4 radian/s. Similarly the active and reactive powers tracking is smooth with the proposed control system, while with SMC method the reactive power oscillates on both sides of the reference and it reaches 0.01 kVAR on positive side and −0.01kVAR on the negative side of the plot.Under parameters variation, system with FFORC control scheme offers minimum steady state error which is about 0.01 radian/s, while in case of SMC with saturation function a peak value of 0.6 radian/s is recorded. In case of SMC with sgn function, the speed tracking error is around 0.1 radian/s.Moreover the proposed FFORC scheme exhibits minimum chattering.","",""
46,"I. Poel","Embedding Values in Artificial Intelligence (AI) Systems",2020,"","","","",58,"2022-07-13 09:35:20","","10.1007/s11023-020-09537-4","","",,,,,46,23.00,46,1,2,"","",""
4,"Irene-Angelica Chounta, Emanuele Bardone, Aet Raudsep, M. Pedaste","Exploring Teachers’ Perceptions of Artificial Intelligence as a Tool to Support their Practice in Estonian K-12 Education",2021,"","","","",59,"2022-07-13 09:35:20","","10.1007/S40593-021-00243-5","","",,,,,4,4.00,1,4,1,"","",""
4,"O. L. Saldanha, P. Quirke, N. West, J. James, M. Loughrey, H. Grabsch, M. Salto‐Tellez, E. Alwers, Didem Cifci, Narmin Ghaffari Laleh, T. Seibel, Richard Gray, G. Hutchins, H. Brenner, T. Yuan, T. Brinker, J. Chang-Claude, Firas Khader, A. Schuppert, T. Luedde, S. Foersch, H. Muti, C. Trautwein, M. Hoffmeister, D. Truhn, J. Kather","Swarm learning for decentralized artificial intelligence in cancer histopathology",2021,"","","","",60,"2022-07-13 09:35:20","","10.1038/s41591-022-01768-5","","",,,,,4,4.00,0,26,1,"","",""
5,"F. Hussain, R. Hussain, E. Hossain","Explainable Artificial Intelligence (XAI): An Engineering Perspective",2021,"","","","",61,"2022-07-13 09:35:20","","","","",,,,,5,5.00,2,3,1,"The remarkable advancements in Deep Learning (DL) algorithms have fueled enthusiasm for using Artificial Intelligence (AI) technologies in almost every domain; however, the opaqueness of these algorithms put a question mark on their applications in safety-critical systems. In this regard, the ‘explainability’ dimension is not only essential to both explain the inner workings of black-box algorithms, but it also adds accountability and transparency dimensions that are of prime importance for regulators, consumers, and service providers. eXplainable Artificial Intelligence (XAI) is the set of techniques and methods to convert the so-called black-box AI algorithms to white-box algorithms, where the results achieved by these algorithms and the variables, parameters, and steps taken by the algorithm to reach the obtained results, are transparent and explainable. To complement the existing literature on XAI, in this paper, we take an ‘engineering’ approach to illustrate the concepts of XAI. We discuss the stakeholders in XAI and describe the mathematical contours of XAI from engineering perspective. Then we take the autonomous car as a use-case and discuss the applications of XAI for its different components such as object detection, perception, control, action decision, and so on. This work is an exploratory study to identify new avenues of research in the field of XAI.","",""
50,"Emilio Calvano, G. Calzolari, V. Denicoló, S. Pastorello","Artificial Intelligence, Algorithmic Pricing, and Collusion",2020,"","","","",62,"2022-07-13 09:35:20","","10.1257/AER.20190623","","",,,,,50,25.00,13,4,2,"Increasingly, pricing algorithms are supplanting human decision making in real marketplaces. To inform the competition policy debate on the possible consequences of this development, we experiment with pricing algorithms powered by Artificial Intelligence (AI) in controlled environments (computer simulations), studying the interaction among a number of Q-learning algorithms in a workhorse oligopoly model of price competition with Logit demand and constant marginal costs. In this setting the algorithms consistently learn to charge supra-competitive prices, without communicating with one another. The high prices are sustained by classical collusive strategies with a finite phase of punishment followed by a gradual return to cooperation. This finding is robust to asymmetries in cost or demand and to changes in the number of players.","",""
96,"Eduardo H. B. Maia, L. Assis, Tiago Alves de Oliveira, Alisson Marques da Silva, A. Taranto","Structure-Based Virtual Screening: From Classical to Artificial Intelligence",2020,"","","","",63,"2022-07-13 09:35:20","","10.3389/fchem.2020.00343","","",,,,,96,48.00,19,5,2,"The drug development process is a major challenge in the pharmaceutical industry since it takes a substantial amount of time and money to move through all the phases of developing of a new drug. One extensively used method to minimize the cost and time for the drug development process is computer-aided drug design (CADD). CADD allows better focusing on experiments, which can reduce the time and cost involved in researching new drugs. In this context, structure-based virtual screening (SBVS) is robust and useful and is one of the most promising in silico techniques for drug design. SBVS attempts to predict the best interaction mode between two molecules to form a stable complex, and it uses scoring functions to estimate the force of non-covalent interactions between a ligand and molecular target. Thus, scoring functions are the main reason for the success or failure of SBVS software. Many software programs are used to perform SBVS, and since they use different algorithms, it is possible to obtain different results from different software using the same input. In the last decade, a new technique of SBVS called consensus virtual screening (CVS) has been used in some studies to increase the accuracy of SBVS and to reduce the false positives obtained in these experiments. An indispensable condition to be able to utilize SBVS is the availability of a 3D structure of the target protein. Some virtual databases, such as the Protein Data Bank, have been created to store the 3D structures of molecules. However, sometimes it is not possible to experimentally obtain the 3D structure. In this situation, the homology modeling methodology allows the prediction of the 3D structure of a protein from its amino acid sequence. This review presents an overview of the challenges involved in the use of CADD to perform SBVS, the areas where CADD tools support SBVS, a comparison between the most commonly used tools, and the techniques currently used in an attempt to reduce the time and cost in the drug development process. Finally, the final considerations demonstrate the importance of using SBVS in the drug development process.","",""
35,"S. Lo Piano","Ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward",2020,"","","","",64,"2022-07-13 09:35:20","","10.1057/s41599-020-0501-9","","",,,,,35,17.50,35,1,2,"","",""
7,"J. McDermid, Yan Jia, Zoe Porter, I. Habli","Artificial intelligence explainability: the technical and ethical dimensions",2021,"","","","",65,"2022-07-13 09:35:20","","10.1098/rsta.2020.0363","","",,,,,7,7.00,2,4,1,"In recent years, several new technical methods have been developed to make AI-models more transparent and interpretable. These techniques are often referred to collectively as ‘AI explainability’ or ‘XAI’ methods. This paper presents an overview of XAI methods, and links them to stakeholder purposes for seeking an explanation. Because the underlying stakeholder purposes are broadly ethical in nature, we see this analysis as a contribution towards bringing together the technical and ethical dimensions of XAI. We emphasize that use of XAI methods must be linked to explanations of human decisions made during the development life cycle. Situated within that wider accountability framework, our analysis may offer a helpful starting point for designers, safety engineers, service providers and regulators who need to make practical judgements about which XAI methods to employ or to require. This article is part of the theme issue ‘Towards symbiotic autonomous systems’.","",""
3,"Jesús Salgado-Criado, Celia Fernández-Aller","A Wide Human-Rights Approach to Artificial Intelligence Regulation in Europe",2021,"","","","",66,"2022-07-13 09:35:20","","10.1109/MTS.2021.3056284","","",,,,,3,3.00,2,2,1,"Editor’s note: This article was written before the publication by the EU Commission of its proposal for an artificial intelligence (AI) regulation [29]. In a first and provisional analysis of the proposed regulation, we observe that the proposed regulation incorporates some of the basic principles laid down in our article: it prioritizes fundamental rights and incorporates some human rights principles, such as accountability, and the inclusion of governance through supervisory authorities to implement and enforce the regulation. Nevertheless, we still feel that many of the suggestions present in our article, which would help to operationalize the regulation, are not addressed. One example is the reduced scope of the regulation to a list of “high risk applications,” leaving without a legal framework all other AI applications. We believe that the principles that inspire the regulation should also be applied in “lower risk applications.” Defining only the compliance process for AI developers, but leaving open the specific technical requirements that these high risk applications shall meet leaves untouched the existing gap between legal language and engineering practice. There are no described mechanisms by which all stakeholders (other than developers and implementers) can influence AI development, monitor their performance or claim redress if harmed. These shortcomings and other issues presented in our article leave the door open to loopholes that we hope the European Parliament can fix during the legislative process.","",""
4,"Shivam Mehta, Y. Suhail, J. Nelson, M. Upadhyay","Artificial Intelligence for radiographic image analysis",2021,"","","","",67,"2022-07-13 09:35:20","","10.1053/J.SODO.2021.05.007","","",,,,,4,4.00,1,4,1,"Abstract Automated identification of landmarks on lateral cephalogram and cone-beam computed tomography (CBCT) scans can save time for the clinicians and act as a second set of eyes for analysis of radiographic images in diagnosis and treatment planning. Several machine-learning techniques have been utilized for this purpose with varying accuracies. However, high degree of variability in the clinical presentation of orthodontic patients, limitations of the algorithms, lack of labelled data, high compute power, etc. are some drawbacks that have limited robust clinical application of such techniques. In recent years, artificial neural networks like deep learning and more specifically deep neural networks are making significant inroads in the true adoption of this technology. YOLOv3 and Single Shot Multibox Detector are some of the deep learning algorithms that have shown promising results. This paper is a theoretical review of the evolution of these technologies and the current state of the art in orthodontic image analysis.","",""
1,"Mateus De Oliveira Fornasier","THE REGULATION OF THE USE OF ARTIFICIAL INTELLIGENCE (AI) IN WARFARE: between International Humanitarian Law (IHL) and Meaningful Human Control",2021,"","","","",68,"2022-07-13 09:35:20","","10.20499/2236-3645.RJP2021V23E129-2229","","",,,,,1,1.00,1,1,1,"The proper principles for the regulation of autonomous weapons were studied here, some of which have already been inserted in International Humanitarian Law (IHL), and others are still merely theoretical. The differentiation between civilians and non-civilians, the solution of liability blanks and proportionality are fundamental principles for the regulation of the warlike use of artificial intelligence (AI), but the significant human control of the warlike AI must be added to them. Through the hypothetical-deductive procedure, with a qualitative approach and bibliographic review, it was concluded that the realization of the differentiation criterion, value-sensitive design, the elimination of accountability gaps, significant human control and IHL must support the regulation of the use of autonomous weapon systems – however, the differentiation between civilians and non-civilians and proportionality are not yet technologically possible, which makes compliance with IHL still dependent on significant human control; and the opacity of warlike AI algorithms would make legal accountability for its use difficult.","",""
0,"Xiaohong W. Gao, B. Braden","Artificial intelligence in endoscopy: The challenges and future directions",2021,"","","","",69,"2022-07-13 09:35:20","","10.37126/aige.v2.i4.117","","",,,,,0,0.00,0,2,1,"Artificial intelligence based approaches, in particular deep learning, have achieved state-of-the-art performance in medical fields with increasing number of software systems being approved by both Europe and United States. This paper reviews their applications to early detection of oesophageal cancers with a focus on their advantages and pitfalls. The paper concludes with future recommendations towards the development of a real-time, clinical implementable, interpretable and robust diagnosis support systems.","",""
0,"Caijin Ling, Ting Zeng, Yang Su","Research on Intelligent Supervision and Application System of Food Traceability Based on Blockchain and Artificial intelligence",2021,"","","","",70,"2022-07-13 09:35:20","","10.1109/ICIBA52610.2021.9688295","","",,,,,0,0.00,0,3,1,"The lack of transparency in the production and circulation of commodities and the lack of corresponding supervision have led to endless problems such as food safety, counterfeit and shoddy products, loss and damage of commodities, and damage to the rights and interests of consumers. The traditional centralized database traceability monitoring system has serious problems of data trust, data fragmentation, difficulty in accountability, and low enthusiasm of merchants. In order to solve the traditional system problems, it is proposed to build an intelligent supervision system model for food traceability based on blockchain and artificial intelligence. Blockchain technology can effectively make up and improve the shortcomings of the existing commodity traceability technology, and achieve full process control and real-time storage. Forensic forensics, increase transparency, prevent counterfeiting, and increase consumer trust; AI uses industry-sharing data to perform big data analysis to guide companies in business decisions; at the same time, in order to increase user stickiness and increase the ecological environment of the platform, the article proposes to increase Blockchain and artificial intelligence and application ecology form a more practical and complete integrated system model of traceability, supervision and application. Finally, using FISCO BCOS as a blockchain platform development platform, the validity of the model is verified, and it can provide a certain reference for food traceability companies, software R&D companies, and government regulatory agencies.","",""
0,"M. Aggarwal, Christian Gingras, R. Deber","Artificial Intelligence in Healthcare from a Policy Perspective",2021,"","","","",71,"2022-07-13 09:35:20","","10.1007/978-3-030-67303-1_5","","",,,,,0,0.00,0,3,1,"","",""
30,"S. L. Piano","Ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward",2020,"","","","",72,"2022-07-13 09:35:20","","10.1057/S41599-020-0501-9","","",,,,,30,15.00,30,1,2,"","",""
29,"Grayson W. Armstrong, A. Lorch","A(eye): A Review of Current Applications of Artificial Intelligence and Machine Learning in Ophthalmology",2019,"","","","",73,"2022-07-13 09:35:20","","10.1097/IIO.0000000000000298","","",,,,,29,9.67,15,2,3,"Artificial intelligence (AI) is a branch of computer science that aims to enable computers to perform human-like tasks. Although AI is a broad discipline, machine learning is a specific branch of AI that uses computer algorithms capable of “learning” through the simulation of human intelligence. Machine learning algorithms have been applied to the medical field since the 1970s,1 and since that time have proven useful in computerassisted diagnosis, screening, and prognostication of disease.2–7 Ophthalmology is uniquely capable of capitalizing on the promise of AI. Ophthalmologists, during routine clinical encounters, generate robust data sources capable of supporting machine learning algorithms including multimodal ophthalmic images and quantifiable metrics such as visual acuity (VA), intraocular pressure, and cup to disk ratio. To date, AI techniques have been applied to ophthalmology to screen for and diagnose diseases, such as diabetic retinopathy (DR), age-related macular degeneration (AMD), macular edema (ME), glaucoma, keratoconus, postlaserassisted in situ keratomileusis corneal ectasia, retinopathy of prematurity (ROP), and cataracts, as well as predict the prognosis of various ophthalmic diseases. Advances in ophthalmology-specific AI stand to increase patient access to clinical screening and diagnosis as well as decrease health care costs, especially when applied to high-risk populations, low-resource communities, or when combined with telemedicine initiatives. This review provides an introduction to AI andmachine learning, as well as an overview of current applications in the field of ophthalmology.","",""
20,"L. McCoy, Sujay Nagaraj, F. Morgado, V. Harish, Sunit Das, L. Celi","What do medical students actually need to know about artificial intelligence?",2020,"","","","",74,"2022-07-13 09:35:20","","10.1038/s41746-020-0294-7","","",,,,,20,10.00,3,6,2,"","",""
28,"H. Alami, L. Rivard, P. Lehoux, S. Hoffman, Stephanie B. M. Cadeddu, Mathilde Savoldelli, M. A. Samri, M. A. Ag Ahmed, R. Fleet, J. Fortin","Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",2020,"","","","",75,"2022-07-13 09:35:20","","10.1186/s12992-020-00584-1","","",,,,,28,14.00,3,10,2,"","",""
44,"Chiara Longoni, Luca Cian","Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",2020,"","","","",76,"2022-07-13 09:35:20","","10.1177/0022242920957347","","",,,,,44,22.00,22,2,2,"Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).","",""
24,"Paul Henman","Improving public services using artificial intelligence: possibilities, pitfalls, governance",2020,"","","","",77,"2022-07-13 09:35:20","","10.1080/23276665.2020.1816188","","",,,,,24,12.00,24,1,2,"Artificial intelligence arising from the use of machine learning is rapidly being developed and deployed by governments to enhance operations, public services, and compliance and security activities. This article reviews how artificial intelligence is being used in public sector for automated decision making, for chatbots to provide information and advice, and for public safety and security. It then outlines four public administration challenges to deploying artificial intelligence in public administration: accuracy, bias and discrimination; legality, due process and administrative justice; responsibility, accountability, transparency and explainability; and power, compliance and control. The article outlines technological and governance innovations that are being developed to address these challenges.","",""
25,"D. Schiff","Out of the laboratory and into the classroom: the future of artificial intelligence in education",2020,"","","","",78,"2022-07-13 09:35:20","","10.1007/s00146-020-01033-8","","",,,,,25,12.50,25,1,2,"","",""
23,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, Craig Williams, Jayde Whittingham-Dowd, E. Shaw, Matt D. Hodges, L. Butler, M. Bates, R. L. La Ragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (AI-LAMP) for Rapid Detection of SARS-CoV-2",2020,"","","","",79,"2022-07-13 09:35:20","","10.3390/v12090972","","",,,,,23,11.50,2,28,2,"Until vaccines and effective therapeutics become available, the practical solution to transit safely out of the current coronavirus disease 19 (CoVID-19) lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of results, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected NHS patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. Therefore, this system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
23,"A. Fischer, A. Varga-Szemes, Simon S. Martin, J. Sperl, P. Sahbaee, D. Neumann, J. Gawlitza, T. Henzler, Colin M Johnson, J. Nance, S. Schoenberg, U. Schoepf","Artificial Intelligence-based Fully Automated Per Lobe Segmentation and Emphysema-quantification Based on Chest Computed Tomography Compared With Global Initiative for Chronic Obstructive Lung Disease Severity of Smokers.",2020,"","","","",80,"2022-07-13 09:35:20","","10.1097/RTI.0000000000000500","","",,,,,23,11.50,2,12,2,"OBJECTIVES The objective of this study was to evaluate an artificial intelligence (AI)-based prototype algorithm for the fully automated per lobe segmentation and emphysema quantification (EQ) on chest-computed tomography as it compares to the Global Initiative for Chronic Obstructive Lung Disease (GOLD) severity classification of chronic obstructive pulmonary disease (COPD) patients.   METHODS Patients (n=137) who underwent chest-computed tomography acquisition and spirometry within 6 months were retrospectively included in this Institutional Review Board-approved and Health Insurance Portability and Accountability Act-compliant study. Patient-specific spirometry data, which included forced expiratory volume in 1 second, forced vital capacity, and the forced expiratory volume in 1 second/forced vital capacity ratio (Tiffeneau-Index), were used to assign patients to their respective GOLD stage I to IV. Lung lobe segmentation was carried out using AI-RAD Companion software prototype (Siemens Healthineers), a deep convolution image-to-image network and emphysema was quantified in each lung lobe to detect the low attenuation volume.   RESULTS A strong correlation between the whole-lung-EQ and the GOLD stages was found (ρ=0.88, P<0.0001). The most significant correlation was noted in the left upper lobe (ρ=0.85, P<0.0001), and the weakest in the left lower lobe (ρ=0.72, P<0.0001) and right middle lobe (ρ=0.72, P<0.0001).   CONCLUSIONS AI-based per lobe segmentation and its EQ demonstrate a very strong correlation with the GOLD severity stages of COPD patients. Furthermore, the low attenuation volume of the left upper lobe not only showed the strongest correlation to GOLD severity but was also able to most clearly distinguish mild and moderate forms of COPD. This is particularly relevant due to the fact that early disease processes often elude conventional pulmonary function diagnostics. Earlier detection of COPD is a crucial element for positively altering the course of disease progression through various therapeutic options.","",""
37,"H.J. Yu, S. Cho, M. Kim, Won Hwa Kim, J.W. Kim, J. Choi","Automated Skeletal Classification with Lateral Cephalometry Based on Artificial Intelligence",2020,"","","","",81,"2022-07-13 09:35:20","","10.1177/0022034520901715","","",,,,,37,18.50,6,6,2,"Lateral cephalometry has been widely used for skeletal classification in orthodontic diagnosis and treatment planning. However, this conventional system, requiring manual tracing of individual landmarks, contains possible errors of inter- and intravariability and is highly time-consuming. This study aims to provide an accurate and robust skeletal diagnostic system by incorporating a convolutional neural network (CNN) into a 1-step, end-to-end diagnostic system with lateral cephalograms. A multimodal CNN model was constructed on the basis of 5,890 lateral cephalograms and demographic data as an input. The model was optimized with transfer learning and data augmentation techniques. Diagnostic performance was evaluated with statistical analysis. The proposed system exhibited >90% sensitivity, specificity, and accuracy for vertical and sagittal skeletal diagnosis. Clinical performance of the vertical classification showed the highest accuracy at 96.40 (95% CI, 93.06 to 98.39; model III). The receiver operating characteristic curve and the area under the curve both demonstrated the excellent performance of the system, with a mean area under the curve >95%. The heat maps of cephalograms were also provided for deeper understanding of the quality of the learned model by visually representing the region of the cephalogram that is most informative in distinguishing skeletal classes. In addition, we present broad applicability of this system through subtasks. The proposed CNN-incorporated system showed potential for skeletal orthodontic diagnosis without the need for intermediary steps requiring complicated diagnostic procedures.","",""
1,"K. Vogel, Gwendolynne Reid, Christopher Kampe, Paul Jones","The impact of AI on intelligence analysis: tackling issues of collaboration, algorithmic transparency, accountability, and management",2021,"","","","",82,"2022-07-13 09:35:20","","10.1080/02684527.2021.1946952","","",,,,,1,1.00,0,4,1,"In January 2019, the U.S. Office of the Director of National Intelligence (ODNI) released a new strategy on the use of artificial intelligence (AI) technologies in U.S. intelligence. The report called for incorporating AI and automation technologies into intelligence work ‘to amplify the effectiveness of our workforce . . . advance mission capability and enhance the IC’s [Intelligence Community’s] ability to provide data interpretation to decision makers’. The ODNI noted it was evaluating and monitoring how these technologies might also have ‘vulnerabilities in development and adoption’. The report stated it was critical to address issues of ‘AI assurance, transparency, and reliability . . . to . . . understand how AI algorithms may fail’, and noted the importance of developing AI systems that ‘can demonstrate the underlying rationale behind decisions and responses to both users and overseers’. Finally, it emphasized the importance of monitoring ‘implementation and user feedback’ in a future AI-enabled workforce. This imagined future is not only to come; it is being realized now. Within the past few years, probably one of the most visibly controversial IC projects involving AI and intelligence analysis was Project Maven, a 2017 Department of Defense–driven intelligence project that used advances in big data, machine learning, and deep learning to extract objects of interest from drone-derived imagery, saving intelligence analysts hours of tedious imagery processing time. Project Maven partnered with Google to use some of the tech giant’s AI technology, but the project was ultimately cancelled in 2018 because of Google employee protests against the use of company algorithms for military targeting. Beyond Project Maven, a number of less controversial R&D programs ARE underway that aim to augment intelligence analysts’ capabilities. For example, the Defense Advanced Research Project Agency (DARPA)’s Explainable (XAI) Program is creating a set of new machine-learning techniques to ‘enable human users to understand, appropriately trust, and effectively manage the emerging generation of artificially intelligent partners’. The National Security Agency’s Laboratory for Analytic Sciences is developing big-data and AI-enabled technological platforms to bring more AI-enabled systems to analysts’ desktops. To date, these are individual proof-ofconcept technologies that may be applied and integrated into a variety of potential intelligence tools, such as: Journaling, a productivity device for intelligence analysts that enables them to understand their own individual work flows; OpenKE, which automates the collection and analysis of open-source information; BEAST, a platform of natural language processing and other extraction services that can scrape and process data from various sources for anticipatory intelligence analysis; and CyberMonkey, which allows a large number of analytic tools to be executed proactively in-browser instead of having to utilize tools sequentially or separately. All of these technologies aim ‘to assist the analyst without the analyst explicitly telling the machine everything it needs to do’. The Intelligence Advanced Research Project Activity (IARPA)’s Multimodal","",""
27,"Omar Alshorman, Muhammad Irfan, N. Saad, D. Zhen, Noman Haider, A. Głowacz, Ahmad M. Alshorman","A Review of Artificial Intelligence Methods for Condition Monitoring and Fault Diagnosis of Rolling Element Bearings for Induction Motor",2020,"","","","",83,"2022-07-13 09:35:20","","10.1155/2020/8843759","","",,,,,27,13.50,4,7,2,"The fault detection and diagnosis (FDD) along with condition monitoring (CM) and of rotating machinery (RM) have critical importance for early diagnosis to prevent severe damage of infrastructure in industrial environments. Importantly, valuable industrial equipment needs continuous monitoring to enhance the safety, reliability, and availability and to decrease the cost of maintenance of modern industrial systems and applications. However, induction motor (IM) has been extensively used in several industrial processes because it is cheap, reliable, and robust. Rolling bearings are considered to be the main component of IM. Undoubtedly, any failure of this basic component can lead to a serious breakdown of IM and for whole industrial system. Thus, many current methods based on different techniques are employed as a fault prognosis and diagnosis of rolling elements bearing of IM. Moreover, these techniques include signal/image processing, intelligent diagnostics, data fusion, data mining, and expert systems for time and frequency as well as time-frequency domains. Artificial intelligence (AI) techniques have proven their significance in every field of digital technology. Industrial machines, automation, and processes are the net frontiers of AI adaptation. There are quite developed literatures that have been approaching the issues using signals and data processing techniques. However, the key contribution of this work is to present an extensive review of CM and FDD of the IM, especially for rolling elements bearings, based on artificial intelligent (AI) methods. This study highlights the advantages and performance limitations of each method. Finally, challenges and future trends are also highlighted.","",""
0,"Keeley A. Crockett, Edwin Colyer, A. Latham","The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives",2021,"","","","",84,"2022-07-13 09:35:20","","10.1109/SSCI50451.2021.9660153","","",,,,,0,0.00,0,3,1,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.","",""
0,"Lucas Mendes Lima, Victor Calebe Cavalcante, Mariana Guimarães de Sousa, Cláudio Afonso Fleury, D. Oliveira, Eduardo Noronha de Andrade Freitas","Artificial Intelligence in Support of Welfare Monitoring of Dairy Cattle: A Systematic Literature Review",2021,"","","","",85,"2022-07-13 09:35:20","","10.1109/CSCI54926.2021.00324","","",,,,,0,0.00,0,6,1,"Context: Although agribusiness corresponded to more than 20% of Brazil’s Gross Domestic Product (GDP), most livestock is under manual control and manual monitoring. Additionally, alternative technologies are either uncomfortable and stressful, or expensive. Now, despite the great scientific advances in the area, there is still a pressing need for an automated robust, inexpensive and (sub)optimal technology to monitor animal behavior in a cost-effective, contact-less and stress-free fashion. Overall, this niche can leverage the benefits of Deep Learning schemes.Objective: This review aims to provide a systematic overview of most current projects in the area of comfort monitoring dairy cattle, as well as their corresponding image recognition-based techniques and technologies.Methods: First, a systematic review planning was carried out, and objectives, research questions, search strings, among others, were defined. Subsequently,a broad survey was conducted to extract, analyze and compile the data, to generate a easy-to-read visual source of information (tables and graphics).Results: Information was extracted from the reviewed papers. Among this data collected from the papers are techniques utilized, target behaviors, cow bodyparts identified in visual computational, besides their paper source font, the publication date, and localization. For example, the papers present are mostly recent. China has had a larger number of relevant papers in the area. The back was the body region most analyzed by the papers and the behaviors most analyzed were body condition score, lameness, cow’s body position and feeding/drinking behavior. Among the methods used is RCNN Inception V3 with the best accuracy for cow’s back region.Conclusion: The aim of this work is to present some of the papers that are being carried out in the area of dairy cow behavior monitoring, using techniques of Artifical Intelligence. It is expected that the information collected and presented in the present systematic review paper contribute to the future researches and projects of the area and the application of new techniques.","",""
43,"Stuart J. Russell, Thomas G. Dietterich, Eric Horvitz, B. Selman, F. Rossi, D. Hassabis, S. Legg, Mustafa Suleyman, D. George, D. Phoenix","Letter to the Editor: Research Priorities for Robust and Beneficial Artificial Intelligence: An Open Letter",2015,"","","","",86,"2022-07-13 09:35:20","","10.1609/aimag.v36i4.2621","","",,,,,43,6.14,4,10,7,"Artificial intelligence (AI) research has explored a variety of problems and approaches since its inception, but for the last 20 years or so has been focused on the problems surrounding the construction of intelligent agents — systems that perceive and act in some environment. In this context, ""intelligence"" is related to statistical and economic notions of rationality — colloquially, the ability to make good decisions, plans, or inferences. The adoption of probabilistic and decision-theoretic representations and statistical learning methods has led to a large degree of integration and cross-fertilization among AI, machine learning, statistics, control theory, neuroscience, and other fields. The establishment of shared theoretical frameworks, combined with the availability of data and processing power, has yielded remarkable successes in various component tasks such as speech recognition, image classification, autonomous vehicles, machine translation, legged locomotion, and question-answering systems. As capabilities in these areas and others cross the threshold from laboratory research to economically valuable technologies, a virtuous cycle takes hold whereby even small improvements in performance are worth large sums of money, prompting greater investments in research. There is now a broad consensus that AI research is progressing steadily, and that its impact on society is likely to increase. The potential benefits are huge, since everything that civilization has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable. Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls. The progress in AI research makes it timely to focus research not only on making AI more capable, but also on maximizing the societal benefit of AI. Such considerations motivated the AAAI 2008–09 Presidential Panel on Long-Term AI Futures and other projects on AI impacts, and constitute a significant expansion of the field of AI itself, which up to now has focused largely on techniques that are neutral with respect to purpose. We recommend expanded research aimed at ensuring that increasingly capable AI systems are robust and beneficial: our AI systems must do what we want them to do. The attached research priorities document [see page X] gives many examples of such research directions that can help maximize the societal benefit of AI. This research is by necessity interdisciplinary, because it involves both society and AI. It ranges from economics, law and philosophy to computer security, formal methods and, of course, various branches of AI itself. In summary, we believe that research on how to make AI systems robust and beneficial is both important and timely, and that there are concrete research directions that can be pursued today.","",""
18,"Ahmed Gowida, Salaheldin Elkatatny, Saad F. K. Al-Afnan, A. Abdulraheem","New Computational Artificial Intelligence Models for Generating Synthetic Formation Bulk Density Logs While Drilling",2020,"","","","",87,"2022-07-13 09:35:20","","10.3390/su12020686","","",,,,,18,9.00,5,4,2,"Synthetic well log generation using artificial intelligence tools is a robust solution for situations in which logging data are not available or are partially lost. Formation bulk density (RHOB) logging data greatly assist in identifying downhole formations. These data are measured in the field while drilling by using a density log tool in the form of either a logging while drilling (LWD) technique or (more often) by wireline logging after the formations are drilled. This is due to operational limitations during the drilling process. Therefore, the objective of this study was to develop a predictive tool for estimating RHOB while drilling using an adaptive network-based fuzzy interference system (ANFIS), functional network (FN), and support vector machine (SVM). The proposed model uses the mechanical drilling constraints as feeding input parameters, and the conventional RHOB log data as an output parameter. These mechanical drilling parameters are usually measured while drilling, and their responses vary with different formations. A dataset of 2400 actual datapoints, obtained from a horizontal well in the Middle East, were used to build the proposed models. The obtained dataset was divided into a 70/30 ratio for model training and testing, respectively. The optimized ANFIS-based model outperformed the FN- and SVM-based models with a correlation coefficient (R) of 0.93, and average absolute percentage error (AAPE) of 0.81% between the predicted and measured RHOB values. These results demonstrate the reliability of the developed ANFIS model for predicting RHOB while drilling, based on the mechanical drilling parameters. Subsequently, the ANFIS-based model was validated using unseen data from another well within the same field. The validation process yielded an AAPE of 0.97% between the predicted and actual RHOB values, which confirmed the robustness of the developed model as an effective predictive tool for RHOB.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",88,"2022-07-13 09:35:20","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
14,"L. Robert, G. Bansal, C. Lütge","ICIS 2019 SIGHCI Workshop Panel Report: Human– Computer Interaction Challenges and Opportunities for Fair, Trustworthy and Ethical Artificial Intelligence",2020,"","","","",89,"2022-07-13 09:35:20","","10.17705/1thci.00130","","",,,,,14,7.00,5,3,2,"Artificial Intelligence (AI) is rapidly changing every aspect of our society—including amplifying our biases. Fairness, trust and ethics are at the core of many of the issues underlying the implications of AI. Despite this, research on AI with relation to fairness, trust and ethics in the information systems (IS) field is still scarce. This panel brought together academia, business and government perspectives to discuss the challenges and identify potential solutions to address such challenges. This panel report presents eight themes based around the discussion of two questions: (1) What are the biggest challenges to designing, implementing and deploying fair, ethical and trustworthy AI?; and (2) What are the biggest challenges to policy and governance for fair, ethical and trustworthy AI? The eight themes are: (1) identifying AI biases; (2) drawing attention to AI biases; (3) addressing AI biases; (4) designing transparent and explainable AI; (5) AI fairness, trust, ethics: old wine in a new bottle?; (6) AI accountability; (7) AI laws, policies, regulations and standards; and (8) frameworks for fair, ethical and trustworthy AI. Based on the results of the panel discussion, we present research questions for each theme to guide future research in the area of human–computer interaction.","",""
14,"I. Hazarika","Artificial intelligence: opportunities and implications for the health workforce",2020,"","","","",90,"2022-07-13 09:35:20","","10.1093/inthealth/ihaa007","","",,,,,14,7.00,14,1,2,"Abstract Healthcare involves cyclic data processing to derive meaningful, actionable decisions. Rapid increases in clinical data have added to the occupational stress of healthcare workers, affecting their ability to provide quality and effective services. Health systems have to radically rethink strategies to ensure that staff are satisfied and actively supported in their jobs. Artificial intelligence (AI) has the potential to augment provider performance. This article reviews the available literature to identify AI opportunities that can potentially transform the role of healthcare providers. To leverage AI’s full potential, policymakers, industry, healthcare providers and patients have to address a new set of challenges. Optimizing the benefits of AI will require a balanced approach that enhances accountability and transparency while facilitating innovation.","",""
14,"Claudia Gonzalez Viejo, S. Fuentes","Beer Aroma and Quality Traits Assessment Using Artificial Intelligence",2020,"","","","",91,"2022-07-13 09:35:20","","10.3390/fermentation6020056","","",,,,,14,7.00,7,2,2,"Increasing beer quality demands from consumers have put pressure on brewers to target specific steps within the beer-making process to modify beer styles and quality traits. However, this demands more robust methodologies to assess the final aroma profiles and physicochemical characteristics of beers. This research shows the construction of artificial intelligence (AI) models based on aroma profiles, chemometrics, and chemical fingerprinting using near-infrared spectroscopy (NIR) obtained from 20 commercial beers used as targets. Results showed that machine learning models obtained using NIR from beers as inputs were accurate and robust in the prediction of six important aromas for beer (Model 1; R = 0.91; b = 0.87) and chemometrics (Model 2; R = 0.93; b = 0.90). Additionally, two more accurate models were obtained from robotics (RoboBEER) to obtain the same aroma profiles (Model 3; R = 0.99; b = 1.00) and chemometrics (Model 4; R = 0.98; b = 1.00). Low-cost robotics and sensors coupled with computer vision and machine learning modeling could help brewers in the decision-making process to target specific consumer preferences and to secure higher consumer demands.","",""
12,"C. Ho, Joseph Ali, K. Caals","Ensuring trustworthy use of artificial intelligence and big data analytics in health insurance",2020,"","","","",92,"2022-07-13 09:35:20","","10.2471/BLT.19.234732","","",,,,,12,6.00,4,3,2,"Abstract Technological advances in big data (large amounts of highly varied data from many different sources that may be processed rapidly), data sciences and artificial intelligence can improve health-system functions and promote personalized care and public good. However, these technologies will not replace the fundamental components of the health system, such as ethical leadership and governance, or avoid the need for a robust ethical and regulatory environment. In this paper, we discuss what a robust ethical and regulatory environment might look like for big data analytics in health insurance, and describe examples of safeguards and participatory mechanisms that should be established. First, a clear and effective data governance framework is critical. Legal standards need to be enacted and insurers should be encouraged and given incentives to adopt a human-centred approach in the design and use of big data analytics and artificial intelligence. Second, a clear and accountable process is necessary to explain what information can be used and how it can be used. Third, people whose data may be used should be empowered through their active involvement in determining how their personal data may be managed and governed. Fourth, insurers and governance bodies, including regulators and policy-makers, need to work together to ensure that the big data analytics based on artificial intelligence that are developed are transparent and accurate. Unless an enabling ethical environment is in place, the use of such analytics will likely contribute to the proliferation of unconnected data systems, worsen existing inequalities, and erode trustworthiness and trust.","",""
12,"M. He, Zhixi Li, Chi Liu, Danli Shi, Zachary Tan","Deployment of Artificial Intelligence in Real-World Practice: Opportunity and Challenge.",2020,"","","","",93,"2022-07-13 09:35:20","","10.1097/APO.0000000000000301","","",,,,,12,6.00,2,5,2,"Artificial intelligence has rapidly evolved from the experimental phase to the implementation phase in many image-driven clinical disciplines, including ophthalmology. A combination of the increasing availability of large datasets and computing power with revolutionary progress in deep learning has created unprecedented opportunities for major breakthrough improvements in the performance and accuracy of automated diagnoses that primarily focus on image recognition and feature detection. Such an automated disease classification would significantly improve the accessibility, efficiency, and cost-effectiveness of eye care systems where it is less dependent on human input, potentially enabling diagnosis to be cheaper, quicker, and more consistent. Although this technology will have a profound impact on clinical flow and practice patterns sooner or later, translating such a technology into clinical practice is challenging and requires similar levels of accountability and effectiveness as any new medication or medical device due to the potential problems of bias, and ethical, medical, and legal issues that might arise. The objective of this review is to summarize the opportunities and challenges of this transition and to facilitate the integration of artificial intelligence (AI) into routine clinical practice based on our best understanding and experience in this area.","",""
14,"G. Coskuner, Majeed S Jassim, M. Zontul, Seda Karateke","Application of artificial intelligence neural network modeling to predict the generation of domestic, commercial and construction wastes",2020,"","","","",94,"2022-07-13 09:35:20","","10.1177/0734242X20935181","","",,,,,14,7.00,4,4,2,"Reliable prediction of municipal solid waste (MSW) generation rates is a significant element of planning and implementation of sustainable solid waste management strategies. In this study, the multi-layer perceptron artificial neural network (MLP-ANN) is applied to verify the prediction of annual generation rates of domestic, commercial and construction and demolition (C&D) wastes from the year 1997 to 2016 in Askar Landfill site in the Kingdom of Bahrain. The proposed robust predictive models incorporated selected explanatory variables to reflect the influence of social, demographical, economic, geographical and touristic factors upon waste generation rates (WGRs). The Mean Squared Error (MSE) and coefficient of determination (R2) are used as performance indicators to evaluate effectiveness of the developed models. MLP-ANN models exhibited strong accuracy in predictions with high R2 and low MSE values. The R2 values for domestic, commercial and C&D wastes are 0.95, 0.99 and 0.91, respectively. Our results show that the developed MLP-ANN models are effective for the prediction of WGRs from different sources and could be considered as a cost-effective approach for planning integrated MSW management systems.","",""
10,"Xiaohang Wu, Lixue Liu, Lanqin Zhao, Chong Guo, Ruiyang Li, Ting Wang, Xiaonan Yang, Peichen Xie, Yizhi Liu, Haotian Lin","Application of artificial intelligence in anterior segment ophthalmic diseases: diversity and standardization.",2020,"","","","",95,"2022-07-13 09:35:20","","10.21037/ATM-20-976","","",,,,,10,5.00,1,10,2,"Artificial intelligence (AI) based on machine learning (ML) and deep learning (DL) techniques has gained tremendous global interest in this era. Recent studies have demonstrated the potential of AI systems to provide improved capability in various tasks, especially in image recognition field. As an image-centric subspecialty, ophthalmology has become one of the frontiers of AI research. Trained on optical coherence tomography, slit-lamp images and even ordinary eye images, AI can achieve robust performance in the detection of glaucoma, corneal arcus and cataracts. Moreover, AI models based on other forms of data also performed satisfactorily. Nevertheless, several challenges with AI application in ophthalmology have also arisen, including standardization of data sets, validation and applicability of AI models, and ethical issues. In this review, we provided a summary of the state-of-the-art AI application in anterior segment ophthalmic diseases, potential challenges in clinical implementation and our prospects.","",""
11,"Rebekah H. Gensure, M. Chiang, J. P. Campbell","Artificial intelligence for retinopathy of prematurity.",2020,"","","","",96,"2022-07-13 09:35:20","","10.1097/ICU.0000000000000680","","",,,,,11,5.50,4,3,2,"PURPOSE OF REVIEW In this article, we review the current state of artificial intelligence applications in retinopathy of prematurity (ROP) and provide insight on challenges as well as strategies for bringing these algorithms to the bedside.   RECENT FINDINGS In the past few years, there has been a dramatic shift from machine learning approaches based on feature extraction to 'deep' convolutional neural networks for artificial intelligence applications. Several artificial intelligence for ROP approaches have demonstrated adequate proof-of-concept performance in research studies. The next steps are to determine whether these algorithms are robust to variable clinical and technical parameters in practice. Integration of artificial intelligence into ROP screening and treatment is limited by generalizability of the algorithms to maintain performance on unseen data and integration of artificial intelligence technology into new or existing clinical workflows.   SUMMARY Real-world implementation of artificial intelligence for ROP diagnosis will require massive efforts targeted at developing standards for data acquisition, true external validation, and demonstration of feasibility. We must now focus on ethical, technical, clinical, regulatory, and financial considerations to bring this technology to the infant bedside to realize the promise offered by this technology to reduce preventable blindness from ROP.","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",97,"2022-07-13 09:35:20","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
10,"Virginia Dignum","Responsibility and Artificial Intelligence",2020,"","","","",98,"2022-07-13 09:35:20","","10.1093/oxfordhb/9780190067397.013.12","","",,,,,10,5.00,10,1,2,"This chapter explores the concept of responsibility in artificial intelligence (AI). Being fundamentally tools, AI systems are fully under the control and responsibility of their owners or users. However, their potential autonomy and capability to learn require that design considers accountability, responsibility, and transparency principles in an explicit and systematic manner. The main concern of Responsible AI is thus the identification of the relative responsibility of all actors involved in the design, development, deployment, and use of AI systems. Firstly, society must be prepared to take responsibility for AI impact. Secondly, Responsible AI implies the need for mechanisms that enable AI systems to act according to ethics and human values. Lastly, Responsible AI is about participation. It is necessary to understand how different people work with and live with AI technologies across cultures in order to develop frameworks for responsible AI.","",""
0,"Yusen Xie, Ting Sun, Xinglong Cui, Shuixin Deng, Lei Deng, Baohua Chen","Fast-robust book information extraction system for automated intelligence library",2021,"","","","",99,"2022-07-13 09:35:20","","10.1109/AIID51893.2021.9456499","","",,,,,0,0.00,0,6,1,"At present, in the large-scale book management scene, book sorting, daily maintenance and book retrieval are very common, but the book information is complicated and the efficiency of relying on manual management is extremely poor. Although there have been many self-service book systems based on optics or vision, they are mostly based on traditional computer vision algorithms such as boundary extraction. Due to the fact that there are more artificial experience thresholds, some shortcomings such as low detection accuracy, poor robustness, and inability to systematically deploy on a large scale, which lack of insufficient intelligence. Therefore, we proposed a book information extraction algorithm based on object detection and optical character recognition (OCR) that is suitable for multiple book information recognition, multiple book image angles and multiple book postures. It can be applied to scenes such as book sorting, bookshelf management and book retrieval. The system we designed includes the classification of book covers and back covers, the classification of books upright and inverted, the detection of book pages side and spine side, the recognition of book pricing. In terms of accuracy, the classification accuracy of the front cover and the back cover is 99.9%, the upright classification accuracy of book front covers is 98.8%, the back cover reaches 99.9%, the accuracy of book price recognition get 94.5%, and the book spine/page side detection mAP reaches 99.6%; in terms of detection speed, Yolov5 detection model was improved and the statistical-based pre-pruning strategy was adopted, support by our algorithm the system reaches 2.09 FPS in book price recognition, which improves the detection speed to meet actual needs.","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",100,"2022-07-13 09:35:20","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
7,"F. Contini","Artificial Intelligence and the Transformation of Humans, Law and Technology Interactions in Judicial Proceedings",2020,"","","","",101,"2022-07-13 09:35:20","","10.5204/lthj.v2i1.1478","","",,,,,7,3.50,7,1,2,"The paper connects the potentially disruptive effects of Artificial Intelligence (AI) deployment in the administration of justice to the pre-existing trajectories and consequences of court technology development. The theoretical framework combines Luhmann’s theory of technology with actor–network theory to analyse how the new digital environment affects judicial agency. Then, it explores law and technology dynamics to map out the conditions that make legal the use of technologies in judicial proceedings. The framework is applied to analyse ‘traditional’ digital technologies (simple online forms and large-scale e-justice platforms) and AI-based systems (speech-to-text and recidivism assessment). The case comparison shows similarities and dynamics triggered by AI and traditional technologies, as well as a radical difference. While system developers and owners remain accountable before the law for the functioning of traditional systems, with AI, such accountability is transferred to users. Judges—users in general—remain accountable for the consequences of their actions supported or suggested by systems that are opaque and autonomous. This contingency, if not adequately faced with new forms of accountability, restricts the areas in which AI can be used without hampering judicial integrity.","",""
7,"Ashley Kras, L. Celi, John B. Miller","Accelerating ophthalmic artificial intelligence research: the role of an open access data repository.",2020,"","","","",102,"2022-07-13 09:35:20","","10.1097/ICU.0000000000000678","","",,,,,7,3.50,2,3,2,"PURPOSE OF REVIEW Artificial intelligence has already provided multiple clinically relevant applications in ophthalmology. Yet, the explosion of nonstandardized reporting of high-performing algorithms are rendered useless without robust and streamlined implementation guidelines. The development of protocols and checklists will accelerate the translation of research publications to impact on patient care.   RECENT FINDINGS Beyond technological scepticism, we lack uniformity in analysing algorithmic performance generalizability, and benchmarking impacts across clinical settings. No regulatory guardrails have been set to minimize bias or optimize interpretability; no consensus clinical acceptability thresholds or systematized postdeployment monitoring has been set. Moreover, stakeholders with misaligned incentives deepen the landscape complexity especially when it comes to the requisite data integration and harmonization to advance the field. Therefore, despite increasing algorithmic accuracy and commoditization, the infamous 'implementation gap' persists. Open clinical data repositories have been shown to rapidly accelerate research, minimize redundancies and disseminate the expertise and knowledge required to overcome existing barriers. Drawing upon the longstanding success of existing governance frameworks and robust data use and sharing agreements, the ophthalmic community has tremendous opportunity in ushering artificial intelligence into medicine. By collaboratively building a powerful resource of open, anonymized multimodal ophthalmic data, the next generation of clinicians can advance data-driven eye care in unprecedented ways.   SUMMARY This piece demonstrates that with readily accessible data, immense progress can be achieved clinically and methodologically to realize artificial intelligence's impact on clinical care. Exponentially progressive network effects can be seen by consolidating, curating and distributing data amongst both clinicians and data scientists.","",""
7,"Nariman Ammar, Arash Shaban-Nejad","Explainable Artificial Intelligence Recommendation System by Leveraging the Semantics of Adverse Childhood Experiences: Proof-of-Concept Prototype Development",2020,"","","","",103,"2022-07-13 09:35:20","","10.2196/18752","","",,,,,7,3.50,4,2,2,"Background The study of adverse childhood experiences and their consequences has emerged over the past 20 years. Although the conclusions from these studies are available, the same is not true of the data. Accordingly, it is a complex problem to build a training set and develop machine-learning models from these studies. Classic machine learning and artificial intelligence techniques cannot provide a full scientific understanding of the inner workings of the underlying models. This raises credibility issues due to the lack of transparency and generalizability. Explainable artificial intelligence is an emerging approach for promoting credibility, accountability, and trust in mission-critical areas such as medicine by combining machine-learning approaches with explanatory techniques that explicitly show what the decision criteria are and why (or how) they have been established. Hence, thinking about how machine learning could benefit from knowledge graphs that combine “common sense” knowledge as well as semantic reasoning and causality models is a potential solution to this problem. Objective In this study, we aimed to leverage explainable artificial intelligence, and propose a proof-of-concept prototype for a knowledge-driven evidence-based recommendation system to improve mental health surveillance. Methods We used concepts from an ontology that we have developed to build and train a question-answering agent using the Google DialogFlow engine. In addition to the question-answering agent, the initial prototype includes knowledge graph generation and recommendation components that leverage third-party graph technology. Results To showcase the framework functionalities, we here present a prototype design and demonstrate the main features through four use case scenarios motivated by an initiative currently implemented at a children’s hospital in Memphis, Tennessee. Ongoing development of the prototype requires implementing an optimization algorithm of the recommendations, incorporating a privacy layer through a personal health library, and conducting a clinical trial to assess both usability and usefulness of the implementation. Conclusions This semantic-driven explainable artificial intelligence prototype can enhance health care practitioners’ ability to provide explanations for the decisions they make.","",""
8,"Kuang-Hua Hu, Fu-Hsiang Chen, Ming-Fu Hsu, G. Tzeng","IDENTIFYING KEY FACTORS FOR ADOPTING ARTIFICIAL INTELLIGENCE-ENABLED AUDITING TECHNIQUES BY JOINT UTILIZATION OF FUZZY-ROUGH SET THEORY AND MRDM TECHNIQUE",2020,"","","","",104,"2022-07-13 09:35:20","","10.3846/tede.2020.13181","","",,,,,8,4.00,2,4,2,"In today’s big-data era, enterprises are able to generate complex and non-structured information that could cause considerable challenges for CPA firms in data analysis and to issue improper audited reports within the required period. Artificial intelligence (AI)-enabled auditing technology not only facilitates accurate and comprehensive auditing for CPA firms, but is also a major breakthrough in auditing’s new environment. Applications of an AI-enabled auditing technique in external auditing can add to auditing efficiency, increase financial reporting accountability, ensure audit quality, and assist decision-makers in making reliable decisions. Strategies related to the adoption of an AI-enabled auditing technique by CPA firms cover the classical multiple criteria decision-making (MCDM) task (i.e., several perspectives/criteria must be considered). To address this critical task, the present study proposes a fusion multiple rule-based decision making (MRDM) model that integrates rule-based technique (i.e., the fuzzy rough set theory (FRST) with ant colony optimization (ACO)) into MCDM techniques that can assist decision makers in selecting the best methods necessary to achieve the aspired goals of audit success. We also consider potential implications for articulating suitable strategies that can improve the adoption of AI-enabled auditing techniques and that target continuous improvement and sustainable development.","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",105,"2022-07-13 09:35:20","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
6,"N. Elkin-Koren","Contesting algorithms: Restoring the public interest in content filtering by artificial intelligence",2020,"","","","",106,"2022-07-13 09:35:20","","10.1177/2053951720932296","","",,,,,6,3.00,6,1,2,"In recent years, artificial intelligence has been deployed by online platforms to prevent the upload of allegedly illegal content or to remove unwarranted expressions. These systems are trained to spot objectionable content and to remove it, block it, or filter it out before it is even uploaded. Artificial intelligence filters offer a robust approach to content moderation which is shaping the public sphere. This dramatic shift in norm setting and law enforcement is potentially game-changing for democracy. Artificial intelligence filters carry censorial power, which could bypass traditional checks and balances secured by law. Their opaque and dynamic nature creates barriers to oversight, and conceals critical value choices and tradeoffs. Currently, we lack adequate tools to hold them accountable. This paper seeks to address this gap by introducing an adversarial procedure— – Contesting Algorithms. It proposes to deliberately introduce friction into the dominant removal systems governed by artificial intelligence. Algorithmic content moderation often seeks to optimize a single goal, such as removing copyright-infringing materials or blocking hate speech, while other values in the public interest, such as fair use or free speech, are often neglected. Contesting algorithms introduce an adversarial design which reflects conflicting values, and thereby may offer a check on dominant removal systems. Facilitating an adversarial intervention may promote democratic principles by keeping society in the loop. An adversarial public artificial intelligence system could enhance dynamic transparency, facilitate an alternative public articulation of social values using machine learning systems, and restore societal power to deliberate and determine social tradeoffs.","",""
11,"R. Aldrich, Daniela Richterova","Ambient accountability: intelligence services in Europe and the decline of state secrecy",2018,"","","","",107,"2022-07-13 09:35:20","","10.1080/01402382.2017.1415780","","",,,,,11,2.75,6,2,4,"Abstract In the 1990s, judgments in the European Court of Human Rights concerning state surveillance forced many West European countries to introduce new parliamentary bodies and formal systems for accountability. Promising both greater transparency and lawful intelligence, these frameworks were then energetically rolled out to Central and Eastern Europe. Although officials boasted about their effectiveness, these formal accountability mechanisms have failed to identify serious abuses over the last decade. Moreover, the security regime in much of Central Europe still remains largely unreconstructed. The article argues that a robust culture of accountability cannot be conjured into existence merely by introducing new laws and regulations, or indeed by the increasing tide of media revelations about intelligence. However, it suggests that we are now seeing the rise of a more complex pattern of ‘ambient accountability’ which is at last challenging the secret state across Europe.","",""
2,"E. Kazim, Adriano Soares Koshiyama","No AI Regulator: An Analysis of Artificial Intelligence and Public Standards Report (UK Government)",2020,"","","","",108,"2022-07-13 09:35:20","","10.2139/ssrn.3544871","","",,,,,2,1.00,1,2,2,"The Committee on Standards in Public Life has recently published (February 2020) a review on ‘Artificial Intelligence and Public Standards’. Chaired by Lord Evans of Weardale KCB DL, the report takes a thorough look at the use of AI in public service through the framework of the Nolan Principles (Selflessness, Integrity, Objectivity, Accountability, Openness, Honestly, and Leadership). This paper briefly comments upon and analyses selections form the publication by surveying the recommendations.","",""
2,"Dr. Uma Devi, Maria Tresita, V. Paul","Artificial Intelligence: Pertinence in Supply Chain and Logistics Management",2020,"","","","",109,"2022-07-13 09:35:20","","","","",,,,,2,1.00,1,3,2,"-Artificial Intelligence (AI) is the revolutionary invention of human intelligence. Artificial Intelligence is nothing but the duplication of human in which machines are programmed to rationally think and behave like humans developed for very many purposes including business decision making, problem-solving, business data analysis and interpretation and information management. The application of AI in business endeavours decides the competitive advantage, market leadership, robust operating efficiency of corporates and other business houses. Exploiting the application of AI in the manufacturing and distribution process enables the organisations to reach the pinnacle in their business graph. Businesses are operating in the international market which is highly multifaceted and challenging to serve the world as a sole market for their products, services and their products and without the integration of technology into their business processes, they cannot assure the sustainable growth. The management of the process of transforming the raw materials into the final product is called Supply Chain Management (SCM) and the effective movement and storage of goods, services and information are called Logistics Management (LM). This article analyses the applications of Artificial Intelligence in Supply Chain and Logistics Management (SC&LM) Keywords--Artificial Intelligence, Supply Chain Management, Logistics Management, Supply Chain Profitability","",""
4,"Diogo M. F. Mattos, F. Krief, S. Rueda","Blockchain and artificial intelligence for network security",2020,"","","","",110,"2022-07-13 09:35:20","","10.1007/s12243-020-00754-7","","",,,,,4,2.00,1,3,2,"","",""
4,"Niels van Berkel, Benjamin Tag, Jorge Gonçalves, S. Hosio","Human-centred artificial intelligence: a contextual morality perspective",2020,"","","","",111,"2022-07-13 09:35:20","","10.1080/0144929X.2020.1818828","","",,,,,4,2.00,1,4,2,"ABSTRACT The emergence of big data combined with the technical developments in Artificial Intelligence has enabled novel opportunities for autonomous and continuous decision support. While initial work has begun to explore how human morality can inform the decision making of future Artificial Intelligence applications, these approaches typically consider human morals as static and immutable. In this work, we present an initial exploration of the effect of context on human morality from a Utilitarian perspective. Through an online narrative transportation study, in which participants are primed with either a positive story, a negative story or a control condition (N = 82), we collect participants' perceptions on technology that has to deal with moral judgment in changing contexts. Based on an in-depth qualitative analysis of participant responses, we contrast participant perceptions to related work on Fairness, Accountability and Transparency. Our work highlights the importance of contextual morality for Artificial Intelligence and identifies opportunities for future work through a FACT-based (Fairness, Accountability, Context and Transparency) perspective.","",""
2,"M. Rohaim, E. Clayton, I. Sahin, J. Vilela, M. Khalifa, M. Al-Natour, M. Bayoumi, A. Poirier, M. Branavan, M. Tharmakulasingam, N. S. Chaudhry, R. Sodi, A. Brown, P. Burkhart, W. Hacking, J. Botham, J. Boyce, H. Wilkinson, C. Williams, M. Bates, R. Laragione, W. Balachandran, A. Fernando, M. Munir","Artificial Intelligence-Assisted Loop Mediated Isothermal Amplification (ai-LAMP) for Rapid and Reliable Detection of SARS-CoV-2",2020,"","","","",112,"2022-07-13 09:35:20","","10.1101/2020.07.08.20148999","","",,,,,2,1.00,0,24,2,"Until vaccines and effective therapeutics become available, the practical way to transit safely out of the current lockdown may include the implementation of an effective testing, tracing and tracking system. However, this requires a reliable and clinically validated diagnostic platform for the sensitive and specific identification of SARS-CoV-2. Here, we report on the development of a de novo, high-resolution and comparative genomics guided reverse-transcribed loop-mediated isothermal amplification (LAMP) assay. To further enhance the assay performance and to remove any subjectivity associated with operator interpretation of result, we engineered a novel hand-held smart diagnostic device. The robust diagnostic device was further furnished with automated image acquisition and processing algorithms, and the collated data was processed through artificial intelligence (AI) pipelines to further reduce the assay run time and the subjectivity of the colorimetric LAMP detection. This advanced AI algorithm-implemented LAMP (ai-LAMP) assay, targeting the RNA-dependent RNA polymerase gene, showed high analytical sensitivity and specificity for SARS-CoV-2. A total of ~200 coronavirus disease (CoVID-19)-suspected patient samples were tested using the platform and it was shown to be reliable, highly specific and significantly more sensitive than the current gold standard qRT-PCR. The system could provide an efficient and cost-effective platform to detect SARS-CoV-2 in resource-limited laboratories.","",""
2,"T. Miller, Rosina O. Weber, D. Magazzeni","Report on the 2019 International Joint Conferences on Artificial Intelligence Explainable Artificial Intelligence Workshop",2020,"","","","",113,"2022-07-13 09:35:20","","","","",,,,,2,1.00,1,3,2,"Copyright © 2020, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 Spring 2020 103 As artificial intelligence (Ai) becomes more ubiquitous, complex, and consequential, the need for people to understand how decisions are made and to judge their correctness becomes increasingly crucial due to concerns of ethics, accountability, and trust. The field of explainable Ai (XAi) aims to address this problem by designing Ai whose decisions can be understood by humans. The workshops in XAi have been receiving growing interest. The 2019 international Joint Conferences on Artificial intelligence’s Explainable Artificial intelligence workshop attracted 163 registered attendees, following the tradition of being the largest international Joint Conferences on Artificial intelligence workshop since 2017.  This article reports on the Explainable Artificial Intelligence Workshop, held within the International Joint Conferences on Artificial Intelligence 2019 Workshop Program in Macau, August 11, 2019. With over 160 registered attendees, the workshop was the largest workshop at the conference. It featured an invited talk and 23 oral presentations, and closed with an audience discussion about where explainable artificial intelligence research stands. Report on the 2019 International Joint Conferences on Artificial Intelligence Explainable Artificial Intelligence Workshop","",""
2,"Carlos E. Jimenez-Gomez, Jesús Cano Carrillo, F. Falcone","Artificial Intelligence in Government",2020,"","","","",114,"2022-07-13 09:35:20","","10.1109/MC.2020.3010043","","",,,,,2,1.00,1,3,2,"The articles in this special section focus on government applications that use artificial intelligence (AI). The repercussions of artificial intelligence (AI) in government are broad and significant. The characteristics of these technologies will have an impact on almost everything in public organizations, from governance or the multidimensional perspective of interoperability, to the organizational or social implications linked to concepts like public value, transparency, or accountability. This special issue seeks to shed light on foundations and key elements to be taken into account for AI adoption by public organizations. Governments are the primary enablers of technology and market stimulators and regulators of general activities in our society. Governments have always sought the common good and, therefore, the advancement of public and collective interests. This is key to understanding, as a first step, why the principles of public-sector organizations do not always match those of the private sector. Public and private perspectives are very different, whether they be management, strategy, or policy.","",""
6,"","Artificial intelligence: From ethics to policy",2020,"","","","",115,"2022-07-13 09:35:20","","","","",,,,,6,3.00,0,0,2,"Based on a framing of 'AI as a social experiment,' this study arrives at regulatory options for public administrations and governmental organisations who are looking to deploy AI/ML solutions, as well as the private companies who are creating AI/ML solutions for use in the public arena. The reasons for targeting this application sector concern: the need for a high standard of transparency, respect for democratic values, and legitimacy. The policy options presented in the study demand targeted procedural solutions. Together, these chart a path towards accountability in AI; procedures and decisions of an ethical nature are systematically logged prior to the deployment of an AI system. This logging is the first step in allowing ethics to play a formidable role in the implementation of AI for the public good.","",""
496,"Christopher J. Kelly, A. Karthikesalingam, Mustafa Suleyman, Greg Corrado, Dominic King","Key challenges for delivering clinical impact with artificial intelligence",2019,"","","","",116,"2022-07-13 09:35:20","","10.1186/s12916-019-1426-2","","",,,,,496,165.33,99,5,3,"","",""
1,"S. Weiner, Melissa McMahan","Action Taking Augmented by Artificial Intelligence",2020,"","","","",117,"2022-07-13 09:35:20","","10.1093/oso/9780190939717.003.0021","","",,,,,1,0.50,1,2,2,"Taking action is unequivocally the most important aspect of any employee survey program. Many organizations struggle to achieve adoption and accountability and, in turn, to realize meaningful change. In our rapid-cycle economy, organizations need solutions to nimbly respond to the changing expectations and needs of customers, employees, and managers. Advances in the use of artificial intelligence (AI) have the power to be a game changer if coupled with evidence-based and forward-thinking industrial and organizational psychology practices. We propose an action-taking approach summarized as take action that matters, communicate, and repeat frequently. AI has greatly facilitated our ability to quickly determine the actions that will matter most and empower managers and employees toward real-time action taking. AI can deliver real-time prescriptive and predictive analytics, provide greater insights and guidance to managers, leverage natural language processing, and free human resources departments to focus on coaching and systemic issues, which together drive agile practices to achieve meaningful change.","",""
1,"Al Naqvi","Artificial Intelligence for Audit, Forensic Accounting, and Valuation",2020,"","","","",118,"2022-07-13 09:35:20","","10.1002/9781119601906","","",,,,,1,0.50,1,1,2,"This book examines current topics and trends in strategic auditing, accounting and finance in digital transformation both from a theoretical and practical perspective. It covers areas such as internal control, corporate governance, enterprise risk management, sustainability and competition. The contributors of this volume emphasize how strategic approaches in this area help companies in achieving targets. The contributions illustrate how by providing good governance, reliable financial reporting, and accountability, businesses can win a competitive advantage. It further discusses how new technological developments like artificial intelligence (AI), cybersystems, network technologies, financial mobility and smart applications, will shape the future of accounting and auditing for firms.?","",""
54,"G. Collins, P. Dhiman, Constanza L. Andaur Navarro, Jie Ma, L. Hooft, J. Reitsma, P. Logullo, Andrew Beam, Lily Peng, B. van Calster, M. van Smeden, R. Riley, K. Moons","Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",2021,"","","","",119,"2022-07-13 09:35:20","","10.1136/bmjopen-2020-048008","","",,,,,54,54.00,5,13,1,"Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.","",""
47,"L. Faes, B. Geerts, Xiaoxuan Liu, L. Morgan, P. Watkinson, P. McCulloch","DECIDE-AI: new reporting guidelines to bridge the development-to-implementation gap in clinical artificial intelligence.",2021,"","","","",120,"2022-07-13 09:35:20","","10.1038/s41591-021-01229-5","","",,,,,47,47.00,8,6,1,"","",""
4,"Bahman Zohuri","From Business Intelligence to Artificial Intelligence",2020,"","","","",121,"2022-07-13 09:35:20","","10.32474/MAMS.2020.02.000137","","",,,,,4,2.00,4,1,2,"With today’s growing information and overloading of its volume based on tremendous size of data growing to the level of big data, Business Intelligence (BI) is not enough to handle any day-to-day business operation of any enterprises. It is becoming tremendously difficult to analyze the huge amounts of data that contain the information and makes it very strenuous and inconvenient to introduce an appropriate methodology of decision-making fast enough to the point that it can be, considered as real time, a methodology that we used to call it BI. The demand for real time processing information and related data both structured and unstructured is on the rise and consequently makes it harder and harder to implement correct decision making at enterprise level that was driven by BI, in order to keep the organization robust and resilient against either man made threats or natural disasters. With smart malware in modern computation world and necessity for Internet-of-Things (IoT), we are in need of a better intelligence system that today we know it as Artificial Intelligence (AI). AI with its two other subset that are called Machine Learning (ML) and Deep Learning (DL), we have a better chance against any cyber-attack and makes our day-to-day operation within our organization a more robust one as well makes our decision making as stakeholder more trust worthy one as well.","",""
5,"Lindong Zhao, Xuguang Zhang, Jianxin Chen, Liang Zhou","Physical Layer Security in the Age of Artificial Intelligence and Edge Computing",2020,"","","","",122,"2022-07-13 09:35:20","","10.1109/MWC.001.2000044","","",,,,,5,2.50,1,4,2,"Physical layer security (PLS) is emerging as an attractive security paradigm to complement or even replace complex cryptography. Although information-theoretical transmission optimization and physical-layer key generation have been thoroughly researched, there still exist many critical issues to be tackled before PLS is extensively applied. In this article, we investigate the prospect for exploiting artificial intelligent (AI) and edge computing (EC) to facilitate the practical application of PLS. First, two outstanding challenges facing PLS designers are identified by analyzing the fundamental assumptions regarding eavesdroppers and wireless channels. Accordingly, two enhancement schemes are designed by reaping the benefits offered by AI and EC. Specifically, a novel secure resource management framework is developed to enhance the adaptability of an optimization-based PLS paradigm, and a robust physical-layer key generation method is designed to cope with reciprocity failure. Finally, we discuss a coordinated defense architecture with multi-layer, multi-domain, and multi-dimension, which is expected to exploit the compatibility and complementarity of the existing PLS methods.","",""
0,"Katanosh Morovat, B. Panda","A Survey of Artificial Intelligence in Cybersecurity",2020,"","","","",123,"2022-07-13 09:35:20","","10.1109/CSCI51800.2020.00026","","",,,,,0,0.00,0,2,2,"During the last decades, not only the number of cyberattacks have increased significantly, they have also become more sophisticated. Hence designing a cyber-resilient approach is of paramount importance. Traditional security methods are not adequate to prevent data breaches in case of cyberattacks. Cybercriminals have learned how to use new techniques and robust tools to hack, attack, and breach data. Fortunately, Artificial Intelligence (AI) technologies have been introduced into cyberspace to construct smart models for defending systems from attacks. Since AI technologies can rapidly evolve to address complex situations, they can be used as fundamental tools in the field of cybersecurity. Al-based techniques can provide efficient and powerful cyber defense tools to recognize malware attacks, network intrusions, phishing and spam emails, and data breaches, to name a few, and to alert security incidents when they occur. In this paper, we review the impact of AI in cybersecurity and summarize existing research in terms of benefits of AI in cybersecurity.","",""
17,"Shengjie Xu, Y. Qian, R. Hu","Data-Driven Edge Intelligence for Robust Network Anomaly Detection",2020,"","","","",124,"2022-07-13 09:35:20","","10.1109/TNSE.2019.2936466","","",,,,,17,8.50,6,3,2,"The advancement of networking platforms for assured online services requires robust and effective network intelligence systems against anomalous events and malicious threats. With the rapid development of modern communication technologies, artificial intelligence, and the revolution of computing devices, cloud computing empowered network intelligence will inevitably become a core platform for various smart applications. While cloud computing provides strong and powerful computation, storage, and networking services to detect and defend cyber threats, edge computing on the other hand will deliver more benefits in specific yet potential critical areas. In this paper, we present a study on the data-driven edge intelligence for robust network anomaly detection. We first highlight the main motivations for edge intelligence, and then propose an intelligence system empowered by edge computing for network anomaly detection. We further propose a scheme on the data-driven robust network anomaly detection. In the proposed scheme, four phases are designed to incorporate with data-driven approaches to train a learning model which is able to detect and identify a network anomaly in a robust way. In the performance evaluations with data experiments, we demonstrate that the proposed scheme achieves the robustness of trained model and the efficiency on the detection of specific anomalies.","",""
21,"Adrien Bécue, Isabel Praça, J. Gama","Artificial intelligence, cyber-threats and Industry 4.0: challenges and opportunities",2021,"","","","",125,"2022-07-13 09:35:20","","10.1007/S10462-020-09942-2","","",,,,,21,21.00,7,3,1,"","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",126,"2022-07-13 09:35:20","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
20,"Hong Zhang, Hoang Nguyen, X. Bui, B. Pradhan, P. Asteris, R. Costache, J. Aryal","A generalized artificial intelligence model for estimating the friction angle of clays in evaluating slope stability using a deep neural network and Harris Hawks optimization algorithm",2021,"","","","",127,"2022-07-13 09:35:20","","10.1007/S00366-020-01272-9","","",,,,,20,20.00,3,7,1,"","",""
26,"Kathleen Murphy, E. Di Ruggiero, Ross Upshur, D. Willison, N. Malhotra, J. Cai, Nakul Malhotra, Vincci Lui, J. Gibson","Artificial intelligence for good health: a scoping review of the ethics literature",2020,"","","","",128,"2022-07-13 09:35:20","","10.1186/s12910-021-00577-8","","",,,,,26,13.00,3,9,2,"","",""
15,"Aleksandre Asatiani, P. Malo, Per Rådberg Nagbøl, Esko Penttinen, Tapani Rinta-Kahila, Antti Salovaara","Sociotechnical Envelopment of Artificial Intelligence: An Approach to Organizational Deployment of Inscrutable Artificial Intelligence Systems",2021,"","","","",129,"2022-07-13 09:35:20","","10.17705/1JAIS.00664","","",,,,,15,15.00,3,6,1,"The paper presents an approach for implementing inscrutable (i.e., nonexplainable) artificial intelligence (AI) such as neural networks in an accountable and safe manner in organizational settings. Drawing on an exploratory case study and the recently proposed concept of envelopment, it describes a case of an organization successfully “enveloping” its AI solutions to balance the performance benefits of flexible AI models with the risks that inscrutable models can entail. The authors present several envelopment methods—establishing clear boundaries within which the AI is to interact with its surroundings, choosing and curating the training data well, and appropriately managing input and output sources—alongside their influence on the choice of AI models within the organization. This work makes two key contributions: It introduces the concept of sociotechnical envelopment by demonstrating the ways in which an organization’s successful AI envelopment depends on the interaction of social and technical factors, thus extending the literature’s focus beyond mere technical issues. Secondly, the empirical examples illustrate how operationalizing a sociotechnical envelopment enables an organization to manage the trade-off between low explainability and high performance presented by inscrutable models. These contributions pave the way for more responsible, accountable AI implementations in organizations, whereby humans can gain better control of even inscrutable machine-learning models.","",""
19,"Ruhhee Tabbussum, A. Q. Dar","Performance evaluation of artificial intelligence paradigms—artificial neural networks, fuzzy logic, and adaptive neuro-fuzzy inference system for flood prediction",2021,"","","","",130,"2022-07-13 09:35:20","","10.1007/s11356-021-12410-1","","",,,,,19,19.00,10,2,1,"","",""
15,"S. Ebrahimian, Fatemeh Homayounieh, M. Rockenbach, Preetham Putha, T. Raj, I. Dayan, B. Bizzo, Varun Buch, Dufan Wu, Kyungsang Kim, Quanzheng Li, S. Digumarthy, M. Kalra","Artificial intelligence matches subjective severity assessment of pneumonia for prediction of patient outcome and need for mechanical ventilation: a cohort study",2021,"","","","",131,"2022-07-13 09:35:20","","10.1038/s41598-020-79470-0","","",,,,,15,15.00,2,13,1,"","",""
21,"Radhia Garraoui, M. Hamed, L. Sbita","Comparison of MPPT algorithms for DC-DC boost converters based PV systems using robust control technique and artificial intelligence algorithm",2015,"","","","",132,"2022-07-13 09:35:20","","10.1109/SSD.2015.7348163","","",,,,,21,3.00,7,3,7,"This paper proposes two methods of maximum power point tracking algorithm for photovoltaic systems, based on the first hand on fuzzy logic control and on the other hand on the first order sliding mode control. According to the nonlinear characteristic of photovoltaic array, it's necessary to find a solution to track the maximum power of the PV system in order to improve its efficiency. The fuzzy logic controller was presented in many works. It provides fast response and good performance against the climatic and load change and uses directly the DC/DC converter duty cycle as a control parameter. Moreover, the sliding mode control approach is recognized as one of the efficient tools to design robust controllers it has been receiving much more attention within the last two decades and many research are dealing with this type of robust controllers. A detailed comparison between the fuzzy logic and slinging mode controllers was presented in this work. Simulation results show that the proposed algorithms can effectively improve the efficiency of a photovoltaic array output.","",""
5,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: A Sensible Artificial Intelligence That Plays with Handicap and Targets High Scores in 9×9 Go",2020,"","","","",133,"2022-07-13 09:35:20","","10.3233/FAIA200119","","",,,,,5,2.50,1,6,2,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9×9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
755,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xisheng Fang, Shiqin Zhang, J. Xia, Jun Xia","Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT",2020,"","","","",134,"2022-07-13 09:35:20","","10.1148/radiol.2020200905","","",,,,,755,377.50,76,18,2,"Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","",""
155,"Prasanna Tambe, P. Cappelli, V. Yakubovich","Artificial Intelligence in Human Resources Management: Challenges and a Path Forward",2019,"","","","",135,"2022-07-13 09:35:20","","10.1177/0008125619867910","","",,,,,155,51.67,52,3,3,"There is a substantial gap between the promise and reality of artificial intelligence in human resource (HR) management. This article identifies four challenges in using data science techniques for HR tasks: complexity of HR phenomena, constraints imposed by small data sets, accountability questions associated with fairness and other ethical and legal constraints, and possible adverse employee reactions to management decisions via data-based algorithms. It then proposes practical responses to these challenges based on three overlapping principles—causal reasoning, randomization and experiments, and employee contribution—that would be both economically efficient and socially appropriate for using data science in the management of employees.","",""
99,"R. Colling, Helen Pitman, K. Oien, N. Rajpoot, P. Macklin, D. Snead, Tony Sackville, C. Verrill","Artificial intelligence in digital pathology: a roadmap to routine use in clinical practice",2019,"","","","",136,"2022-07-13 09:35:20","","10.1002/path.5310","","",,,,,99,33.00,12,8,3,"The use of artificial intelligence will transform clinical practice over the next decade and the early impact of this will likely be the integration of image analysis and machine learning into routine histopathology. In the UK and around the world, a digital revolution is transforming the reporting practice of diagnostic histopathology and this has sparked a proliferation of image analysis software tools. While this is an exciting development that could discover novel predictive clinical information and potentially address international pathology workforce shortages, there is a clear need for a robust and evidence‐based framework in which to develop these new tools in a collaborative manner that meets regulatory approval. With these issues in mind, the NCRI Cellular Molecular Pathology (CM‐Path) initiative and the British In Vitro Diagnostics Association (BIVDA) have set out a roadmap to help academia, industry, and clinicians develop new software tools to the point of approved clinical use. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.","",""
15,"J. Janet, Chenru Duan, A. Nandy, Fang Liu, H. Kulik","Navigating Transition-Metal Chemical Space: Artificial Intelligence for First-Principles Design.",2021,"","","","",137,"2022-07-13 09:35:20","","10.1021/acs.accounts.0c00686","","",,,,,15,15.00,3,5,1,"ConspectusThe variability of chemical bonding in open-shell transition-metal complexes not only motivates their study as functional materials and catalysts but also challenges conventional computational modeling tools. Here, tailoring ligand chemistry can alter preferred spin or oxidation states as well as electronic structure properties and reactivity, creating vast regions of chemical space to explore when designing new materials atom by atom. Although first-principles density functional theory (DFT) remains the workhorse of computational chemistry in mechanism deduction and property prediction, it is of limited use here. DFT is both far too computationally costly for widespread exploration of transition-metal chemical space and also prone to inaccuracies that limit its predictive performance for localized d electrons in transition-metal complexes. These challenges starkly contrast with the well-trodden regions of small-organic-molecule chemical space, where the analytical forms of molecular mechanics force fields and semiempirical theories have for decades accelerated the discovery of new molecules, accurate DFT functional performance has been demonstrated, and gold-standard methods from correlated wavefunction theory can predict experimental results to chemical accuracy.The combined promise of transition-metal chemical space exploration and lack of established tools has mandated a distinct approach. In this Account, we outline the path we charted in exploration of transition-metal chemical space starting from the first machine learning (ML) models (i.e., artificial neural network and kernel ridge regression) and representations for the prediction of open-shell transition-metal complex properties. The distinct importance of the immediate coordination environment of the metal center as well as the lack of low-level methods to accurately predict structural properties in this coordination environment first motivated and then benefited from these ML models and representations. Once developed, the recipe for prediction of geometric, spin state, and redox potential properties was straightforwardly extended to a diverse range of other properties, including in catalysis, computational ""feasibility"", and the gas separation properties of periodic metal-organic frameworks. Interpretation of selected features most important for model prediction revealed new ways to encapsulate design rules and confirmed that models were robustly mapping essential structure-property relationships. Encountering the special challenge of ensuring that good model performance could generalize to new discovery targets motivated investigation of how to best carry out model uncertainty quantification. Distance-based approaches, whether in model latent space or in carefully engineered feature space, provided intuitive measures of the domain of applicability. With all of these pieces together, ML can be harnessed as an engine to tackle the large-scale exploration of transition-metal chemical space needed to satisfy multiple objectives using efficient global optimization methods. In practical terms, bringing these artificial intelligence tools to bear on the problems of transition-metal chemical space exploration has resulted in ML-model assessments of large, multimillion compound spaces in minutes and validated new design leads in weeks instead of decades.","",""
93,"Mark O. Riedl","Human-Centered Artificial Intelligence and Machine Learning",2019,"","","","",138,"2022-07-13 09:35:20","","10.1002/HBE2.117","","",,,,,93,31.00,93,1,3,"Humans are increasingly coming into contact with artificial intelligence and machine learning systems. Human-centered artificial intelligence is a perspective on AI and ML that algorithms must be designed with awareness that they are part of a larger system consisting of humans. We lay forth an argument that human-centered artificial intelligence can be broken down into two aspects: (1) AI systems that understand humans from a sociocultural perspective, and (2) AI systems that help humans understand them. We further argue that issues of social responsibility such as fairness, accountability, interpretability, and transparency.","",""
85,"A. Grzybowski, Piotr Brona, Gilbert Lim, P. Ruamviboonsuk, G. Tan, M. Abràmoff, D. Ting","Artificial intelligence for diabetic retinopathy screening: a review",2019,"","","","",139,"2022-07-13 09:35:20","","10.1038/s41433-019-0566-0","","",,,,,85,28.33,12,7,3,"","",""
73,"Valentina Bellemo, Gilbert Lim, T. Rim, G. Tan, C. Cheung, S. Sadda, M. He, A. Tufail, M. Lee, W. Hsu, D. Ting","Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application",2019,"","","","",140,"2022-07-13 09:35:20","","10.1007/s11892-019-1189-3","","",,,,,73,24.33,7,11,3,"","",""
67,"Yonghui Shang, Hoang Nguyen, X. Bui, Quang-Hieu Tran, H. Moayedi","A Novel Artificial Intelligence Approach to Predict Blast-Induced Ground Vibration in Open-Pit Mines Based on the Firefly Algorithm and Artificial Neural Network",2019,"","","","",141,"2022-07-13 09:35:20","","10.1007/s11053-019-09503-7","","",,,,,67,22.33,13,5,3,"","",""
51,"Xiaohang Wu, Yelin Huang, Zhenzhen Liu, Weiyi Lai, Erping Long, Kai Zhang, Jiewei Jiang, Duoru Lin, Kexin Chen, Tongyong Yu, Dongxuan Wu, Cong Li, Yanyi Chen, Minjie Zou, Chuan Chen, Yi Zhu, Chong Guo, Xiayin Zhang, Ruixin Wang, Yahan Yang, Yifan Xiang, Lijian Chen, Congxin Liu, J. Xiong, Z. Ge, Ding-ding Wang, Guihua Xu, Shao-lin Du, Chi Xiao, Jianghao Wu, Ke Zhu, Dan-yao Nie, Fan Xu, Jian Lv, Weirong Chen, Yizhi Liu, Haotian Lin","Universal artificial intelligence platform for collaborative management of cataracts",2019,"","","","",142,"2022-07-13 09:35:20","","10.1136/bjophthalmol-2019-314729","","",,,,,51,17.00,5,37,3,"Purpose To establish and validate a universal artificial intelligence (AI) platform for collaborative management of cataracts involving multilevel clinical scenarios and explored an AI-based medical referral pattern to improve collaborative efficiency and resource coverage. Methods The training and validation datasets were derived from the Chinese Medical Alliance for Artificial Intelligence, covering multilevel healthcare facilities and capture modes. The datasets were labelled using a three-step strategy: (1) capture mode recognition; (2) cataract diagnosis as a normal lens, cataract or a postoperative eye and (3) detection of referable cataracts with respect to aetiology and severity. Moreover, we integrated the cataract AI agent with a real-world multilevel referral pattern involving self-monitoring at home, primary healthcare and specialised hospital services. Results The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance in three-step tasks: (1) capture mode recognition (area under the curve (AUC) 99.28%–99.71%), (2) cataract diagnosis (normal lens, cataract or postoperative eye with AUCs of 99.82%, 99.96% and 99.93% for mydriatic-slit lamp mode and AUCs >99% for other capture modes) and (3) detection of referable cataracts (AUCs >91% in all tests). In the real-world tertiary referral pattern, the agent suggested 30.3% of people be ‘referred’, substantially increasing the ophthalmologist-to-population service ratio by 10.2-fold compared with the traditional pattern. Conclusions The universal AI platform and multilevel collaborative pattern showed robust diagnostic performance and effective service for cataracts. The context of our AI-based medical referral pattern will be extended to other common disease conditions and resource-intensive situations.","",""
47,"T. Phong, Trong Trinh Phan, Indra Prakash, S. Singh, A. Shirzadi, K. Chapi, H. Ly, Lanh Si Ho, Nguyen Kim Quoc, B. Pham","Landslide susceptibility modeling using different artificial intelligence methods: a case study at Muong Lay district, Vietnam",2019,"","","","",143,"2022-07-13 09:35:20","","10.1080/10106049.2019.1665715","","",,,,,47,15.67,5,10,3,"Abstract Landslide is a natural hazard which causes huge loss of properties and human life in many places of the world. Mapping of landslide susceptibility is an important task for preventing and combating the landslides problems. Main objective of this study is to use different artificial intelligence methods namely support vector machines (SVM), artificial neural networks (ANN), logistic regression (LR), and reduced error-pruning tree (REPT) in the development of models for landslide susceptibility mapping of Muong Lay district of Vietnam. In total data of 217 landslide locations of the study area was used for the development and evaluation of the models. Nine landslide-conditioning factors were used for generating the datasets for training and validating the models. Results show that the SVM outperformed all other methods namely ANN, LR and REPT. Thus, it can be suggested that the SVM method is more useful in developing accurate and robust landslide prediction model.","",""
41,"Y. Ongena, M. Haan, Derya Yakar, T. Kwee","Patients’ views on the implementation of artificial intelligence in radiology: development and validation of a standardized questionnaire",2019,"","","","",144,"2022-07-13 09:35:20","","10.1007/s00330-019-06486-0","","",,,,,41,13.67,10,4,3,"","",""
0,"O. Lehner, Kim Ittonen, H. Silvola, E. Ström, Alena Wührleitner","Artificial intelligence based decision-making in accounting and auditing: ethical challenges and normative thinking",2022,"","","","",145,"2022-07-13 09:35:20","","10.1108/aaaj-09-2020-4934","","",,,,,0,0.00,0,5,1,"PurposeThis paper aims to identify ethical challenges of using artificial intelligence (AI)-based accounting systems for decision-making and discusses its findings based on Rest's four-component model of antecedents for ethical decision-making. This study derives implications for accounting and auditing scholars and practitioners.Design/methodology/approachThis research is rooted in the hermeneutics tradition of interpretative accounting research, in which the reader and the texts engage in a form of dialogue. To substantiate this dialogue, the authors conduct a theoretically informed, narrative (semi-systematic) literature review spanning the years 2015–2020. This review's narrative is driven by the depicted contexts and the accounting/auditing practices found in selected articles are used as sample instead of the research or methods.FindingsIn the thematic coding of the selected papers the authors identify five major ethical challenges of AI-based decision-making in accounting: objectivity, privacy, transparency, accountability and trustworthiness. Using Rest's component model of antecedents for ethical decision-making as a stable framework for our structure, the authors critically discuss the challenges and their relevance for a future human–machine collaboration within varying agency between humans and AI.Originality/valueThis paper contributes to the literature on accounting as a subjectivising as well as mediating practice in a socio-material context. It does so by providing a solid base of arguments that AI alone, despite its enabling and mediating role in accounting, cannot make ethical accounting decisions because it lacks the necessary preconditions in terms of Rest's model of antecedents. What is more, as AI is bound to pre-set goals and subjected to human made conditions despite its autonomous learning and adaptive practices, it lacks true agency. As a consequence, accountability needs to be shared between humans and AI. The authors suggest that related governance as well as internal and external auditing processes need to be adapted in terms of skills and awareness to ensure an ethical AI-based decision-making.","",""
32,"Matt Taddy","The Technological Elements of Artificial Intelligence",2018,"","","","",146,"2022-07-13 09:35:20","","10.3386/W24301","","",,,,,32,8.00,32,1,4,"We have seen in the past decade a sharp increase in the extent that companies use data to optimize their businesses. Variously called the `Big Data' or `Data Science' revolution, this has been characterized by massive amounts of data, including unstructured and nontraditional data like text and images, and the use of fast and flexible Machine Learning (ML) algorithms in analysis. With recent improvements in Deep Neural Networks (DNNs) and related methods, application of high-performance ML algorithms has become more automatic and robust to different data scenarios. That has led to the rapid rise of an Artificial Intelligence (AI) that works by combining many ML algorithms together – each targeting a straightforward prediction task – to solve complex problems. We will define a framework for thinking about the ingredients of this new ML-driven AI. Having an understanding of the pieces that make up these systems and how they fit together is important for those who will be building businesses around this technology. Those studying the economics of AI can use these definitions to remove ambiguity from the conversation on AI's projected productivity impacts and data requirements. Finally, this framework should help clarify the role for AI in the practice of modern business analytics and economic measurement.","",""
32,"Jun-Ho Huh, Yeong-Seok Seo","Understanding Edge Computing: Engineering Evolution With Artificial Intelligence",2019,"","","","",147,"2022-07-13 09:35:20","","10.1109/ACCESS.2019.2945338","","",,,,,32,10.67,16,2,3,"The key to the explosion of the Internet of Things and the ability to collect, analyze, and provide big data in the cloud is edge computing, which is a new computing paradigm in which data is processed from edges. Edge Computing has been attracting attention as one of the top 10 strategic technology trends in the past two years and has innovative potential. It provides shorter response times, lower bandwidth costs, and more robust data safety and privacy protection than cloud computing. In particular, artificial intelligence technologies are rapidly incorporating edge computing. In this paper, we introduce the concepts, backgrounds, and pros and cons of edge computing, explain how it operates and its structure hierarchically with artificial intelligence concepts, list examples of its applications in various fields, and finally suggest some improvements and discuss the challenges of its application in three representative technological fields. We intend to clarify various analyses and opinions regarding edge computing and artificial intelligence.","",""
29,"David Valle-Cruz, E. A. R. Gómez, Rodrigo Sandoval-Almazán, J. I. Criado","A Review of Artificial Intelligence in Government and its Potential from a Public Policy Perspective",2019,"","","","",148,"2022-07-13 09:35:20","","10.1145/3325112.3325242","","",,,,,29,9.67,7,4,3,"Artificial intelligence (AI) is the latest trend being implemented in the public sector. Recent advances in this field and the AI explosion in the private sector have served to promote a revolution for government, public service management, accountability, and public value. Incipient research to understand, conceptualize and express challenges and limitations is now ongoing. This paper is the first approach in such a direction; our research question is: What are the current AI trends in the public sector? In order to achieve that goal, we collected 78 papers related to this new field in recent years. We also used a public policy framework to identify future areas of implementation for this trend. We found that only normative and exploratory papers have been published so far and there are a lot of public policy challenges facing in this area, and that AI implementation results are unknown and unexpected; since there may be great benefits for governments and society, but, on the other hand, it may have negative results like the so-called ”algorithmic bias” of AI when making important decisions for social development. However, we consider that AI has potential benefits in the public health, public policies on climate change, public management, decision-making, disaster prevention and response, improving government-citizen interaction, personalization of services, interoperability, analyzing large amounts of data, detecting abnormalities and patterns, and discovering new solutions through dynamic models and simulation in real time.","",""
27,"E. Donahoe, M. Metzger","Artificial Intelligence and Human Rights",2019,"","","","",149,"2022-07-13 09:35:20","","10.1353/JOD.2019.0029","","",,,,,27,9.00,14,2,3,"Abstract:Rapid adoption of artificial intelligence (AI) technologies and increased reliance upon AI by both governments and the private sector have led to rising concern about potential negative implications for human dignity, democratic accountability, and the bedrock principles of free societies. We need a global governance framework to address the wide range of societal challenges associated with AI, including threats to privacy, information access, and the right to equal protection and nondiscrimination. Rather than working to develop new frameworks from scratch, we argue that the challenges associated with AI can best be confronted by drawing onthe existing international human-rights framework.","",""
0,"","A Novel Approach to Adopt Explainable Artificial Intelligence in X-ray Image Classification",2022,"","","","",150,"2022-07-13 09:35:20","","10.33140/amlai.03.01.01","","",,,,,0,0.00,0,0,1,"Robust “Blackbox” algorithms such as Convolutional Neural Networks (CNNs) are known for making high prediction performance. However, the ability to explain and interpret these algorithms still require innovation in the understanding of influential and, more importantly, explainable features that directly or indirectly impact the performance of predictivity. In view of the above needs, this study proposes an interaction- based methodology – Influence Score (I-score) – to screen out the noisy and non-informative variables in the images hence it nourishes an environment with explainable and interpretable features that are directly associated to feature predictivity. We apply the proposed method on a real-world application in Pneumonia Chest X-ray Image data set and produced state- of-the-art results. We demonstrate how to apply the proposed approach for more general big data problems by improving the explain ability and interpretability without sacrificing the prediction performance. The contribution of this paper opens a novel angle that moves the community closer to the future pipelines of XAI problems.","",""
6,"Davinder Kaur, Suleyman Uslu, Kaley J. Rittichier, A. Durresi","Trustworthy Artificial Intelligence: A Review",2022,"","","","",151,"2022-07-13 09:35:20","","10.1145/3491209","","",,,,,6,6.00,2,4,1,"Artificial intelligence (AI) and algorithmic decision making are having a profound impact on our daily lives. These systems are vastly used in different high-stakes applications like healthcare, business, government, education, and justice, moving us toward a more algorithmic society. However, despite so many advantages of these systems, they sometimes directly or indirectly cause harm to the users and society. Therefore, it has become essential to make these systems safe, reliable, and trustworthy. Several requirements, such as fairness, explainability, accountability, reliability, and acceptance, have been proposed in this direction to make these systems trustworthy. This survey analyzes all of these different requirements through the lens of the literature. It provides an overview of different approaches that can help mitigate AI risks and increase trust and acceptance of the systems by utilizing the users and society. It also discusses existing strategies for validating and verifying these systems and the current standardization efforts for trustworthy AI. Finally, we present a holistic view of the recent advancements in trustworthy AI to help the interested researchers grasp the crucial facets of the topic efficiently and offer possible future research directions.","",""
5,"Kimon Kieslich, Birte Keller, C. Starke","Artificial intelligence ethics by design. Evaluating public perception on the importance of ethical design principles of artificial intelligence",2021,"","","","",152,"2022-07-13 09:35:20","","10.1177/20539517221092956","","",,,,,5,5.00,2,3,1,"Despite the immense societal importance of ethically designing artificial intelligence, little research on the public perceptions of ethical artificial intelligence principles exists. This becomes even more striking when considering that ethical artificial intelligence development has the aim to be human-centric and of benefit for the whole society. In this study, we investigate how ethical principles (explainability, fairness, security, accountability, accuracy, privacy, and machine autonomy) are weighted in comparison to each other. This is especially important, since simultaneously considering ethical principles is not only costly, but sometimes even impossible, as developers must make specific trade-off decisions. In this paper, we give first answers on the relative importance of ethical principles given a specific use case—the use of artificial intelligence in tax fraud detection. The results of a large conjoint survey ( n = 1099 ) suggest that, by and large, German respondents evaluate the ethical principles as equally important. However, subsequent cluster analysis shows that different preference models for ethically designed systems exist among the German population. These clusters substantially differ not only in the preferred ethical principles but also in the importance levels of the principles themselves. We further describe how these groups are constituted in terms of sociodemographics as well as opinions on artificial intelligence. Societal implications, as well as design challenges, are discussed.","",""
22,"Rushikesh S. Joshi, Alexander F. Haddad, Darryl Lau, C. Ames","Artificial Intelligence for Adult Spinal Deformity",2019,"","","","",153,"2022-07-13 09:35:20","","10.14245/ns.1938414.207","","",,,,,22,7.33,6,4,3,"Adult spinal deformity (ASD) is a complex disease that significantly affects the lives of many patients. Surgical correction has proven to be effective in achieving improvement of spinopelvic parameters as well as improving quality of life (QoL) for these patients. However, given the relatively high complication risk associated with ASD correction, it is of paramount importance to develop robust prognostic tools for predicting risk profile and outcomes. Historically, statistical models such as linear and logistic regression models were used to identify preoperative factors associated with postoperative outcomes. While these tools were useful for looking at simple associations, they represent generalizations across large populations, with little applicability to individual patients. More recently, predictive analytics utilizing artificial intelligence (AI) through machine learning for comprehensive processing of large amounts of data have become available for surgeons to implement. The use of these computational techniques has given surgeons the ability to leverage far more accurate and individualized predictive tools to better inform individual patients regarding predicted outcomes after ASD correction surgery. Applications range from predicting QoL measures to predicting the risk of major complications, hospital readmission, and reoperation rates. In addition, AI has been used to create a novel classification system for ASD patients, which will help surgeons identify distinct patient subpopulations with unique risk-benefit profiles. Overall, these tools will help surgeons tailor their clinical practice to address patients’ individual needs and create an opportunity for personalized medicine within spine surgery.","",""
21,"D. Ting, M. Ang, J. Mehta, D. Ting","Artificial intelligence-assisted telemedicine platform for cataract screening and management: a potential model of care for global eye health",2019,"","","","",154,"2022-07-13 09:35:20","","10.1136/bjophthalmol-2019-315025","","",,,,,21,7.00,5,4,3,"Artificial intelligence (AI) is the fourth industrial revolution.1 Deep learning is a robust machine learning technique that uses convolutional neural network to perform multilevel data abstraction without the need for manual feature engineering.2 In ophthalmology, many studies showed comparable, if not better, diagnostic performance in using AI to screen, diagnose, predict and monitor various eye conditions on fundus photographs and optical coherence tomography,3 4 including diabetic retinopathy (DR),5 age-related macular degeneration,6 glaucoma,7 retinopathy of prematurity (ROP).8   To date, many countries have reported well-established telemedicine programme to screen for DR and ROP,9–12 but limited for cataracts. Cataract is the leading cause of reversible blindness, affecting approximately 12.6 million (3.4–28.7 million) worldwide.13 14 The prevalence of cataract-related visual impairment also varies between high-income and low-income countries, with the latter having poorer access to tertiary care.13 In this issue, Wu et al 15 reported an AI-integrated telemedicine platform to screen and refer patients with cataract. This article consists of two parts: (1) the first part focusing on the AI system in detection of three tasks (capture mode, cataract diagnosis and referable cataract) and (2) the second part describing how these AI algorithms could be integrated in the telemedicine platform for real-world operational use. In this study, the referable cases were defined as: (1) grade 3 and grade 4 nuclear sclerotic …","",""
18,"Mason Marks","Artificial Intelligence Based Suicide Prediction",2019,"","","","",155,"2022-07-13 09:35:20","","","","",,,,,18,6.00,18,1,3,"Suicidal thoughts and behaviors are an international public health problem contributing to 800,000 annual deaths and up to 25 million nonfatal suicide attempts. In the United States, suicide rates have increased steadily for two decades, reaching 47,000 per year and surpassing annual motor vehicle deaths. This trend has prompted government agencies, healthcare systems, and multinational corporations to invest in artificial intelligence-based suicide prediction algorithms. This article describes these tools and the underexplored risks they pose to patients and consumers.    AI-based suicide prediction is developing along two separate tracks. In “medical suicide prediction,” AI analyzes data from patient medical records. In “social suicide prediction,” AI analyzes consumer behavior derived from social media, smartphone apps, and the Internet of Things (IoT). Because medical suicide prediction occurs within the context of healthcare, it is governed by the Health Information Portability and Accountability Act (HIPAA), which protects patient privacy; the Federal Common Rule, which protects the safety of human research subjects; and general principles of medical ethics. Medical suicide prediction tools are developed methodically in compliance with these regulations, and the methods of its developers are published in peer-reviewed academic journals. In contrast, social suicide prediction typically occurs outside the healthcare system where it is almost completely unregulated. Corporations maintain their suicide prediction methods as proprietary trade secrets. Despite this lack of transparency, social suicide predictions are deployed globally to affect people’s lives every day. Yet little is known about their safety or effectiveness.    Though AI-based suicide prediction has the potential to improve our understanding of suicide while saving lives, it raises many risks that have been underexplored. The risks include stigmatization of people with mental illness, the transfer of sensitive personal data to third-parties such as advertisers and data brokers, unnecessary involuntary confinement, violent confrontations with police, exacerbation of mental health conditions, and paradoxical increases in suicide risk.","",""
17,"Nathalie A. Smuha","From a 'Race to AI' to a 'Race to AI Regulation' - Regulatory Competition for Artificial Intelligence",2019,"","","","",156,"2022-07-13 09:35:20","","10.2139/ssrn.3501410","","",,,,,17,5.67,17,1,3,"Against a background of global competition to seize the opportunities promised by Artificial Intelligence (AI), many countries and regions are explicitly taking part in a ‘race to AI’. Yet the increased visibility of the technology’s risks has led to ever-louder calls for regulators to look beyond the benefits, and also secure appropriate regulation to ensure AI that is ‘trustworthy’ – i.e. legal, ethical and robust. Besides minimising those risks, such regulation could facilitate AI’s uptake, boost legal certainty, and hence also contribute to advancing countries’ position in the race. Consequently, this paper argues that the ‘race to AI’ also brings forth a ‘race to AI regulation’. After discussing the regulatory toolbox for AI and some of the challenges that regulators face when making use thereof, this paper assesses to which extent regulatory competition for AI – or its counterpart, regulatory convergence – is (1) a possibility, (2) a reality and (3) a desirability.","",""
16,"K. Denecke, E. Gabarron, R. Grainger, S. Konstantinidis, A. Lau, O. Rivera-Romero, T. Miron-Shatz, M. Merolli","Artificial Intelligence for Participatory Health: Applications, Impact, and Future Implications",2019,"","","","",157,"2022-07-13 09:35:20","","10.1055/s-0039-1677902","","",,,,,16,5.33,2,8,3,"Summary Objective : Artificial intelligence (AI) provides people and professionals working in the field of participatory health informatics an opportunity to derive robust insights from a variety of online sources. The objective of this paper is to identify current state of the art and application areas of AI in the context of participatory health. Methods : A search was conducted across seven databases (PubMed, Embase, CINAHL, PsychInfo, ACM Digital Library, IEEExplore, and SCOPUS), covering articles published since 2013. Additionally, clinical trials involving AI in participatory health contexts registered at clinicaltrials.gov were collected and analyzed. Results : Twenty-two articles and 12 trials were selected for review. The most common application of AI in participatory health was the secondary analysis of social media data: self-reported data including patient experiences with healthcare facilities, reports of adverse drug reactions, safety and efficacy concerns about over-the-counter medications, and other perspectives on medications. Other application areas included determining which online forum threads required moderator assistance, identifying users who were likely to drop out from a forum, extracting terms used in an online forum to learn its vocabulary, highlighting contextual information that is missing from online questions and answers, and paraphrasing technical medical terms for consumers. Conclusions : While AI for supporting participatory health is still in its infancy, there are a number of important research priorities that should be considered for the advancement of the field. Further research evaluating the impact of AI in participatory health informatics on the psychosocial wellbeing of individuals would help in facilitating the wider acceptance of AI into the healthcare ecosystem.","",""
15,"J. Bryson","The Artificial Intelligence of the Ethics of Artificial Intelligence",2020,"","","","",158,"2022-07-13 09:35:20","","10.1093/oxfordhb/9780190067397.013.1","","",,,,,15,7.50,15,1,2,"Artificial intelligence (AI) is a technical term often referring to artifacts used to detect contexts for human actions, or sometimes also for machines able to effect actions in response to detected contexts. Our capacity to build such artifacts has been increasing, and with it the impact they have on our society. This does not alter the fundamental roots or motivations of law, regulation, or diplomacy, which rest on persuading humans to behave in a way that provides sustainable security for humans. It does however alter nearly every other aspect of human social behaviour, including making accountability and responsibility potentially easier to trace. This chapter reviews the nature and implications of AI with particular attention to how they impinge on possible applications to and of law.","",""
14,"R. Bradford, C. Sangwin, S. Shashikumar, S. Nemati","Does the ""Artificial Intelligence Clinician"" learn optimal treatment strategies for sepsis in intensive care?",2019,"","","","",159,"2022-07-13 09:35:20","","","","",,,,,14,4.67,4,4,3,"From 2017 to 2018 the number of scientific publications found via PubMed search using the keyword ""Machine Learning"" increased by 46% (4,317 to 6,307). The results of studies involving machine learning, artificial intelligence (AI), and big data have captured the attention of healthcare practitioners, healthcare managers, and the public at a time when Western medicine grapples with unmitigated cost increases and public demands for accountability. The complexity involved in healthcare applications of machine learning and the size of the associated data sets has afforded many researchers an uncontested opportunity to satisfy these demands with relatively little oversight. In a recent Nature Medicine article, ""The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care,"" Komorowski and his coauthors propose methods to train an artificial intelligence clinician to treat sepsis patients with vasopressors and IV fluids. In this post, we will closely examine the claims laid out in this paper. In particular, we will study the individual treatment profiles suggested by their AI Clinician to gain insight into how their AI Clinician intends to treat patients on an individual level.","",""
14,"C. Marsden, Trisha Meyer","Regulating disinformation with artificial intelligence:effects of disinformation initiatives on freedom of expression and media pluralism",2019,"","","","",160,"2022-07-13 09:35:20","","10.2861/003689","","",,,,,14,4.67,7,2,3,"This study examines the consequences of the increasingly prevalent use of artificial intelligence (AI) disinformation initiatives upon freedom of expression, pluralism and the functioning of a democratic polity.  The study examines the trade-offs in using automated technology to limit the spread of disinformation online. It presents options (from self-regulatory to legislative) to regulate automated content recognition (ACR) technologies in this context. Special attention is paid to the opportunities for the European Union as a whole to take the lead in setting the framework for designing these technologies in a way that enhances accountability and transparency and respects free speech. The present project reviews some of the key academic and policy ideas on technology and disinformation and highlights their relevance to European policy.  Chapter 1 introduces the background to the study and presents the definitions used. Chapter 2 scopes the policy boundaries of disinformation from economic, societal and technological perspectives, focusing on the media context, behavioural economics and technological regulation. Chapter 3 maps and evaluates existing regulatory and technological responses to disinformation. In Chapter 4, policy options are presented, paying particular attention to interactions between technological solutions, freedom of expression and media pluralism.","",""
1,"K. Werder, B. Ramesh, Rongen Zhang","Establishing Data Provenance for Responsible Artificial Intelligence Systems",2022,"","","","",161,"2022-07-13 09:35:20","","10.1145/3503488","","",,,,,1,1.00,0,3,1,"Data provenance, a record that describes the origins and processing of data, offers new promises in the increasingly important role of artificial intelligence (AI)-based systems in guiding human decision making. To avoid disastrous outcomes that can result from bias-laden AI systems, responsible AI builds on four important characteristics: fairness, accountability, transparency, and explainability. To stimulate further research on data provenance that enables responsible AI, this study outlines existing biases and discusses possible implementations of data provenance to mitigate them. We first review biases stemming from the data's origins and pre-processing. We then discuss the current state of practice, the challenges it presents, and corresponding recommendations to address them. We present a summary highlighting how our recommendations can help establish data provenance and thereby mitigate biases stemming from the data's origins and pre-processing to realize responsible AI-based systems. We conclude with a research agenda suggesting further research avenues.","",""
0,"Akanksha Bisoyi","Ownership, liability, patentability, and creativity issues in artificial intelligence",2022,"","","","",162,"2022-07-13 09:35:20","","10.1080/19393555.2022.2060879","","",,,,,0,0.00,0,1,1,"ABSTRACT While Artificial Intelligence technologies find increasing use in different industries such as transportation, healthcare and other services, it gives rise to legal complexities in respect of ownership and liability of AI, patentability of AI inventions, and creativity & ownership of AI-generated works attributable to various components of AI. The autonomous decision-making ability of AI challenges the existing IP framework. Since AI machines can “think” and “act” without any human effort, if any damage or harm occurs to the properties, does the current model of tort liability (product liability, negligence, strict liability) adequately address the legal concerns? Robust regulatory bodies and institutional mechanisms are required to develop rigorous safety standards and establish safety certification processes for AI. Even though AI inventions can be patented, many jurisdictions recognize only a “human” as an inventor and not the AI. With the increasing capability of AI to generate works without human intervention, there seems to be a strong case for granting copyright protection to AI-generated works. Exploring a separate legal framework for AI to reduce ambiguity and increase accountability would be in order.","",""
0,"N. Rafie, J. Jentzer, P. Noseworthy, A. Kashou","Mortality Prediction in Cardiac Intensive Care Unit Patients: A Systematic Review of Existing and Artificial Intelligence Augmented Approaches",2022,"","","","",163,"2022-07-13 09:35:20","","10.3389/frai.2022.876007","","",,,,,0,0.00,0,4,1,"The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient's clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.","",""
19,"E. O. Kontis, T. Papadopoulos, M. Syed, E. Guillo‐Sansano, G. Burt, G. Papagiannis","Artificial-Intelligence Method for the Derivation of Generic Aggregated Dynamic Equivalent Models",2019,"","","","",164,"2022-07-13 09:35:20","","10.1109/TPWRS.2019.2894185","","",,,,,19,6.33,3,6,3,"Aggregated equivalent models for the dynamic analysis of active distribution networks (ADNs) can be efficiently developed using dynamic responses recorded through field measurements. However, equivalent model parameters are highly affected from the time-varying composition of power system loads and the stochastic behavior of distributed generators. Thus, equivalent models, developed through in situ measurements, are valid only for the operating conditions from which they have been derived. To overcome this issue, in this paper, a new method is proposed for the derivation of generic aggregated dynamic equivalent models, i.e., for equivalent models that can be used for the dynamic analysis of a wide range of network conditions. The method incorporates clustering and artificial neural network techniques to derive robust sets of parameters for a variable-order dynamic equivalent model. The effectiveness of the proposed method is evaluated using measurements recorded on a laboratory-scale ADN, while its performance is compared with a conventional technique. The corresponding results reveal the applicability of the proposed approach for the analysis and simulation of a wide range of distinct network conditions.","",""
11,"Luke Stark, Jevan Hutson","Physiognomic Artificial Intelligence",2021,"","","","",165,"2022-07-13 09:35:20","","10.2139/ssrn.3927300","","",,,,,11,11.00,6,2,1,"The reanimation of the pseudosciences of physiognomy and phrenology at scale through computer vision and machine learning is a matter of urgent concern. This Article, which contributes to critical data studies, consumer protection law, biometric privacy law, and anti-discrimination law, endeavors to conceptualize and problematize physiognomic artificial intelligence (AI) and offer policy recommendations for state and federal lawmakers to forestall its proliferation.    Physiognomic AI, we contend, is the practice of using computer software and related systems to infer or create hierarchies of an individual’s body composition, protected class status, perceived character, capabilities, and future social outcomes based on their physical or behavioral characteristics. Physiognomic and phrenological logics are intrinsic to the technical mechanism of computer vision applied to humans. In this Article, we observe how computer vision is a central vector for physiognomic AI technologies, unpacking how computer vision reanimates physiognomy in conception, form, and practice and the dangers this trend presents for civil liberties.    This Article thus argues for legislative action to forestall and roll back the proliferation of physiognomic AI. To that end, we consider a potential menu of safeguards and limitations to significantly limit the deployment of physiognomic AI systems, which we hope can be used to strengthen local, state, and federal legislation. We foreground our policy discussion by proposing the abolition of physiognomic AI. From there, we posit regimes of U.S. consumer protection law, biometric privacy law, and civil rights law as vehicles for rejecting physiognomy’s digital renaissance in artificial intelligence. Specifically, we argue that physiognomic AI should be categorically rejected as oppressive and unjust. Second, we argue that lawmakers should declare physiognomic AI to be unfair and deceptive per se. Third, we argue that lawmakers should enact or expand biometric privacy laws to prohibit physiognomic AI. Fourth, we argue that lawmakers should prohibit physiognomic AI in places of public accommodation. We also observe the paucity of procedural and managerial regimes of fairness, accountability, and transparency in addressing physiognomic AI and attend to potential counterarguments in support of physiognomic AI.","",""
27,"Óscar Álvarez-Machancoses, J. Fernández-Martínez","Using artificial intelligence methods to speed up drug discovery",2019,"","","","",166,"2022-07-13 09:35:20","","10.1080/17460441.2019.1621284","","",,,,,27,9.00,14,2,3,"ABSTRACT Introduction: Drug discovery is the process through which potential new compounds are identified by means of biology, chemistry, and pharmacology. Due to the high complexity of genomic data, AI techniques are increasingly needed to help reduce this and aid the adoption of optimal decisions. Phenotypic prediction is of particular use to drug discovery and precision medicine where sets of genes that predict a given phenotype are determined. Phenotypic prediction is an undetermined problem given that the number of monitored genetic probes markedly exceeds the number of collected samples (from patients). This imbalance creates ambiguity in the characterization of the biological pathways that are responsible for disease development. Areas covered: In this paper, the authors present AI methodologies that perform a robust deep sampling of altered genetic pathways to locate new therapeutic targets, assist in drug repurposing and speed up and optimize the drug selection process. Expert opinion: AI is a potential solution to a number of drug discovery problems, though one should, bear in mind that the quality of data predicts the overall quality of the prediction, as in any modeling task in data science. The use of transparent methodologies is crucial, particularly in drug repositioning/repurposing in rare diseases.","",""
10,"Zihao Chen, Long Hu, Baoting Zhang, Aiping Lu, Yaofeng Wang, Yuanyuan Yu, Ge Zhang","Artificial Intelligence in Aptamer–Target Binding Prediction",2021,"","","","",167,"2022-07-13 09:35:20","","10.3390/ijms22073605","","",,,,,10,10.00,1,7,1,"Aptamers are short single-stranded DNA, RNA, or synthetic Xeno nucleic acids (XNA) molecules that can interact with corresponding targets with high affinity. Owing to their unique features, including low cost of production, easy chemical modification, high thermal stability, reproducibility, as well as low levels of immunogenicity and toxicity, aptamers can be used as an alternative to antibodies in diagnostics and therapeutics. Systematic evolution of ligands by exponential enrichment (SELEX), an experimental approach for aptamer screening, allows the selection and identification of in vitro aptamers with high affinity and specificity. However, the SELEX process is time consuming and characterization of the representative aptamer candidates from SELEX is rather laborious. Artificial intelligence (AI) could help to rapidly identify the potential aptamer candidates from a vast number of sequences. This review discusses the advancements of AI pipelines/methods, including structure-based and machine/deep learning-based methods, for predicting the binding ability of aptamers to targets. Structure-based methods are the most used in computer-aided drug design. For this part, we review the secondary and tertiary structure prediction methods for aptamers, molecular docking, as well as molecular dynamic simulation methods for aptamer–target binding. We also performed analysis to compare the accuracy of different secondary and tertiary structure prediction methods for aptamers. On the other hand, advanced machine-/deep-learning models have witnessed successes in predicting the binding abilities between targets and ligands in drug discovery and thus potentially offer a robust and accurate approach to predict the binding between aptamers and targets. The research utilizing machine-/deep-learning techniques for prediction of aptamer–target binding is limited currently. Therefore, perspectives for models, algorithms, and implementation strategies of machine/deep learning-based methods are discussed. This review could facilitate the development and application of high-throughput and less laborious in silico methods in aptamer selection and characterization.","",""
10,"Shun Zhang, Muye Li, Mengnan Jian, Yajun Zhao, Feifei Gao","AIRIS: Artificial intelligence enhanced signal processing in reconfigurable intelligent surface communications",2021,"","","","",168,"2022-07-13 09:35:20","","10.23919/JCC.2021.07.013","","",,,,,10,10.00,2,5,1,"Reconfigurable intelligent surface (RIS) is an emerging meta-surface that can provide additional communications links through reflecting the signals, and has been recognized as a strong candidate of 6G mobile communications systems. Meanwhile, it has been recently admitted that implementing artificial intelligence (AI) into RIS communications will extensively benefit the reconfiguration capacity and enhance the robustness to complicated transmission environments. Besides the conventional model-driven approaches, AI can also deal with the existing signal processing problems in a data-driven manner via digging the inherent characteristic from the real data. Hence, AI is particularly suitable for the signal processing problems over RIS networks under unideal scenarios like modeling mismatching, insufficient resource, hardware impairment, as well as dynamical transmissions. As one of the earliest survey papers, we will introduce the merging of AI and RIS, called AIRIS, over various signal processing topics, including environmental sensing, channel acquisition, beam-forming design, and resource scheduling, etc. We will also discuss the challenges of AIRIS and present some interesting future directions.","",""
822,"Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Q. Song, K. Cao, Daliang Liu, Guisheng Wang, Qizhong Xu, Xi Fang, Shiqin Zhang, J. Xia, Jun Xia","Using Artificial Intelligence to Detect COVID-19 and Community-acquired Pneumonia Based on Pulmonary CT: Evaluation of the Diagnostic Accuracy",2020,"","","","",169,"2022-07-13 09:35:20","","10.1148/RADIOL.2020200905","","",,,,,822,411.00,82,18,2,"Background Coronavirus disease 2019 (COVID-19) has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performance. Materials and Methods In this retrospective and multicenter study, a deep learning model, the COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT scans for the detection of COVID-19. CT scans of community-acquired pneumonia (CAP) and other non-pneumonia abnormalities were included to test the robustness of the model. The datasets were collected from six hospitals between August 2016 and February 2020. Diagnostic performance was assessed with the area under the receiver operating characteristic curve, sensitivity, and specificity. Results The collected dataset consisted of 4352 chest CT scans from 3322 patients. The average patient age (±standard deviation) was 49 years ± 15, and there were slightly more men than women (1838 vs 1484, respectively; P = .29). The per-scan sensitivity and specificity for detecting COVID-19 in the independent test set was 90% (95% confidence interval [CI]: 83%, 94%; 114 of 127 scans) and 96% (95% CI: 93%, 98%; 294 of 307 scans), respectively, with an area under the receiver operating characteristic curve of 0.96 (P < .001). The per-scan sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175 scans) and 92% (239 of 259 scans), respectively, with an area under the receiver operating characteristic curve of 0.95 (95% CI: 0.93, 0.97). Conclusion A deep learning model can accurately detect coronavirus 2019 and differentiate it from community-acquired pneumonia and other lung conditions. © RSNA, 2020 Online supplemental material is available for this article.","",""
427,"D. Ting, L. Pasquale, L. Peng, J. P. Campbell, Aaron Y. Lee, R. Raman, G. Tan, L. Schmetterer, P. Keane, T. Wong","Artificial intelligence and deep learning in ophthalmology",2018,"","","","",170,"2022-07-13 09:35:20","","10.1136/bjophthalmol-2018-313173","","",,,,,427,106.75,43,10,4,"Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition, speech recognition and natural language processing, but is only beginning to impact on healthcare. In ophthalmology, DL has been applied to fundus photographs, optical coherence tomography and visual fields, achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity, the glaucoma-like disc, macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen, diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless, there are also potential challenges with DL application in ophthalmology, including clinical and technical challenges, explainability of the algorithm results, medicolegal issues, and physician and patient acceptance of the AI ‘black-box’ algorithms. DL could potentially revolutionise how ophthalmology is practised in the future. This review provides a summary of the state-of-the-art DL systems described for ophthalmic applications, potential challenges in clinical deployment and the path forward.","",""
13,"J. Prassl","What if your boss was an algorithm? Economic incentives, legal challenges, and the rise of artificial intelligence at work",2019,"","","","",171,"2022-07-13 09:35:20","","","","",,,,,13,4.33,13,1,3,"Rapid advancements in automation will have a profound impact on labour markets. This paper focuses on a comparatively overlooked aspect of debates surrounding automation and the future of work: the rise of algorithmic management, enabled by hitherto infeasible forms of data collection and processing. As AI-driven decision-making is quickly becoming an important element of most employer functions, from hiring workers through to daily performance monitoring, received models of the legal regulation of employment relationships are faced with complex challenges – some of which, such as the rules of privacy and data protection, can be addressed through the careful adaptation and development of existing standards, whereas others, including notably management accountability for key workplace decision, may require a fundamental rethink of existing norms.","",""
13,"Wolfgang Hoffmann-Riem","Artificial Intelligence as a Challenge for Law and Regulation",2019,"","","","",172,"2022-07-13 09:35:20","","10.1007/978-3-030-32361-5_1","","",,,,,13,4.33,13,1,3,"","",""
0,"Sandro González-González, L. Serpa-Andrade","Development of a virtual assistant chatbot based on Artificial Intelligence to control and supervise a process of 4 tanks which are interconnected",2022,"","","","",173,"2022-07-13 09:35:20","","10.54941/ahfe1001464","","",,,,,0,0.00,0,2,1,"This article presents the gathering of works related to the usage of virtual assistants into the 4.0 industry in order to stablish the parameters and essential characteristics to define the creation of a ‘chatbot’ virtual assistant. This device should be applicable to a process of 4 tanks which are interconnected with a robust multivariable PID control with the aim of controlling and supervising this process using a mobile messaging application from a smartphone by sending key words in text messages which will be interpreted by the chatbot and this will be capable of acting depending on the message it receives; it can be either a consultation of the status of the process and the tanks which will be answered with a text message with the required information, or a command which will make it work starting or stopping the process. This system is proposed as a solution in the case of long-distance supervision and control during different processes. With this, an option to optimize the execution of actions such as security, speed, reliability of data, and resource maximization can be implemented, which leads to a better general performance of an industry","",""
9,"Nawaf H. M. M. Shrifan, M. F. Akbar, N. Isa","Prospect of Using Artificial Intelligence for Microwave Nondestructive Testing Technique: A Review",2019,"","","","",174,"2022-07-13 09:35:20","","10.1109/ACCESS.2019.2934143","","",,,,,9,3.00,3,3,3,"The development in materials technology has produced stronger, lighter, stiffer, and more durable electrically insulating composites which are replacing metals in many applications. These composites require alternative inspection techniques because the conventional nondestructive testing (NDT) techniques such as thermography, eddy currents, ultrasonic, X-ray and magnetic particles have limitations of inspecting them. Microwave NDT technique employing open-ended rectangular waveguides (OERW) has emerged as a promising approach to detect the defects in both metal and composite materials. Despite its promising results over conventional NDT techniques, OERW microwave NDT technique has shown numerous limitations in terms of poor spatial resolution due to the stand-off distance variations, inspection area irregularities and quantitative estimation in imaging the size of defects. Microwave NDT employing OERW in conjunction with robust artificial intelligence approaches have tremendous potential and viability for evaluating composite structures for the purpose mentioned here. Artificial intelligence techniques with signal processing techniques are highly possible to enhance the efficiency and resolution of microwave NDT technique because the impact of artificial intelligence approaches is proven in various conventional NDT techniques. This paper provides a comprehensive review of NDT techniques as well as the prospect of using artificial intelligence approaches in microwave NDT technique with regards to other conventional NDT techniques.","",""
10,"A. Gaon, I. Stedman","A Call to Action: Moving Forward with the Governance of Artificial Intelligence in Canada",2019,"","","","",175,"2022-07-13 09:35:20","","10.29173/ALR2547","","",,,,,10,3.33,5,2,3,"The Government of Canada has committed to accelerating the growth of the country’s world-class artificial intelligence (AI) sector. This emerging technology has the potential to impact nearly every segment of Canada’s economy, including national security, health care, and government services. To prepare for the key challenges and opportunities that AI will give rise to, we offer an innovative governance model for Canadian governments to adopt. This model recognizes the uncertainty ahead and prioritizes oversight and accountability while also encouraging a flexible policy-first approach. This approach fosters responsible AI innovation and supports Canada’s emergence as a leader in AI technology and governance.","",""
10,"S. Larsson","The Socio-Legal Relevance of Artificial Intelligence",2019,"","","","",176,"2022-07-13 09:35:20","","10.3917/DRS1.103.0573","","",,,,,10,3.33,10,1,3,"This article draws on socio-legal theory in relation to growing concerns over fairness, accountability and transparency of societally applied artificial intelligence (AI) and machine learning. The purpose is to contribute to a broad socio-legal orientation by describing legal and normative challenges posed by applied AI. To do so, the article first analyzes a set of problematic cases, e.g., image recognition based on gender-biased databases. It then presents seven aspects of transparency that may complement notions of explainable AI (XAI) within AI-research undertaken by computer scientists. The article finally discusses the normative mirroring effect of using human values and societal structures as training data for learning technologies; it concludes by arguing for the need for a multidisciplinary approach in AI research, development, and governance.","",""
90,"R. Shafin, Lingjia Liu, V. Chandrasekhar, Hao Chen, J. Reed, Jianzhong Zhang","Artificial Intelligence-Enabled Cellular Networks: A Critical Path to Beyond-5G and 6G",2019,"","","","",177,"2022-07-13 09:35:20","","10.1109/MWC.001.1900323","","",,,,,90,30.00,15,6,3,"Mobile network operators (MNOs) are in the process of overlaying their conventional macro cellular networks with shorter range cells such as outdoor pico cells. The resultant increase in network complexity creates substantial overhead in terms of operating expenses, time, and labor for their planning and management. Artificial intelligence (AI) offers the potential for MNOs to operate their networks in a more organic and cost-efficient manner. We argue that deploying AI in fifth generation (5G) and beyond will require surmounting significant technical barriers in terms of robustness, performance, and complexity. We outline future research directions, identify top five challenges, and present a possible roadmap to realize the vision of AI-enabled cellular networks for Beyond- 5G and sixth generation (6G) networks.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",178,"2022-07-13 09:35:20","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
8,"S. Kalam, Mohammad Rasheed Khan, Zeeshan Tariq, F. Siddique, A. Abdulraheem, Rizwan Ahmed Khan","A Novel Correlation to Predict Gas Flow Rates Utilizing Artificial Intelligence: An Industrial 4.0 Approach",2019,"","","","",179,"2022-07-13 09:35:20","","10.2118/201170-ms","","",,,,,8,2.67,1,6,3,"  Reservoir and production engineers rely heavily on well production rates to optimize well activities such as ensuring optimum reservoir monitoring. Individual gas well rates are not readily available, rather, they can be estimated thru multi-phase flow meter (MPFM) and well test analysis. These methods are associated with certain limitations such as high cost, high uncertainty, and technically elaborate calculations. Consequently, empirical and numerical calculations are employed with well test data to calculate daily rates. These practices lead to inaccurate gas rate estimations.  A model with an ability to provide accurate estimates of gas rates for a gas reservoir can serve as a handy tool for the subsurface engineers in addressing well and reservoir optimization strategies. This work presents artificial intelligence models to estimate gas rates in a gas field containing ten wells. The aim is to develop a correlation that is simple and easy to incorporate yet providing robust answers on a global scale. Multiple machine learning tools are employed. These include; Artificial Neural Network (ANN), Functional Network (FN), and Adaptive Neuro Fuzzy Inference System (ANFIS).  Production data from a dry gas field X was used for the model development. Data cleaning and data reduction steps were carried out to ensure the input parameters for the proposed model are physically relevant and accurate. Missing these steps would result in the development of an erroneous correlation, i.e., garbage -in garbage-out (GIGO). This led to finalization of certain basic well-head parameters which are available at any typical well and had direct impact on the output production rate. The target parameter for model training is the gas rate. A rigorous comparison between the investigated artificial intelligence models was conducted by calculating average absolute percentage error (AAPE) and coefficient of determination. The comparative analysis shows that the intelligent model is able to predict the gas rate in condensate wells with accuracy in excess of 90%. Examples of such large accuracy has not been reported previously.  ANN performs a step ahead as compared to the various intelligent algorithms used in this study. This paper sheds light on the potential of the Industrial Revolution 4.0 for the Pakistani Oil and Gas Sector. Data-driven artificial intelligent models are capable of validating the well test and multiphase flow meter results. In addition, it can prove to be a vital tool in an engineer's tool-kit to reduce uncertainties in gas rate measurements.","",""
8,"Martin Abrams, J. Abrams, P. Cullen, L. Goldstein","Artificial Intelligence, Ethics, and Enhanced Data Stewardship",2019,"","","","",180,"2022-07-13 09:35:20","","10.1109/MSEC.2018.2888778","","",,,,,8,2.67,2,4,3,"The Information Accountability Foundation (IAF) has launched the Artificial Intelligence and Ethics Project to encourage discussion of how organizations might apply ethical principles to data processing, especially in cases where computers, not people, make data-enabled decisions.","",""
7,"Gabriele Buchholtz","Artificial Intelligence and Legal Tech: Challenges to the Rule of Law",2019,"","","","",181,"2022-07-13 09:35:20","","10.1007/978-3-030-32361-5_8","","",,,,,7,2.33,7,1,3,"","",""
7,"David K. Spencer, Stephen Duncan, Adam Taliaferro","Operationalizing artificial intelligence for multi-domain operations: a first look",2019,"","","","",182,"2022-07-13 09:35:20","","10.1117/12.2524227","","",,,,,7,2.33,2,3,3,"Artificial Intelligence / Machine Learning (AI/ML) is a foundational requirement for Multi-Domain Operations (MDO). To solve some of MDO’s most critical problems, for example, penetrating and dis-integrating an adversary’s antiaccess/area denial (A2/AD) systems, the future force requires the ability to converge capabilities from across multiple domains at speeds and scales beyond human cognitive abilities. This requires robust, interoperable AI/ML that operates across multiple layers: from optimizing technologies and platforms, to fusing data from multiple sources, to transferring knowledge across joint functions to accomplish critical MDO tactical tasks. This paper provides an overview of ongoing work from the Unified Quest Future Study Plan and other events with the Army’s Futures and Concepts Center to operationalize AI/ML to address MDO problems with this layered approach. It includes insights and required AI/ML capabilities determined with subject matter experts from various organizations at these learning events over the past two years, as well as vignettes that illustrate how AI/ML can be operationalized to enable successful Multi-Domain Operations against a near peer adversary.","",""
7,"S. Larsson, Mikael Anneroth, Anna Felländer, L. Felländer-Tsai, F. Heintz, Rebecka Cedering Ångström","Sustainable AI: An inventory of the state of knowledge of ethical, social, and legal challenges related to artificial intelligence",2019,"","","","",183,"2022-07-13 09:35:20","","","","",,,,,7,2.33,1,6,3,"This report is an inventory of the state of knowledge of ethical, social, and legal challenges related to artificial intelligence conducted within the Swedish Vinnova-funded project “Hallbar AI – AI Ethics and Sustainability”, led by Anna Fellander. Based on a review and mapping of reports and studies, a quantitative and bibliometric analysis, and in-depth analyses of the healt- care sector, the telecom sector, and digital platforms, the report proposes three recommendations. Sustainable AI requires: 1. a broad focus on AI governance and regulation issues, 2. promoting multi-disciplinary collaboration, and 3. building trust in AI applications and applied machine-learning, which is a matter of key importance and requires further study of the relationship between transparency and accountability. (Less)","",""
43,"Dan Liu, Fei Liu, Xiao-yan Xie, Liya Su, Ming Liu, Xiaohua Xie, M. Kuang, Guangliang Huang, Yuqi Wang, Hui Zhou, Kun Wang, Manxia Lin, Jie Tian","Accurate prediction of responses to transarterial chemoembolization for patients with hepatocellular carcinoma by using artificial intelligence in contrast-enhanced ultrasound",2020,"","","","",184,"2022-07-13 09:35:20","","10.1007/s00330-019-06553-6","","",,,,,43,21.50,4,13,2,"","",""
37,"T. Babina, A. Fedyk, A. He, James Hodson","Artificial Intelligence, Firm Growth, and Industry Concentration",2020,"","","","",185,"2022-07-13 09:35:20","","10.2139/ssrn.3651052","","",,,,,37,18.50,9,4,2,"Which firms invest in artificial intelligence (AI) technologies, and how do these investments affect individual firms and industries? We provide a comprehensive picture of the use of AI technologies and their impact among US firms over the last decade, using a unique combination of job postings and individual-level employment profiles. We introduce a novel measure of investments in AI technologies based on human capital and document that larger firms with higher sales, markups, and cash holdings tend to invest more in AI. Firms that invest in AI experience faster growth in both sales and employment, which translates into analogous growth at the industry level. The positive effects are concentrated among the ex ante largest firms, leading to a positive correlation between AI investments and an increase in industry concentration. However, the increase in concentration is not accompanied by either increased markups or increased productivity. Instead, firms tend to expand into new product and geographic markets. Our results are robust to instrumenting firm-level AI investments with foreign industry-level AI investments and with local variation in industry-level AI investments, and to controlling for investments in general information technology and robotics. We also document consistent patterns across measures of AI using firms' demand for AI talent (job postings) and actual AI talent (resumes). Overall, our findings support the view that new technologies, such as AI, increase the scale of the most productive firms and contribute to the rise of superstar firms.","",""
4,"A. Samareh, Xiangyu Chang, W. Lober, H. Evans, Zhangyang Wang, Xiaoning Qian, Shuai Huang","Artificial Intelligence Methods for Surgical Site Infection: Impacts on Detection, Monitoring, and Decision Making.",2019,"","","","",186,"2022-07-13 09:35:20","","10.1089/sur.2019.150","","",,,,,4,1.33,1,7,3,"Background: There has been tremendous growth in the amount of new surgical site infection (SSI) data generated. Key challenges exist in understanding the data for robust clinical decision-support. Limitations of traditional methodologies to handle these data led to the emergence of artificial intelligence (AI). This article emphasizes the capabilities of AI to identify patterns of SSI data. Method: Artificial intelligence comprises various subfields that present potential solutions to identify patterns of SSI data. Discussions on opportunities, challenges, and limitations of applying these methods to derive accurate SSI prediction are provided. Results: Four main challenges in dealing with SSI data were defined: (1) complexities in using SSI data, (2) disease knowledge, (3) decision support, and (4) heterogeneity. The implications of some of the recent advances in AI methods to optimize clinical effectiveness were discussed. Conclusions: Artificial intelligence has the potential to provide insight in detecting and decision-support of SSI. As we turn SSI data into intelligence about the disease, we increase the possibility of improving surgical practice with the promise of a future optimized for the highest quality patient care.","",""
2,"O. Ahmad, L. Lovat","Artificial intelligence for colorectal polyp detection: are we ready for prime time?",2019,"","","","",187,"2022-07-13 09:35:20","","10.21037/jmai.2019.09.02","","",,,,,2,0.67,1,2,3,"Colorectal cancer (CRC) is a leading cause of cancer-related mortality worldwide. Colonoscopy is protective against CRC through the detection and removal of neoplastic polyps. Unfortunately, the procedure is highly operator dependent with significant miss rates for polyps. Artificial intelligence (AI) and computer-aided detection software offers a promising solution by providing real-time assistance to highlight lesions that may otherwise be overlooked. Rapid advances have occurred in the field with recent prospective clinical trials demonstrating an improved adenoma detection rate (ADR) with AI assistance. Deployment in routine clinical practice is possible in the near future although further robust clinical trials are necessary and important practical challenges relating to real-world implementation must be addressed.","",""
4,"Timothy J. Rademacher","Artificial Intelligence and Law Enforcement",2019,"","","","",188,"2022-07-13 09:35:20","","10.1007/978-3-030-32361-5_10","","",,,,,4,1.33,4,1,3,"","",""
3,"N. Kshetri","Complementary and Synergistic Properties of Blockchain and Artificial Intelligence",2019,"","","","",189,"2022-07-13 09:35:20","","10.1109/MITP.2019.2940364","","",,,,,3,1.00,3,1,3,"Artificial intelligence (AI) and blockchain are likely to bring powerful economic and social effects. Blockchain's ability to cryptographically validate identities and transactions and create immutable records can enhance trust, transparency, and accountability. Part of the fascinating character of the AI stems from the fact that computers perform better than humans in repetitive tasks. Their judgment and intelligence are not affected by emotions, feelings, and needs. They have better memories and can process large amounts of information.1 AI, thus, enhances efficiency and provides new opportunities for cost savings and revenue generation. What is even more important is that AI and blockchain have strong complementary capabilities that can have dramatic effects on the performance of industries and markets. Each also has a potential to improve the performance and functioning of the other (see Figure 1).","",""
3,"M. Ahmad, C. Eckert, A. Teredesai","The Challenge of Imputation in Explainable Artificial Intelligence Models",2019,"","","","",190,"2022-07-13 09:35:20","","","","",,,,,3,1.00,1,3,3,"Explainable models in Artificial Intelligence are often employed to ensure transparency and accountability of AI systems. The fidelity of the explanations are dependent upon the algorithms used as well as on the fidelity of the data. Many real world datasets have missing values that can greatly influence explanation fidelity. The standard way to deal with such scenarios is imputation. This can, however, lead to situations where the imputed values may correspond to a setting which refer to counterfactuals. Acting on explanations from AI models with imputed values may lead to unsafe outcomes. In this paper, we explore different settings where AI models with imputation can be problematic and describe ways to address such scenarios.","",""
6,"W. Wendel","The Promise and Limitations of Artificial Intelligence in the Practice of Law",2019,"","","","",191,"2022-07-13 09:35:20","","","","",,,,,6,2.00,6,1,3,"Artificial intelligence has demonstrated the ability to outperform humans at tasks that were previously thought to offer a decisive advantage to human intelligence. Computer technology has already changed the practice of law in many ways. Lawyers may therefore wonder whether they will soon be replaced by computers. This Article looks at that issue from another direction, beginning with the nature of law as a means to enhance the human ethical capacity for reason-giving in response to demands for accountability. Moral reason-giving reflects the mutual recognition of two agents as free and equal. The law merely enables the process of giving reasons on a much larger scale, given background conditions of disagreement and uncertainty. The core function of lawyers is to facilitate the law’s practical authority, by interpreting and applying the law to give reasons that suffice to justify actions that affect the interests of others. The Article reviews the current state of research on machine ethics and the development of artificial moral agents and concludes that human technology is a long way from being able to design a computer system that can satisfy the demand for authority and accountability that is constitutive of the core function of lawyers in a liberal democratic political community.","",""
3,"Scott Esko Brummel, Ma","Artificial Intelligence – Emerging Opportunities , Challenges , and Implications for Policy and Research ( GAO Report )",2019,"","","","",192,"2022-07-13 09:35:20","","","","",,,,,3,1.00,2,2,3,"In March 2018, the Government Accountability Office [8] (GAO) published “Artificial Intelligence – Emerging Opportunities, Challenges, and Implications [9]” following its July 2017 forum on Artificial Intelligence (AI). This forum convened AI experts and stakeholders from industry, academia, government, and nonprofits to consider the impacts and policy implications of AI in the cybersecurity, transportation, criminal justice, and financial sectors. Following the GAO’s report, a summary testimony [10] of the Forum’s findings was presented before the Subcommittees on Research and Technology [11], and Energy [12] within the House Committee on Science, Space, and Technology [13].","",""
3,"R. Braun","Artificial Intelligence: Socio-Political Challenges of Delegating Human Decision-Making to Machines",2019,"","","","",193,"2022-07-13 09:35:20","","","","",,,,,3,1.00,3,1,3,"Artificial intelligence is at the heart of current debates related to ethical, social and political issues of technological innovation. This briefing refocuses attention from the techno-ethical challenges of AI to artificial decision-making (ADM) and the questions related to delegating human decisions to ADM. It is argued that (a) from a socio-ethical point of view the delegation is more relevant than the actual ethical problems of AI systems; (b) instead of traditional responsible AI approaches focusing on accountability, responsibility and transparency (ART) we should direct our attention to trustworthiness in the delegation process; and (c) trustworthiness as a socio-communicational challenge leads to questions that may be guided by a responsible research and innovation framework of anticipation, reflexivity, inclusion, and responsiveness. This may lead to different questions policymakers and other interested publics may ask as well as novel approaches, including regulatory sandboxes and other measures to foster a more inclusive, open and democratic culture of human-ADM relations.","",""
6,"Francisco Javier Abarca-Álvarez, F. S. Campos-Sánchez, Fernando Osuna-Pérez","Urban Shape and Built Density Metrics through the Analysis of European Urban Fabrics Using Artificial Intelligence",2019,"","","","",194,"2022-07-13 09:35:20","","10.3390/su11236622","","",,,,,6,2.00,2,3,3,"In recent decades, the concept of urban density has been considered key to the creation of sustainable urban fabrics. However, when it comes to measuring the built density, a difficulty has been observed in defining valid measurement indicators universally. With the intention of identifying the variables that allow the best characterization of the shape of urban fabrics and of obtaining the metrics of their density, a multi-variable analysis methodology from the field of artificial intelligence is proposed. The main objective of this paper was to evaluate the capacity and interest of such a methodology from standard indicators of the built density, measured at various urban scales, (i) to cluster differentiated urban profiles in a robust way by assessing the results statistically, and (ii) to obtain the metrics that characterize them with an identity. As a case study, this methodology was applied to the state of the art European urban fabrics (N = 117) by simultaneously integrating 13 regular parameters to qualify urban shape and density. It was verified that the profiles obtained were more robust than those based on a limited number of indicators, evidencing that the proposed methodology offers operational opportunities in urban management by allowing the comparison of a fabric with the identified profiles.","",""
10,"Michael Landon-Murray, Edin Mujkic, Brian Nussbaum","Disinformation in Contemporary U.S. Foreign Policy: Impacts and Ethics in an Era of Fake News, Social Media, and Artificial Intelligence",2019,"","","","",195,"2022-07-13 09:35:20","","10.1080/10999922.2019.1613832","","",,,,,10,3.33,3,3,3,"Misinformation and disinformation, often in the form of fake news disseminated on social media, are proliferating in the “post-truth” era, with profound implications for public and policy discourse, political accountability and integrity, elections and governance. The United States is grappling with an information landscape eroded by deeply flawed information from a variety of sources, including Russian efforts to undermine its recent presidential election. As it struggles with these problems, the U.S. must also decide if and how to deploy political disinformation. U.S. foreign policy has made significant use of disinformation to influence politics and elections, and as emerging technologies allow new means of producing, disseminating, and amplifying disinformation, American presidents, security officials, and covert operators will weigh their use and usefulness. These technologies will also create new, largely unknown effects, the normative, practical, and governance implications of which must be scrutinized. Despite the attention now focused on disinformation, this angle has received inadequate consideration. This article argues that in rapidly shifting technological and political landscapes, disinformation programs require the highest possible degree of examination and accountability. Congress; the electorate; media; and researchers must engage in the public conversation to ensure that American democratic and ethical values inform U.S. policy.","",""
34,"T. H. Aldhyani, M. Al-Yaari, Hasan Alkahtani, Mashael S. Maashi","Water Quality Prediction Using Artificial Intelligence Algorithms",2020,"","","","",196,"2022-07-13 09:35:20","","10.1155/2020/6659314","","",,,,,34,17.00,9,4,2,"During the last years, water quality has been threatened by various pollutants. Therefore, modeling and predicting water quality have become very important in controlling water pollution. In this work, advanced artificial intelligence (AI) algorithms are developed to predict water quality index (WQI) and water quality classification (WQC). For the WQI prediction, artificial neural network models, namely nonlinear autoregressive neural network (NARNET) and long short-term memory (LSTM) deep learning algorithm, have been developed. In addition, three machine learning algorithms, namely, support vector machine (SVM), K-nearest neighbor (K-NN), and Naive Bayes, have been used for the WQC forecasting. The used dataset has 7 significant parameters, and the developed models were evaluated based on some statistical parameters. The results revealed that the proposed models can accurately predict WQI and classify the water quality according to superior robustness. Prediction results demonstrated that the NARNET model performed slightly better than the LSTM for the prediction of the WQI values and the SVM algorithm has achieved the highest accuracy (97.01%) for the WQC prediction. Furthermore, the NARNET and LSTM models have achieved similar accuracy for the testing phase with a slight difference in the regression coefficient (RNARNET = 96.17% and RLSTM = 94.21%). This kind of promising research can contribute significantly to water management.","",""
103,"F. Schwendicke, W. Samek, J. Krois","Artificial Intelligence in Dentistry: Chances and Challenges",2020,"","","","",197,"2022-07-13 09:35:20","","10.1177/0022034520915714","","",,,,,103,51.50,34,3,2,"The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.","",""
6,"Justus Wolff, J. Pauling, A. Keck, J. Baumbach","Success Factors of Artificial Intelligence Implementation in Healthcare",2021,"","","","",198,"2022-07-13 09:35:20","","10.3389/fdgth.2021.594971","","",,,,,6,6.00,2,4,1,"Background: Artificial Intelligence (AI) in healthcare has demonstrated high efficiency in academic research, while only few, and predominantly small, real-world AI applications exist in the preventive, diagnostic and therapeutic contexts. Our identification and analysis of success factors for the implementation of AI aims to close the gap between recent years' significant academic AI advancements and the comparably low level of practical application in healthcare. Methods: A literature and real life cases analysis was conducted in Scopus and OpacPlus as well as the Google advanced search database. The according search queries have been defined based on success factor categories for AI implementation derived from a prior World Health Organization survey about barriers of adoption of Big Data within 125 countries. The eligible publications and real life cases were identified through a catalog of in- and exclusion criteria focused on concrete AI application cases. These were then analyzed to deduct and discuss success factors that facilitate or inhibit a broad-scale implementation of AI in healthcare. Results: The analysis revealed three categories of success factors, namely (1) policy setting, (2) technological implementation, and (3) medical and economic impact measurement. For each of them a set of recommendations has been deducted: First, a risk adjusted policy frame is required that distinguishes between precautionary and permissionless principles, and differentiates among accountability, liability, and culpability. Second, a “privacy by design” centered technology infrastructure shall be applied that enables practical and legally compliant data access. Third, the medical and economic impact need to be quantified, e.g., through the measurement of quality-adjusted life years while applying the CHEERS and PRISMA reporting criteria. Conclusions: Private and public institutions can already today leverage AI implementation based on the identified results and thus drive the translation from scientific development to real world application. Additional success factors could include trust-building measures, data categorization guidelines, and risk level assessments and as the success factors are interlinked, future research should elaborate on their optimal interaction to utilize the full potential of AI in real world application.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",199,"2022-07-13 09:35:20","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
0,"Joshua A. Kroll","CA State Legislature Senate Select Committee on the Growing Impact of Artificial Intelligence in California Hearing on 25 June , 2019 : Overview of Policy Issues Testimony of",2019,"","","","",200,"2022-07-13 09:35:20","","","","",,,,,0,0.00,0,1,3,"Chairman Umberg, members of the Select Committee, thank you for the opportunity to speak to you today. My name is Joshua Kroll, and I am a computer scientist studying the relationship between technology and governance – with a focus on AI and automated decision-making – at the UC Berkeley School of Information, as a postdoctoral research scholar. My work focuses on the need to design computer systems to support human values such as fairness, privacy, security and legal compliance when computers are used to make life-altering decisions such as who wins an election, who gets access to financial products, whether someone should be incarcerated, or whether a diagnostic image shows a malignancy. As we move into a world where artificial intelligence increases the number, stakes, and speed of these decisions, it is essential that we design systems to support human values and to be subject to robust governance so that we can ensure people and organizations remain accountable. Here, I use the term “artificial intelligence” to mean any behavior by a machine that a person would consider to be intelligent, regardless of how that behavior is implemented.","",""
