Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
4,"Jae-Gil Lee, Yuji Roh, Hwanjun Song, S. E. Whang","Machine Learning Robustness, Fairness, and their Convergence",2021,"","","","",1,"2022-07-13 09:24:47","","10.1145/3447548.3470799","","",,,,,4,4.00,1,4,1,"Responsible AI becomes critical where robustness and fairness must be satisfied together. Traditionally, the two topics have been studied by different communities for different applications. Robust training is designed for noisy or poisoned data where image data is typically considered. In comparison, fair training primarily deals with biased data where structured data is typically considered. Nevertheless, robust training and fair training are fundamentally similar in considering that both of them aim at fixing the inherent flaws of real-world data. In this tutorial, we first cover state-of-the-art robust training techniques where most of the research is on combating various label noises. In particular, we cover label noise modeling, robust training approaches, and real-world noisy data sets. Then, proceeding to the related fairness literature, we discuss pre-processing, in-processing, and post-processing unfairness mitigation techniques, depending on whether the mitigation occurs before, during, or after the model training. Finally, we cover the recent trend emerged to combine robust and fair training in two flavors: the former is to make the fair training more robust (i.e., robust fair training), and the latter is to consider robustness and fairness as two equals to incorporate them into a holistic framework. This tutorial is indeed timely and novel because the convergence of the two topics is increasingly common, but yet to be addressed in tutorials. The tutors have extensive experience publishing papers in top-tier machine learning and data mining venues and developing machine learning platforms.","",""
4,"J. Guan, Wang Fang, M. Ying","Robustness Verification of Quantum Machine Learning",2020,"","","","",2,"2022-07-13 09:24:47","","","","",,,,,4,2.00,1,3,2,"Several important models of machine learning algorithms have been successfully generalized to the quantum world, with potential applications to data analytics in quantum physics that can be implemented on the near future quantum computers. However, noise and decoherence are two major obstacles to the practical implementation of quantum machine learning. In this work, we introduce a general framework for the robustness analysis of quantum machine learning algorithms against noise and decoherence. We argue that fidelity is the only pick of measuring the robustness. A robust bound is derived and an algorithm is developed to check whether or not a quantum machine learning algorithm is robust with respect to the training data. In particular, this algorithm can help to defense attacks and improve the accuracy as it can identify useful new training data during checking. The effectiveness of our robust bound and algorithm is confirmed by the case study of quantum phase recognition. Furthermore, this experiment demonstrates a trade-off between the accuracy of quantum machine learning algorithms and their robustness.","",""
7,"Ming Gao, Runmin Liu, Jie Mao","Noise Robustness Low-Rank Learning Algorithm for Electroencephalogram Signal Classification",2021,"","","","",3,"2022-07-13 09:24:47","","10.3389/fnins.2021.797378","","",,,,,7,7.00,2,3,1,"Electroencephalogram (EEG) is often used in clinical epilepsy treatment to monitor electrical signal changes in the brain of patients with epilepsy. With the development of signal processing and artificial intelligence technology, artificial intelligence classification method plays an important role in the automatic recognition of epilepsy EEG signals. However, traditional classifiers are easily affected by impurities and noise in epileptic EEG signals. To solve this problem, this paper develops a noise robustness low-rank learning (NRLRL) algorithm for EEG signal classification. NRLRL establishes a low-rank subspace to connect the original data space and label space. Making full use of supervision information, it considers the local information preservation of samples to ensure the low-rank representation of within-class compactness and between-classes dispersion. The asymmetric least squares support vector machine (aLS-SVM) is embedded into the objective function of NRLRL. The aLS-SVM finds the maximum quantile distance between the two classes of samples based on the pinball loss function, which further improves the noise robustness of the model. Several classification experiments with different noise intensity are designed on the Bonn data set, and the experiment results verify the effectiveness of the NRLRL algorithm.","",""
19,"Henry Gerdes, P. Casado, A. Dokal, Maruan Hijazi, N. Akhtar, Ruth Osuntola, V. Rajeeve, J. Fitzgibbon, Jon Travers, D. Britton, S. Khorsandi, P. Cutillas","Drug ranking using machine learning systematically predicts the efficacy of anti-cancer drugs",2021,"","","","",4,"2022-07-13 09:24:47","","10.1038/s41467-021-22170-8","","",,,,,19,19.00,2,12,1,"","",""
9,"K. Kunaraj, S. Maria Wenisch, S. Balaji, F. P. Mahimai Don Bosco","Impulse Noise Classification Using Machine Learning Classifier and Robust Statistical Features",2019,"","","","",5,"2022-07-13 09:24:47","","10.1007/978-3-030-37218-7_72","","",,,,,9,3.00,2,4,3,"","",""
13,"A. Anand, Jonathan Romero, M. Degroote, A. Aspuru‐Guzik","Noise Robustness and Experimental Demonstration of a Quantum Generative Adversarial Network for Continuous Distributions",2020,"","","","",6,"2022-07-13 09:24:47","","10.1002/qute.202000069","","",,,,,13,6.50,3,4,2,"The potential advantage of machine learning in quantum computers is a topic of intense discussion in the literature. Theoretical, numerical, and experimental explorations will most likely be required to understand its power. There have been different algorithms proposed to exploit the probabilistic nature of variational quantum circuits for generative modeling. In this paper, a hybrid architecture for quantum generative adversarial networks (QGANs) is employed and their robustness in the presence of noise is studied. A simple way of adding different types of noise to the quantum generator circuit is devised, and the noisy hybrid QGANs (HQGANs) are simulated numerically to learn continuous probability distributions, and to show that the performance of HQGANs remains unaffected. The effect of different parameters on the training time is also investigated to reduce the computational scaling of the algorithm and simplify its deployment on a quantum computer. The training on Rigetti's Aspen‐4‐2Q‐A quantum processing unit is then performed, and the results from the training are presented. The authors' results pave the way for experimental exploration of different quantum machine learning algorithms on noisy intermediate‐scale quantum devices.","",""
14,"S. Boonprong, C. Cao, Wei Chen, X. Ni, Min Xu, B. Acharya","The Classification of Noise-Afflicted Remotely Sensed Data Using Three Machine-Learning Techniques: Effect of Different Levels and Types of Noise on Accuracy",2018,"","","","",7,"2022-07-13 09:24:47","","10.3390/ijgi7070274","","",,,,,14,3.50,2,6,4,"Remotely sensed data are often adversely affected by many types of noise, which influences the classification result. Supervised machine-learning (ML) classifiers such as random forest (RF), support vector machine (SVM), and back-propagation neural network (BPNN) are broadly reported to improve robustness against noise. However, only a few comparative studies that may help investigate this robustness have been reported. An important contribution, going beyond previous studies, is that we perform the analyses by employing the most well-known and broadly implemented packages of the three classifiers and control their settings to represent users’ actual applications. This facilitates an understanding of the extent to which the noise types and levels in remotely sensed data impact classification accuracy using ML classifiers. By using those implementations, we classified the land cover data from a satellite image that was separately afflicted by seven-level zero-mean Gaussian, salt–pepper, and speckle noise. The modeling data and features were strictly controlled. Finally, we discussed how each noise type affects the accuracy obtained from each classifier and the robustness of the classifiers to noise in the data. This may enhance our understanding of the relationship between noises, the supervised ML classifiers, and remotely sensed data.","",""
2,"Zahra Nazari, Masoom Nazari, Mir Sayed Shah, Dongshik Kang","Evaluation of Class Noise Impact on Performance of Machine Learning Algorithms",2018,"","","","",8,"2022-07-13 09:24:47","","","","",,,,,2,0.50,1,4,4,"Real-world datasets are not perfect and always suffer from noise that may affect classifiers built under the effect of such type of disturbance. Different types of noise are existing in almost any real-world problem, but not always known. Existence of noise decreases the accuracy of a classifier and increases its training time and complexity of the induced model. Most of existing machine learning algorithms have integrated different approaches to enhance their learning abilities in presence of noise, but noise still can make negative impacts. Therefore noise robustness of a classifier is an important issue in noisy environments and should be studied. This paper evaluates the robustness of different machine learning algorithms against class noise. The Equalized Loss of Accuracy (ELA) is the robustness metric which is used in this study. Ten benchmark datasets with 0-20% of noise level are used in experiments and finally ELA results of algorithms are compared.","",""
6,"R. Gatto, C. Forster","Audio-Based Machine Learning Model for Traffic Congestion Detection",2021,"","","","",9,"2022-07-13 09:24:47","","10.1109/tits.2020.3003111","","",,,,,6,6.00,3,2,1,"The present work approaches intelligent traffic evaluation and congestion detection using sound sensors and machine learning. For this, two important problems are addressed: traffic condition assessment from audio data, and analysis of audio under uncontrolled environments. By modeling the traffic parameters and the sound generation from passing vehicles and using the produced audio as a source of data for learning the traffic audio patterns, we provide a solution that copes with the time, the cost and the constraints inherent to the activity of traffic monitoring. External noise sources were introduced to produce more realistic acoustic scenes and to verify the robustness of the methods presented. Audio-based monitoring becomes a simple and low-cost option, comparing to other methods based on detector loops, or GPS, and as good as camera-based solutions, without some of the common problems of image-based monitoring, such as occlusions and light conditions. The approach is evaluated with data from audio analysis of traffic registered in locations around the city of São Jose dos Campos, Brazil, and audio files from places around the world, downloaded from YouTube. Its validation shows the feasibility of traffic automatic audio monitoring as well as using machine learning algorithms to recognize audio patterns under noisy environments.","",""
6,"N. Costa, Omar Yasser, A. Sultanov, G. Paraoanu","Benchmarking machine learning algorithms for adaptive quantum phase estimation with noisy intermediate-scale quantum sensors",2021,"","","","",10,"2022-07-13 09:24:47","","10.1140/epjqt/s40507-021-00105-y","","",,,,,6,6.00,2,4,1,"","",""
6,"Q. Gao, Qijie Li, Shaowu Pan, Hongping Wang, Runjie Wei, Jin-jun Wang","Particle reconstruction of volumetric particle image velocimetry with the strategy of machine learning",2019,"","","","",11,"2022-07-13 09:24:47","","10.1186/s42774-021-00087-6","","",,,,,6,2.00,1,6,3,"","",""
3,"Xinjiang Lu, Li Ming, TeTe Hu, Bin Fan","Collaborative Learning-Based Clustered Support Vector Machine for Modeling of Nonlinear Processes Subject to Noise",2020,"","","","",12,"2022-07-13 09:24:47","","10.1109/TSMC.2018.2867238","","",,,,,3,1.50,1,4,2,"The least squares support vector machine (LS-SVM) is often employed to model data with a nonlinear distribution using a divide-and-conquer strategy. However, when nonlinear data are contaminated by either noise or outliers, LS-SVM is often an ineffective approach due to a lack of robustness. In this paper, a collaborative learning-based clustered LS-SVM method is proposed for modeling of nonlinear processes that are subject to noise or outliers. First, a large-scale dataset is divided into several subsets and the data distribution of each subset is estimated. A robust LS-SVM is then developed to represent each subset using this distributional information. A global model is further constructed through integration of all submodels, whose continuity and smoothness are ensured by the development of the collaborative learning technique. As a result, the proposed method considers both the nonlinear distribution of data and the robustness of each submodel, and ensures the continuity and smoothness of the global model. Thus, it can effectively model nonlinear data that is subject to either noise or outliers. As further validation of this approach, both artificial and real cases demonstrated its effectiveness.","",""
15,"Shuyan Zhou, Xiangkai Zeng, Yingqi Zhou, Antonios Anastasopoulos, Graham Neubig","Improving Robustness of Neural Machine Translation with Multi-task Learning",2019,"","","","",13,"2022-07-13 09:24:47","","10.18653/v1/W19-5368","","",,,,,15,5.00,3,5,3,"While neural machine translation (NMT) achieves remarkable performance on clean, in-domain text, performance is known to degrade drastically when facing text which is full of typos, grammatical errors and other varieties of noise. In this work, we propose a multi-task learning algorithm for transformer-based MT systems that is more resilient to this noise. We describe our submission to the WMT 2019 Robustness shared task based on this method. Our model achieves a BLEU score of 32.8 on the shared task French to English dataset, which is 7.1 BLEU points higher than the baseline vanilla transformer trained with clean text.","",""
3,"Justin Morris, Kazim Ergun, Behnam Khaleghi, M. Imani, Baris Aksanli, T. Simunic","HyDREA: Towards More Robust and Efficient Machine Learning Systems with Hyperdimensional Computing",2021,"","","","",14,"2022-07-13 09:24:47","","10.23919/DATE51398.2021.9474218","","",,,,,3,3.00,1,6,1,"Today's systems, especially in the age of federated learning, rely on sending all the data to the cloud, and then use complex algorithms, such as Deep Neural Networks, which require billions of parameters and many hours to train a model. In contrast, the human brain can do much of this learning effortlessly. Hyperdimensional (HD) Computing aims to mimic the behavior of the human brain by utilizing high dimensional representations. This leads to various desirable properties that other Machine Learning (ML) algorithms lack such as: robustness to noise in the system and simple, highly parallel operations. In this paper, we propose HyDREA, a HD computing system that is Robust, Efficient, and Accurate. To evaluate the feasibility of HyDREA in a federated learning environment with wireless communication noise, we utilize NS-3, a popular network simulator that models a real world environment with wireless communication noise. We found that HyDREA is 48× more robust to noise than other comparable ML algorithms. We additionally propose a Processing-in-Memory (PIM) architecture that adaptively changes the bitwidth of the model based on the signal to noise ratio (SNR) of the incoming sample to maintain the robustness of the HD model while achieving high accuracy and energy efficiency. Our results indicate that our proposed system loses less than 1% classification accuracy, even in scenarios with an SNR of 6.64. Our PIM architecture is also able to achieve 255× better energy efficiency and speed up execution time by 28× compared to the baseline PIM architecture.","",""
484,"Kangwook Lee, Maximilian Lam, Ramtin Pedarsani, Dimitris Papailiopoulos, K. Ramchandran","Speeding Up Distributed Machine Learning Using Codes",2015,"","","","",15,"2022-07-13 09:24:47","","10.1109/TIT.2017.2736066","","",,,,,484,69.14,97,5,7,"Codes are widely used in many engineering applications to offer <italic>robustness</italic> against <italic>noise</italic>. In large-scale systems, there are several types of noise that can affect the performance of distributed machine learning algorithms—straggler nodes, system failures, or communication bottlenecks—but there has been little interaction cutting across codes, machine learning, and distributed systems. In this paper, we provide theoretical insights on how <italic>coded</italic> solutions can achieve significant gains compared with uncoded ones. We focus on two of the most basic building blocks of distributed learning algorithms: <italic>matrix multiplication</italic> and <italic>data shuffling</italic>. For matrix multiplication, we use codes to alleviate the effect of stragglers and show that if the number of homogeneous workers is <inline-formula> <tex-math notation=""LaTeX"">$n$ </tex-math></inline-formula>, and the runtime of each subtask has an exponential tail, coded computation can speed up distributed matrix multiplication by a factor of <inline-formula> <tex-math notation=""LaTeX"">$\log n$ </tex-math></inline-formula>. For data shuffling, we use codes to reduce communication bottlenecks, exploiting the excess in storage. We show that when a constant fraction <inline-formula> <tex-math notation=""LaTeX"">$\alpha $ </tex-math></inline-formula> of the data matrix can be cached at each worker, and <inline-formula> <tex-math notation=""LaTeX"">$n$ </tex-math></inline-formula> is the number of workers, <italic>coded shuffling</italic> reduces the communication cost by a factor of <inline-formula> <tex-math notation=""LaTeX"">$\left({\alpha + \frac {1}{n}}\right)\gamma (n)$ </tex-math></inline-formula> compared with uncoded shuffling, where <inline-formula> <tex-math notation=""LaTeX"">$\gamma (n)$ </tex-math></inline-formula> is the ratio of the cost of unicasting <inline-formula> <tex-math notation=""LaTeX"">$n$ </tex-math></inline-formula> messages to <inline-formula> <tex-math notation=""LaTeX"">$n$ </tex-math></inline-formula> users to multicasting a common message (of the same size) to <inline-formula> <tex-math notation=""LaTeX"">$n$ </tex-math></inline-formula> users. For instance, <inline-formula> <tex-math notation=""LaTeX"">$\gamma (n) \simeq n$ </tex-math></inline-formula> if multicasting a message to <inline-formula> <tex-math notation=""LaTeX"">$n$ </tex-math></inline-formula> users is as cheap as unicasting a message to one user. We also provide experimental results, corroborating our theoretical gains of the coded algorithms.","",""
18,"Yohei Nishizaki, R. Horisaki, K. Kitaguchi, M. Saito, J. Tanida","Analysis of non-iterative phase retrieval based on machine learning",2020,"","","","",16,"2022-07-13 09:24:47","","10.1007/s10043-019-00574-8","","",,,,,18,9.00,4,5,2,"","",""
17,"Jaskaran Singh, M. Azamfar, Fei Li, Jay Lee","A systematic review of machine learning algorithms for prognostics and health management of rolling element bearings: fundamentals, concepts and applications",2020,"","","","",17,"2022-07-13 09:24:47","","10.1088/1361-6501/ab8df9","","",,,,,17,8.50,4,4,2,"This article aims to present a comprehensive review of the recent efforts and advances in applying machine learning (ML) techniques in the area of diagnostics and prognostics of rolling element bearings. The significant goal of this study is to review, recognize and evaluate the performance of various ML techniques and compare them on criteria's such as reliability, accuracy, robustness to noise, data volume requirements and implementation aspects. The merits and demerits of the reviewed ML techniques have been comprehensively analyzed and discussed. A comparative benchmarking of the performance of the reviewed ML algorithms is provided both from the viewpoint of theoretical aspects and industrial applicability. Finally, the potential challenges that come along with the implementation of ML technology are discussed in detail that will likely play a major role in prognostics and health management of rolling element bearings. It is expected that this review would serve as a reference point for researchers to explore the opportunities for further improvement in the field of ML-based fault diagnosis and prognosis of rolling element bearings.","",""
7,"Eric Minor, Stian D. Howard, Adam A S Green, M. Glaser, C. Park, N. Clark","End-to-end machine learning for experimental physics: using simulated data to train a neural network for object detection in video microscopy.",2019,"","","","",18,"2022-07-13 09:24:47","","10.1039/c9sm01979k","","",,,,,7,2.33,1,6,3,"We demonstrate a method for training a convolutional neural network with simulated images for usage on real-world experimental data. Modern machine learning methods require large, robust training data sets to generate accurate predictions. Generating these large training sets requires a significant up-front time investment that is often impractical for small-scale applications. Here we demonstrate a 'full-stack' computational solution, where the training data set is generated on-the-fly using a noise injection process to produce simulated data characteristic of the experimental system. We demonstrate the power of this full-stack approach by applying it to the study of topological defect annihilation in systems of liquid crystal freely-suspended films. This specific experimental system requires accurate observations of both the spatial distribution of the defects and the total number of defects, making it an ideal system for testing the robustness of the trained network. The fully trained network was found to be comparable in accuracy to human hand-annotation, with four-orders of magnitude improvement in time efficiency.","",""
6,"Yashar Deldjoo, T. D. Noia, Felice Antonio Merra","Adversarial Machine Learning in Recommender Systems: State of the art and Challenges",2020,"","","","",19,"2022-07-13 09:24:47","","","","",,,,,6,3.00,2,3,2,"Latent-factor models (LFM) based on collaborative filtering (CF), such as matrix factorization (MF) and deep CF methods, are widely used in modern recommender systems (RS) due to their excellent performance and recommendation accuracy. Notwithstanding their great success, in recent years, it has been shown that these methods are vulnerable to adversarial examples, i.e., subtle but non-random perturbations designed to force recommendation models to produce erroneous outputs. The main reason for this behavior is that user interaction data used for training of LFM can be contaminated by malicious activities or users' misoperation that can induce an unpredictable amount of natural noise and harm recommendation outcomes. On the other side, it has been shown that these systems, conceived originally to attack machine learning applications, can be successfully adopted to strengthen their robustness against attacks as well as to train more precise recommendation engines. In this respect, the goal of this survey is two-fold: (i) to present recent advances on AML-RS for the security of RS (i.e., attacking and defense recommendation models), (ii) to show another successful application of AML in generative adversarial networks (GANs), which use the core concept of learning in AML (i.e., the min-max game) for generative applications. In this survey, we provide an exhaustive literature review of 60 articles published in major RS and ML journals and conferences. This review serves as a reference for the RS community, working on the security of RS and recommendation models leveraging generative models to improve their quality.","",""
8,"Christina Frederick, Soledad Villar, Z. Michalopoulou","Seabed classification using physics-based modeling and machine learning.",2020,"","","","",20,"2022-07-13 09:24:47","","10.1121/10.0001728","","",,,,,8,4.00,3,3,2,"In this work, model-based methods are employed, along with machine learning techniques, to classify sediments in oceanic environments based on the geoacoustic properties of a two-layer seabed. Two different scenarios are investigated. First, a simple low-frequency case is set up, in which the acoustic field is modeled with normal modes. Four different hypotheses are made for seafloor sediment possibilities, and these are explored using both various machine learning techniques and a simple matched-field approach. For most noise levels, the latter has an inferior performance to the machine learning methods. Second, the high-frequency model of the scattering from a rough, two-layer seafloor is considered. Again, four different sediment possibilities are classified with machine learning. For higher accuracy, one-dimensional convolutional neural networks are employed. In both cases, the machine learning methods, both in simple and more complex formulations, lead to effective sediment characterization. The results assess the robustness to noise and model misspecification of different classifiers.","",""
6,"S. Daraeizadeh, S. Premaratne, N. Khammassi, X. Song, M. Perkowski, A. Matsuura","Machine-learning-based three-qubit gate design for the Toffoli gate and parity check in transmon systems",2020,"","","","",21,"2022-07-13 09:24:47","","10.1103/physreva.102.012601","","",,,,,6,3.00,1,6,2,"We use machine-learning techniques to design three-qubit entangling gates with fidelities of g99.9% and duration of 50 ns for nearest-neighbor coupled flux-tunable transmons in circuit quantum electrodynamics architectures. The gate design procedure enforces realistic constraints and analyzes the robustness of the new gates under decoherence, distortion, and random noise. The controlled-controlled-phase gate in combination with two single-qubit gates realizes a Toffoli gate which is widely used in quantum circuits, logic synthesis, and quantum error correction. We also introduce a three-qubit entangling Parity Checker gate which has applications in quantum arithmetic circuits and quantum error correction schemes. Using these three-qubit gates, we design a circuit for Shor's nine-qubit quantum error correction code and compare its performance to conventional realizations.","",""
11,"Ayesha Pervaiz, F. Hussain, Humayun Israr, M. Tahir, Fawad Riasat Raja, N. K. Baloch, Farruh Ishmanov, Yousaf Bin Zikria","Incorporating Noise Robustness in Speech Command Recognition by Noise Augmentation of Training Data",2020,"","","","",22,"2022-07-13 09:24:47","","10.3390/s20082326","","",,,,,11,5.50,1,8,2,"The advent of new devices, technology, machine learning techniques, and the availability of free large speech corpora results in rapid and accurate speech recognition. In the last two decades, extensive research has been initiated by researchers and different organizations to experiment with new techniques and their applications in speech processing systems. There are several speech command based applications in the area of robotics, IoT, ubiquitous computing, and different human-computer interfaces. Various researchers have worked on enhancing the efficiency of speech command based systems and used the speech command dataset. However, none of them catered to noise in the same. Noise is one of the major challenges in any speech recognition system, as real-time noise is a very versatile and unavoidable factor that affects the performance of speech recognition systems, particularly those that have not learned the noise efficiently. We thoroughly analyse the latest trends in speech recognition and evaluate the speech command dataset on different machine learning based and deep learning based techniques. A novel technique is proposed for noise robustness by augmenting noise in training data. Our proposed technique is tested on clean and noisy data along with locally generated data and achieves much better results than existing state-of-the-art techniques, thus setting a new benchmark.","",""
6,"R. Alata, J. Pauwels, M. Haelterman, S. Massar","Phase Noise Robustness of a Coherent Spatially Parallel Optical Reservoir",2020,"","","","",23,"2022-07-13 09:24:47","","10.1109/JSTQE.2019.2929181","","",,,,,6,3.00,2,4,2,"Reservoir computing is a machine learning algorithm particularly adapted to process time-dependent signals. It can be easily implemented experimentally with good performance. However experimental implementations are subject to noise, which degrades performance. We develop strategies to mitigate the effects of noise. The specific system on which we illustrate our approaches—currently under development in our laboratory—is a coherent linear Fabry–Perot resonator in which neurons are encoded as a grid of spots on the input mirror plane. In this system, changes in the length of the resonator are the major source of noise and can be modeled as phase noise. This can in principle be partially solved by active stabilisation, but it is interesting to find other strategies to counter the effect of phase noise. We show that a completely unknown phase can be tolerated with only a small degradation of performance by using appropriate training and a readout layer architecture in which the output weights depend on the noisy parameter (the phase). Furthermore, the phase can be estimated by the reservoir itself, leading to an architecture in which the reservoir has two outputs, one of which (the phase estimation) is used to control the other. Our approach should find applications in many experimental implementations of reservoir computing.","",""
5,"Andrew Hines, P. Kendrick, A. Barri, Manish Narwaria, J. Redi","Robustness and prediction accuracy of Machine Learning for objective visual quality assessment",2014,"","","","",24,"2022-07-13 09:24:47","","","","",,,,,5,0.63,1,5,8,"Machine Learning (ML) is a powerful tool to support the development of objective visual quality assessment metrics, serving as a substitute model for the perceptual mechanisms acting in visual quality appreciation. Nevertheless, the reliability of ML-based techniques within objective quality assessment metrics is often questioned. In this study, the robustness of ML in supporting objective quality assessment is investigated, specifically when the feature set adopted for prediction is suboptimal. A Principal Component Regression based algorithm and a Feed Forward Neural Network are compared when pooling the Structural Similarity Index (SSIM) features perturbed with noise. The neural network adapts better with noise and intrinsically favours features according to their salient content.","",""
25,"R. Pugalenthi, M. Rajakumar, J. Ramya, V. Rajinikanth","Evaluation and Classification of the Brain Tumor MRI using Machine Learning Technique",2019,"","","","",25,"2022-07-13 09:24:47","","","","",,,,,25,8.33,6,4,3,"The proposed work implements a Machine-Learning-Technique (MLT) to evaluate and classify the tumor regions into low/high grade based on the analysis carriedout with the brain MRI slices. The MLT implements a sequence of procedures, such as pre-processing, post-processing and classification procedures. The pre-processing enhances the tumor section based on Social Group Optimization (SGO) algorithm assisted Fuzzy-Tsallis thresholding. The robustness of the proposed thresholding is also confirmed by considering the noise corrupted MRI slices.  The post-processing implements the Level-Set Segmentation (LSS) to mine the tumor region. The performance of the LSS is validated with segmentation procedures, like Active-Contour (ACS) and Chan-Vese (CVS) technique. The fundamental data of the tumor section is then extracted using the Gray Level Co-occurrence Matrix (GLCM) and most dominating features are then chosen with a statistical test. Finally, a two-class classifier is implemented using the Support Vector Machine with Radial Basis Function (SVM-RBF) kernel and its performance is then validated with  other classifiers, like the Random-Forest and k-Nearest Neighbor. The outcome of the proposed work confirms that, implemented tool with the SVM-RBF helps to achieve an accuracy of >94% on the benchmark BRATS2015 database.","",""
17,"Faizal M. F. Hafiz, A. Swain, C. Naik, Scott Abecrombie, Andrew Eaton","Identification of power quality events: selection of optimum base wavelet and machine learning algorithm",2019,"","","","",26,"2022-07-13 09:24:47","","10.1049/IET-SMT.2018.5044","","",,,,,17,5.67,3,5,3,"This study comprehensively investigates power quality (PQ) identification problem and proposes the optimum combination of base wavelet and machine learning algorithm (MLA) which would yield the highest classification accuracy. Although this problem has been studied by various researchers in the recent past, the selection of appropriate base wavelet and MLA, which would give better classification accuracy, have received comparatively less attention. This study bridges this gap by investigating the classification performance of 110 wavelets and 7 well-known MLAs across various noise levels using over 3500 PQ events generated as per IEEE Standard 1159. The results of this investigation demonstrate that the choice of base wavelet does significantly affect the classification performance. Further, it was observed that a single base wavelet does not provide optimum performance across all MLAs at various noise levels. In contrast, each MLA gives the maximum accuracy with a distinct base wavelet. The robustness of MLA against noise is studied which establishes that the simple MLAs, such as decision tree and Naive-Bayes, are more robust against noise compared to the other intricate MLAs. Finally, several recommendations are drawn for the selection of base wavelet and MLA which yields the best possible accuracy.","",""
13,"N. D. Truong, J. Y. Haw, S. Assad, P. Lam, O. Kavehei","Machine Learning Cryptanalysis of a Quantum Random Number Generator",2019,"","","","",27,"2022-07-13 09:24:47","","10.1109/TIFS.2018.2850770","","",,,,,13,4.33,3,5,3,"Random number generators (RNGs) that are crucial for cryptographic applications have been the subject of adversarial attacks. These attacks exploit environmental information to predict generated random numbers that are supposed to be truly random and unpredictable. Though quantum random number generators (QRNGs) are based on the intrinsic indeterministic nature of quantum properties, the presence of classical noise in the measurement process compromises the integrity of a QRNG. In this paper, we develop a predictive machine learning (ML) analysis to investigate the impact of deterministic classical noise in different stages of an optical continuous variable QRNG. Our ML model successfully detects inherent correlations when the deterministic noise sources are prominent. After appropriate filtering and randomness extraction processes are introduced, our QRNG system, in turn, demonstrates its robustness against ML. We further demonstrate the robustness of our ML approach by applying it to uniformly distributed random numbers from the QRNG and a congruential RNG. Hence, our result shows that ML has potentials in benchmarking the quality of RNG devices.","",""
6,"Roberto Medico, D. Spina, D. Vande Ginste, D. Deschrijver, T. Dhaene","Machine-Learning-Based Error Detection and Design Optimization in Signal Integrity Applications",2019,"","","","",28,"2022-07-13 09:24:47","","10.1109/TCPMT.2019.2916902","","",,,,,6,2.00,1,5,3,"Evaluating the robustness of integrated circuits (ICs) against noise and disturbances is of crucial importance in signal integrity (SI) applications. In this paper, the addressed challenge is to build a software-based framework allowing for automated detection of failures and fast simulation-based evaluation of designs. In particular, these tasks are here addressed using anomaly detection (AD), a branch of machine learning (ML) techniques focused on identifying erroneous or deviant data. In the proposed framework, the ML model only requires the time-domain waveforms and no additional knowledge about the circuit nor about the errors to be identified. Specifically, a two-step approach to detect anomalous behaviors in output waveforms of digital ICs is proposed, comprising a first phase where the ML models are trained to learn relevant features describing the data and a second one where those features are used to identify anomalies with unsupervised or semisupervised AD techniques. Two relevant application examples validate the performance and flexibility of the proposed method.","",""
14,"Yaoqing Yang, Rekha Khanna, Yaodong Yu, A. Gholami, K. Keutzer, Joseph Gonzalez, K. Ramchandran, M. Mahoney","Boundary thickness and robustness in learning models",2020,"","","","",29,"2022-07-13 09:24:47","","","","",,,,,14,7.00,2,8,2,"Robustness of machine learning models to various adversarial and non-adversarial corruptions continues to be of interest. In this paper, we introduce the notion of the boundary thickness of a classifier, and we describe its connection with and usefulness for model robustness. Thick decision boundaries lead to improved performance, while thin decision boundaries lead to overfitting (e.g., measured by the robust generalization gap between training and testing) and lower robustness. We show that a thicker boundary helps improve robustness against adversarial examples (e.g., improving the robust test accuracy of adversarial training) as well as so-called out-of-distribution (OOD) transforms, and we show that many commonly-used regularization and data augmentation procedures can increase boundary thickness. On the theoretical side, we establish that maximizing boundary thickness during training is akin to the so-called mixup training. Using these observations, we show that noise-augmentation on mixup training further increases boundary thickness, thereby combating vulnerability to various forms of adversarial attacks and OOD transforms. We can also show that the performance improvement in several lines of recent work happens in conjunction with a thicker boundary.","",""
178,"J. Otterbach, R. Manenti, N. Alidoust, A. Bestwick, M. Block, B. Bloom, S. Caldwell, N. Didier, E. Fried, S. Hong, Peter J. Karalekas, C. Osborn, A. Papageorge, E. C. Peterson, G. Prawiroatmodjo, N. Rubin, C. Ryan, D. Scarabelli, M. Scheer, E. A. Sete, P. Sivarajah, Robert S. Smith, A. Staley, N. Tezak, W. Zeng, A. Hudson, Blake R. Johnson, M. Reagor, M. Silva, C. Rigetti","Unsupervised Machine Learning on a Hybrid Quantum Computer",2017,"","","","",30,"2022-07-13 09:24:47","","","","",,,,,178,35.60,18,30,5,"Machine learning techniques have led to broad adoption of a statistical model of computing. The statistical distributions natively available on quantum processors are a superset of those available classically. Harnessing this attribute has the potential to accelerate or otherwise improve machine learning relative to purely classical performance. A key challenge toward that goal is learning to hybridize classical computing resources and traditional learning techniques with the emerging capabilities of general purpose quantum processors. Here, we demonstrate such hybridization by training a 19-qubit gate model processor to solve a clustering problem, a foundational challenge in unsupervised learning. We use the quantum approximate optimization algorithm in conjunction with a gradient-free Bayesian optimization to train the quantum machine. This quantum/classical hybrid algorithm shows robustness to realistic noise, and we find evidence that classical optimization can be used to train around both coherent and incoherent imperfections.","",""
2,"Xu Zhou, Pak Lun Kevin Ding, Baoxin Li","Improving Robustness of Random Forest Under Label Noise",2019,"","","","",31,"2022-07-13 09:24:47","","10.1109/WACV.2019.00106","","",,,,,2,0.67,1,3,3,"Random forest is a well-known and widely-used machine learning model. In many applications where the training data arise from real-world sources, there may be labeling errors in the data. In spite of its superior performance, the basic model of random forest dose not consider potential label noise in learning, and thus its performance can suffer significantly in the presence of label noise. In order to solve this problem, we present a new variation of random forest - a novel learning approach that leads to an improved noise robust random forest (NRRF) model. We incorporate the noise information by introducing a global multi-class noise tolerant loss function into the training of the classic random forest model. This new loss function was found to significantly boost the performance of random forest. We evaluated the proposed NRRF by extensive experiments of classification tasks on standard machine learning/computer vision datasets like MNIST, letter and Cifar10. The proposed NRRF produced very promising results under a wide range of noise settings.","",""
23,"J. Gröhl, T. Kirchner, T. Adler, L. Maier-Hein","Confidence Estimation for Machine Learning-Based Quantitative Photoacoustics",2018,"","","","",32,"2022-07-13 09:24:47","","10.3390/jimaging4120147","","",,,,,23,5.75,6,4,4,"In medical applications, the accuracy and robustness of imaging methods are of crucial importance to ensure optimal patient care. While photoacoustic imaging (PAI) is an emerging modality with promising clinical applicability, state-of-the-art approaches to quantitative photoacoustic imaging (qPAI), which aim to solve the ill-posed inverse problem of recovering optical absorption from the measurements obtained, currently cannot comply with these high standards. This can be attributed to the fact that existing methods often rely on several simplifying a priori assumptions of the underlying physical tissue properties or cannot deal with realistic noise levels. In this manuscript, we address this issue with a new method for estimating an indicator of the uncertainty of an estimated optical property. Specifically, our method uses a deep learning model to compute error estimates for optical parameter estimations of a qPAI algorithm. Functional tissue parameters, such as blood oxygen saturation, are usually derived by averaging over entire signal intensity-based regions of interest (ROIs). Therefore, we propose to reduce the systematic error of the ROI samples by additionally discarding those pixels for which our method estimates a high error and thus a low confidence. In silico experiments show an improvement in the accuracy of optical absorption quantification when applying our method to refine the ROI, and it might thus become a valuable tool for increasing the robustness of qPAI methods.","",""
20,"Changjiang Shi","Signal Pattern Recognition Based on Fractal Features and Machine Learning",2018,"","","","",33,"2022-07-13 09:24:47","","10.3390/APP8081327","","",,,,,20,5.00,20,1,4,"As a typical pattern recognition method, communication signal modulation involves many complicated factors. Fractal theory can be used for signal modulation feature extraction and recognition because of its good ability to express complex information. In this paper, we conduct a systematic research study by using the fractal dimension as the feature of modulation signals. Box fractal dimension, Katz fractal dimension, Higuchi fractal dimension, Petrosian fractal dimension, and Sevcik fractal dimension are extracted from eight different modulation signals for signal pattern recognition. Meanwhile, the anti-noise function, box-diagram, and running time are used to evaluate the noise robustness, separability, and computational complexity of five different fractal features. Finally, Bback-Propagation (BP) neural network, grey relation analysis, random forest, and K-nearest neighbor are proposed to classify the different modulation signals based on these fractal features. The confusion matrices and recognition results are provided in the experimental section. They indicate that random forest had a better recognition performance, which could reach 96% in 10 dB.","",""
15,"Signe Moe, A. M. Rustad, K. G. Hanssen","Machine Learning in Control Systems: An Overview of the State of the Art",2018,"","","","",34,"2022-07-13 09:24:47","","10.1007/978-3-030-04191-5_23","","",,,,,15,3.75,5,3,4,"","",""
14,"R. Gupta, M. Biercuk","Machine Learning for Predictive Estimation of Qubit Dynamics Subject to Dephasing",2017,"","","","",35,"2022-07-13 09:24:47","","10.1103/PhysRevApplied.9.064042","","",,,,,14,2.80,7,2,5,"Decoherence remains a major challenge in quantum computing hardware and a variety of physical-layer controls provide opportunities to mitigate the impact of this phenomenon through feedback and feedforward control. In this work, we compare a variety of machine learning algorithms derived from diverse fields for the task of state estimation (retrodiction) and forward prediction of future qubit state evolution for a single qubit subject to classical, non-Markovian dephasing. Our approaches involve the construction of a dynamical model capturing qubit dynamics via autoregressive or Fourier-type protocols using only a historical record of projective measurements. A detailed comparison of achievable prediction horizons, model robustness, and measurement-noise-filtering capabilities for Kalman Filters (KF) and Gaussian Process Regression (GPR) algorithms is provided. We demonstrate superior performance from the autoregressive KF relative to Fourier-based KF approaches and focus on the role of filter optimization in achieving suitable performance. Finally, we examine several realizations of GPR using different kernels and discover that these approaches are generally not suitable for forward prediction. We highlight the underlying failure mechanism in this application and identify ways in which the output of the algorithm may be misidentified numerical artefacts.","",""
11,"S. P. Singh, Sharan Janjuha, Samata Chaudhuri, Susanne Reinhardt, A. Kränkel, S. Dietz, A. Eugster, Halil I. Bilgin, Selçuk Korkmaz, G. Zararsiz, N. Ninov, John E. Reid","Machine learning based classification of cells into chronological stages using single-cell transcriptomics",2018,"","","","",36,"2022-07-13 09:24:47","","10.1038/s41598-018-35218-5","","",,,,,11,2.75,1,12,4,"","",""
18,"R. Ormiston, Tri Nguyen, M. Coughlin, R. Adhikari, E. Katsavounidis","Noise reduction in gravitational-wave data via deep learning",2020,"","","","",37,"2022-07-13 09:24:47","","10.1103/PHYSREVRESEARCH.2.033066","","",,,,,18,9.00,4,5,2,"With the advent of gravitational wave astronomy, techniques to extend the reach of gravitational wave detectors are desired. In addition to the stellar-mass black hole and neutron star mergers already detected, many more are below the surface of the noise, available for detection if the noise is reduced enough. Our method (DeepClean) applies machine learning algorithms to gravitational wave detector data and data from on-site sensors monitoring the instrument to reduce the noise in the time-series due to instrumental artifacts and environmental contamination. This framework is generic enough to subtract linear, non-linear, and non-stationary coupling mechanisms. It may also provide handles in learning about the mechanisms which are not currently understood to be limiting detector sensitivities. The robustness of the noise reduction technique in its ability to efficiently remove noise with no unintended effects on gravitational-wave signals is also addressed through software signal injection and parameter estimation of the recovered signal. It is shown that the optimal SNR ratio of the injected signal is enhanced by $\sim 21.6\%$ and the recovered parameters are consistent with the injected set. We present the performance of this algorithm on linear and non-linear noise sources and discuss its impact on astrophysical searches by gravitational wave detectors.","",""
6,"B. Zhao, S. Wolter, J. Greenberg","Application of machine learning to x-ray diffraction-based classification",2018,"","","","",38,"2022-07-13 09:24:47","","10.1117/12.2304683","","",,,,,6,1.50,2,3,4,"X-ray diffraction-based baggage screening provides the potential for the material sensitivity needed to realize high detection probabilities and low false alarm rates. However, the combination of noisy signals, variability in the XRD form factors based on slight material differences, and incomplete material libraries lead to decreased system performance. By using a machine learning classification approach to XRD-based explosives detection, we show that the probability of error can be reduced relative to traditional, correlation-based classifiers. This improved performance exists at a variety of noise levels and degrees of library completeness, and indicates a path toward increased XRD-based classifier robustness.","",""
4,"Liang-Rui Ren, Ying-Lian Gao, Jin-Xing Liu, J. Shang, C. Zheng","Correntropy induced loss based sparse robust graph regularized extreme learning machine for cancer classification",2020,"","","","",39,"2022-07-13 09:24:47","","10.1186/s12859-020-03790-1","","",,,,,4,2.00,1,5,2,"","",""
48,"Rodolphe Jenatton, R. Gribonval, F. Bach","Local stability and robustness of sparse dictionary learning in the presence of noise",2012,"","","","",40,"2022-07-13 09:24:47","","","","",,,,,48,4.80,16,3,10,"A popular approach within the signal processing and machine learning communities consists in modelling signals as sparse linear combinations of atoms selected from a learned dictionary. While this paradigm has led to numerous empirical successes in various fields ranging from image to audio processing, there have only been a few theoretical arguments supporting these evidences. In particular, sparse coding, or sparse dictionary learning, relies on a non-convex procedure whose local minima have not been fully analyzed yet. In this paper, we consider a probabilistic model of sparse signals, and show that, with high probability, sparse coding admits a local minimum around the reference dictionary generating the signals. Our study takes into account the case of over-complete dictionaries and noisy signals, thus extending previous work limited to noiseless settings and/or under-complete dictionaries. The analysis we conduct is non-asymptotic and makes it possible to understand how the key quantities of the problem, such as the coherence or the level of noise, can scale with respect to the dimension of the signals, the number of atoms, the sparsity and the number of observations.","",""
6,"Yao Qian, Rutuja Ubale, P. Lange, Keelan Evanini, Vikram Ramanarayanan, F. Soong","Spoken Language Understanding of Human-Machine Conversations for Language Learning Applications",2020,"","","","",41,"2022-07-13 09:24:47","","10.1007/s11265-019-01484-3","","",,,,,6,3.00,1,6,2,"","",""
3,"Ming-Kun Xie, Sheng-Jun Huang","CCMN: A General Framework for Learning with Class-Conditional Multi-Label Noise",2021,"","","","",42,"2022-07-13 09:24:47","","10.1109/TPAMI.2022.3141240","","",,,,,3,3.00,2,2,1,"Class-conditional noise commonly exists in machine learning tasks, where the class label is corrupted with a probability depending on its ground-truth. Many research efforts have been made to improve the model robustness against the class-conditional noise. However, they typically focus on the single label case by assuming that only one label is corrupted. In real applications, an instance is usually associated with multiple labels, which could be corrupted simultaneously with their respective conditional probabilities. In this paper, we formalize this problem as a general framework of learning with Class-Conditional Multi-label Noise (CCMN for short). We establish two unbiased estimators with error bounds for solving the CCMN problems, and further prove that they are consistent with commonly used multi-label loss functions. Finally, a new method for partial multi-label learning is implemented with the unbiased estimator under the CCMN framework. Empirical studies on multiple datasets and various evaluation metrics validate the effectiveness of the proposed method.","",""
62,"E. Zahedinejad, J. Ghosh, B. Sanders","Designing High-Fidelity Single-Shot Three-Qubit Gates: A Machine Learning Approach",2015,"","","","",43,"2022-07-13 09:24:47","","10.1103/PHYSREVAPPLIED.6.054005","","",,,,,62,8.86,21,3,7,"Three-qubit quantum gates are key ingredients for quantum error correction and quantum information processing. We generate quantum-control procedures to design three types of three-qubit gates, namely Toffoli, Controlled-Not-Not and Fredkin gates. The design procedures are applicable to a system comprising three nearest-neighbor-coupled superconducting artificial atoms. For each three-qubit gate, the numerical simulation of the proposed scheme achieves 99.9% fidelity, which is an accepted threshold fidelity for fault-tolerant quantum computing. We test our procedure in the presence of decoherence-induced noise as well as show its robustness against random external noise generated by the control electronics. The three-qubit gates are designed via the machine learning algorithm called Subspace-Selective Self-Adaptive Differential Evolution (SuSSADE).","",""
29,"Md. Khayrul Bashar, Ishio Chiaki, Hiroaki Yoshida","Human identification from brain EEG signals using advanced machine learning method EEG-based biometrics",2016,"","","","",44,"2022-07-13 09:24:47","","10.1109/IECBES.2016.7843496","","",,,,,29,4.83,10,3,6,"EEG-based human recognition is increasingly becoming a popular modality for biometric authentication. Two important features of EEG signals are liveliness and the robustness against falsification. However, a comprehensive study on human authentication using EEG signal is still remains. On the other hand, low-cost wireless EEG recording devices are now growing in the market places. Although these devices have the potential to many applications, researches have yet to be done to find the feasibility of these devices. In this study, we propose a method for human identification using EEG signals obtained from such low-cost devices. EEG signal is first preprocessed to remove noise and artifacts using Bandpass FIR filter. These signals are then divided into disjoint segments. Three feature extraction methods, namely multiscale shape description (MSD), multiscale wavelet packet statistics (WPS) and multiscale wavelet packet energy statistics (WPES) are then applied. These features are finally used to train a supervised error-correcting output code multiclass model (ECOC) using support vector machine (SVM) classifier, which ultimately can recognize humans from test EEG signals. A preliminary experiment with 9 EEG records from 9 subjects shows the true positive rate of 94.44% of the proposed method.","",""
26,"Yen-Kai Cheng, Hsin-Jui Chou, Ronald Y. Chang","Machine-Learning Indoor Localization with Access Point Selection and Signal Strength Reconstruction",2016,"","","","",45,"2022-07-13 09:24:47","","10.1109/VTCSpring.2016.7504333","","",,,,,26,4.33,9,3,6,"Indoor localization technique is a key enabling technology for the future Internet of things (IoT) paradigm. Improving the precision of indoor localization will expand the horizon of indoor IoT applications. In this paper, we propose an enhanced machine-learning indoor localization scheme which incorporates access point (AP) selection and the proposed signal strength reconstruction to enhance robustness in noisy environments. The proposed signal strength reconstruction scheme estimates/reconstructs the received signal strength indicator (RSSI) values of the nonselected APs from those of the selected APs to increase the size of the feature space for enhanced noise robustness. The proposed concept can be applied to various machine-learning frameworks. Simulation results demonstrate improved precision yielded by the proposed method in conjunction with support vector regression (SVR), ensemble SVR, and artificial neural network (ANN) models, as compared to these machine- learning techniques alone.","",""
83,"Evangelos Stromatias, Daniel Neil, Michael Pfeiffer, F. Galluppi, S. Furber, Shih-Chii Liu","Robustness of spiking Deep Belief Networks to noise and reduced bit precision of neuro-inspired hardware platforms",2015,"","","","",46,"2022-07-13 09:24:47","","10.3389/fnins.2015.00222","","",,,,,83,11.86,14,6,7,"Increasingly large deep learning architectures, such as Deep Belief Networks (DBNs) are the focus of current machine learning research and achieve state-of-the-art results in different domains. However, both training and execution of large-scale Deep Networks require vast computing resources, leading to high power requirements and communication overheads. The on-going work on design and construction of spike-based hardware platforms offers an alternative for running deep neural networks with significantly lower power consumption, but has to overcome hardware limitations in terms of noise and limited weight precision, as well as noise inherent in the sensor signal. This article investigates how such hardware constraints impact the performance of spiking neural network implementations of DBNs. In particular, the influence of limited bit precision during execution and training, and the impact of silicon mismatch in the synaptic weight parameters of custom hybrid VLSI implementations is studied. Furthermore, the network performance of spiking DBNs is characterized with regard to noise in the spiking input signal. Our results demonstrate that spiking DBNs can tolerate very low levels of hardware bit precision down to almost two bits, and show that their performance can be improved by at least 30% through an adapted training mechanism that takes the bit precision of the target platform into account. Spiking DBNs thus present an important use-case for large-scale hybrid analog-digital or digital neuromorphic platforms such as SpiNNaker, which can execute large but precision-constrained deep networks in real time.","",""
26,"Yuxuan Du, Min-Hsiu Hsieh, Tongliang Liu, D. Tao, Nana Liu","Quantum noise protects quantum classifiers against adversaries",2020,"","","","",47,"2022-07-13 09:24:47","","10.1103/PhysRevResearch.3.023153","","",,,,,26,13.00,5,5,2,"Noise in quantum information processing is often viewed as a disruptive and difficult-to-avoid feature, especially in near-term quantum technologies. However, noise has often played beneficial roles, from enhancing weak signals in stochastic resonance to protecting the privacy of data in differential privacy. It is then natural to ask, can we harness the power of quantum noise that is beneficial to quantum computing? An important current direction for quantum computing is its application to machine learning, such as classification problems. One outstanding problem in machine learning for classification is its sensitivity to adversarial examples. These are small, undetectable perturbations from the original data where the perturbed data is completely misclassified in otherwise extremely accurate classifiers. They can also be considered as `worst-case' perturbations by unknown noise sources. We show that by taking advantage of depolarisation noise in quantum circuits for classification, a robustness bound against adversaries can be derived where the robustness improves with increasing noise. This robustness property is intimately connected with an important security concept called differential privacy which can be extended to quantum differential privacy. For the protection of quantum data, this is the first quantum protocol that can be used against the most general adversaries. Furthermore, we show how the robustness in the classical case can be sensitive to the details of the classification model, but in the quantum case the details of classification model are absent, thus also providing a potential quantum advantage for classical data that is independent of quantum speedups. This opens the opportunity to explore other ways in which quantum noise can be used in our favour, as well as identifying other ways quantum algorithms can be helpful that is independent of quantum speedups.","",""
24,"Florin Isaila, Prasanna Balaprakash, Stefan M. Wild, D. Kimpe, R. Latham, R. Ross, P. Hovland","Collective I/O Tuning Using Analytical and Machine Learning Models",2015,"","","","",48,"2022-07-13 09:24:47","","10.1109/CLUSTER.2015.29","","",,,,,24,3.43,3,7,7,"The optimization of parallel I/O has become challenging because of the increasing storage hierarchy, performance variability of shared storage systems, and the number of factors in the hardware and software stacks that impact performance. In this paper, we perform an in-depth study of the complexity involved in I/O autotuning and performance modeling, including the architecture, software stack, and noise. We propose a novel hybrid model combining analytical models for communication and storage operations and black-box models for the performance of the individual operations. The experimental results show that the hybrid approach performs significantly better and shows a higher robustness to noise than state-of-the-art machine learning approaches, at the cost of a higher modeling complexity.","",""
4,"Rafael Pinot, Laurent Meunier, F. Yger, C. Gouy-Pailler, Y. Chevaleyre, J. Atif","On the robustness of randomized classifiers to adversarial examples",2021,"","","","",49,"2022-07-13 09:24:47","","","","",,,,,4,4.00,1,6,1,"This paper investigates the theory of robustness against adversarial attacks. We focus on randomized classifiers (i.e. classifiers that output random variables) and provide a thorough analysis of their behavior through the lens of statistical learning theory and information theory. To this aim, we introduce a new notion of robustness for randomized classifiers, enforcing local Lipschitzness using probability metrics. Equipped with this definition, we make two new contributions. The first one consists in devising a new upper bound on the adversarial generalization gap of randomized classifiers. More precisely, we devise bounds on the generalization gap and the adversarial gap (i.e. the gap between the risk and the worst-case risk under attack) of randomized classifiers. The second contribution presents a yet simple but efficient noise injection method to design robust randomized classifiers. We show that our results are applicable to a wide range of machine learning models under mild hypotheses. We further corroborate our findings with experimental results using deep neural networks on standard image datasets, namely CIFAR-10 and CIFAR-100. All robust models we trained models can simultaneously achieve state-of-the-art accuracy (over 0.82 clean accuracy on CIFAR-10) and enjoy guaranteed robust accuracy bounds (0.45 against `2 adversaries with magnitude 0.5 on CIFAR-10).","",""
4,"Maurice Weber, Nana Liu, Bo Li, Ce Zhang, Zhikuan Zhao","Optimal provable robustness of quantum classification via quantum hypothesis testing",2020,"","","","",50,"2022-07-13 09:24:47","","10.1038/s41534-021-00410-5","","",,,,,4,2.00,1,5,2,"","",""
110,"Raphael Gontijo Lopes, Dong Yin, Ben Poole, J. Gilmer, E. D. Cubuk","Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation",2019,"","","","",51,"2022-07-13 09:24:47","","","","",,,,,110,36.67,22,5,3,"Deploying machine learning systems in the real world requires both high accuracy on clean data and robustness to naturally occurring corruptions. While architectural advances have led to improved accuracy, building robust models remains challenging. Prior work has argued that there is an inherent trade-off between robustness and accuracy, which is exemplified by standard data augment techniques such as Cutout, which improves clean accuracy but not robustness, and additive Gaussian noise, which improves robustness but hurts accuracy. To overcome this trade-off, we introduce Patch Gaussian, a simple augmentation scheme that adds noise to randomly selected patches in an input image. Models trained with Patch Gaussian achieve state of the art on the CIFAR-10 and ImageNetCommon Corruptions benchmarks while also improving accuracy on clean data. We find that this augmentation leads to reduced sensitivity to high frequency noise(similar to Gaussian) while retaining the ability to take advantage of relevant high frequency information in the image (similar to Cutout). Finally, we show that Patch Gaussian can be used in conjunction with other regularization methods and data augmentation policies such as AutoAugment, and improves performance on the COCO object detection benchmark.","",""
10,"Yixuan Dai, Xinman Zhang, Zhiqi Chen, Xuebin Xu","Classification of electroencephalogram signals using wavelet-CSP and projection extreme learning machine.",2018,"","","","",52,"2022-07-13 09:24:47","","10.1063/1.5006511","","",,,,,10,2.50,3,4,4,"Brain-computer interface (BCI) systems establish a direct communication channel from the brain to an output device. As the basis of BCIs, recognizing motor imagery activities poses a considerable challenge to signal processing due to the complex and non-stationary characteristics. This paper introduces an optimal and intelligent method for motor imagery BCIs. Because of the robustness to noise, wavelet packet decomposition and common spatial pattern (CSP) methods were implemented to reduce the dimensions of preprocessed signals. And a novel and efficient classifier projection extreme learning machine (PELM) was employed to recognize the labels of electroencephalogram signals. Experiments have been performed on the BCI Competition Dataset to demonstrate the superiority of wavelet-CSP in BCI and the outperformance of the PELM-based method. Results show that the average recognition rate of PELM approaches approximately 70%, while the optimal rate of other methods is 72%, whose training time and classification time are relatively longer as 11.00 ms and 11.66 ms, respectively, compared with 4.75 ms and 4.87 ms obtained by using the proposed BCI system.","",""
223,"Nic Ford, J. Gilmer, Nicholas Carlini, E. D. Cubuk","Adversarial Examples Are a Natural Consequence of Test Error in Noise",2019,"","","","",53,"2022-07-13 09:24:47","","","","",,,,,223,74.33,56,4,3,"Over the last few years, the phenomenon of adversarial examples --- maliciously constructed inputs that fool trained machine learning models --- has captured the attention of the research community, especially when the adversary is restricted to small modifications of a correctly handled input. Less surprisingly, image classifiers also lack human-level performance on randomly corrupted images, such as images with additive Gaussian noise. In this paper we provide both empirical and theoretical evidence that these are two manifestations of the same underlying phenomenon, establishing close connections between the adversarial robustness and corruption robustness research programs. This suggests that improving adversarial robustness should go hand in hand with improving performance in the presence of more general and realistic image corruptions. Based on our results we recommend that future adversarial defenses consider evaluating the robustness of their methods to distributional shift with benchmarks such as Imagenet-C.","",""
15,"J. Villalba, Yuekai Zhang, N. Dehak","x-Vectors Meet Adversarial Attacks: Benchmarking Adversarial Robustness in Speaker Verification",2020,"","","","",54,"2022-07-13 09:24:47","","10.21437/interspeech.2020-2458","","",,,,,15,7.50,5,3,2,"Automatic Speaker Verification (ASV) enables high-security applications like user authentication or criminal investigation. However, ASV can be subjected to malicious attacks, which could compromise that security. The ASV literature mainly studies spoofing (a.k.a impersonation) attacks such as voice replay, synthesis or conversion. Meanwhile, other kinds of attacks, known as adversarial attacks, have become a threat to all kind of machine learning systems. Adversarial attacks introduce an imperceptible perturbation in the input signal that radically changes the behavior of the system. These attacks have been intensively studied in the image domain but less in the speech domain. In this work, we investigate the vulnerability of state-ofthe-art ASV systems to adversarial attacks. We consider a threat model consisting in adding a perturbation noise to the test waveform to alter the ASV decision. We also discuss the methodology and metrics to benchmark adversarial attacks and defenses in ASV. We evaluated three x-vector architectures, which performed among the best in recent ASV evaluations, against fast gradient sign and Carlini-Wagner attacks. All networks were highly vulnerable in the white-box attack scenario, even for high SNR (30-60 dB). Furthermore, we successfully transferred attacks generated with smaller white-box networks to attack a larger black-box network.","",""
22,"Xiaolin Liang, Hao Zhang, Tingting Lv, T. Gulliver","Extreme learning machine for 60 GHz millimetre wave positioning",2017,"","","","",55,"2022-07-13 09:24:47","","10.1049/iet-com.2016.0080","","",,,,,22,4.40,6,4,5,"Extreme learning machine (ELM) has attracted considerable attention in recent years due to its numerous applications in classification and regression. In this study, the authors investigate the performance of an ELM-based threshold selection algorithm for 60 GHz millimetre wave time of arrival estimation using energy detector (ED). A hybrid metric based on the skewness, kurtosis, standard deviation, and slope of the ED values is employed. The optimal normalised threshold for different signal-to-noise ratios (SNRs) is investigated, and the effects of the integration period and channel model are examined. Performance results are presented which show that the proposed ELM-based algorithm provides high precision and better robustness than existing techniques over a wide range of SNRs for the IEEE 802.15.3c CM1.1 and CM2.1 channel models. Further, the performance is largely independent of the integration period and channel model.","",""
83,"Preetum Nakkiran","Adversarial Robustness May Be at Odds With Simplicity",2019,"","","","",56,"2022-07-13 09:24:47","","","","",,,,,83,27.67,83,1,3,"Current techniques in machine learning are so far are unable to learn classifiers that are robust to adversarial perturbations. However, they are able to learn non-robust classifiers with very high accuracy, even in the presence of random perturbations. Towards explaining this gap, we highlight the hypothesis that $\textit{robust classification may require more complex classifiers (i.e. more capacity) than standard classification.}$  In this note, we show that this hypothesis is indeed possible, by giving several theoretical examples of classification tasks and sets of ""simple"" classifiers for which: (1) There exists a simple classifier with high standard accuracy, and also high accuracy under random $\ell_\infty$ noise. (2) Any simple classifier is not robust: it must have high adversarial loss with $\ell_\infty$ perturbations. (3) Robust classification is possible, but only with more complex classifiers (exponentially more complex, in some examples).  Moreover, $\textit{there is a quantitative trade-off between robustness and standard accuracy among simple classifiers.}$ This suggests an alternate explanation of this phenomenon, which appears in practice: the tradeoff may occur not because the classification task inherently requires such a tradeoff (as in [Tsipras-Santurkar-Engstrom-Turner-Madry `18]), but because the structure of our current classifiers imposes such a tradeoff.","",""
11,"Chuteng Zhou, Prad Kadambi, Matthew Mattina, P. Whatmough","Noisy Machines: Understanding Noisy Neural Networks and Enhancing Robustness to Analog Hardware Errors Using Distillation",2020,"","","","",57,"2022-07-13 09:24:47","","","","",,,,,11,5.50,3,4,2,"The success of deep learning has brought forth a wave of interest in computer hardware design to better meet the high demands of neural network inference. In particular, analog computing hardware has been heavily motivated specifically for accelerating neural networks, based on either electronic, optical or photonic devices, which may well achieve lower power consumption than conventional digital electronics. However, these proposed analog accelerators suffer from the intrinsic noise generated by their physical components, which makes it challenging to achieve high accuracy on deep neural networks. Hence, for successful deployment on analog accelerators, it is essential to be able to train deep neural networks to be robust to random continuous noise in the network weights, which is a somewhat new challenge in machine learning. In this paper, we advance the understanding of noisy neural networks. We outline how a noisy neural network has reduced learning capacity as a result of loss of mutual information between its input and output. To combat this, we propose using knowledge distillation combined with noise injection during training to achieve more noise robust networks, which is demonstrated experimentally across different networks and datasets, including ImageNet. Our method achieves models with as much as two times greater noise tolerance compared with the previous best attempts, which is a significant step towards making analog hardware practical for deep learning.","",""
16,"M. Hassan, Md. Rafiul Hassan, S. Huda, V. H. C. de Albuquerque","A Robust Deep-Learning-Enabled Trust-Boundary Protection for Adversarial Industrial IoT Environment",2021,"","","","",58,"2022-07-13 09:24:47","","10.1109/JIOT.2020.3019225","","",,,,,16,16.00,4,4,1,"In recent years, trust-boundary protection has become a challenging problem in Industrial Internet of Things (IIoT) environments. Trust boundaries separate IIoT processes and data stores in different groups based on user access privilege. Points where dataflow intersects with the trust boundary are becoming entry points for attackers. Attackers use various model skewing and intelligent techniques to generate adversarial/noisy examples that are indistinguishable from natural data. Many of the existing machine-learning (ML)-based approaches attempt to circumvent this problem. However, owing to an extremely large attack surface in the IIoT network, capturing a true distribution during training is difficult. The standard generative adversarial network (GAN) commonly generates adversarial examples for training using randomly sampled noise. However, the distribution of noisy inputs of GAN largely differs from actual distribution of data in IIoT networks and shows less robustness against adversarial attacks. Therefore, in this article, we propose a downsampler-encoder-based cooperative data generator that is trained using an algorithm to ensure better capture of the actual distribution of attack models for the large IIoT attack surface. The proposed downsampler-based data generator is alternatively updated and verified during training using a deep neural network discriminator to ensure robustness. This guarantees the performance of the generator against input sets with a high noise level at time of training and testing. Various experiments are conducted on a real IIoT testbed data set. Experimental results show that the proposed approach outperforms conventional deep learning and other ML techniques in terms of robustness against adversarial/noisy examples in the IIoT environment.","",""
7,"Yong Cheng, Wei Wang, Lu Jiang, Wolfgang Macherey","Self-supervised and Supervised Joint Training for Resource-rich Machine Translation",2021,"","","","",59,"2022-07-13 09:24:47","","","","",,,,,7,7.00,2,4,1,"Self-supervised pre-training of text representations has been successfully applied to lowresource Neural Machine Translation (NMT). However, it usually fails to achieve notable gains on resource-rich NMT. In this paper, we propose a joint training approach, F2-XEnDec, to combine self-supervised and supervised learning to optimize NMT models. To exploit complementary self-supervised signals for supervised learning, NMT models are trained on examples that are interbred from monolingual and parallel sentences through a new process called crossover encoder-decoder. Experiments on two resourcerich translation benchmarks, WMT’14 EnglishGerman and WMT’14 English-French, demonstrate that our approach achieves substantial improvements over several strong baseline methods and obtains a new state of the art of 46.19 BLEU on English-French when incorporating back translation. Results also show that our approach is capable of improving model robustness to input perturbations such as code-switching noise which frequently appears on social media.","",""
6,"Jeet Mohapatra, Ching-Yun Ko, Tsui-Wei Weng, Sijia Liu, Pin-Yu Chen, L. Daniel","Rethinking Randomized Smoothing for Adversarial Robustness",2020,"","","","",60,"2022-07-13 09:24:47","","","","",,,,,6,3.00,1,6,2,"The fragility of modern machine learning models has drawn a considerable amount of attention from both academia and the public. While immense interests were in either crafting adversarial attacks as a way to measure the robustness of neural networks or devising worst-case analytical robustness verification with guarantees, few methods could enjoy both scalability and robustness guarantees at the same time. As an alternative to these attempts, randomized smoothing adopts a different prediction rule that enables statistical robustness arguments and can scale to large networks. However, in this paper, we point out for the first time the side effects of current randomized smoothing workflows. Specifically, we articulate and prove two major points: 1) the decision boundaries shrink with the adoption of randomized smoothing prediction rule; 2) noise augmentation does not necessarily resolve the shrinking issue and can even create additional issues.","",""
3,"Yunzhe Xue, Meiyan Xie, Usman Roshan","Towards adversarial robustness with 01 loss neural networks",2020,"","","","",61,"2022-07-13 09:24:47","","10.1109/ICMLA51294.2020.00204","","",,,,,3,1.50,1,3,2,"Motivated by the general robustness properties of the 01 loss we propose a single hidden layer 01 loss neural network trained with stochastic coordinate descent as a defense against adversarial attacks in machine learning. One measure of a model’s robustness is the minimum distortion required to make the input adversarial. This can be approximated with the Boundary Attack (Brendel et. al. 2018) and HopSkipJump (Chen et. al. 2019) methods. We compare the minimum distortion of the 01 loss network to the binarized neural network and the standard sigmoid activation network with cross-entropy loss all trained with and without Gaussian noise on the CIFAR10 benchmark binary classification between classes 0 and 1. Both with and without noise training we find our 01 loss network to have the largest adversarial distortion of the three models by non-trivial margins. To further validate these results we subject all models to substitute model black box attacks under different distortion thresholds and find that the 01 loss network is the hardest to attack across all distortions. At a distortion of 0.125 both sigmoid activated cross-entropy loss and binarized networks have almost 0% accuracy on adversarial examples whereas the 01 loss network is at 40%. Even though both 01 loss and the binarized network use sign activations their training algorithms are different which in turn give different solutions for robustness. Finally we compare our network to simple convolutional models under substitute model black box attacks and find their accuracies to be comparable. Our work shows that the 01 loss network has the potential to defend against black box adversarial attacks better than convex loss and binarized networks.","",""
48,"Elvis Dohmatob","Generalized No Free Lunch Theorem for Adversarial Robustness",2018,"","","","",62,"2022-07-13 09:24:47","","","","",,,,,48,12.00,48,1,4,"This manuscript presents some new impossibility results on adversarial robustness in machine learning, a very important yet largely open problem. We show that if conditioned on a class label the data distribution satisfies the $W_2$ Talagrand transportation-cost inequality (for example, this condition is satisfied if the conditional distribution has density which is log-concave; is the uniform measure on a compact Riemannian manifold with positive Ricci curvature, any classifier can be adversarially fooled with high probability once the perturbations are slightly greater than the natural noise level in the problem. We call this result The Strong ""No Free Lunch"" Theorem as some recent results (Tsipras et al. 2018, Fawzi et al. 2018, etc.) on the subject can be immediately recovered as very particular cases. Our theoretical bounds are demonstrated on both simulated and real data (MNIST). We conclude the manuscript with some speculation on possible future research directions.","",""
3,"X. Valero, P. Farré, Francesc Alías","Comparison of Machine Learning Techniques for the Automatic Recognition of Soundscapes",2012,"","","","",63,"2022-07-13 09:24:47","","","","",,,,,3,0.30,1,3,10,"Rather than recognising single environmental sound sources, research on soundscape recognition aims at identifying general unstructured auditory scenes composed of multiple simultaneous sound sources. Nowadays, soundscape recognition has multiple applications, such as: i) contextawareness for mobile robots and portable devices, so as to provide information about the surrounding acoustic environment, enabling the automatic reaction of the device without human intervention; ii) background noise identification for speech recognition systems, so as to improve the robustness of such systems by facilitating their adaptability to any indoor or outdoor environment; iii) support tool in urban planning and noise annoyance assessment. In this paper, pattern recognition techniques specially designed to automatically recognise soundscapes are implemented. Specifically, the study focuses on finding the most appropriated learning paradigm. A set of machine learning techniques, commonly employed in similar sound recognition tasks, are considered: decision trees, K-Nearest Neighbours algorithm, Gaussian Mixture Models and Neural Networks. Extensive experiments are carried out so as to empirically test and compare the performance attained by the different learning techniques. The experiments are performed employing an audio data corpus composed of 15 different soundscenes, such as park, traffic street, restaurant or stadium.","",""
8,"M. López, I. Di Palma, M. Drago, P. Cerdá-Durán, F. Ricci","Deep learning for core-collapse supernova detection",2021,"","","","",64,"2022-07-13 09:24:47","","10.1103/PHYSREVD.103.063011","","",,,,,8,8.00,2,5,1,"The detection of gravitational waves from core-collapse supernova (CCSN) explosions is a challenging task, yet to be achieved, in which it is key the connection between multiple messengers, including neutrinos and electromagnetic signals. In this work, we present a method for detecting these kind of signals based on machine learning techniques. We tested its robustness by injecting signals in the real noise data taken by the Advanced LIGO-Virgo network during the second observing run, O2. We trained a newly developed Mini-Inception Resnet neural network using time-frequency images corresponding to injections of simulated phenomenological signals, which mimic the waveforms obtained in 3D numerical simulations of CCSNe. With this algorithm we were able to identify signals from both our phenomenological template bank and from actual numerical 3D simulations of CCSNe. We computed the detection efficiency versus the source distance, obtaining that, for signal to noise ratio higher than 15, the detection efficiency is 70% at a false alarm rate lower than 5%. We notice also that, in the case of the O2 run, it would have been possible to detect signals emitted at 1 kpc of distance, while lowering down the efficiency to 60%, the event distance reaches values up to 14 kpc.","",""
15,"Subramanian, Emmanouil Benetos, M. Sandler, Events","Robustness of Adversarial Attacks in Sound Event Classification",2019,"","","","",65,"2022-07-13 09:24:47","","10.33682/SP9N-QK06","","",,,,,15,5.00,4,4,3,"An adversarial attack is a method to generate perturbations to the input of a machine learning model in order to make the output of the model incorrect. The perturbed inputs are known as adversarial examples. In this paper, we investigate the robustness of adversarial examples to simple input transformations such as mp3 compression, resampling, white noise and reverb in the task of sound event classification. By performing this analysis, we aim to provide insights on strengths and weaknesses in current adversarial attack algorithms as well as provide a baseline for defenses against adversarial attacks. Our work shows that adversarial attacks are not robust to simple input transformations. White noise is the most consistent method to defend against adversarial attacks with a success rate of 73.72% averaged across all models and attack algorithms.","",""
7,"Lukas Schott, Julius von Kügelgen, F. Träuble, P. Gehler, Chris Russell, M. Bethge, B. Schölkopf, Francesco Locatello, Wieland Brendel","Visual Representation Learning Does Not Generalize Strongly Within the Same Domain",2021,"","","","",66,"2022-07-13 09:24:47","","","","",,,,,7,7.00,1,9,1,"An important component for generalization in machine learning is to uncover underlying latent factors of variation as well as the mechanism through which each factor acts in the world. In this paper, we test whether 17 unsupervised, weakly supervised, and fully supervised representation learning approaches correctly infer the generative factors of variation in simple datasets (dSprites, Shapes3D, MPI3D). In contrast to prior robustness work that introduces novel factors of variation during test time, such as blur or other (un)structured noise, we here recompose, interpolate, or extrapolate only existing factors of variation from the training data set (e.g., small and medium-sized objects during training and large objects during testing). Models that learn the correct mechanism should be able to generalize to this benchmark. In total, we train and test 2000+ models and observe that all of them struggle to learn the underlying mechanism regardless of supervision signal and architectural bias. Moreover, the generalization capabilities of all tested models drop significantly as we move from artificial datasets towards more realistic real-world datasets. Despite their inability to identify the correct mechanism, the models are quite modular as their ability to infer other in-distribution factors remains fairly stable, providing only a single factor is out-of-distribution. These results point to an important yet understudied problem of learning mechanistic models of observations that can facilitate generalization.","",""
7,"Yulei Wu","Robust Learning-Enabled Intelligence for the Internet of Things: A Survey From the Perspectives of Noisy Data and Adversarial Examples",2021,"","","","",67,"2022-07-13 09:24:47","","10.1109/JIOT.2020.3018691","","",,,,,7,7.00,7,1,1,"The Internet of Things (IoT) has been widely adopted in a range of verticals, e.g., automation, health, energy, and manufacturing. Many of the applications in these sectors, such as self-driving cars and remote surgery, are critical and high stakes applications, calling for advanced machine learning (ML) models for data analytics. Essentially, the training and testing data that are collected by massive IoT devices may contain noise (e.g., abnormal data, incorrect labels, and incomplete information) and adversarial examples. This requires high robustness of ML models to make reliable decisions for IoT applications. The research of robust ML has received tremendous attention from both academia and industry in recent years. This article will investigate the state of the art and representative works of robust ML models that can enable high resilience and reliability of IoT intelligence. Two aspects of robustness will be focused on, i.e., when the training data of ML models contain noises and adversarial examples, which may typically happen in many real-world IoT scenarios. In addition, the reliability of both neural networks and reinforcement learning framework will be investigated. Both of these two ML paradigms have been widely used in handling data in IoT scenarios. The potential research challenges and open issues will be discussed to provide future research directions.","",""
8,"L. Yao, Yan Wan, Hongjie Ni, Bugao Xu","Action unit classification for facial expression recognition using active learning and SVM",2021,"","","","",68,"2022-07-13 09:24:47","","10.1007/S11042-021-10836-W","","",,,,,8,8.00,2,4,1,"","",""
5,"Tom Z. Jiahao, M. Hsieh, E. Forgoston","Knowledge-based learning of nonlinear dynamics and chaos",2020,"","","","",69,"2022-07-13 09:24:47","","10.1063/5.0065617","","",,,,,5,2.50,2,3,2,"Extracting predictive models from nonlinear systems is a central task in scientific machine learning. One key problem is the reconciliation between modern data-driven approaches and first principles. Despite rapid advances in machine learning techniques, embedding domain knowledge into datadriven models remains a challenge. In this work, we present a universal learning framework for extracting predictive models from nonlinear systems based on observations. Our framework can readily incorporate first principle knowledge because it naturally models nonlinear systems as continuous-time systems. This both improves the extracted models’ extrapolation power and reduces the amount of data needed for training. In addition, our framework has the advantages of robustness to observational noise and applicability to irregularly sampled data. We demonstrate the effectiveness of our scheme by learning predictive models for a wide variety of systems including a stiff Van der Pol oscillator, the Lorenz system, and the Kuramoto-Sivashinsky equation. For the Lorenz system, different types of domain knowledge are incorporated to demonstrate the strength of knowledge embedding in data-driven system identification.","",""
9,"S. Bodapati, Hyokun Yun, Y. Al-Onaizan","Robustness to Capitalization Errors in Named Entity Recognition",2019,"","","","",70,"2022-07-13 09:24:47","","10.18653/v1/D19-5531","","",,,,,9,3.00,3,3,3,"Robustness to capitalization errors is a highly desirable characteristic of named entity recognizers, yet we find standard models for the task are surprisingly brittle to such noise.Existing methods to improve robustness to the noise completely discard given orthographic information, which significantly degrades their performance on well-formed text. We propose a simple alternative approach based on data augmentation, which allows the model to learn to utilize or ignore orthographic information depending on its usefulness in the context. It achieves competitive robustness to capitalization errors while making negligible compromise to its performance on well-formed text and significantly improving generalization power on noisy user-generated text. Our experiments clearly and consistently validate our claim across different types of machine learning models, languages, and dataset sizes.","",""
53,"Magdalini Paschali, Sailesh Conjeti, Fernando Navarro, Nassir Navab","Generalizability vs. Robustness: Investigating Medical Imaging Networks Using Adversarial Examples",2018,"","","","",71,"2022-07-13 09:24:47","","10.1007/978-3-030-00928-1_56","","",,,,,53,13.25,13,4,4,"","",""
19,"A. Iess, E. Cuoco, F. Morawski, J. Powell","Core-Collapse Supernova Gravitational-Wave Search and Deep Learning Classification",2020,"","","","",72,"2022-07-13 09:24:47","","10.1088/2632-2153/ab7d31","","",,,,,19,9.50,5,4,2,"We describe a search and classification procedure for gravitational waves emitted by core-collapse supernova (CCSN) explosions, using a convolutional neural network (CNN) combined with an event trigger generator known as Wavelet Detection Filter (WDF). We employ both a 1-D CNN search using time series gravitational-wave data as input, and a 2-D CNN search with time-frequency representation of the data as input. To test the accuracies of our 1-D and 2-D CNN classification, we add CCSN waveforms from the most recent hydrodynamical simulations of neutrino-driven core-collapse to simulated Gaussian colored noise with the Virgo interferometer and the planned Einstein Telescope sensitivity curve. We find classification accuracies, for a single detector, of over 95% for both 1-D and 2-D CNN pipelines. For the first time in machine learning CCSN studies, we add short duration detector noise transients to our data to test the robustness of our method against false alarms created by detector noise artifacts. Further to this, we show that the CNN can distinguish between different types of CCSN waveform models.","",""
77,"Hossein Hosseini, Baicen Xiao, R. Poovendran","Google's Cloud Vision API is Not Robust to Noise",2017,"","","","",73,"2022-07-13 09:24:47","","10.1109/ICMLA.2017.0-172","","",,,,,77,15.40,26,3,5,"Google has recently introduced the Cloud Vision API for image analysis. According to the demonstration website, the API ""quickly classifies images into thousands of categories, detects individual objects and faces within images, and finds and reads printed words contained within images."" It can be also used to ""detect different types of inappropriate content from adult to violent content."" In this paper, we evaluate the robustness of Google Cloud Vision API to input perturbation. In particular, we show that by adding sufficient noise to the image, the API generates completely different outputs for the noisy image, while a human observer would perceive its original content. We show that the attack is consistently successful, by performing extensive experiments on different image types, including natural images, images containing faces and images with texts. For instance, using images from ImageNet dataset, we found that adding an average of 14.25% impulse noise is enough to deceive the API. Our findings indicate the vulnerability of the API in adversarial environments. For example, an adversary can bypass an image filtering system by adding noise to inappropriate images. We then show that when a noise filter is applied on input images, the API generates mostly the same outputs for restored images as for original images. This observation suggests that cloud vision API can readily benefit from noise filtering, without the need for updating image analysis algorithms.","",""
3,"Yunfei Zheng, Badong Chen, Shiyuan Wang, Weiqun Wang, Wei Qin","Mixture Correntropy-Based Kernel Extreme Learning Machines",2020,"","","","",74,"2022-07-13 09:24:47","","10.1109/TNNLS.2020.3029198","","",,,,,3,1.50,1,5,2,"Kernel-based extreme learning machine (KELM), as a natural extension of ELM to kernel learning, has achieved outstanding performance in addressing various regression and classification problems. Compared with the basic ELM, KELM has a better generalization ability owing to no needs of the number of hidden nodes given beforehand and random projection mechanism. Since KELM is derived under the minimum mean square error (MMSE) criterion for the Gaussian assumption of noise, its performance may deteriorate under the non-Gaussian cases, seriously. To improve the robustness of KELM, this article proposes a mixture correntropy-based KELM (MC-KELM), which adopts the recently proposed maximum mixture correntropy criterion as the optimization criterion, instead of using the MMSE criterion. In addition, an online sequential version of MC-KELM (MCOS-KELM) is developed to deal with the case that the data arrive sequentially (one-by-one or chunk-by-chunk). Experimental results on regression and classification data sets are reported to validate the performance superiorities of the new methods.","",""
14,"M. Singla, K. K. Shukla","Robust statistics-based support vector machine and its variants: a survey",2019,"","","","",75,"2022-07-13 09:24:47","","10.1007/s00521-019-04627-6","","",,,,,14,4.67,7,2,3,"","",""
28,"Kevin Lee, Z. Man, Dianhui Wang, Z. Cao","Classification of bioinformatics dataset using finite impulse response extreme learning machine for cancer diagnosis",2013,"","","","",76,"2022-07-13 09:24:47","","10.1007/s00521-012-0847-z","","",,,,,28,3.11,7,4,9,"","",""
26,"Elvis Dohmatob","Limitations of adversarial robustness: strong No Free Lunch Theorem",2018,"","","","",77,"2022-07-13 09:24:47","","","","",,,,,26,6.50,26,1,4,"This manuscript presents some new impossibility results on adversarial robustness in machine learning, a very important yet largely open problem. We show that if conditioned on a class label the data distribution satisfies the $W_2$ Talagrand transportation-cost inequality (for example, this condition is satisfied if the conditional distribution has density which is log-concave; is the uniform measure on a compact Riemannian manifold with positive Ricci curvature, any classifier can be adversarially fooled with high probability once the perturbations are slightly greater than the natural noise level in the problem. We call this result The Strong ""No Free Lunch"" Theorem as some recent results (Tsipras et al. 2018, Fawzi et al. 2018, etc.) on the subject can be immediately recovered as very particular cases. Our theoretical bounds are demonstrated on both simulated and real data (MNIST). We conclude the manuscript with some speculation on possible future research directions.","",""
54,"P. Wiecha, A. Lecestre, N. Mallet, G. Larrieu","Pushing the limits of optical information storage using deep learning",2018,"","","","",78,"2022-07-13 09:24:47","","10.1038/s41565-018-0346-1","","",,,,,54,13.50,14,4,4,"","",""
5,"Amirreza Shaeiri, Rozhin Nobahari, M. Rohban","Towards Deep Learning Models Resistant to Large Perturbations",2020,"","","","",79,"2022-07-13 09:24:47","","","","",,,,,5,2.50,2,3,2,"Adversarial robustness has proven to be a required property of machine learning algorithms. A key and often overlooked aspect of this problem is to try to make the adversarial noise magnitude as large as possible to enhance the benefits of the model robustness. We show that the well-established algorithm called ""adversarial training"" fails to train a deep neural network given a large, but reasonable, perturbation magnitude. In this paper, we propose a simple yet effective initialization of the network weights that makes learning on higher levels of noise possible. We next evaluate this idea rigorously on MNIST ($\epsilon$ up to $\approx 0.40$) and CIFAR10 ($\epsilon$ up to $\approx 32/255$) datasets assuming the $\ell_{\infty}$ attack model. Additionally, in order to establish the limits of $\epsilon$ in which the learning is feasible, we study the optimal robust classifier assuming full access to the joint data and label distribution. Then, we provide some theoretical results on the adversarial accuracy for a simple multi-dimensional Bernoulli distribution, which yields some insights on the range of feasible perturbations for the MNIST dataset.","",""
7,"Siyuan Chen, Yuquan Meng, Haichuan Tang, Yin Tian, Niao He, Chenhui Shao","Robust Deep Learning-Based Diagnosis of Mixed Faults in Rotating Machinery",2020,"","","","",80,"2022-07-13 09:24:47","","10.1109/TMECH.2020.3007441","","",,,,,7,3.50,1,6,2,"Fault diagnosis for rolling elements in rotating machinery persistently receives high research interest due to the said machinery's prevalence in a broad range of applications. State-of-the-art methods in such setups focus on effective identification of faults that usually involve a single component while rejecting noise from limited sources. This article studies the data-based diagnosis of mixed faults coming from multiple components with an emphasis on model robustness against a wide spectrum of external perturbation. A dataset is collected on a rotor and bearing system by varying the levels and types of faults in both the rotor and bearing, which results in 48 machine health conditions. A duplet classifier is developed by combining two 1-D convolutional neural networks (CNNs) that are responsible for the diagnosis of the rotor and bearing faults, respectively. Experimental results show that the proposed classifier can reliably identify the onset and nature of mixed faults. In addition, one-vs-all classifiers are built using the features generated by the developed 1-D CNNs as predictors to recognize previously unlearned fault types. The effectiveness of such classifiers is demonstrated using data collected from four new fault types. Finally, the robustness and ability to reject external perturbation of the duplet classification model are analyzed using kernel density estimation. The code for the proposed classifiers is available at https://github.com/siyuanc2/machine-fault-diag.","",""
15,"Magdalini Paschali, Sailesh Conjeti, Fernando Navarro, Nassir Navab","Generalizability vs. Robustness: Adversarial Examples for Medical Imaging",2018,"","","","",81,"2022-07-13 09:24:47","","","","",,,,,15,3.75,4,4,4,"In this paper, for the first time, we propose an evaluation method for deep learning models that assesses the performance of a model not only in an unseen test scenario, but also in extreme cases of noise, outliers and ambiguous input data. To this end, we utilize adversarial examples, images that fool machine learning models, while looking imperceptibly different from original data, as a measure to evaluate the robustness of a variety of medical imaging models. Through extensive experiments on skin lesion classification and whole brain segmentation with state-of-the-art networks such as Inception and UNet, we show that models that achieve comparable performance regarding generalizability may have significant variations in their perception of the underlying data manifold, leading to an extensive performance gap in their robustness.","",""
40,"Zhikuan Zhao, Alejandro Pozas-Kerstjens, P. Rebentrost, P. Wittek","Bayesian deep learning on a quantum computer",2018,"","","","",82,"2022-07-13 09:24:47","","10.1007/s42484-019-00004-7","","",,,,,40,10.00,10,4,4,"","",""
302,"N. Lane, Petko Georgiev, Lorena Qendro","DeepEar: robust smartphone audio sensing in unconstrained acoustic environments using deep learning",2015,"","","","",83,"2022-07-13 09:24:47","","10.1145/2750858.2804262","","",,,,,302,43.14,101,3,7,"Microphones are remarkably powerful sensors of human behavior and context. However, audio sensing is highly susceptible to wild fluctuations in accuracy when used in diverse acoustic environments (such as, bedrooms, vehicles, or cafes), that users encounter on a daily basis. Towards addressing this challenge, we turn to the field of deep learning; an area of machine learning that has radically changed related audio modeling domains like speech recognition. In this paper, we present DeepEar -- the first mobile audio sensing framework built from coupled Deep Neural Networks (DNNs) that simultaneously perform common audio sensing tasks. We train DeepEar with a large-scale dataset including unlabeled data from 168 place visits. The resulting learned model, involving 2.3M parameters, enables DeepEar to significantly increase inference robustness to background noise beyond conventional approaches present in mobile devices. Finally, we show DeepEar is feasible for smartphones by building a cloud-free DSP-based prototype that runs continuously, using only 6% of the smartphone's battery daily.","",""
8,"Yufei Han, Xiangliang Zhang","Robust Federated Training via Collaborative Machine Teaching using Trusted Instances",2019,"","","","",84,"2022-07-13 09:24:47","","","","",,,,,8,2.67,4,2,3,"Federated learning performs distributed model training using local data hosted by agents. It shares only model parameter updates for iterative aggregation at the server. Although it is privacy-preserving by design, federated learning is vulnerable to noise corruption of local agents, as demonstrated in the previous study on adversarial data poisoning threat against federated learning systems. Even a single noise-corrupted agent can bias the model training. In our work, we propose a collaborative and privacy-preserving machine teaching paradigm with multiple distributed teachers, to improve robustness of the federated training process against local data corruption. We assume that each local agent (teacher) have the resources to verify a small portions of trusted instances, which may not by itself be adequate for learning. In the proposed collaborative machine teaching method, these trusted instances guide the distributed agents to jointly select a compact while informative training subset from data hosted by their own. Simultaneously, the agents learn to add changes of limited magnitudes into the selected data instances, in order to improve the testing performances of the federally trained model despite of the training data corruption. Experiments on toy and real data demonstrate that our approach can identify training set bugs effectively and suggest appropriate changes to the labels. Our algorithm is a step toward trustworthy machine learning.","",""
146,"Alexios Koutsoukas, Keith J. Monaghan, Xiaoli Li, Jun Huan","Deep-learning: investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data",2017,"","","","",85,"2022-07-13 09:24:47","","10.1186/s13321-017-0226-y","","",,,,,146,29.20,37,4,5,"","",""
11,"S. Al-Sharafat, Reyadh Sh","Adaptive Framework for Network Intrusion Detection by Using Genetic-Based Machine Learning Algorithm",2009,"","","","",86,"2022-07-13 09:24:47","","","","",,,,,11,0.85,6,2,13,"Summery Computer networks have expanded significantly in use and in numbers. This expansion makes them target to different attacks. Intrusion Detection System (IDS) is used to identify unknown or new type of attacks or in dynamic environments as mobile networks. As a result, it is necessary to find a ways to implement and operate IDSs. Among different techniques, Genetic-based machine learning algorithm (GBML) which offers a good ability to be adapted to changing environments, robustness to noise and ability to identify unknown attacks. The objective of this paper is to incorporate different techniques into classifier system to detect and classify intrusion from normal network packet. Among several techniques, steady state genetic-based machine leaning algorithm (SSGBML) which will be used to detect intrusions. Steady State Genetic Algorithm (SSGA) and Zeroth Level Classifier system (ZCS) are investigated. SSGA is used as a discovery mechanism for classifiers, while ZCS plays the role of detector by matching incoming environment message with classifiers to determine whether it is normal or intrusion. As a feedback, the environment will make a decision on whether to take action or not. In order to attain the best results, modifying SSGA will enhance our discovery engine. The experiments and evaluations of the proposed method were performed with the KDD 99 intrusion detection dataset.","",""
34,"R. Rastgoo, K. Kiani, S. Escalera","Multi-Modal Deep Hand Sign Language Recognition in Still Images Using Restricted Boltzmann Machine",2018,"","","","",87,"2022-07-13 09:24:47","","10.3390/e20110809","","",,,,,34,8.50,11,3,4,"In this paper, a deep learning approach, Restricted Boltzmann Machine (RBM), is used to perform automatic hand sign language recognition from visual data. We evaluate how RBM, as a deep generative model, is capable of generating the distribution of the input data for an enhanced recognition of unseen data. Two modalities, RGB and Depth, are considered in the model input in three forms: original image, cropped image, and noisy cropped image. Five crops of the input image are used and the hand of these cropped images are detected using Convolutional Neural Network (CNN). After that, three types of the detected hand images are generated for each modality and input to RBMs. The outputs of the RBMs for two modalities are fused in another RBM in order to recognize the output sign label of the input image. The proposed multi-modal model is trained on all and part of the American alphabet and digits of four publicly available datasets. We also evaluate the robustness of the proposal against noise. Experimental results show that the proposed multi-modal model, using crops and the RBM fusing methodology, achieves state-of-the-art results on Massey University Gesture Dataset 2012, American Sign Language (ASL). and Fingerspelling Dataset from the University of Surrey’s Center for Vision, Speech and Signal Processing, NYU, and ASL Fingerspelling A datasets.","",""
3,"Huang Yi-han","Extreme learning machine on robust estimation",2012,"","","","",88,"2022-07-13 09:24:47","","","","",,,,,3,0.30,3,1,10,"Extreme learning machine(ELM) is a kind of single-hidden layer feedforword neural networks(SLFNs).Comparing with traditional neural network algorithms,it is simpler in structure,with higher learning speed,and good generalization performance.The output-weight of ELM was calculated by LSE(least square estimation) method.However,LSE lack of robustness,the result would be seriously damaged when there were outliers in the training data.In order to solve this problem,this paper derived a novel approach based on M-estimators of extreme learning machine called RBELM.Simulation results indicate that the RBELM proposed can significantly robust against data noise and outliers.","",""
6,"J. Yousafzai, M. Ager, Z. Cvetković, Peter Sollich","Discriminative and generative machine learning approaches towards robust phoneme classification",2008,"","","","",89,"2022-07-13 09:24:47","","10.1109/ITA.2008.4601091","","",,,,,6,0.43,2,4,14,"Robustness of classification of isolated phoneme segments using discriminative and generative classifiers is investigated for the acoustic waveform and PLP speech representations. The two approaches used are support vector machines (SVMs) and mixtures of probabilistic PCA (MPPCA). While recognition in the PLP domain attains superb accuracy on clean data, it is significantly affected by mismatch between training and test noise levels. Classification in the high-dimensional acoustic waveform domain, on the other hand, is more robust in the presence of additive white Gaussian noise. We also show some results on the effects of custom-designed kernel functions for SVM classification in the acoustic waveform domain.","",""
4,"M. Cococcioni, P. Forte, S. Manconi, C. Sacchi","A Machine Learning Approach to Fault Diagnosis of Rolling Bearings",2008,"","","","",90,"2022-07-13 09:24:47","","10.1109/ICCCYB.2008.4721407","","",,,,,4,0.29,1,4,14,"This paper presents a method based on classification techniques for automatic fault diagnosis of rolling element bearings. Experimental results achieved on vibration signals collected by an accelerometer on an experimental test rig show that the method can automatically detect different types of faults. Furthermore, the method is able, once trained on an appropriate representative set of basic faults, to recognize more serious faults, provided they are of the same type. We also analyzed the trend of correct classification of bearing faults on variation of the signal-to-noise ratio achieving high levels of robustness.","",""
44,"M. Mozina, J. Zabkar, Trevor J. M. Bench-Capon, I. Bratko","Argument Based Machine Learning Applied to Law",2005,"","","","",91,"2022-07-13 09:24:47","","10.1007/s10506-006-9002-4","","",,,,,44,2.59,11,4,17,"","",""
564,"Bin Cheng, Jianchao Yang, Shuicheng Yan, Yun Fu, Thomas S. Huang","Learning With $\ell ^{1}$-Graph for Image Analysis",2010,"","","","",92,"2022-07-13 09:24:47","","10.1109/TIP.2009.2038764","","",,,,,564,47.00,113,5,12,"The graph construction procedure essentially determines the potentials of those graph-oriented learning algorithms for image analysis. In this paper, we propose a process to build the so-called directed ¿1-graph, in which the vertices involve all the samples and the ingoing edge weights to each vertex describe its ¿1-norm driven reconstruction from the remaining samples and the noise. Then, a series of new algorithms for various machine learning tasks, e.g., data clustering, subspace learning, and semi-supervised learning, are derived upon the ¿1-graphs. Compared with the conventional k -nearest-neighbor graph and ¿-ball graph, the ¿1-graph possesses the advantages: (1) greater robustness to data noise, (2) automatic sparsity, and (3) adaptive neighborhood for individual datum. Extensive experiments on three real-world datasets show the consistent superiority of ¿1-graph over those classic graphs in data clustering, subspace learning, and semi-supervised learning tasks.","",""
6,"Joong-Sung Lee, Jeongho Bang, Sunghyuk Hong, Changhyoup Lee, Kang Hee Seol, Jinhyoung Lee, Kwang-Geol Lee","Experimental demonstration of quantum learning speedup with classical input data",2017,"","","","",93,"2022-07-13 09:24:47","","10.1103/PhysRevA.99.012313","","",,,,,6,1.20,1,7,5,"We consider quantum-classical hybrid machine learning in which large-scale input channels remain classical and small-scale working channels process quantum operations conditioned on classical input data. This does not require the conversion of classical (big) data to a quantum superposed state, in contrast to recently developed approaches for quantum machine learning. We performed optical experiments to illustrate a single-bit universal machine, which can be extended to a large-bit circuit for binary classification task. Our experimental machine exhibits quantum learning speed-up of approximately 36%, as compared to the fully classical machine. In addition, it features strong robustness against dephasing noise.","",""
4,"Francesco Cursi, Guang-Zhong Yang","A Novel Approach for Outlier Detection and Robust Sensory Data Model Learning",2019,"","","","",94,"2022-07-13 09:24:47","","10.1109/IROS40897.2019.8967653","","",,,,,4,1.33,2,2,3,"In the past few decades machine learning and data analysis have been having a huge growth and they have been applied in many different problems in the field of robotics. Data are usually the result of sensor measurements and, as such, they might be subjected to noise and outliers. The presence of outliers has a huge impact on modelling the acquired data, resulting in inappropriate models. In this work a novel approach for outlier detection and rejection for input/output mapping in regression problems is presented. The robustness of the method is shown both through simulated data for linear and nonlinear regression, and real sensory data. Despite being validated by using artificial neural networks, the method can be generalized to any other regression method.","",""
292,"B. Biggio, Blaine Nelson, P. Laskov","Support Vector Machines Under Adversarial Label Noise",2011,"","","","",95,"2022-07-13 09:24:47","","","","",,,,,292,26.55,97,3,11,"In adversarial classication tasks like spam ltering and intrusion detection, malicious adversaries may manipulate data to thwart the outcome of an automatic analysis. Thus, besides achieving good classication performances, machine learning algorithms have to be robust against adversarial data manipulation to successfully operate in these tasks. While support vector machines (SVMs) have shown to be a very successful approach in classication problems, their eectiveness in adversarial classication tasks has not been extensively investigated yet. In this paper we present a preliminary investigation of the robustness of SVMs against adversarial data manipulation. In particular, we assume that the adversary has control over some training data, and aims to subvert the SVM learning process. Within this assumption, we show that this is indeed possible, and propose a strategy to improve the robustness of SVMs to training data manipulation based on a simple kernel matrix correction.","",""
3,"Francesco Cursi, Guang-Zhong Yang","A Robust Regression Approach for Robot Model Learning",2019,"","","","",96,"2022-07-13 09:24:47","","","","",,,,,3,1.00,2,2,3,"Machine learning and data analysis have been used in many robotics fields, especially for modelling. Data are usually the result of sensor measurements and, as such, they might be subjected to noise and outliers. The presence of outliers has a huge impact on modelling the acquired data, resulting in inappropriate models. In this work a novel approach for outlier detection and rejection for input/output mapping in regression problems is presented. The robustness of the method is shown both through simulated data for linear and nonlinear regression, and real sensory data. Despite being validated by using artificial neural networks, the method can be generalized to any other regression method","",""
6,"Petra Povalej Brzan, P. Kokol, T. Welzer, B. Stiglic","Machine-Learning with Cellular Automata",2005,"","","","",97,"2022-07-13 09:24:47","","10.1007/11552253_28","","",,,,,6,0.35,2,4,17,"","",""
9,"Kevin Lee, Z. Man, Dianhui Wang, Z. Cao","Classification of microarray datasets using finite impulse response extreme learning machine for cancer diagnosis",2011,"","","","",98,"2022-07-13 09:24:47","","10.1109/IECON.2011.6119676","","",,,,,9,0.82,2,4,11,"Cancer diagnosis is a highly researched field in bioinformatics since the introduction of microarray gene expression technology which allows multiple diseases to be simultaneously tested and compared between healthy and malignant cells. This paper analyses the use of a recently suggested neural network based classifier known as the finite impulse response extreme learning machine (FIR-ELM) for the classification of two binary bioinformatics datasets consisting of microarray gene expressions for leukemia and colon tumor. The FIR-ELM is based on the single hidden layer feedforward neural network (SLFN) whose weights are trained to reduce the effects of noise and improve the robustness of the classifier. The hidden layer of the FIR-ELM is seen to be able to reduce the noise and disturbances from the full microarray dataset which is known to consist of many experimental errors and biases accrued from the production process. Experimental results have shown that the FIR-ELM is capable of achieving good performance compared to conventional classifiers such as the back propagation artificial neural network (BP-ANN), extreme learning machine (ELM), and support vector machine (SVM) which implement a gene selection procedure prior to working on the datasets.","",""
3,"Shir Li Wang, Kamran Shafi, C. Lokan, H. Abbass","Robustness of neural ensembles against targeted and random Adversarial Learning",2010,"","","","",99,"2022-07-13 09:24:47","","10.1109/FUZZY.2010.5584822","","",,,,,3,0.25,1,4,12,"Machine learning has become a prominent tool in various domains owing to its adaptability. However, this adaptability can be taken advantage of by an adversary to cause dysfunction of machine learning; a process known as Adversarial Learning. This paper investigates Adversarial Learning in the context of artificial neural networks. The aim is to test the hypothesis that an ensemble of neural networks trained on the same data manipulated by an adversary would be more robust than a single network. We investigate two attack types: targeted and random. We use Mahalanobis distance and covariance matrices to selected targeted attacks. The experiments use both artificial and UCI datasets. The results demonstrate that an ensemble of neural networks trained on attacked data are more robust against the attack than a single network. While many papers have demonstrated that an ensemble of neural networks is more robust against noise than a single network, the significance of the current work lies in the fact that targeted attacks are not white noise.","",""
18,"A. Kampouraki, Christophoros Nikou, G. Manis","Robustness of Support Vector Machine-based Classification of Heart Rate Signals",2006,"","","","",100,"2022-07-13 09:24:47","","10.1109/IEMBS.2006.260550","","",,,,,18,1.13,6,3,16,"In this study, we discuss the use of support vector machine (SVM) learning to classify heart rate signals. Each signal is represented by an attribute vector containing a set of statistical measures for the respective signal. At first, the SVM classifier is trained by data (attribute vectors) with known ground truth. Then, the classifier learnt parameters can be used for the categorization of new signals not belonging to the training set. We have experimented with both real and artificial signals and the SVM classifier performs very well even with signals exhibiting very low signal to noise ratio which is not the case for other standard methods proposed by the literature","",""
16,"M. Copelli, R. Eichhorn, O. Kinouchi, Michael Biehl, R. Simonetti, P. Riegler, N. Caticha","Noise robustness in multilayer neural networks",1997,"","","","",101,"2022-07-13 09:24:47","","10.1209/EPL/I1997-00167-2","","",,,,,16,0.64,2,7,25,"The training of multilayered neural networks in the presence of different types of noise is studied. We consider the learning of realizable rules in nonoverlapping architectures. Achieving optimal generalization depends on the knowledge of the noise level, however its misestimation may lead to partial or complete loss of the generalization ability. We demonstrate this effect in the framework of online learning and present the results in terms of noise robustness phase diagrams. While for additive (weight) noise the robustness properties depend on the architecture and size of the networks, this is not so for multiplicative (output) noise. In this case we find a universal behaviour independent of the machine size for both the tree parity and committee machines.","",""
13,"Wendyam Eric Lionel Ilboudo, Taisuke Kobayashi, Kenji Sugimoto","Robust Stochastic Gradient Descent With Student-t Distribution Based First-Order Momentum",2020,"","","","",102,"2022-07-13 09:24:47","","10.1109/TNNLS.2020.3041755","","",,,,,13,6.50,4,3,2,"Remarkable achievements by deep neural networks stand on the development of excellent stochastic gradient descent methods. Deep-learning-based machine learning algorithms, however, have to find patterns between observations and supervised signals, even though they may include some noise that hides the true relationship between them, more or less especially in the robotics domain. To perform well even with such noise, we expect them to be able to detect outliers and discard them when needed. We, therefore, propose a new stochastic gradient optimization method, whose robustness is directly built in the algorithm, using the robust student-t distribution as its core idea. We integrate our method to some of the latest stochastic gradient algorithms, and in particular, Adam, the popular optimizer, is modified through our method. The resultant algorithm, called t-Adam, along with the other stochastic gradient methods integrated with our core idea is shown to effectively outperform Adam and their original versions in terms of robustness against noise on diverse tasks, ranging from regression and classification to reinforcement learning problems.","",""
22,"V. Suriyakumar, Nicolas Papernot, A. Goldenberg, M. Ghassemi","Chasing Your Long Tails: Differentially Private Prediction in Health Care Settings",2020,"","","","",103,"2022-07-13 09:24:47","","10.1145/3442188.3445934","","",,,,,22,11.00,6,4,2,"Machine learning models in health care are often deployed in settings where it is important to protect patient privacy. In such settings, methods for differentially private (DP) learning provide a general-purpose approach to learn models with privacy guarantees. Modern methods for DP learning ensure privacy through the addition of calibrated noise. The resulting privacy-preserving models are unable to learn too much information about the tails of a data distribution, resulting in a loss of accuracy that can disproportionately affect small groups. In this paper, we study the effects of DP learning in health care. We use state-of-the-art methods for DP learning to train privacy-preserving models in clinical prediction tasks, including x-ray classification of images and mortality prediction in time series data. We use these models to perform a comprehensive empirical investigation of the tradeoffs between privacy, utility, robustness to dataset shift and fairness. Our results highlight lesser-known limitations of methods for DP learning in health care, models that exhibit steep tradeoffs between privacy and utility, and models whose predictions are disproportionately influenced by large demographic groups in the training data. We discuss the costs and benefits of differentially private learning in health care with open directions for differential privacy, machine learning and health care.","",""
65,"Ryan LaRose, Brian Coyle","Robust data encodings for quantum classifiers",2020,"","","","",104,"2022-07-13 09:24:47","","10.1103/PHYSREVA.102.032420","","",,,,,65,32.50,33,2,2,"Data representation is crucial for the success of machine learning models. In the context of quantum machine learning with near-term quantum computers, equally important considerations of how to efficiently input (encode) data and effectively deal with noise arise. In this work, we study data encodings for binary quantum classification and investigate their properties both with and without noise. For the common classifier we consider, we show that encodings determine the classes of learnable decision boundaries as well as the set of points which retain the same classification in the presence of noise. After defining the notion of a robust data encoding, we prove several results on robustness for different channels, discuss the existence of robust encodings, and prove an upper bound on the number of robust points in terms of fidelities between noisy and noiseless states. Numerical results for several example implementations are provided to reinforce our findings.","",""
20,"Sheeba Lal, S. Rehman, J. H. Shah, Talha Meraj, Hafiz Tayyab Rauf, Robertas Damaševičius, M. Mohammed, Karrar Hameed Abdulkareem","Adversarial Attack and Defence through Adversarial Training and Feature Fusion for Diabetic Retinopathy Recognition",2021,"","","","",105,"2022-07-13 09:24:47","","10.3390/s21113922","","",,,,,20,20.00,3,8,1,"Due to the rapid growth in artificial intelligence (AI) and deep learning (DL) approaches, the security and robustness of the deployed algorithms need to be guaranteed. The security susceptibility of the DL algorithms to adversarial examples has been widely acknowledged. The artificially created examples will lead to different instances negatively identified by the DL models that are humanly considered benign. Practical application in actual physical scenarios with adversarial threats shows their features. Thus, adversarial attacks and defense, including machine learning and its reliability, have drawn growing interest and, in recent years, has been a hot topic of research. We introduce a framework that provides a defensive model against the adversarial speckle-noise attack, the adversarial training, and a feature fusion strategy, which preserves the classification with correct labelling. We evaluate and analyze the adversarial attacks and defenses on the retinal fundus images for the Diabetic Retinopathy recognition problem, which is considered a state-of-the-art endeavor. Results obtained on the retinal fundus images, which are prone to adversarial attacks, are 99% accurate and prove that the proposed defensive model is robust.","",""
307,"Robert Geirhos, Carlos R. Medina Temme, Jonas Rauber, H. Schütt, M. Bethge, Felix Wichmann","Generalisation in humans and deep neural networks",2018,"","","","",106,"2022-07-13 09:24:47","","10.15496/PUBLIKATION-30814","","",,,,,307,76.75,51,6,4,"We compare the robustness of humans and current convolutional deep neural networks (DNNs) on object recognition under twelve different types of image degradations. First, using three well known DNNs (ResNet-152, VGG-19, GoogLeNet) we find the human visual system to be more robust to nearly all of the tested image manipulations, and we observe progressively diverging classification error-patterns between humans and DNNs when the signal gets weaker. Secondly, we show that DNNs trained directly on distorted images consistently surpass human performance on the exact distortion types they were trained on, yet they display extremely poor generalisation abilities when tested on other distortion types. For example, training on salt-and-pepper noise does not imply robustness on uniform white noise and vice versa. Thus, changes in the noise distribution between training and testing constitutes a crucial challenge to deep learning vision systems that can be systematically addressed in a lifelong machine learning approach. Our new dataset consisting of 83K carefully measured human psychophysical trials provide a useful reference for lifelong robustness against image degradations set by the human visual system.","",""
9,"Noushin Jafarpisheh, M. Teshnehlab","Cancers classification based on deep neural networks and emotional learning approach",2018,"","","","",107,"2022-07-13 09:24:47","","10.1049/iet-syb.2018.5002","","",,,,,9,2.25,5,2,4,"In the present era, enormous factors contribute to causing cancer. So cancer classification cannot rely only on doctor's thoughts. As a result, intelligent algorithms concerning doctor's help are inevitable. Therefore, the authors are motivated to suggest a novel algorithm to classify three cancer datasets; colon, ALL‐AML, and leukaemia cancers. Their proposed algorithm is based on the deep neural network and emotional learning process. First of all, by applying the principal component analysis, they had a feature reduction. Then, they used deep neural as a feature extraction. Then, they implemented different classifiers; multi‐layer perceptron, support vector machine (SVM), decision tree, and Gaussian mixture model. In the end, because in the real world, especially when working on systems biology, unpredictable events, and uncertainties are undeniable, the robustness of their model against uncertainties is important. So they added Gaussian noise to the input features of the first encoder in each dataset, then, they applied the stacked denoising method. Experimental results disclosed that, generally, using emotional learning increased the accuracy. In addition, the highest accuracy was gained by SVM, 91.66, 92.27, and 96.56% for colon, ALL‐AML, and leukaemia, respectively. However, GMM led to the lowest accuracy. The best accuracy gained by GMM was 60%.","",""
32,"C. Fei, Guangchen Bai, W. Tang, Shuang Ma","Quantitative Diagnosis of Rotor Vibration Fault Using Process Power Spectrum Entropy and Support Vector Machine Method",2014,"","","","",108,"2022-07-13 09:24:47","","10.1155/2014/957531","","",,,,,32,4.00,8,4,8,"To improve the diagnosis capacity of rotor vibration fault in stochastic process, an effective fault diagnosis method (named Process Power Spectrum Entropy (PPSE) and Support Vector Machine (SVM) (PPSE-SVM, for short) method) was proposed. The fault diagnosis model of PPSE-SVM was established by fusing PPSE method and SVM theory. Based on the simulation experiment of rotor vibration fault, process data for four typical vibration faults (rotor imbalance, shaft misalignment, rotor-stator rubbing, and pedestal looseness) were collected under multipoint (multiple channels) and multispeed. By using PPSE method, the PPSE values of these data were extracted as fault feature vectors to establish the SVM model of rotor vibration fault diagnosis. From rotor vibration fault diagnosis, the results demonstrate that the proposed method possesses high precision, good learning ability, good generalization ability, and strong fault-tolerant ability (robustness) in four aspects of distinguishing fault types, fault severity, fault location, and noise immunity of rotor stochastic vibration. This paper presents a novel method (PPSE-SVM) for rotor vibration fault diagnosis and real-time vibration monitoring. The presented effort is promising to improve the fault diagnosis precision of rotating machinery like gas turbine.","",""
5,"Zhuo Ren, Liming Yang","Robust Extreme Learning Machines with Different Loss Functions",2018,"","","","",109,"2022-07-13 09:24:47","","10.1007/s11063-018-9890-9","","",,,,,5,1.25,3,2,4,"","",""
7,"Jing Bai, X.-y. Zhang, Ji-kang Duan","Application of Support Vector Machine with Modified Gaussian Kernel in A Noise-Robust Speech Recognition System",2008,"","","","",110,"2022-07-13 09:24:47","","10.1109/KAMW.2008.4810534","","",,,,,7,0.50,2,3,14,"To improve the generalization ability of the machine learning and solve the problem that recognition rates of the speech recognition system become worse in the noisy environment, a modified Gaussian kernel function which may pay attention to the similar degree between sample space and feature space is proposed. In this paper, used the modified Gaussian kernel support vector machine to a speech recognition system for Chinese isolated words, non-specific person and middle glossary quantity and chose the improved noise-robust MFCC parameters as the speech feature, used ""one-against-one"" method for the multi-class classification problem of SVM, and analyzed the influence of Gaussian kernel parameter gamma and error penalty parameter C on SVM generalization ability. Experiments indicate that the recognition rates of SVM which chose the best parameters and modified Gaussian kernel are much better than those of traditional HMM model and RBF network. The robustness is better too.","",""
3,"Wei Gao, Bin-Bin Yang, Zhi-Hua Zhou","On the Robustness of Nearest Neighbor with Noisy Data",2016,"","","","",111,"2022-07-13 09:24:47","","","","",,,,,3,0.50,1,3,6,"Nearest neighbor has always been one of the most appealing non-parametric approaches in machine learning, pattern recognition, computer vision, etc. Previous empirical studies partially demonstrate that nearest neighbor is resistant to noise, yet there is a lack of deep analysis. This work presents a full understanding on the robustness of nearest neighbor in the random noise setting.  We provide finite-sample, distribution-dependent bounds on the consistency of nearest neighbor. The theoretical results show that, for asymmetric noises, k-nearest neighbor is robust enough to classify most data correctly, except for a handful of examples, whose labels are totally misled by random noises. For symmetric noises, however, k-nearest neighbor achieves the same consistent rate as that of noise-free setting, which verifies the robustness of $k$-nearest neighbor. Motivated by theoretical analysis, we propose the Robust k-Nearest Neighbor (RNN) approach to deal with noisy labels. The basic idea is to make unilateral corrections to examples, whose labels are totally misled by random noises, and classify the others directly by utilizing the robustness of k-nearest neighbor. Extensive experiments show the effectiveness and robustness of the proposed algorithm.","",""
4,"Fátima A. Saiz, Ismael Serrano, Iñigo Barandiaran, Jairo R. Sánchez","A Robust and Fast Deep Learning-Based Method for Defect Classification in Steel Surfaces",2018,"","","","",112,"2022-07-13 09:24:47","","10.1109/IS.2018.8710501","","",,,,,4,1.00,1,4,4,"The final product quality control is critical for any manufacturing process. In the case of steel products, there are different inspection methods that are able to classify the defects, but they usually require human intervention. In this context, a deep learning-based automatic defect classifier method for steel surfaces is proposed. The method combines some traditional Machine Learning techniques with a Convolutional Neural Network (CNN). Different experiments were carried out in order to obtain the best classifier parameter setup. To verily the robustness of the classifier some additional experiments were done, obtaining high classification rate against some sources of noise such as illumination changes or occlusions. The proposed method achieves a classification rate of 99.95% taking 0.019 seconds to classify a single image. The method is compared with seventeen related methods and outperforms them on a publicly available dataset, with six types of defects and 300 samples for each class. The source code of the proposed method is publicly available.","",""
50,"Kunjin Chen, Jun Hu, Yu Zhang, Zhanqing Yu, Jinliang He","Fault Location in Power Distribution Systems via Deep Graph Convolutional Networks",2018,"","","","",113,"2022-07-13 09:24:47","","10.1109/JSAC.2019.2951964","","",,,,,50,12.50,10,5,4,"This paper develops a novel graph convolutional network (GCN) framework for fault location in power distribution networks. The proposed approach integrates multiple measurements at different buses while taking system topology into account. The effectiveness of the GCN model is corroborated by the IEEE 123 bus benchmark system. Simulation results show that the GCN model significantly outperforms other widely-used machine learning schemes with very high fault location accuracy. In addition, the proposed approach is robust to measurement noise and data loss errors. Data visualization results of two competing neural networks are presented to explore the mechanism of GCNs superior performance. A data augmentation procedure is proposed to increase the robustness of the model under various levels of noise and data loss errors. Further experiments show that the model can adapt to topology changes of distribution networks and perform well with a limited number of measured buses.","",""
10,"Ruijun Gao, Qing Guo, Felix Juefei-Xu, Hongkai Yu, Wei Feng","AdvHaze: Adversarial Haze Attack",2021,"","","","",114,"2022-07-13 09:24:47","","","","",,,,,10,10.00,2,5,1,"In recent years, adversarial attacks have drawn more attention for their value on evaluating and improving the robustness of machine learning models, especially, neural network models. However, previous attack methods have mainly focused on applying some l normbounded noise perturbations. In this paper, we instead introduce a novel adversarial attack method based on haze, which is a common phenomenon in real-world scenery. Our method can synthesize potentially adversarial haze into an image based on the atmospheric scattering model with high realisticity and mislead classifiers to predict an incorrect class. We launch experiments on two popular datasets, i.e., ImageNet and NIPS 2017. We demonstrate that the proposed method achieves a high success rate, and holds better transferability across different classification models than the baselines. We also visualize the correlation matrices, which inspire us to jointly apply different perturbations to improve the success rate of the attack. We hope this work can boost the development of non-noisebased adversarial attacks and help evaluate and improve the robustness of DNNs.","",""
8,"Hongpo Zhang, Ning Cheng, Yang Zhang, Zhanbo Li","Label flipping attacks against Naive Bayes on spam filtering systems",2021,"","","","",115,"2022-07-13 09:24:47","","10.1007/s10489-020-02086-4","","",,,,,8,8.00,2,4,1,"","",""
8,"Jeet Mohapatra, Ching-Yun Ko, Lily Weng, Pin-Yu Chen, Sijia Liu, L. Daniel","Hidden Cost of Randomized Smoothing",2021,"","","","",116,"2022-07-13 09:24:47","","","","",,,,,8,8.00,1,6,1,"The fragility of modern machine learning models has drawn a considerable amount of attention from both academia and the public. While immense interests were in either crafting adversarial attacks as a way to measure the robustness of neural networks or devising worst-case analytical robustness verification with guarantees, few methods could enjoy both scalability and robustness guarantees at the same time. As an alternative to these attempts, randomized smoothing adopts a different prediction rule that enables statistical robustness arguments which easily scale to large networks. However, in this paper, we point out the side effects of current randomized smoothing workflows. Specifically, we articulate and prove two major points: 1) the decision boundaries of smoothed classifiers will shrink, resulting in disparity in class-wise accuracy; 2) applying noise augmentation in the training process does not necessarily resolve the shrinking issue due to the inconsistent learning objectives.","",""
28,"Tae Gyoon Kang, N. Kim","DNN-Based Voice Activity Detection with Multi-Task Learning",2016,"","","","",117,"2022-07-13 09:24:47","","10.1587/TRANSINF.2015EDL8168","","",,,,,28,4.67,14,2,6,"Recently, notable improvements in voice activity detection (VAD) problem have been achieved by adopting several machine learning techniques. Among them, the deep neural network (DNN) which learns the mapping between the noisy speech features and the corresponding voice activity status with its deep hidden structure has been one of the most popular techniques. In this letter, we propose a novel approach which enhances the robustness of DNN in mismatched noise conditions with multi-task learning (MTL) framework. In the proposed algorithm, a feature enhancement task for speech features is jointly trained with the conventional VAD task. The experimental results show that the DNN with the proposed framework outperforms the conventional DNN-based VAD algorithm. key words: deep neural network, voice activity detection, multi-task learning","",""
28,"Zhutian Yang, Wei Qiu, Hongjian Sun, A. Nallanathan","Robust Radar Emitter Recognition Based on the Three-Dimensional Distribution Feature and Transfer Learning",2016,"","","","",118,"2022-07-13 09:24:47","","10.3390/s16030289","","",,,,,28,4.67,7,4,6,"Due to the increasing complexity of electromagnetic signals, there exists a significant challenge for radar emitter signal recognition. To address this challenge, multi-component radar emitter recognition under a complicated noise environment is studied in this paper. A novel radar emitter recognition approach based on the three-dimensional distribution feature and transfer learning is proposed. The cubic feature for the time-frequency-energy distribution is proposed to describe the intra-pulse modulation information of radar emitters. Furthermore, the feature is reconstructed by using transfer learning in order to obtain the robust feature against signal noise rate (SNR) variation. Last, but not the least, the relevance vector machine is used to classify radar emitter signals. Simulations demonstrate that the approach proposed in this paper has better performances in accuracy and robustness than existing approaches.","",""
4,"Purvi Agrawal, S. Ganapathy","Comparison of Unsupervised Modulation Filter Learning Methods for ASR",2018,"","","","",119,"2022-07-13 09:24:47","","10.21437/Interspeech.2018-1972","","",,,,,4,1.00,2,2,4,"The widespread deployment of automatic speech recognition (ASR) system in consumer centric applications such as voice interaction and voice search demands the need for noise robustness in such systems. One approach to this problem is to achieve the desired robustness in speech representations used in the ASR. Motivated from studies on robust human speech recognition, we analyse the unsupervised data-driven temporal modulation filter learning for robust feature extraction. In this paper, we compare various unsupervised models for data driven filter learning like convolutional autoencoder (CAE), generative adversarial network (GAN) and convolutional restricted Boltzmann machine (CRBM). The unsupervised models are designed to learn a set of filters from long temporal trajectories of speech sub-band energy. The filters learnt from these models are used for modulation filtering of the input spectrogram before the ASR training. The ASR experiments are performed on Wall Street Journal (WSJ) Aurora-4 database with clean and multi condition training setup. The experimental results obtained from the modulation filtered representations shows considerable robustness to noise, channel distortions and reverberant conditions compared to other feature extraction methods. Among the three approaches compared in this paper, the GAN approach provides the most consistent improvements in ASR accuracy in different training scenarios.","",""
357,"K. Crammer, Alex Kulesza, Mark Dredze","Adaptive regularization of weight vectors",2009,"","","","",120,"2022-07-13 09:24:47","","10.1007/s10994-013-5327-x","","",,,,,357,27.46,119,3,13,"","",""
23,"Yuwei Cui, Chetan Surpur, Subutai Ahmad, J. Hawkins","A comparative study of HTM and other neural network models for online sequence learning with streaming data",2016,"","","","",121,"2022-07-13 09:24:47","","10.1109/IJCNN.2016.7727380","","",,,,,23,3.83,6,4,6,"Online sequence learning from streaming data is one of the most challenging topics in machine learning. Neural network models represent promising candidates for sequence learning due to their ability to learn and recognize complex temporal patterns. In this paper, we present a comparative study of Hierarchical Temporal Memory (HTM), a neurally-inspired model, and other feedforward and recurrent artificial neural network models on both artificial and real-world sequence prediction algorithms. HTM and long-short term memory (LSTM) give the best prediction accuracy. HTM additionally demonstrates many other features that are desirable for real-world sequence learning, such as fast adaptation to changes in the data stream, robustness to sensor noise and fault tolerance. These features make HTM an ideal candidate for online sequence learning problems.","",""
24,"Sajad Farokhi, S. Shamsuddin, J. Flusser, U. U. Sheikh, M. Khansari, K. Jafari-Khouzani","Rotation and noise invariant near-infrared face recognition by means of Zernike moments and spectral regression discriminant analysis",2013,"","","","",122,"2022-07-13 09:24:47","","10.1117/1.JEI.22.1.013030","","",,,,,24,2.67,4,6,9,"Abstract. Face recognition is a rapidly growing research area, which is based heavily on the methods of machine learning, computer vision, and image processing. We propose a rotation and noise invariant near-infrared face-recognition system using an orthogonal invariant moment, namely, Zernike moments (ZMs) as a feature extractor in the near-infrared domain and spectral regression discriminant analysis (SRDA) as an efficient algorithm to decrease the computational complexity of the system, enhance the discrimination power of features, and solve the “small sample size” problem simultaneously. Experimental results based on the CASIA NIR database show the noise robustness and rotation invariance of the proposed approach. Further analysis shows that SRDA as a sophisticated technique, improves the accuracy and time complexity of the system compared with other data reduction methods such as linear discriminant analysis.","",""
20,"Tyler M. Tomita, J. Browne, Cencheng Shen, Jaewon Chung, Jesse Patsolic, Benjamin Falk, C. Priebe, Jason Yim, R. Burns, M. Maggioni, J. Vogelstein","Sparse Projection Oblique Randomer Forests",2015,"","","","",123,"2022-07-13 09:24:47","","","","",,,,,20,2.86,2,11,7,"Decision forests, including Random Forests and Gradient Boosting Trees, have recently demonstrated state-of-the-art performance in a variety of machine learning settings. Decision forests are typically ensembles of axis-aligned decision trees; that is, trees that split only along feature dimensions. In contrast, many recent extensions to decision forests are based on axis-oblique splits. Unfortunately, these extensions forfeit one or more of the favorable properties of decision forests based on axis-aligned splits, such as robustness to many noise dimensions, interpretability, or computational efficiency. We introduce yet another decision forest, called ""Sparse Projection Oblique Randomer Forests"" (SPORF). SPORF uses very sparse random projections, i.e., linear combinations of a small subset of features. SPORF significantly improves accuracy over existing state-of-the-art algorithms on a standard benchmark suite for classification with >100 problems of varying dimension, sample size, and number of classes. To illustrate how SPORF addresses the limitations of both axis-aligned and existing oblique decision forest methods, we conduct extensive simulated experiments. SPORF typically yields improved performance over existing decision forests, while mitigating computational efficiency and scalability and maintaining interpretability. SPORF can easily be incorporated into other ensemble methods such as boosting to obtain potentially similar gains.","",""
5,"Tse-Yu Pan, Chih-Hsuan Kuo, Min-Chun Hu","A noise reduction method for IMU and its application on handwriting trajectory reconstruction",2016,"","","","",124,"2022-07-13 09:24:47","","10.1109/ICMEW.2016.7574685","","",,,,,5,0.83,2,3,6,"In this paper, we propose a trajectory reconstruction method based on a low-cost IMU (Inertial Measurement Unit), which is usually equipped in smartphones. The IMU used in our work consists of a 3-axis accelerometer and a 3-axis gyroscope, which can record information of acceleration and rotation, respectively. However, intrinsic bias and random noise cause unreliable IMU signals. Thus, to improve the accuracy of the reconstructed trajectory, we apply filtering methods to reduce high or low frequency noises of the signal. Moreover, the machine learning technique is utilized to detect the movement state of the smartphone. Also, instead of a simple threshold to detect the smartphone movement as implemented in previous related works, we extract multiple features from IMU signals and train a movement detection model based on the linear discriminant analysis (LDA) to increase the robustness of the system. Finally, a “reset switch” mechanism is used to more effectively restrain the accumulated error of the accelerometer.","",""
7,"Min-You Chen, Xuemin Tan, Li Zhang","An iterative self-training support vector machine algorithm in brain-computer interfaces",2016,"","","","",125,"2022-07-13 09:24:47","","10.3233/IDA-150794","","",,,,,7,1.17,2,3,6,"In this paper, an iterative self-training Support Vector Machine (SVM) algorithm combined feature re-extraction is proposed for semi-supervised learning, which only needs a small set of labeled samples to train classifier and is thus very useful in Brain-Computer Interface (BCI) design. Two methods, the model selection based self-training and the confidence criterion, respectively, is also proposed for searching the best parameter pair of SVM and selecting the most useful unlabeled data to expand the labeled training data set. The Dataset IVa of BCI Competition III, is presented to demonstrate the validity of our algorithm with statistical significance test. As an iterative algorithm, experimental results of the proposed algorithm show the validity of re-extracting feature and the robustness of the feature to the noise. In addition, the convergence of the proposed algorithm and the validity of the method measuring the consistency of the feature are also demonstrated in experiments.","",""
6,"Jingrui Zhang, Li Zhang, Hai Huang, Xiaojun Jing","Improved cyclostationary feature detection based on correlation between the signal and noise",2016,"","","","",126,"2022-07-13 09:24:47","","10.1109/ISCIT.2016.7751705","","",,,,,6,1.00,2,4,6,"With the presence of noise floor, characteristic points of signals are submerged easily in conventional cyclostationary feature detection. In this paper, a new cyclostationary feature detection method based on the correlation between signal and noise is proposed for detection of OFDM based primary users. The proposed scheme aims to improve the noise robustness through making the utmost of the information in the cyclic spectrum of the received signals. Meanwhile, in order to obtain the clearer feature, the signal processing technology is used to deal with the cyclic spectrum. Finally, the classification detection is realized by machine learning. Extensive simulation results demonstrate that proposed method provides superiority detection performance compared to the conventional cyclostationary feature detection, especially in low SNR environment.","",""
17,"Chen Dan, Yuting Wei, Pradeep Ravikumar","Sharp Statistical Guarantees for Adversarially Robust Gaussian Classification",2020,"","","","",127,"2022-07-13 09:24:47","","","","",,,,,17,8.50,6,3,2,"Adversarial robustness has become a fundamental requirement in modern machine learning applications. Yet, there has been surprisingly little statistical understanding so far. In this paper, we provide the first result of the optimal minimax guarantees for the excess risk for adversarially robust classification, under Gaussian mixture model proposed by \cite{schmidt2018adversarially}. The results are stated in terms of the Adversarial Signal-to-Noise Ratio (AdvSNR), which generalizes a similar notion for standard linear classification to the adversarial setting. For the Gaussian mixtures with AdvSNR value of $r$, we establish an excess risk lower bound of order $\Theta(e^{-(\frac{1}{8}+o(1)) r^2} \frac{d}{n})$ and design a computationally efficient estimator that achieves this optimal rate. Our results built upon minimal set of assumptions while cover a wide spectrum of adversarial perturbations including $\ell_p$ balls for any $p \ge 1$.","",""
69,"Anastasios Tsiamis, George J. Pappas","Finite Sample Analysis of Stochastic System Identification",2019,"","","","",128,"2022-07-13 09:24:47","","10.1109/CDC40024.2019.9029499","","",,,,,69,23.00,35,2,3,"In this paper, we analyze the finite sample complexity of stochastic system identification using modern tools from machine learning and statistics. An unknown discrete-time linear system evolves over time under Gaussian noise without external inputs. The objective is to recover the system parameters as well as the Kalman filter gain, given a single trajectory of output measurements over a finite horizon of length N. Based on a subspace identification algorithm and a finite number of N output samples, we provide non-asymptotic high-probability upper bounds for the system parameter estimation errors. Our analysis uses recent results from random matrix theory, self-normalized martingales and SVD robustness, in order to show that with high probability the estimation errors decrease with a rate of $1/\sqrt N$ up to logarithmic terms. Our non-asymptotic bounds not only agree with classical asymptotic results, but are also valid even when the system is marginally stable.","",""
6,"J. Xia, X. Li, Y. Liu","Application of a new Restricted Boltzmann Machine to Radar Target Recognition",2016,"","","","",129,"2022-07-13 09:24:47","","10.1109/PIERS.2016.7734910","","",,,,,6,1.00,2,3,6,"When facing radar target recognition, the main problems focus on the data representation capability and the robustness to cope with noise. The merits of deep learning such as automatic setting for training and hierarchical extraction of features. Most of existing deep networks are related to Restricted Boltzmann machine (RBM), which has played an important role in deep learning techniques. The models election problem in RBM and its deep architecture is very intractable since both their learning and inference are highly time-consuming. As regular RBM has a restriction between visible units and hidden units, this restriction will cause reduction of the recognition probability when training data samples are degraded by noise. Fuzzy Restricted Boltzmann machine (FRBM) is a new RBM, in which the parameters of collection between visible units and hidden units are replaced by fuzzy number. In this paper, FRBM has been applied to moving airplane radar target data. Tested target contain three categories airplane HRRP data samples. The proposed FRBM can significantly reduce the number of free parameters and the degree of over fitting. Moreover, compared with RBM and traditional classification methods, it has showed better representation capacity and better robustness property when the training data are contaminated by noises.","",""
129,"Kuldeep Randhawa, C. Loo, M. Seera, C. Lim, A. Nandi","Credit Card Fraud Detection Using AdaBoost and Majority Voting",2018,"","","","",130,"2022-07-13 09:24:47","","10.1109/ACCESS.2018.2806420","","",,,,,129,32.25,26,5,4,"Credit card fraud is a serious problem in financial services. Billions of dollars are lost due to credit card fraud every year. There is a lack of research studies on analyzing real-world credit card data owing to confidentiality issues. In this paper, machine learning algorithms are used to detect credit card fraud. Standard models are first used. Then, hybrid methods which use AdaBoost and majority voting methods are applied. To evaluate the model efficacy, a publicly available credit card data set is used. Then, a real-world credit card data set from a financial institution is analyzed. In addition, noise is added to the data samples to further assess the robustness of the algorithms. The experimental results positively indicate that the majority voting method achieves good accuracy rates in detecting fraud cases in credit cards.","",""
145,"M. Ravanelli, Philemon Brakel, M. Omologo, Yoshua Bengio","Light Gated Recurrent Units for Speech Recognition",2018,"","","","",131,"2022-07-13 09:24:47","","10.1109/TETCI.2017.2762739","","",,,,,145,36.25,36,4,4,"A field that has directly benefited from the recent advances in deep learning is automatic speech recognition (ASR). Despite the great achievements of the past decades, however, a natural and robust human–machine speech interaction still appears to be out of reach, especially in challenging environments characterized by significant noise and reverberation. To improve robustness, modern speech recognizers often employ acoustic models based on recurrent neural networks (RNNs) that are naturally able to exploit large time contexts and long-term speech modulations. It is thus of great interest to continue the study of proper techniques for improving the effectiveness of RNNs in processing speech signals. In this paper, we revise one of the most popular RNN models, namely, gated recurrent units (GRUs), and propose a simplified architecture that turned out to be very effective for ASR. The contribution of this work is twofold: First, we analyze the role played by the reset gate, showing that a significant redundancy with the update gate occurs. As a result, we propose to remove the former from the GRU design, leading to a more efficient and compact single-gate model. Second, we propose to replace hyperbolic tangent with rectified linear unit activations. This variation couples well with batch normalization and could help the model learn long-term dependencies without numerical issues. Results show that the proposed architecture, called light GRU, not only reduces the per-epoch training time by more than 30% over a standard GRU, but also consistently improves the recognition accuracy across different tasks, input features, noisy conditions, as well as across different ASR paradigms, ranging from standard DNN-HMM speech recognizers to end-to-end connectionist temporal classification models.","",""
11,"Muhammad Ali Abdul Aziz, J. Niu, Xiaoke Zhao, Xuelong Li","Efficient and Robust Learning for Sustainable and Reacquisition-Enabled Hand Tracking",2016,"","","","",132,"2022-07-13 09:24:47","","10.1109/TCYB.2015.2418275","","",,,,,11,1.83,3,4,6,"The use of machine learning approaches for long-term hand tracking poses some major challenges such as attaining robustness to inconsistencies in lighting, scale and object appearances, background clutter, and total object occlusion/disappearance. To address these issues in this paper, we present a robust machine learning approach based on enhanced particle filter trackers. The inherent drawbacks associated with the particle filter approach, i.e., sample degeneration and sample impoverishment, are minimized by infusing the particle filter with the mean shift approach. Moreover, to instill our tracker with reacquisition ability, we propose a rotation invariant and efficient detection framework named beta histograms of oriented gradients. Our robust appearance model operates on the red, green, blue color histogram and our newly proposed rotation invariant noise compensated local binary patterns descriptor, which is a noise compensated, rotation invariant version of the local binary patterns descriptor. Through our experiments, we demonstrate that our proposed hand tracker performs favorably against state-of-the-art algorithms on numerous challenging video sequences of hand postures, and overcomes the largely unsolved problem of redetecting hands after they vanish and reappear into the frame.","",""
8,"F. de-la-Calle-Silos, A. Gallardo-Antolín, Carmen Peláez-Moreno","Deep Maxout Networks Applied to Noise-Robust Speech Recognition",2014,"","","","",133,"2022-07-13 09:24:47","","10.1007/978-3-319-13623-3_12","","",,,,,8,1.00,3,3,8,"","",""
8,"B. Twala","Impact of noise on credit risk prediction: Does data quality really matter?",2013,"","","","",134,"2022-07-13 09:24:47","","10.3233/IDA-130623","","",,,,,8,0.89,8,1,9,"Machine learning has been successfully used for credit-evaluation decisions. Most research on machine learning assumes that the attributes of training and tests instances are not only completely specified but are also free from noise. Real world data, however, often suffer from corruptions or noise but not always known. This is the heart of information-based credit risk models. However, blindly applying such machine learning techniques to noisy financial credit risk evaluation data may fail to make very good or perfect predictions. Unfortunately, despite extensive research over the last decades, the impact of poor quality of data especially noise on the accuracy of credit risk has attracted less attention, even though it remains a significant problem for many. This paper investigates the robustness of five machine learning supervised algorithms to noisy credit risk environment. In particular, we show that when noise is added to four real-world credit risk domains, a significant and disproportionate number of total errors are contributed by class noise compared to attribute noise; thus, in the presence of noise, it is noise on the class variable that are responsible for the poor predictive accuracy of the learning concept.","",""
189,"Haomin Zhang, I. Mcloughlin, Yan Song","Robust sound event recognition using convolutional neural networks",2015,"","","","",135,"2022-07-13 09:24:47","","10.1109/ICASSP.2015.7178031","","",,,,,189,27.00,63,3,7,"Traditional sound event recognition methods based on informative front end features such as MFCC, with back end sequencing methods such as HMM, tend to perform poorly in the presence of interfering acoustic noise. Since noise corruption may be unavoidable in practical situations, it is important to develop more robust features and classifiers. Recent advances in this field use powerful machine learning techniques with high dimensional input features such as spectrograms or auditory image. These improve robustness largely thanks to the discriminative capabilities of the back end classifiers. We extend this further by proposing novel features derived from spectrogram energy triggering, allied with the powerful classification capabilities of a convolutional neural network (CNN). The proposed method demonstrates excellent performance under noise-corrupted conditions when compared against state-of-the-art approaches on standard evaluation tasks. To the author's knowledge this in the first application of CNN in this field.","",""
89,"C. Leistner, Amir Saffari, P. Roth, H. Bischof","On robustness of on-line boosting - a competitive study",2009,"","","","",136,"2022-07-13 09:24:47","","10.1109/ICCVW.2009.5457451","","",,,,,89,6.85,22,4,13,"On-line boosting is one of the most successful on-line algorithms and thus applied in many computer vision applications. However, even though boosting, in general, is well known to be susceptible to class-label noise, on-line boosting is mostly applied to self-learning applications such as visual object tracking, where label-noise is an inherent problem. This paper studies the robustness of on-line boosting. Since mainly the applied loss function determines the behavior of boosting, we propose an on-line version of GradientBoost, which allows us to plug in arbitrary loss-functions into the on-line learner. Hence, we can easily study the importance and the behavior of different loss-functions. We evaluate various on-line boosting algorithms in form of a competitive study on standard machine learning problems as well as on common computer vision applications such as tracking and autonomous training of object detectors. Our results show that using on-line Gradient-Boost with robust loss functions leads to superior results in all our experiments.","",""
11,"Wendyam Eric Lionel Ilboudo, Taisuke Kobayashi, Kenji Sugimoto","TAdam: A Robust Stochastic Gradient Optimizer",2020,"","","","",137,"2022-07-13 09:24:47","","","","",,,,,11,5.50,4,3,2,"Machine learning algorithms aim to find patterns from observations, which may include some noise, especially in robotics domain. To perform well even with such noise, we expect them to be able to detect outliers and discard them when needed. We therefore propose a new stochastic gradient optimization method, whose robustness is directly built in the algorithm, using the robust student-t distribution as its core idea. Adam, the popular optimization method, is modified with our method and the resultant optimizer, so-called TAdam, is shown to effectively outperform Adam in terms of robustness against noise on diverse task, ranging from regression and classification to reinforcement learning problems. The implementation of our algorithm can be found at this https URL","",""
12,"Deng-ao Li, X. Jia, Jumin Zhao","A Novel Hybrid Fusion Algorithm for Low-Cost GPS/INS Integrated Navigation System During GPS Outages",2020,"","","","",138,"2022-07-13 09:24:47","","10.1109/ACCESS.2020.2981015","","",,,,,12,6.00,4,3,2,"It is the main challenge for Global Positioning System (GPS)/Inertial Navigation System (INS) to achieve reliable and low-cost positioning solutions during GPS outages. A new GPS/INS hybrid method is proposed to bridge GPS outages. Firstly, a data pre-processing algorithm based on empirical mode decomposition (EMD) for wavelet de-noising is developed to reduce the uncertain noise of IMU raw measurements and provide accurate information for subsequent GPS/INS data fusion and training samples. Then, the interactive multi-model extended Kalman filter(IMM-EKF) algorithm is proposed to improve the robustness of Kalman filter output and the accuracy of model training target output. Finally, a new intelligent structure of GPS/INS based on Extreme Learning Machine (ELM) is proposed. When the GPS is available, the IMM-EKF is used to fuse the GPS and de-noised INS data, and the de-noised INS data and the outputs of IMM-EKF are used to train the ELM. During GPS outages, the ELM is used to predict and correct the INS position error. In order to evaluate the effectiveness of the proposed method, 3 tests were performed in the actual field test. The comparison results show that the proposed fusion method can significantly improve the accuracy and reliability of positioning during GPS outages.","",""
81,"Yang Young Lu, Yingying Fan, Jinchi Lv, William Stafford Noble","DeepPINK: reproducible feature selection in deep neural networks",2018,"","","","",139,"2022-07-13 09:24:47","","","","",,,,,81,20.25,20,4,4,"Deep learning has become increasingly popular in both supervised and unsupervised machine learning thanks to its outstanding empirical performance. However, because of their intrinsic complexity, most deep learning methods are largely treated as black box tools with little interpretability. Even though recent attempts have been made to facilitate the interpretability of deep neural networks (DNNs), existing methods are susceptible to noise and lack of robustness. Therefore, scientists are justifiably cautious about the reproducibility of the discoveries, which is often related to the interpretability of the underlying statistical models. In this paper, we describe a method to increase the interpretability and reproducibility of DNNs by incorporating the idea of feature selection with controlled error rate. By designing a new DNN architecture and integrating it with the recently proposed knockoffs framework, we perform feature selection with a controlled error rate, while maintaining high power. This new method, DeepPINK (Deep feature selection using Paired-Input Nonlinear Knockoffs), is applied to both simulated and real data sets to demonstrate its empirical utility.","",""
15,"S. Anvar, A. Tucker, V. Vinciotti, A. Venema, G. V. Ommen, S. V. D. Maarel, V. Raz, P. Hoen","Interspecies Translation of Disease Networks Increases Robustness and Predictive Accuracy",2011,"","","","",140,"2022-07-13 09:24:47","","10.1371/journal.pcbi.1002258","","",,,,,15,1.36,2,8,11,"Gene regulatory networks give important insights into the mechanisms underlying physiology and pathophysiology. The derivation of gene regulatory networks from high-throughput expression data via machine learning strategies is problematic as the reliability of these models is often compromised by limited and highly variable samples, heterogeneity in transcript isoforms, noise, and other artifacts. Here, we develop a novel algorithm, dubbed Dandelion, in which we construct and train intraspecies Bayesian networks that are translated and assessed on independent test sets from other species in a reiterative procedure. The interspecies disease networks are subjected to multi-layers of analysis and evaluation, leading to the identification of the most consistent relationships within the network structure. In this study, we demonstrate the performance of our algorithms on datasets from animal models of oculopharyngeal muscular dystrophy (OPMD) and patient materials. We show that the interspecies network of genes coding for the proteasome provide highly accurate predictions on gene expression levels and disease phenotype. Moreover, the cross-species translation increases the stability and robustness of these networks. Unlike existing modeling approaches, our algorithms do not require assumptions on notoriously difficult one-to-one mapping of protein orthologues or alternative transcripts and can deal with missing data. We show that the identified key components of the OPMD disease network can be confirmed in an unseen and independent disease model. This study presents a state-of-the-art strategy in constructing interspecies disease networks that provide crucial information on regulatory relationships among genes, leading to better understanding of the disease molecular mechanisms.","",""
5,"R. Ross, John D. Kelleher","A Comparative Study of the Effect of Sensor Noise on Activity Recognition Models",2013,"","","","",141,"2022-07-13 09:24:47","","10.1007/978-3-319-04406-4_15","","",,,,,5,0.56,3,2,9,"","",""
6,"Zhonghan Niu, Zhaoxi Chen, Linyi Li, Yubin Yang, Bo Li, Jinfeng Yi","On the Limitations of Denoising Strategies as Adversarial Defenses",2020,"","","","",142,"2022-07-13 09:24:47","","","","",,,,,6,3.00,1,6,2,"As adversarial attacks against machine learning models have raised increasing concerns, many denoising-based defense approaches have been proposed. In this paper, we summarize and analyze the defense strategies in the form of symmetric transformation via data denoising and reconstruction (denoted as $F+$ inverse $F$, $F-IF$ Framework). In particular, we categorize these denoising strategies from three aspects (i.e. denoising in the spatial domain, frequency domain, and latent space, respectively). Typically, defense is performed on the entire adversarial example, both image and perturbation are modified, making it difficult to tell how it defends against the perturbations. To evaluate the robustness of these denoising strategies intuitively, we directly apply them to defend against adversarial noise itself (assuming we have obtained all of it), which saving us from sacrificing benign accuracy. Surprisingly, our experimental results show that even if most of the perturbations in each dimension is eliminated, it is still difficult to obtain satisfactory robustness. Based on the above findings and analyses, we propose the adaptive compression strategy for different frequency bands in the feature domain to improve the robustness. Our experiment results show that the adaptive compression strategies enable the model to better suppress adversarial perturbations, and improve robustness compared with existing denoising strategies.","",""
4,"Zifan Liu, Zhechun Zhou, Theodoros Rekatsinas","Picket: Self-supervised Data Diagnostics for ML Pipelines",2020,"","","","",143,"2022-07-13 09:24:47","","","","",,,,,4,2.00,1,3,2,"Data corruption is an impediment to modern machine learning deployments. Corrupted data can severely bias the learned model and can also lead to invalid inference. We present, Picket, a first-of-its-kind system that enables data diagnostics for machine learning pipelines over tabular data. Picket can safeguard against data corruptions that lead to degradation either during training or deployment. For the training stage, Picket identifies erroneous training examples that can result in a biased model, while for the deployment stage, Picket flags corrupted query points to a trained machine learning model that due to noise will result to incorrect predictions. Picket is built around a novel self-supervised deep learning model for mixed-type tabular data. Learning this model is fully unsupervised to minimize the burden of deployment, and Picket is designed as a plugin that can increase the robustness of any machine learning pipeline. We evaluate Picket on a diverse array of real-world data considering different corruption models that include systematic and adversarial noise. We show that Picket offers consistently accurate diagnostics during both training and deployment of various models ranging from SVMs to neural networks, beating competing methods of data quality validation in machine learning pipelines.","",""
5,"Marzieh Ashrafiamiri, Sai Manoj Pudukotai Dinakarrao, Amir Hosein Afandizadeh Zargari, Minjun Seo, F. Kurdahi, H. Homayoun","R2AD: Randomization and Reconstructor-based Adversarial Defense for Deep Neural Networks",2020,"","","","",144,"2022-07-13 09:24:47","","10.1145/3380446.3430628","","",,,,,5,2.50,1,6,2,"Machine learning (ML) has been widely adopted in a plethora of applications ranging from simple time-series forecasting to computer security and autonomous systems. Despite the robustness by the ML algorithms against random noise, it has been shown that inclusion of specially crafted perturbations to the input data termed as adversarial samples can lead to a significant degradation in the ML performance. Existing defenses to mitigate or minimize the impact of adversarial samples including adversarial training or randomization are confined to specific categories of adversaries, compute-intensive and/or often lead to reduce performance even without adversaries. To overcome the shortcomings of the existing works on adversarial defense, we propose a two-stage adversarial defense technique (R2 AD). To thwart the exploitation of the deep neural network by the attacker, we first include a random nullification (RNF) layer. The RNF nullifies/removes some of the features from the input randomly to reduce the impact of adversarial noise and minimizes attacker's feasibility to extract the model parameters. However, the removal of input features through RNF leads to a reduction in the performance of the ML. As an antidote, we equip the network with a Reconstructor. The Reconstructor primarily contributes to reconstructing the input data by utilizing an autoencoder network, but based on the distribution of the normal samples, thereby improving the performance, and also being robust to the adversarial noise. We evaluated the performance of proposed multi-stage R2 AD on the MNIST digits and Fashion-MNIST datasets against multiple adversarial attacks including FGSM, JSMA, BIM, Deepfool, and CW attacks. Our findings report improvements as high as 80% in the performance compared to the existing defenses such as adversarial training and randomization-based defense.","",""
3,"F. Lemarchand, Eduardo Fernandes Montesuma, M. Pelcat, Erwan Nogues","Opendenoising: An Extensible Benchmark for Building Comparative Studies of Image Denoisers",2019,"","","","",145,"2022-07-13 09:24:47","","10.1109/ICASSP40776.2020.9053937","","",,,,,3,1.00,1,4,3,"Image denoising has recently taken a leap forward due to machine learning. However, image denoisers, both expert-based and learning-based, are mostly tested on well-behaved generated noises (usually Gaussian) rather than on real-life noises, making performance comparisons difficult in real-world conditions. This is especially true for learning-based denoisers which performance depends on training data. Hence, choosing which method to use for a specific denoising problem is difficult.This paper proposes a comparative study of existing denoisers, as well as an extensible open tool that makes it possible to reproduce and extend the study. MWCNN is shown to outperform other methods when trained for a real-world image interception noise, and additionally is the second least compute hungry of the tested methods. To evaluate the robustness of conclusions, three test sets are compared. A Kendall’s Tau correlation of only 60% is obtained on methods ranking between noise types, demonstrating the need for a benchmarking tool.","",""
4,"K. Nakadai, H. Okuno","Robot Audition and Computational Auditory Scene Analysis",2020,"","","","",146,"2022-07-13 09:24:47","","10.1002/aisy.202000050","","",,,,,4,2.00,2,2,2,"Robot audition aims at developing robot's ears that work in the real world, that is, machine listening of multiple sound sources. Its critical problem is noise. Speech interfaces have become more familiar and more indispensable as smartphones and artificial intelligence (AI) speakers spread. Their critical problems are noise and multiple simultaneous speakers. Recently two technological advances have contributed to significantly improve the performance of speech interfaces and robot audition. Emerging deep learning technology has improved noise robustness of automatic speech recognition, whereas microphone array processing has improved the performance of preprocessing such as noise reduction. Herein, an overview and history of robot audition are provided together with introduction of an open‐source software for robot audition and its wide applications in the real world. Also, it is discussed how robot audition contributes to the development of computational auditory scene analysis, that is, understanding of real‐world auditory environments.","",""
17,"J. Aspuru, A. Ochoa-Brust, R. A. Félix, Walter A. Mata-López, L. Mena, R. Ostos, R. Martínez-Peláez","Segmentation of the ECG Signal by Means of a Linear Regression Algorithm",2019,"","","","",147,"2022-07-13 09:24:47","","10.3390/s19040775","","",,,,,17,5.67,2,7,3,"The monitoring and processing of electrocardiogram (ECG) beats have been actively studied in recent years: new lines of research have even been developed to analyze ECG signals using mobile devices. Considering these trends, we proposed a simple and low computing cost algorithm to process and analyze an ECG signal. Our approach is based on the use of linear regression to segment the signal, with the goal of detecting the R point of the ECG wave and later, to separate the signal in periods for detecting P, Q, S, and T peaks. After pre-processing of ECG signal to reduce the noise, the algorithm was able to efficiently detect fiducial points, information that is transcendental for diagnosis of heart conditions using machine learning classifiers. When tested on 260 ECG records, the detection approach performed with a Sensitivity of 97.5% for Q-point and 100% for the rest of ECG peaks. Finally, we validated the robustness of our algorithm by developing an ECG sensor to register and transmit the acquired signals to a mobile device in real time.","",""
166,"C. Ballabio, S. Sterlacchini","Support Vector Machines for Landslide Susceptibility Mapping: The Staffora River Basin Case Study, Italy",2012,"","","","",148,"2022-07-13 09:24:47","","10.1007/s11004-011-9379-9","","",,,,,166,16.60,83,2,10,"","",""
16,"S. Prakash, Ahubhakumar, S.Appash, J.Cibiragul","Credit Card Fraud Detection using Adaboost and Majority Voting",2019,"","","","",149,"2022-07-13 09:24:47","","","","",,,,,16,5.33,4,4,3,"Credit card fraud is a serious problem in financial services. Billions of dollars are lost due to credit card fraud every year. There is a lack of research studies on analyzing real-world credit card data owing to confidentiality issues. In this paper, machine learning algorithms are used to detect credit card fraud. Standard models are firstly used. Then, hybrid methods which use AdaBoost and majority voting methods are applied. To evaluate the model efficacy, a publicly available credit card data set is used. Then, a realworld credit card data set from a financial institution is analyzed. In addition, noise is added to the data samples to further assess the robustness of the algorithms. The experimental results positively indicate that the majority voting method achieves good accuracy rates in detecting fraud cases in credit cards.","",""
88,"Huishuai Zhang, Yuejie Chi, Yingbin Liang","Provable Non-convex Phase Retrieval with Outliers: Median TruncatedWirtinger Flow",2016,"","","","",150,"2022-07-13 09:24:47","","","","",,,,,88,14.67,29,3,6,"Solving systems of quadratic equations is a central problem in machine learning and signal processing. One important example is phase retrieval, which aims to recover a signal from only magnitudes of its linear measurements. This paper focuses on the situation when the measurements are corrupted by arbitrary outliers, for which the recently developed non-convex gradient descent Wirtinger flow (WF) and truncated Wirtinger flow (TWF) algorithms likely fail. We develop a novel median-TWF algorithm that exploits robustness of sample median to resist arbitrary outliers in the initialization and the gradient update in each iteration. We show that such a non-convex algorithm provably recovers the signal from a near-optimal number of measurements composed of i.i.d. Gaussian entries, up to a logarithmic factor, even when a constant portion of the measurements are corrupted by arbitrary outliers. We further show that median-TWF is also robust when measurements are corrupted by both arbitrary outliers and bounded noise. Our analysis of performance guarantee is accomplished by development of non-trivial concentration measures of median-related quantities, which may be of independent interest. We further provide numerical experiments to demonstrate the effectiveness of the approach.","",""
8,"Nanhai Yang, Mingming Huang, Ran He, Xiukun Wang","Robust Semi-Supervised Learning Algorithm Based on Maximum Correntropy Criterion: Robust Semi-Supervised Learning Algorithm Based on Maximum Correntropy Criterion",2012,"","","","",151,"2022-07-13 09:24:47","","10.3724/SP.J.1001.2012.03977","","",,,,,8,0.80,2,4,10,"his paper analyzes the problem of sensitivity to noise in the mean square criterion of Gaussian- Laplacian regularized (GLR) algorithm. A robust semi-supervised learning algorithm based on maximum correntropy criterion (MCC), called GLR-MCC, is proposed to improve the robustness of GLR along with its convergence analysis. The half quadratic optimization technique is used to simplify the correntropy optimization problem to a standard semi-supervised problem in each iteration. Experimental results on typical machine learning data sets show that the proposed GLR-MCC can effectively improve the robustness of mislabeling noise and occlusion as compared with related semi-supervised learning algorithms.","",""
33,"M. Etemadi, O. Inan","Wearable ballistocardiogram and seismocardiogram systems for health and performance.",2018,"","","","",152,"2022-07-13 09:24:47","","10.1152/japplphysiol.00298.2017","","",,,,,33,8.25,17,2,4,"Cardiovascular diseases (CVDs) are prevalent in the US, and many forms of CVD primarily affect the mechanical aspects of heart function. Wearable technologies for monitoring the mechanical health of the heart and vasculature could enable proactive management of CVDs through titration of care based on physiological status as well as preventative wellness monitoring to help promote lifestyle choices that reduce the overall risk of developing CVDs. Additionally, such wearable technologies could be used to optimize human performance in austere environments. This review describes our progress in developing wearable ballistocardiogram (BCG)- and seismocardiogram-based systems for monitoring relative changes in cardiac output, contractility, and blood pressure. Our systems use miniature, low-noise accelerometers to measure the movements of the body in response to the heartbeat and novel machine learning algorithms to provide robustness against motion artifacts and sensor misplacement. Moreover, we have mathematically related wearable BCG signals-representing local, cardiogenic movements of a point on the body-to better understood whole body BCG signals, and thereby improved estimation of key health parameters. We validated these systems with experiments in healthy subjects, studies in patients with heart failure, and measurements in austere environments such as water immersion. The systems can be used in future work as a tool for clinicians and physiologists to measure the mechanical aspects of cardiovascular function outside of clinical settings, and to thereby titrate care for patients with CVDs, provide preventative screening, and optimize performance in austere environments by providing real-time in-depth information regarding performance and risk.","",""
295,"Xuegong Zhang, Xin Lu, Qian Shi, Xiu-qin Xu, Hon-chiu E Leung, L. Harris, J. D. Iglehart, A. Miron, Jun S. Liu, W. Wong","Recursive SVM feature selection and sample classification for mass-spectrometry and microarray data",2006,"","","","",153,"2022-07-13 09:24:47","","10.1186/1471-2105-7-197","","",,,,,295,18.44,30,10,16,"","",""
9,"Guan Wang, Jun Gong","Facial Expression Recognition Based on Improved LeNet-5 CNN",2019,"","","","",154,"2022-07-13 09:24:47","","10.1109/CCDC.2019.8832535","","",,,,,9,3.00,5,2,3,"Aiming at the influence of local occlusion on expression recognition, this paper proposes an improved cross-connected multi-layer LeNet-5 Convolutional Neural Network model. Under occlusion conditions, traditional machine learning methods are not robust due to lack of image information and noise interference, and the recognition rate is poor. Based on the advantages of deep learning in feature extraction, this paper adds a convolution layer and a pooling layer based on the LeNet-5 model. The low-level features extracted from the network structure are combined with the high-level features to construct the classifier. The implicit features are extracted by using the trainable convolution kernel, and the extracted implicit features are reduced by the pooling layer. Finally, the Softmax classifier is used for classification and recognition. The contrast experiment between the occlusion determination and the occlusion uncertainty is carried out, and the occlusion robustness of the improved method is verified.","",""
9,"Guillermo Cortés, R. Carniel, M. Á. Mendoza, P. Lesage","Standardization of Noisy Volcanoseismic Waveforms as a Key Step toward Station‐Independent, Robust Automatic Recognition",2019,"","","","",155,"2022-07-13 09:24:47","","10.1785/0220180334","","",,,,,9,3.00,2,4,3,"This work addresses the automatic Volcano-Seismic Recognition (VSR) in a noisy scenario studying the robustness of a classifier based on Hidden Markov Models (HMMs). The system learns recognition models analyzing signals recorded in 1995 to automatically detect and classify noisy events of 2009. Both datasets were acquired in different locations at Deception Island and with a different type of sensor showing a variety of site effects and noises. To deal with the inherent waveform variability of this setup, we propose to reconstruct the seismograms to achieve both modeling standardization and noise reduction goals. We analyze a set of Empirical Mode Decomposition (EMD) algorithms jointly with static and dynamic reconstruction criteria in order to evaluate their impact on the robustness of the recognition process. This machine-learning focus on real-time, continuous, unsupervised VSR paradigm is able to increase by 16% the global VSR accuracy using an adaptive reconstruction compared to the scores obtained without any standardization.","",""
9,"S. Saadaoui, M. Tabaa, F. Monteiro, Mouhamad Chehaitly, A. Dandache","Discrete Wavelet Packet Transform-Based Industrial Digital Wireless Communication Systems",2019,"","","","",156,"2022-07-13 09:24:47","","10.3390/INFO10030104","","",,,,,9,3.00,2,5,3,"The industrial internet of things (IIoT) known as industry 4.0, is the use of internet of things technologies, via the Wireless Sensor Network (WSN), to enhance manufacturing and industrial processes. It incorporates machine learning and big data technologies, to allow machine-to-machine communication that have existed for years in the industrial world. Therefore, it is necessary to propose a robust and functional communication architecture that is based on WSNs, inside factories, in order to show the great interest in the connectivity of things in the industrial environment. In such environment, propagation differs from other conventional indoor mediums, in its large dimensions, and the nature of objects and obstacles inside. Thus, the industrial medium is modeled as a fading channel affected by an impulsive and Gaussian noise. The objective of this paper is to improve robustness and performances of multi-user WSN architecture, based on Discrete Wavelet Transform, under an industrial environment using conventional channel coding and an optimal thresholding receiver.","",""
32,"Yangqin Feng, Lei Zhang, Zhang Yi","Breast cancer cell nuclei classification in histopathology images using deep neural networks",2018,"","","","",157,"2022-07-13 09:24:47","","10.1007/s11548-017-1663-9","","",,,,,32,8.00,11,3,4,"","",""
33,"Xiaogang Yang, F. De Carlo, C. Phatak, Dogˇa Gürsoy","A convolutional neural network approach to calibrating the rotation axis for X-ray computed tomography.",2017,"","","","",158,"2022-07-13 09:24:47","","10.1107/S1600577516020117","","",,,,,33,6.60,8,4,5,"This paper presents an algorithm to calibrate the center-of-rotation for X-ray tomography by using a machine learning approach, the Convolutional Neural Network (CNN). The algorithm shows excellent accuracy from the evaluation of synthetic data with various noise ratios. It is further validated with experimental data of four different shale samples measured at the Advanced Photon Source and at the Swiss Light Source. The results are as good as those determined by visual inspection and show better robustness than conventional methods. CNN has also great potential for reducing or removing other artifacts caused by instrument instability, detector non-linearity, etc. An open-source toolbox, which integrates the CNN methods described in this paper, is freely available through GitHub at tomography/xlearn and can be easily integrated into existing computational pipelines available at various synchrotron facilities. Source code, documentation and information on how to contribute are also provided.","",""
30,"R. Wolfinger, Pei-Yi Tan","Stacked Ensemble Models for Improved Prediction Accuracy",2017,"","","","",159,"2022-07-13 09:24:47","","","","",,,,,30,6.00,15,2,5,"Ensemble modeling is now a well-established means for improving prediction accuracy; it enables you to average out noise from diverse models and thereby enhance the generalizable signal. Basic stacked ensemble techniques combine predictions from multiple machine learning algorithms and use these predictions as inputs to second-level learning models. This paper shows how you can generate a diverse set of models by various methods such as forest, gradient boosted decision trees, factorization machines, and logistic regression and then combine them with stacked-ensemble techniques such as hill climbing, gradient boosting, and nonnegative least squares in SAS Visual Data Mining and Machine Learning. The application of these techniques to real-world big data problems demonstrates how using stacked ensembles produces greater prediction accuracy and robustness than do individual models. The approach is powerful and compelling enough to alter your initial data mining mindset from finding the single best model to finding a collection of really good complementary models. It does involve additional cost due both to training a large number of models and the proper use of cross validation to avoid overfitting. This paper shows how to efficiently handle this computational expense in a modern SAS environment and how to manage an ensemble workflow by using parallel computation in a distributed framework.","",""
3,"Chia-Te Liao, S. Lai","Robust kernel-based learning for image-related problems",2012,"","","","",160,"2022-07-13 09:24:47","","10.1049/IET-IPR.2010.0301","","",,,,,3,0.30,2,2,10,"Robustness is one of the most critical issues in the appearance-based learning techniques. This study develops a novel robust kernel for kernel machines, and consequently improves their robustness in resisting noise for solving the image-related learning problems. By incorporating a robust ρ-function to reduce the influence of outlier components, this kernel gives more reasonable kernel values when images are seriously corrupted. The authors incorporate the proposed kernel into different kernel-based approaches, such as support vector machine (SVM) and kernel Fisher discriminant (KFD) analysis, to validate its performance on various visual learning problems of face recognition and data visualisation. Experimental results indicate that the proposed kernel can provide the superior robustness to the classical approaches.","",""
4,"T. Wan, X. Fu, Kaili Jiang, Yuan Zhao, B. Tang","Radar Antenna Scan Pattern Intelligent Recognition Using Visibility Graph",2019,"","","","",161,"2022-07-13 09:24:47","","10.1109/ACCESS.2019.2957769","","",,,,,4,1.33,1,5,3,"Radar antenna scan pattern (RASP) reconnaissance is a major problem in electronic warfare (EW). The RASP exerts a considerable influence on target identification, jamming decision making, and electronic support measures and thus plays a critical role in modern electronic warfare. A visibility graph (VG) is a tool for converting a time series into complex graphs with excellent noise immunity. This paper proposes a novel method for the intelligent recognition of the RASP based on the VG, including the circular, sector, helical, raster, conical, phased array, phased array azimuth and circular elevation scans. The changes in the signal amplitude received from the EW receiver are determined. Moreover, the related features are extracted from the VG and utilized to classify the RASPs. The comparison experiments performed with different classifiers, such as machine learning, neural network, and deep learning, confirm that the proposed method can improve the robustness of the recognition rate to the noise and recognition accuracy.","",""
68,"Naiyan Wang, D. Yeung","Bayesian Robust Matrix Factorization for Image and Video Processing",2013,"","","","",162,"2022-07-13 09:24:47","","10.1109/ICCV.2013.224","","",,,,,68,7.56,34,2,9,"Matrix factorization is a fundamental problem that is often encountered in many computer vision and machine learning tasks. In recent years, enhancing the robustness of matrix factorization methods has attracted much attention in the research community. To benefit from the strengths of full Bayesian treatment over point estimation, we propose here a full Bayesian approach to robust matrix factorization. For the generative process, the model parameters have conjugate priors and the likelihood (or noise model) takes the form of a Laplace mixture. For Bayesian inference, we devise an efficient sampling algorithm by exploiting a hierarchical view of the Laplace distribution. Besides the basic model, we also propose an extension which assumes that the outliers exhibit spatial or temporal proximity as encountered in many computer vision applications. The proposed methods give competitive experimental results when compared with several state-of-the-art methods on some benchmark image and video processing tasks.","",""
17,"Hang Yang, Y. Zou, Zhongyu Wang, Bing Wu","A Hybrid Method for Short-term Freeway Travel Time Prediction Based on Wavelet Neural Network and Markov Chain",2018,"","","","",163,"2022-07-13 09:24:47","","10.1139/CJCE-2017-0231","","",,,,,17,4.25,4,4,4,"Short-term travel time prediction is an essential input to intelligent transportation systems. Timely and accurate traffic forecasting is necessary for advanced traffic management systems and advanced traveler information systems. Despite several short-term travel time prediction approaches have been proposed in the past decade, especially for hybrid models that consist of machine learning models and statistical models, few studies focus on the over-fitting problem brought by hybrid models. The over-fitting problem deteriorates the prediction accuracy especially during peak hours. This paper proposes a hybrid model that embraces wavelet neural network (WNN), Markov chain (MAR), and the volatility (VOA) model for short-term travel time prediction in a freeway system. The purpose of this paper is to provide deeper insights into underlining dynamic traffic patterns and to improve the prediction accuracy and robustness. The method takes periodical analysis, error correction, and noise extraction into consider...","",""
34,"L. Boulogne, B. Wolf, M. Wiering, S. V. van Netten","Performance of neural networks for localizing moving objects with an artificial lateral line.",2017,"","","","",164,"2022-07-13 09:24:47","","10.1088/1748-3190/aa7fcb","","",,,,,34,6.80,9,4,5,"Fish are able to sense water flow velocities relative to their body with their mechanoreceptive lateral line organ. This organ consists of an array of flow detectors distributed along the fish body. Using the excitation of these individual detectors, fish can determine the location of nearby moving objects. Inspired by this sensory modality, it is shown here how neural networks can be used to extract an object's location from simulated excitation patterns, as can be measured along arrays of stationary artificial flow velocity sensors. The applicability, performance and robustness with respect to input noise of different neural network architectures are compared. When trained and tested under high signal to noise conditions (46 dB), the Extreme Learning Machine architecture performs best with a mean Euclidean error of 0.4% of the maximum depth of the field D, which is taken half the length of the sensor array. Under lower signal to noise conditions Echo State Networks, having recurrent connections, enhance the performance while the Multilayer Perceptron is shown to be the most noise robust architecture. Neural network performance decreased when the source moves close to the sensor array or to the sides of the array. For all considered architectures, increasing the number of detectors per array increased localization performance and robustness.","",""
18,"M. Bruijning, M. Visser, C. Hallmann, E. Jongejans","trackdem: Automated particle tracking to obtain population counts and size distributions from videos in r",2018,"","","","",165,"2022-07-13 09:24:47","","10.1111/2041-210X.12975","","",,,,,18,4.50,5,4,4,"The possibilities for image analysis in scientific research are substantial: the costs of digital cameras and data storage are sharply decreasing, and automated image analyses greatly increase the scale, reproducibility and robustness of biological studies. However, automated image analysis in ecological and evolutionary studies is still in its infancy. There is a clear need for easy to use and accessible tools. Here, we provide a general purpose method to obtain estimates of population densities, individual body sizes and behavioural metrics from video material of moving organisms. The methods are supplied as a new r‐package trackdem, which provides a flexible, easy to install and use, generally applicable and accurate way to analyse ecological video data. The package can detect and track moving particles, count individuals and estimate individual sizes using background detection, particle identification and particle tracking algorithms. Machine learning is implemented to reduce the influence of noise in lower quality videos or to distinguish a single species in multi‐species systems. We show that trackdem provides accurate population counts and body size distributions. Using a series of simulations, we show that our estimates are robust against high levels of noise in videos. When applied to live populations of Daphnia magna, our methods obtained accurate and unbiased estimates of population counts, individual sizes and size distributions, as verified by manual counting and measuring. The package trackdem is also directly usable for movement analysis, for instance in behavioural ecology, as illustrated by the tracking of insects, fish, cars and humans. Within 24 hr, we obtained 192 accurate population counts and body sizes of 22,154 individuals. Such results underscore that automated analysis can improve robustness and reproducibility, and greatly increase the scope of studies in ecology and evolution.","",""
43,"Min Cheng, Qian Xu, Jianming Lv, Wenyin Liu, Qing Li, Jianping Wang","MS-LSTM: A multi-scale LSTM model for BGP anomaly detection",2016,"","","","",166,"2022-07-13 09:24:47","","10.1109/ICNP.2016.7785326","","",,,,,43,7.17,7,6,6,"Detecting anomalous Border Gateway Protocol (BGP) traffic is significantly important in improving both security and robustness of the Internet. Existing solutions apply classic classifiers to make real-time decision based on the traffic features of present moment. However, due to the frequently happening burst and noise in dynamic Internet traffic, the decision based on short-term features is not reliable. To address this problem, we propose MS-LSTM, a multi-scale Long Short-Term Memory (LSTM) model to consider the Internet flow as a multi-dimensional time sequence and learn the traffic pattern from historical features in a sliding time window. In addition, we find that adopting different time scale to preprocess the traffic flow has great impact on the performance of all classifiers. In this paper, comprehensive experiments are conducted and the results show that a proper time scale can improve about 10% accuracy of LSTM as well as all conventional machine learning methods. Particularly, MS-LSTM with optimal time scale 8 can achieve 99.5% accuracy in the best case.","",""
25,"Wei Chu, B. Champagne","A Noise-Robust FFT-Based Auditory Spectrum With Application in Audio Classification",2008,"","","","",167,"2022-07-13 09:24:47","","10.1109/TASL.2007.907569","","",,,,,25,1.79,13,2,14,"In this paper, we investigate the noise robustness of Wang and Shamma's early auditory (EA) model for the calculation of an auditory spectrum in audio classification applications. First, a stochastic analysis is conducted wherein an approximate expression of the auditory spectrum is derived to justify the noise-suppression property of the EA model. Second, we present an efficient fast Fourier transform (FFT)-based implementation for the calculation of a noise-robust auditory spectrum, which allows flexibility in the extraction of audio features. To evaluate the performance of the proposed FFT-based auditory spectrum, a set of speech/music/noise classification tasks is carried out wherein a support vector machine (SVM) algorithm and a decision tree learning algorithm (C4.5) are used as the classifiers. Features used for classification include conventional Mel-frequency cepstral coefficients (MFCCs), MFCC-like features obtained from the original auditory spectrum (i.e., based on the EA model) and the proposed FFT-based auditory spectrum, as well as spectral features (spectral centroid, bandwidth, etc.) computed from the latter. Compared to the conventional MFCC features, both the MFCC-like and spectral features derived from the proposed FFT-based auditory spectrum show more robust performance in noisy test cases. Test results also indicate that, using the new MFCC-like features, the performance of the proposed FFT-based auditory spectrum is slightly better than that of the original auditory spectrum, while its computational complexity is reduced by an order of magnitude.","",""
23,"Chong Peng, Zhao Kang, Yunhong Hu, Jie Cheng, Q. Cheng","Robust Graph Regularized Nonnegative Matrix Factorization for Clustering",2017,"","","","",168,"2022-07-13 09:24:47","","10.1145/3003730","","",,,,,23,4.60,5,5,5,"Matrix factorization is often used for data representation in many data mining and machine-learning problems. In particular, for a dataset without any negative entries, nonnegative matrix factorization (NMF) is often used to find a low-rank approximation by the product of two nonnegative matrices. With reduced dimensions, these matrices can be effectively used for many applications such as clustering. The existing methods of NMF are often afflicted with their sensitivity to outliers and noise in the data. To mitigate this drawback, in this paper, we consider integrating NMF into a robust principal component model, and design a robust formulation that effectively captures noise and outliers in the approximation while incorporating essential nonlinear structures. A set of comprehensive empirical evaluations in clustering applications demonstrates that the proposed method has strong robustness to gross errors and superior performance to current state-of-the-art methods.","",""
46,"Reinhold Scherer, J. Faller, David Balderas, E. Friedrich, M. Pröll, B. Allison, G. Müller-Putz","Brain–computer interfacing: more than the sum of its parts",2013,"","","","",169,"2022-07-13 09:24:47","","10.1007/s00500-012-0895-4","","",,,,,46,5.11,7,7,9,"","",""
40,"Hongwei Zhang, Xiong Xiao, O. Hasegawa","A Load-Balancing Self-Organizing Incremental Neural Network",2014,"","","","",170,"2022-07-13 09:24:47","","10.1109/TNNLS.2013.2287884","","",,,,,40,5.00,13,3,8,"Clustering is widely used in machine learning, feature extraction, pattern recognition, image analysis, information retrieval, and bioinformatics. Online unsupervised incremental learning is an important branch of data clustering. However, accurately separating high-density overlapped areas in a network has a direct impact on the performance of the clustering algorithm. In this paper, we propose a load-balancing self-organizing incremental neural network (LB-SOINN) to achieve good clustering results and demonstrate that it is more stable than an enhanced SOINN (E-SOINN). LB-SOINN has all the advantages of E-SOINN, such as robustness to noise and online unsupervised incremental learning. It overcomes the shortcomings of the topology structure generated by E-SOINN, such as dependence on the sequence of the input data, and avoids the turbulence that occurs when separating a composite class into subclasses. Furthermore, we also introduce a distance combination framework to obtain good performance for high-dimensional space-clustering tasks. Experiments involving both artificial and real world data sets indicate that LB-SOINN has superior performance in comparison with E-SOINN and other methods.","",""
11,"Loai Danial, N. Wainstein, Shraga Kraus, S. Kvatinsky","DIDACTIC: A Data-Intelligent Digital-to-Analog Converter with a Trainable Integrated Circuit using Memristors",2018,"","","","",171,"2022-07-13 09:24:47","","10.1109/JETCAS.2017.2780251","","",,,,,11,2.75,3,4,4,"In an increasingly data-diverse world, in which data are interactively transferred at high rates, there is an ever-growing demand for high-precision data converters. In this paper, we propose a novel digital-to-analog converter (DAC) configuration that is calibrated using an artificial intelligence neural network technique. The proposed technique is demonstrated on an adaptive and self-calibrated binary-weighted DAC that can be configured on-chip in real time. We design a reconfigurable 4-bit DAC with a memristor-based neural network. This circuit uses an online supervised machine learning algorithm called “binary-weighted time-varying gradient descent.” This algorithm fits multiple full-scale voltage ranges and sampling frequencies by iterative synaptic adjustments, while inherently providing mismatch calibration and noise tolerance. Theoretical analysis, as well as simulation results, show the efficiency and robustness of the training algorithm in reconfiguration, self-calibration, and desensitization, leading to a significant improvement in DAC accuracy: 0.12 LSB in terms of integral non-linearity, 0.11 LSB in terms of differential non-linearity, and 3.63 bits in terms of effective number of bits. The findings constitute a promising milestone toward scalable data-driven converters using deep neural networks.","",""
11,"Xu Yang, H. Qiao, Zhiyong Liu","An Algorithm for Finding the Most Similar Given Sized Subgraphs in Two Weighted Graphs",2018,"","","","",172,"2022-07-13 09:24:47","","10.1109/TNNLS.2017.2712794","","",,,,,11,2.75,4,3,4,"We propose a weighted common subgraph (WCS) matching algorithm to find the most similar subgraphs in two labeled weighted graphs. WCS matching, as a natural generalization of equal-sized graph matching and subgraph matching, has found wide applications in many computer vision and machine learning tasks. In this brief, WCS matching is first formulated as a combinatorial optimization problem over the set of partial permutation matrices. Then, it is approximately solved by a recently proposed combinatorial optimization framework—graduated nonconvexity and concavity procedure. Experimental comparisons on both synthetic graphs and real-world images validate its robustness against noise level, problem size, outlier number, and edge density.","",""
9,"A. Carcangiu, L. D. Spano","G-Gene",2018,"","","","",173,"2022-07-13 09:24:47","","10.1145/3229095","","",,,,,9,2.25,5,2,4,"The large availability of touch-sensitive screens fostered the research in gesture recognition. The Machine Learning community focused mainly on accuracy and robustness to noise, creating classifiers that precisely recognize gestures after their performance. Instead, the User Interface Engineering community developed compositional gesture descriptions that model gestures and their sub-parts. They are suitable for building guidance systems, but they lack a robust and accurate recognition support. In this paper, we establish a compromise between the accuracy and the provided information introducing G-Gene, a method for transforming compositional stroke gesture definitions into profile Hidden Markov Models (HMMs), able to provide both a good accuracy and information on gesture sub-parts. It supports online recognition without using any global feature, and it updates the information while receiving the input stream, with an accuracy useful for prototyping the interaction. We evaluated the approach in a user interface development task, showing that it requires less time and effort for creating guidance systems with respect to common gesture classification approaches.","",""
8,"Akram Erraqabi, A. Baratin, Yoshua Bengio, S. Lacoste-Julien","A3T: Adversarially Augmented Adversarial Training",2018,"","","","",174,"2022-07-13 09:24:47","","","","",,,,,8,2.00,2,4,4,"Recent research showed that deep neural networks are highly sensitive to so-called adversarial perturbations, which are tiny perturbations of the input data purposely designed to fool a machine learning classifier. Most classification models, including deep learning models, are highly vulnerable to adversarial attacks. In this work, we investigate a procedure to improve adversarial robustness of deep neural networks through enforcing representation invariance. The idea is to train the classifier jointly with a discriminator attached to one of its hidden layer and trained to filter the adversarial noise. We perform preliminary experiments to test the viability of the approach and to compare it to other standard adversarial training methods.","",""
82,"Chen Huang, X. Ding, Chi Fang","Head Pose Estimation Based on Random Forests for Multiclass Classification",2010,"","","","",175,"2022-07-13 09:24:47","","10.1109/ICPR.2010.234","","",,,,,82,6.83,27,3,12,"Head pose estimation remains a unique challenge for computer vision system due to identity variation, illumination changes, noise, etc. Previous statistical approaches like PCA, linear discriminative analysis (LDA) and machine learning methods, including SVM and Adaboost, cannot achieve both accuracy and robustness that well. In this paper, we propose to use Gabor feature based random forests as the classification technique since they naturally handle such multi-class classification problem and are accurate and fast. The two sources of randomness, random inputs and random features, make random forests robust and able to deal with large feature spaces. Besides, we implement LDA as the node test to improve the discriminative power of individual trees in the forest, with each node generating both constant and variant number of children nodes. Experiments are carried out on two public databases to show the proposed algorithm outperforms other approaches in both accuracy and computational efficiency.","",""
8,"Johannes Schneider, J. Handali, J. Brocke","Increasing Trust in (Big) Data Analytics",2018,"","","","",176,"2022-07-13 09:24:47","","10.1007/978-3-319-92898-2_6","","",,,,,8,2.00,3,3,4,"","",""
6,"C. Poon, N. Keriven, G. Peyré","A Dual Certificates Analysis of Compressive Off-the-Grid Recovery",2018,"","","","",177,"2022-07-13 09:24:47","","","","",,,,,6,1.50,2,3,4,"Many problems in machine learning and imaging can be framed as an infinite dimensional Lasso problem to estimate a sparse measure. This includes for instance regression using a continuously parameterized dictionary, mixture model estimation and super-resolution of images. To make the problem tractable, one typically sketches the observations (often called compressive-sensing in imaging) using randomized projections. In this work, we provide a comprehensive treatment of the recovery performances of this class of approaches, proving that (up to log factors) a number of sketches proportional to the sparsity is enough to identify the sought after measure with robustness to noise. We prove both exact support stability (the number of recovered atoms matches that of the measure of interest) and approximate stability (localization of the atoms) by extending two classical proof techniques (minimal norm dual certificate and golfing scheme certificate).","",""
29,"Philipp Hennig","Fast Probabilistic Optimization from Noisy Gradients",2013,"","","","",178,"2022-07-13 09:24:47","","","","",,,,,29,3.22,29,1,9,"Stochastic gradient descent remains popular in large-scale machine learning, on account of its very low computational cost and robustness to noise. However, gradient descent is only linearly efficient and not transformation invariant. Scaling by a local measure can substantially improve its performance. One natural choice of such a scale is the Hessian of the objective function: Were it available, it would turn linearly efficient gradient descent into the quadratically efficient Newton-Raphson optimization. Existing covariant methods, though, are either super-linearly expensive or do not address noise. Generalising recent results, this paper constructs a nonparametric Bayesian quasi-Newton algorithm that learns gradient and Hessian from noisy evaluations of the gradient. Importantly, the resulting algorithm, like stochastic gradient descent, has cost linear in the number of input dimensions.","",""
21,"Yuanqing Li, Cuntai Guan","A Semi-supervised SVM Learning Algorithm for Joint Feature Extraction and Classification in Brain Computer Interfaces",2006,"","","","",179,"2022-07-13 09:24:47","","10.1109/IEMBS.2006.260327","","",,,,,21,1.31,11,2,16,"In machine learning based Brain Computer Interfaces (BCIs), it is a challenge to use only a small amount of labelled data to build a classifier for a specific subject. This challenge was specifically addressed in BCI Competition 2005. Moreover, an effective BCI system should be adaptive to tackle the dynamic variations in brain signal. One of the solutions is to have its parameters adjustable while the system is used online. In this paper we introduce a new semi-supervised support vector machine (SVM) learning algorithm. In this method, the feature extraction and classification are jointly performed in iterations. This method allows us to use a small training set to train the classifier while maintaining high performance. Therefore, the tedious initial calibration process is shortened. This algorithm can be used online to make the BCI system robust to possible signal changes. We analyze two important issues of the proposed algorithm, the robustness of the features to noise and the convergence of algorithm. We applied our method to data from BCI competition 2005, and the results demonstrated the validity of the proposed algorithm","",""
84,"Yassine Benajiba, Mona T. Diab, Paolo Rosso","Arabic Named Entity Recognition: A Feature-Driven Study",2009,"","","","",180,"2022-07-13 09:24:47","","10.1109/TASL.2009.2019927","","",,,,,84,6.46,28,3,13,"The named entity recognition task aims at identifying and classifying named entities within an open-domain text. This task has been garnering significant attention recently as it has been shown to help improve the performance of many natural language processing applications. In this paper, we investigate the impact of using different sets of features in three discriminative machine learning frameworks, namely, support vector machines, maximum entropy and conditional random fields for the task of named entity recognition. Our language of interest is Arabic. We explore lexical, contextual and morphological features and nine data-sets of different genres and annotations. We measure the impact of the different features in isolation and incrementally combine them in order to evaluate the robustness to noise of each approach. We achieve the highest performance using a combination of 15 features in conditional random fields using broadcast news data (Fbeta = 1=83.34).","",""
4,"R. Rehr, Timo Gerkmann","Robust DNN-Based Speech Enhancement with Limited Training Data",2018,"","","","",181,"2022-07-13 09:24:47","","","","",,,,,4,1.00,2,2,4,"In conventional speech enhancement, statistical models for speech and noise are used to derive clean speech estimators. The parameters of the models are estimated blindly from the noisy observation using carefully designed algorithms. These algorithms generalize well to unseen acoustic conditions, but are unable to reduce highly non-stationary noise types. This shortcoming motivated the usage of machine-learning-based (ML-based) algorithms, in particular deep neural networks (DNNs). But if only limited training data are available, the noise reduction performance in unseen acoustic conditions suffers. In this paper, motivated by conventional speech enhancement, we propose to use the a priori and a posteriori signal-to-noise ratios (SNRs) for DNN-based speech enhancement systems. Instrumental measures show that the proposed features increase the robustness in unknown noise types even if only limited training data are available.","",""
4,"Woojin Kim, Jae Mann Park, H. Kim","Support vector learning approaches for object localization in acoustic wireless sensor networks",2010,"","","","",182,"2022-07-13 09:24:47","","10.1109/IS.2010.5548340","","",,,,,4,0.33,1,3,12,"Object tracking, whose goal is to estimate the location of a target of interests, is one of the key issues in applications of wireless sensor networks (WSNs). Recently, various target tracking methods were proposed, especially using learning techniques such as neural network and support vector machine (SVM). This paper presents two SVM-based learning approaches for target tracking using WSNs. In the first approach, a black-box relationship between the acoustic measurements and the location of object is learned using least-square support vector regression (LSSVR). The other approach is multi-class classification with cell decomposition, which employ posterior probability regression with Platt's method to learn the sensor model. We describe both approaches and evaluate their performance in terms of the accuracy and robustness. Experimental results show that the direct regression approach is more accurate and robust to the sensing noise than the posterior probability regression approach. The localized aspects of the posterior regression can be advantageous in terms of scalability.","",""
23,"Yunlong Feng, Yuning Yang, X. Huang, S. Mehrkanoon, J. Suykens","Robust Support Vector Machines for Classification with Nonconvex and Smooth Losses",2016,"","","","",183,"2022-07-13 09:24:47","","10.1162/NECO_a_00837","","",,,,,23,3.83,5,5,6,"Abstract This letter addresses the robustness problem when learning a large margin classifier in the presence of label noise. In our study, we achieve this purpose by proposing robustified large margin support vector machines. The robustness of the proposed robust support vector classifiers (RSVC), which is interpreted from a weighted viewpoint in this work, is due to the use of nonconvex classification losses. Besides the robustness, we also show that the proposed RSCV is simultaneously smooth, which again benefits from using smooth classification losses. The idea of proposing RSVC comes from M-estimation in statistics since the proposed robust and smooth classification losses can be taken as one-sided cost functions in robust statistics. Its Fisher consistency property and generalization ability are also investigated. Besides the robustness and smoothness, another nice property of RSVC lies in the fact that its solution can be obtained by solving weighted squared hinge loss–based support vector machine problems iteratively. We further show that in each iteration, it is a quadratic programming problem in its dual space and can be solved by using state-of-the-art methods. We thus propose an iteratively reweighted type algorithm and provide a constructive proof of its convergence to a stationary point. Effectiveness of the proposed classifiers is verified on both artificial and real data sets.","",""
66,"Jianing Shi, W. Yin, S. Osher, P. Sajda","A Fast Hybrid Algorithm for Large-Scale l1-Regularized Logistic Regression",2010,"","","","",184,"2022-07-13 09:24:47","","10.5555/1756006.1756029","","",,,,,66,5.50,17,4,12,"l1-regularized logistic regression, also known as sparse logistic regression, is widely used in machine learning, computer vision, data mining, bioinformatics and neural signal processing. The use of l1 regularization attributes attractive properties to the classifier, such as feature selection, robustness to noise, and as a result, classifier generality in the context of supervised learning. When a sparse logistic regression problem has large-scale data in high dimensions, it is computationally expensive to minimize the non-differentiable l1-norm in the objective function. Motivated by recent work (Koh et al., 2007; Hale et al., 2008), we propose a novel hybrid algorithm based on combining two types of optimization iterations: one being very fast and memory friendly while the other being slower but more accurate. Called hybrid iterative shrinkage (HIS), the resulting algorithm is comprised of a fixed point continuation phase and an interior point phase. The first phase is based completely on memory efficient operations such as matrix-vector multiplications, while the second phase is based on a truncated Newton's method. Furthermore, we show that various optimization techniques, including line search and continuation, can significantly accelerate convergence. The algorithm has global convergence at a geometric rate (a Q-linear rate in optimization terminology). We present a numerical comparison with several existing algorithms, including an analysis using benchmark data from the UCI machine learning repository, and show our algorithm is the most computationally efficient without loss of accuracy.","",""
17,"Gongmin Lan, Chenping Hou, Dong-yun Yi","Robust feature selection via simultaneous capped ℓ2-norm and ℓ2,1-norm minimization",2016,"","","","",185,"2022-07-13 09:24:47","","10.1109/ICBDA.2016.7509813","","",,,,,17,2.83,6,3,6,"High dimension is one of the key characters of big data. Feature selection plays a significant role in many machine learning applications dealing with high-dimensional data. To improve the robustness of feature selection, we propose a new robust feature selection method with emphasizing Simultaneous Capped ℓ2-norm loss and ℓ2,1-norm regularizer Minimization (SCM). The capped ℓ2-norm based loss function can effectively eliminate the influence of noise and outliers in regression and the ℓ2,1-norm regularization is used to select features across data sets with joint sparsity. Meanwhile, we propose an effective approach to solve the formulated minimization problem. Experimental studies on real-world data sets demonstrate the effectiveness of our method in comparison with other popular feature selection methods.","",""
19,"Achraf El Allali, John R. Rose","MGC: a metagenomic gene caller",2013,"","","","",186,"2022-07-13 09:24:47","","10.1186/1471-2105-14-S9-S6","","",,,,,19,2.11,10,2,9,"","",""
15,"Der-Chiang Li, Wen-Chih Chen, Che-Jung Chang, C. Chen, I-Hsiang Wen","Practical information diffusion techniques to accelerate new product pilot runs",2015,"","","","",187,"2022-07-13 09:24:47","","10.1080/00207543.2015.1032437","","",,,,,15,2.14,3,5,7,"Under the increasing pressure of global competition, product life cycles are becoming shorter and shorter. This means that better methods are needed to analyse the limited information obtained at the trial stage in order to derive useful knowledge that can aid in mass production. Machine learning algorithms, such as data mining techniques, are widely applied to solve this problem. However, a certain amount of training samples is usually required to determine the validity of the information that is obtained. This study uses only a few data points to estimate the range of data attribute domains using a data diffusion method, in order to derive more useful information. Then, based on practical engineering experience, we generate virtual samples with a noise disturbance method to improve the robustness of the predictions derived from a multiple linear regression. One real data set obtained from a large TFT-LCD company is examined in the experiment, and the results show the proposed approach to be effective.","",""
7,"L. F. Miranda, Luiz Otavio Vilas Boas Oliveira, J. F. B. S. Martins, G. Pappa","How noisy data affects geometric semantic genetic programming",2017,"","","","",188,"2022-07-13 09:24:47","","10.1145/3071178.3071300","","",,,,,7,1.40,2,4,5,"Noise is a consequence of acquiring and pre-processing data from the environment, and shows fluctuations from different sources---e.g., from sensors, signal processing technology or even human error. As a machine learning technique, Genetic Programming (GP) is not immune to this problem, which the field has frequently addressed. Recently, Geometric Semantic Genetic Programming (GSGP), a semantic-aware branch of GP, has shown robustness and high generalization capability. Researchers believe these characteristics may be associated with a lower sensibility to noisy data. However, there is no systematic study on this matter. This paper performs a deep analysis of the GSGP performance over the presence of noise. Using 15 synthetic datasets where noise can be controlled, we added different ratios of noise to the data and compared the results obtained with those of a canonical GP. The results show that, as we increase the percentage of noisy instances, the generalization performance degradation is more pronounced in GSGP than GP. However, in general, GSGP is more robust to noise than GP in the presence of up to 10% of noise, and presents no statistical difference for values higher than that in the test bed.","",""
6,"A. Cheddad, H. Kusetogullari, Håkan Grahn","Object recognition using shape growth pattern",2017,"","","","",189,"2022-07-13 09:24:47","","10.1109/ISPA.2017.8073567","","",,,,,6,1.20,2,3,5,"This paper proposes a preprocessing stage to augment the bank of features that one can retrieve from binary images to help increase the accuracy of pattern recognition algorithms. To this end, by applying successive dilations to a given shape, we can capture a new dimension of its vital characteristics which we term hereafter: the shape growth pattern (SGP). This work investigates the feasibility of such a notion and also builds upon our prior work on structure preserving dilation using Delaunay triangulation. Experiments on two public data sets are conducted, including comparisons to existing algorithms. We deployed two renowned machine learning methods into the classification process (i.e., convolutional neural network-CNN- and random forests-RF-) since they perform well in pattern recognition tasks. The results show a clear improvement of the proposed approach's classification accuracy (especially for data sets with limited training samples) as well as robustness against noise when compared to existing methods.","",""
10,"Tie Cai, Jie Zhu","OOV rejection algorithm based on class-fusion support vector machine for speech recognition",2004,"","","","",190,"2022-07-13 09:24:47","","10.1109/ICMLC.2004.1380453","","",,,,,10,0.56,5,2,18,"Support vector machine (SVM) is a promising pattern classification technique that implements the structural risk minimization principle (SRM) in statistical learning theory. This paper proposes a new improved SVM, called class fusion support vector machine or FSVM, which has more robustness to noise and outliers than the standard SVM. We present an investigation into the application of FSVM to the out-of-vocabulary (OOV) rejection problem in a DTW based real-time ASR system. The feature vector consisting of parameters such as normalized N-best word scores and their 1st differences are directly derived from the recognition results as input to the OOV rejection process. The performance of the proposed FSVM classifier is compared with the standard SVM and neural networks.","",""
11,"S. Han, Hao Huang, Hong Qin, Dantong Yu","Locality-preserving L1-graph and its application in clustering",2015,"","","","",191,"2022-07-13 09:24:47","","10.1145/2695664.2695710","","",,,,,11,1.57,3,4,7,"Constructing a good graph to represent data structures is critical for many important machine learning tasks such as clustering and classification. Recently, a nonparameteric graph construction method called L1-graph is proposed with claimed advantages on sparsity, robustness to data noise and datum-adaptive neighborhood. However, it suffers a lot from the loss of locality and the instability of performance. In this paper, we propose a Locality-Preserving L1- graph (LOP-L1), which preserves higher local-connections and at the same time maintains sparsity. Besides, compared with L1-graph and the succeeding regularization-based techniques, our LOP-L1 requires less amount of running time in the scalability test. We evaluate the effectiveness of LOP-L1 by applying it to clustering application, which confirms that the proposed algorithm outperforms related methods.","",""
8,"M. Boullé","Khiops: A Discretization Method of Continuous Attributes with Guaranteed Resistance to Noise",2003,"","","","",192,"2022-07-13 09:24:47","","10.1007/3-540-45065-3_5","","",,,,,8,0.42,8,1,19,"","",""
8,"Wei Gao, Xin-Yi Niu, Zhi-Hua Zhou","On the Consistency of Exact and Approximate Nearest Neighbor with Noisy Data",2016,"","","","",193,"2022-07-13 09:24:47","","","","",,,,,8,1.33,3,3,6,"Nearest neighbor has been one of the simplest and most appealing non-parametric approaches in machine learning, pattern recognition, computer vision, etc. Empirical studies show the resistance of k-nearest neighbor to noise, yet the theoretical understanding is not clear. This work presents the consistency analysis on exact and approximate nearest neighbor in the random noise setting. Our theoretical studies show that k-nearest neighbor, in the noise setting, gets the same consistent rate as that in the noise-free setting, which verifies the robustness of k-nearest neighbor to random noise. The nearest neighbor (1-NN), however, is proven to be biased by random noise. For approximate $k$-nearest neighbor, we first generalize the Johnson-Lindenstrauss lemma to infinite set, and based on this result, we show that the approximate $k$-nearest neighbor is also robust to random noise as that of the exact k-nearest neighbor, and achieves faster convergence rate yet with a tradeoff between consistency and reduced dimension. Specifically, approximate $k$-nearest neighbor with sharp dimensional reduction tends to cause large deviation from the Bayes risk.","",""
6,"Yuan Gong, C. Poellabauer","Continuous Assessment of Children’s Emotional States Using Acoustic Analysis",2017,"","","","",194,"2022-07-13 09:24:47","","10.1109/ICHI.2017.53","","",,,,,6,1.20,3,2,5,"Emotional and behavioral disorders (EBD) are a widespread healthcare concern in children and adolescents. Prevention and early intervention are the most powerful tools in ameliorating the problem, and therefore, timely and accurate detection of abnormal emotional patterns is of vital importance. In this paper, we propose a system that detects second-level emotional states of children using hour-level audio recordings. The proposed system consists of an audio segmentation and speaker tracking front-end along with an emotion recognition back-end. Supervised support vector machine is used in the front-end to improve its robustness to short and inconsistent child speech pattern and end-to-end deep learning is used in the emotion recognition back-end to improve its robustness to noise and segmentation error. We further demonstrate the potential of the proposed system as an automated emotion analysis tool.","",""
11,"Ryan D. Morton, E. Olson","Robust sensor characterization via max-mixture models: GPS sensors",2013,"","","","",195,"2022-07-13 09:24:47","","10.1109/IROS.2013.6696402","","",,,,,11,1.22,6,2,9,"Large position errors plague GNSS-based sensors (e.g., GPS) due to poor satellite configuration and multipath effects, resulting in frequent outliers. Due to quadratic cost functions when optimizing SLAM via nonlinear least square methods, a single such outlier can cause severe map distortions. Following in the footsteps of recent improvements in the robustness of SLAM optimization process, this work presents a framework for improving sensor noise characterizations by combining a machine learning approach with max-mixture error models. By using max-mixtures, the sensor's noise distribution can be modeled to a desired accuracy, with robustness to outliers. We apply the framework to the task of accurately modeling the uncertainties of consumer-grade GPS sensors. Our method estimates the observation covariances using only weighted feature vectors and a single max operator, learning parameters off-line for efficient on-line calculation.","",""
5,"Chao Li, Zhiyong Feng, Chao Xu","Error-correcting output codes for multi-label emotion classification",2016,"","","","",196,"2022-07-13 09:24:47","","10.1007/s11042-016-3608-7","","",,,,,5,0.83,2,3,6,"","",""
26,"Ji Wu, Xiao-Lei Zhang","Maximum Margin Clustering Based Statistical VAD With Multiple Observation Compound Feature",2011,"","","","",197,"2022-07-13 09:24:47","","10.1109/LSP.2011.2119482","","",,,,,26,2.36,13,2,11,"In this letter, we propose a new robust feature and an unsupervised learning approach for statistical voice activity detection (VAD). Maximum margin clustering (MMC), as an unsupervised classifier, can improve the robustness of support vector machine (SVM) based VAD while requiring no data labeling for model training. In the MMC framework, the multiple observation compound feature (MO-CF) is proposed to improve accuracy. MO-CF is composed of two subfeatures-multiple observation signal-to-noise ratio (MO-SNR) and multiple observation maximum probability (MO-MP). The contributions of the two subfeatures are balanced by a factor which is chosen to yield the largest area under the ROC curve (AUC) of the performance. The proposed approach obtains improved performance over seven commonly used VAD techniques in the experiments covering various noisy scenarios with low SNRs.","",""
6,"P. Xie, E. Xing","Cauchy Principal Component Analysis",2014,"","","","",198,"2022-07-13 09:24:47","","","","",,,,,6,0.75,3,2,8,"Principal Component Analysis (PCA) has wide applications in machine learning, text mining and computer vision. Classical PCA based on a Gaussian noise model is fragile to noise of large magnitude. Laplace noise assumption based PCA methods cannot deal with dense noise effectively. In this paper, we propose Cauchy Principal Component Analysis (Cauchy PCA), a very simple yet effective PCA method which is robust to various types of noise. We utilize Cauchy distribution to model noise and derive Cauchy PCA under the maximum likelihood estimation (MLE) framework with low rank constraint. Our method can robustly estimate the low rank matrix regardless of whether noise is large or small, dense or sparse. We analyze the robustness of Cauchy PCA from a robust statistics view and present an efficient singular value projection optimization method. Experimental results on both simulated data and real applications demonstrate the robustness of Cauchy PCA to various noise patterns.","",""
6,"Yatao Bian, Alexey Gronskiy, J. Buhmann","Greedy MaxCut algorithms and their information content",2015,"","","","",199,"2022-07-13 09:24:47","","10.1109/ITW.2015.7133122","","",,,,,6,0.86,2,3,7,"MAXCUT defines a classical NP-hard problem for graph partitioning and it serves as a typical case of the symmetric non-monotone Unconstrained Submodular Maximization (USM) problem. Applications of MAXCUT are abundant in machine learning, computer vision and statistical physics. Greedy algorithms to approximately solve MAXCUT rely on greedy vertex labelling or on an edge contraction strategy. These algorithms have been studied by measuring their approximation ratios in the worst case setting but very little is known to characterize their robustness to noise contaminations of the input data in the average case. Adapting the framework of Approximation Set Coding, we present a method to exactly measure the cardinality of the algorithmic approximation sets of five greedy MAXCUT algorithms. Their information contents are explored for graph instances generated by two different noise models: the edge reversal model and Gaussian edge weights model. The results provide insights into the robustness of different greedy heuristics and techniques for MAXCUT, which can be used for algorithm design of general USM problems.","",""
7,"Mathieu Plourde, Luc Duong","Multi scale classification approach for coronary artery detection from X-ray angiography",2012,"","","","",200,"2022-07-13 09:24:47","","10.1109/ISSPA.2012.6310542","","",,,,,7,0.70,4,2,10,"X-ray angiography is currently the gold standard for navigation guidance during percutaneous coronary interventions. From X-ray angiography, robust automatic detection of coronary arteries would be of great interest during cardiac interventions. Multi scale Hessian-based filtering was proven successful to automatically detect vessels from X-ray angiography. However, other anatomical structures interfere greatly with the detection process and the result still contains many false positives. The goal of the project is to propose a novel machine learning-based method to improve Hessian-based coronary artery detection from X-ray angiography. The proposed method divides Hessian-filtered images in patches, uses feature extraction with a contour profiling algorithm, and classifies using Support Vector Machines. The method is applied recursively on the detected connected components using patches of different sizes to define the arteries. This scheme allows an improvement of robustness against noise and imaging artifacts.","",""
