Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
4,"T. E. Miller, L. Militello, J. Heaton","Evaluating Air Campaign Plan Quality in Operational Settings I",1996,"","","","",1,"2022-07-13 09:21:51","","","","",,,,,4,0.15,1,3,26,"Artificial Intelligence methods can rapidly generate plans for complex situations. However, these plans may be rejected by air campaign planning experts, who judge dimensions such as robustness using operational rather than computational criteria. Our goal is to capture the tactical and strategic concerns of air campaign planners, and incorporate these into planning technology to filter out the unacceptable options and highlight preferred plans. We are in the process of employing a complete Cognitive Task Analysis (CTA), which uses a variety of knowledge elicitation techniques to fully identify the process of plan evaluation and factors underlying judgments of plan robustness. The CTA will form the foundation of an ACP Plan Critic. The Plan Critic will evaluate plans for plan quality and will highlight potential problem areas and vulnerable assumptions. This paper summarizes the current status of this work. There is often a large gap between technological advances and operational feasibility. In the Artificial Intelligence (AI) planning domain, planning technology often approaches the problem via a process that does not match the way the targeted user thinks about and solves planning problems. In some cases, planning technologists and air campaign planners do not define certain concepts identically; what is robust to the planning technologist does not necessarily match robustness to the military planner. Subsequently, there is a considerable risk that current planning technologies will not be accepted in the field because they do not meet the decision-making needs of the commanders and planning staff. The following pages discuss the need for user-centered planning systems in the air campaign planning domain and describe a Decision-Centered Design approach to building systems, which will enable the generation of AI products that meet the operational needs of air campaign planners.","",""
3,"T. E. Miller, R. R. Copeland, Jennifer K. Phillips, M. McCloskey","A Cognitive Approach to Developing Planning Tools to Support Air Campaign Planners",1999,"","","","",2,"2022-07-13 09:21:51","","10.1037/e444602005-001","","",,,,,3,0.13,1,4,23,"Abstract : Artificial Intelligence methods can rapidly generate detailed plans for complex situations. However, these plans may be rejected by planning experts, who judge dimensions such as robustness using operational rather than computational criteria. Our goal in this research was to capture the tactical and strategic concerns of air campaign planners, and incorporate these into planning technology to assist with filtering out the unacceptable options and highlighting preferred plans. Specifically, we focused on identifying characteristics of quality plans and how these characteristics are judged in operational settings. We used a variety of knowledge elicitation techniques in the Cognitive Task Analysis (CTA) to identify the process of plan evaluation and the factors underlying judgment of plan robustness. Our research drew on observations and interviews in a variety of settings: The primary data sources were from Joint Force Air Component Commander (JFACC) exercises and from a simulation exercise with Pentagon planning staff. The CTA formed the foundation of a software tool, the Bed Down Critic, which highlights potential problem areas, vulnerable assumptions, and summarizes aspects of quality to the user.","",""
0,"Beilei Wang, Jie Jing, Xiaochun Huang, Cheng Hua, Qin Qin, Y. Jia, Zhiyong Wang, Lei Jiang, Bai Gao, Les J. Wu, Xianfei Zeng, Fubo Wang, Chuanbin Mao, Shanrong Liu","Establishment of a Knowledge‐and‐Data‐Driven Artificial Intelligence System with Robustness and Interpretability in Laboratory Medicine",2022,"","","","",3,"2022-07-13 09:21:51","","10.1002/aisy.202100204","","",,,,,0,0.00,0,14,1,"Laboratory medicine plays an important role in clinical diagnosis. However, no laboratory‐based artificial intelligence (AI) diagnostic system has been applied in current clinical practice due to the lack of robustness and interpretability. Although many attempts have been made, it is still difficult for doctors to adopt the existing machine learning (ML) patterns in interpreting laboratory (lab) big data. Here, a knowledge‐and‐data‐driven laboratory diagnostic system is developed, termed AI‐based Lab tEst tO diagNosis (AI LEON), by integrating an innovative knowledge graph analysis framework and “mixed XGboost and Genetic Algorithm (MiXG)” technique to simulate the doctor's laboratory‐based diagnosis. To establish AI LEON, we included 89 116 949 laboratory data and 10 423 581 diagnosis data points from 730 113 participants. Among them, 686 626 participants were recruited for training and validating purposes with the remaining for testing purposes. AI LEON automatically identified and analyzed 2071 lab indexes, resulting in multiple disease recommendations that involved 441 common diseases in ten organ systems. AI LEON exhibited outstanding transparency and interpretability in three universal clinical application scenarios and outperformed human physicians in interpreting lab reports. AI LEON is an advanced intelligent system that enables a comprehensive interpretation of lab big data, which substantially improves the clinical diagnosis.","",""
1,"Liheng Gong, Xiao Zhang, Ling Li","An Artificial Intelligence Fusion Model for Cardiac Emergency Decision Making: Application and Robustness Analysis (Preprint)",2020,"","","","",4,"2022-07-13 09:21:51","","10.2196/preprints.19428","","",,,,,1,0.50,0,3,2,"  BACKGROUND  During cardiac emergency medical treatment, reducing the incidence of avoidable adverse events, ensuring the safety of patients, and generally improving the quality and efficiency of medical treatment have been important research topics in theoretical and practical circles.      OBJECTIVE  This paper examines the robustness of the decision-making reasoning process from the overall perspective of the cardiac emergency medical system.      METHODS  The principle of robustness was introduced into our study on the quality and efficiency of cardiac emergency decision making. We propose the concept of robustness for complex medical decision making by targeting the problem of low reasoning efficiency and accuracy in cardiac emergency decision making. The key bottlenecks such as anti-interference capability, fault tolerance, and redundancy were studied. The rules of knowledge acquisition and transfer in the decision-making process were systematically analyzed to reveal the core role of knowledge reasoning.      RESULTS  The robustness threshold method was adopted to construct the robustness criteria group of the system, and the fusion and coordination mechanism was realized through information entropy, information gain, and mutual information methods.      CONCLUSIONS  A set of fusion models and robust threshold methods such as the R2CMIFS (treatment mode of fibroblastic sarcoma) model and the RTCRF (clinical trial observation mode) model were proposed. Our study enriches the theoretical research on robustness in this field. ","",""
0,"Liheng Gong, Xiao Zhang, Ling Li","An Artificial Intelligence Fusion Model for Cardiac Emergency Decision Making: Application and Robustness Analysis",2020,"","","","",5,"2022-07-13 09:21:51","","10.2196/19428","","",,,,,0,0.00,0,3,2,"Background During cardiac emergency medical treatment, reducing the incidence of avoidable adverse events, ensuring the safety of patients, and generally improving the quality and efficiency of medical treatment have been important research topics in theoretical and practical circles. Objective This paper examines the robustness of the decision-making reasoning process from the overall perspective of the cardiac emergency medical system. Methods The principle of robustness was introduced into our study on the quality and efficiency of cardiac emergency decision making. We propose the concept of robustness for complex medical decision making by targeting the problem of low reasoning efficiency and accuracy in cardiac emergency decision making. The key bottlenecks such as anti-interference capability, fault tolerance, and redundancy were studied. The rules of knowledge acquisition and transfer in the decision-making process were systematically analyzed to reveal the core role of knowledge reasoning. Results The robustness threshold method was adopted to construct the robustness criteria group of the system, and the fusion and coordination mechanism was realized through information entropy, information gain, and mutual information methods. Conclusions A set of fusion models and robust threshold methods such as the R2CMIFS (treatment mode of fibroblastic sarcoma) model and the RTCRF (clinical trial observation mode) model were proposed. Our study enriches the theoretical research on robustness in this field.","",""
0,"D. Lange","Robustness of artificial intelligence in the face of novelty",2022,"","","","",6,"2022-07-13 09:21:51","","10.1117/12.2622912","","",,,,,0,0.00,0,1,1,"A critical factor in utilizing agents with Artificial Intelligence (AI) is their robustness to novelty. AI agents include models that are either engineered or trained. Engineered models include knowledge of those aspects of the environment that are known and considered important by the engineers. Learned models form embeddings of aspects of the environment based on connections made through the training data. In operation, however, a rich environment is likely to present challenges not seen in training sets or accounted for in engineered models. Worse still, adversarial environments are subject to change by opponents. A program at the Defense Advanced Research Project Agency (DARPA) seeks to develop the science necessary to develop and evaluate agents that are robust to novelty. This capability will be required, before AI has the role envisioned within mission critical environments.","",""
0,"N. Komendantova, L. Ekenberg, W. Amann, M. Danielson, V. Koulolias","Chapter 10 The Adequacy of Artificial Intelligence Tools to Combat Misinformation",2021,"","","","",7,"2022-07-13 09:21:51","","10.1007/978-3-030-70370-7_10","","",,,,,0,0.00,0,5,1,"","",""
1,"K. Panetta, Landry Kezebou, Victor Oludare, J. Intriligator, S. Agaian","Artificial Intelligence for Text-Based Vehicle Search, Recognition, and Continuous Localization in Traffic Videos",2021,"","","","",8,"2022-07-13 09:21:51","","10.3390/ai2040041","","",,,,,1,1.00,0,5,1,"The concept of searching and localizing vehicles from live traffic videos based on descriptive textual input has yet to be explored in the scholarly literature. Endowing Intelligent Transportation Systems (ITS) with such a capability could help solve crimes on roadways. One major impediment to the advancement of fine-grain vehicle recognition models is the lack of video testbench datasets with annotated ground truth data. Additionally, to the best of our knowledge, no metrics currently exist for evaluating the robustness and performance efficiency of a vehicle recognition model on live videos and even less so for vehicle search and localization models. In this paper, we address these challenges by proposing V-Localize, a novel artificial intelligence framework for vehicle search and continuous localization captured from live traffic videos based on input textual descriptions. An efficient hashgraph algorithm is introduced to compute valid target information from textual input. This work further introduces two novel datasets to advance AI research in these challenging areas. These datasets include (a) the most diverse and large-scale Vehicle Color Recognition (VCoR) dataset with 15 color classes—twice as many as the number of color classes in the largest existing such dataset—to facilitate finer-grain recognition with color information; and (b) a Vehicle Recognition in Video (VRiV) dataset, a first of its kind video testbench dataset for evaluating the performance of vehicle recognition models in live videos rather than still image data. The VRiV dataset will open new avenues for AI researchers to investigate innovative approaches that were previously intractable due to the lack of annotated traffic vehicle recognition video testbench dataset. Finally, to address the gap in the field, five novel metrics are introduced in this paper for adequately accessing the performance of vehicle recognition models in live videos. Ultimately, the proposed metrics could also prove intuitively effective at quantitative model evaluation in other video recognition applications. T One major advantage of the proposed vehicle search and continuous localization framework is that it could be integrated in ITS software solution to aid law enforcement, especially in critical cases such as of amber alerts or hit-and-run incidents.","",""
25,"Abbas Abbaszadeh Shahri, S. Larsson, Crister Renkel","Artificial intelligence models to generate visualized bedrock level: a case study in Sweden",2020,"","","","",9,"2022-07-13 09:21:51","","10.1007/s40808-020-00767-0","","",,,,,25,12.50,8,3,2,"","",""
1,"Pingping Sun, Lingang Gu","Fuzzy knowledge graph system for artificial intelligence-based smart education",2021,"","","","",10,"2022-07-13 09:21:51","","10.3233/JIFS-189332","","",,,,,1,1.00,1,2,1,"Fuzzy knowledge graph system is a semantic network that reveals the relationships between entities, and a tool or methodology that can formally describe things in the real world and their relationships. Smart education is an educational concept or model that uses advanced information technology to build a smart environment, integrates theory and practice to build an educational framework for information age, and provides paths to practice it. Artificial intelligence (AI) is a comprehensive discipline developed by the interpenetration of computer science, cybernetics, information theory, linguistics, neurophysiology and other disciplines, which is a direction for the development of information technology in the future. On the basis of summarizing and analyzing of previous research works, this paper expounded the research status and significance of AI technology, elaborated the development background, current status and future challenges of the construction and application of fuzzy knowledge graph system for smart education, introduced the methods and principles of data acquisition methods and digitalized apprenticeship, realized the process design, information extraction, entity recognition and relationship mining of smart education, constructed a systematic framework for fuzzy knowledge graph, and analyzed the high-quality resources sharing and personalized service of AI-assisted smart education, discussed automatic knowledge acquisition and fusion of fuzzy knowledge graph, performed co-occurrence relationship analysis, and finally conducted application case analysis. The results show that the smart education knowledge graph for AI-assisted smart education can integrate teaching experience and domain knowledge of discipline experts, enhance explainable and robust machine intelligence for AI-assisted smart education, and provide data-driven and knowledge-driven information processing methods; it can also discover the analysis hotspots and main content of research objects through clustering of high-frequency topic words, reveal the corresponding research structure in depth, and then systematically explore its research dimensions, subject background and theoretical basis.","",""
0,"C. Hamel, Mona Hersi, S. Kelly, A. Tricco, S. Straus, G. Wells, B. Pham, B. Hutton","Guidance for using artificial intelligence for title and abstract screening while conducting knowledge syntheses",2021,"","","","",11,"2022-07-13 09:21:51","","10.1186/s12874-021-01451-2","","",,,,,0,0.00,0,8,1,"","",""
0,"Poona Bahrebar, Leon Denis, Maxim Bonnaerens, Kristof Coddens, J. Dambre, W. Favoreel, I. Khvastunov, A. Munteanu, Hung Nguyen-Duc, S. Schulte, D. Stroobandt, Ramses Valvekens, N. V. D. Broeck, Geert Verbruggen","cREAtIve: reconfigurable embedded artificial intelligence",2021,"","","","",12,"2022-07-13 09:21:51","","10.1145/3457388.3458857","","",,,,,0,0.00,0,14,1,"cREAtIve targets the development of novel highly-adaptable embedded deep learning solutions for automotive and traffic monitoring applications, including position sensor processing, scene interpretation based on LiDAR, and object detection and classification in thermal images for traffic camera systems. These applications share the need for deep learning solutions tailored for deployment on embedded devices with limited resources and featuring high adaptability and robustness to changing environmental conditions. cREAtIve develops knowledge, tools and methods that enable hardware-efficient, adaptable, and robust deep learning.","",""
23,"M. Mitchell","Abstraction and analogy‐making in artificial intelligence",2021,"","","","",13,"2022-07-13 09:21:51","","10.1111/nyas.14619","","",,,,,23,23.00,23,1,1,"Conceptual abstraction and analogy‐making are key abilities underlying humans' abilities to learn, reason, and robustly adapt their knowledge to new domains. Despite a long history of research on constructing artificial intelligence (AI) systems with these abilities, no current AI system is anywhere close to a capability of forming humanlike abstractions or analogies. This paper reviews the advantages and limitations of several approaches toward this goal, including symbolic methods, deep learning, and probabilistic program induction. The paper concludes with several proposals for designing challenge tasks and evaluation measures in order to make quantifiable and generalizable progress in this area.","",""
111,"Zhihan Lv, Yang Han, A. Singh, Gunasekaran Manogaran, Haibin Lv","Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence",2021,"","","","",14,"2022-07-13 09:21:51","","10.1109/TII.2020.2994747","","",,,,,111,111.00,22,5,1,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.","",""
0,"Vida Groznik","Artificial Intelligence Methods for Modelling Tremor Mechanisms",2020,"","","","",15,"2022-07-13 09:21:51","","10.31449/INF.V44I2.3177","","",,,,,0,0.00,0,1,2,"Tremors are one of the most common movement disorders primarily associated with various neurological diseases. Since there are more than 20 different types of tremors, differentiation between them is important from the treatment point of view. In the thesis, we focus on differentiation between three of the most common tremors: Parkinsonian, essential and mixed type of tremor.    Our first goal was to build a diagnostic model for distinguishing between Parkinsonian, essential and mixed type of tremors, based on clinical examination data, family history and digital spirography. The process of building a model was carried out using argument-based machine learning which enabled us to build a decision model through the process of knowledge elicitation from the domain expert (in our case from a neurologist). The obtained model consists of thirteen rules that are medically sensible. The process of knowledge elicitation itself contributed to the higher classification accuracy of the final model in comparison with the initial one.    In the final diagnostic model, attributes derived from the spirography were included in more than half of the rules. This motivated us to build a model based solely on the digital spirography data. For the needs of constructing an understandable model, we first built several attributes which represented domain medical knowledge. We have built more than 500 different attributes which were used in a logistic regression to construct the final diagnostic model. The model is able to distinguish subjects with tremors from those without tremors with 90% classification accuracy.    During the process of attribute construction, we wanted to know what our attributes were detecting. Thus, we have developed a method for attribute visualisation on series. The method not only helped us with attribute construction, but it is also useful for visual interpretation of the diagnostic model's decisions. The visualisation method and consequently the decision model were evaluated with the help of three independent neurology experts. The results show that both the diagnostic model and the visualisation are meaningful and cover medical knowledge of the domain. The final diagnostic model is built into the freely available ParkinsonCheck mobile application.","",""
5,"David Abele, Sara D’Onofrio","Artificial Intelligence – The Big Picture",2020,"","","","",16,"2022-07-13 09:21:51","","10.1007/978-3-658-27941-7_2","","",,,,,5,2.50,3,2,2,"","",""
2,"Yuan Huang, Z. Cheng, Qianyu Zhou, Yuxing Xiang, Ruixiao Zhao","Data Mining Algorithm for Cloud Network Information Based on Artificial Intelligence Decision Mechanism",2020,"","","","",17,"2022-07-13 09:21:51","","10.1109/ACCESS.2020.2981632","","",,,,,2,1.00,0,5,2,"Due to the rapid development of information technology and network technology, there is a lot of data, but the phenomenon of lack of knowledge is becoming more and more serious. Data mining technology has developed vigorously in this environment, and it has shown more and more vitality. Based on Spark programming model, this paper designs the parallel extension of fuzzy c-means. In order to enhance the performance of fuzzy c-means parallel expansion, the improvement strategy of k-means during the initialization phase is borrowed, and k-means// is extended to fuzzy c-means to obtain better clustering performance. Combined with Spark’s programming model, this paper can obtain extended parallel fuzzy c-means algorithm. Several experiments on the data set of the algorithm proposed in this paper have shown good scalability and parallelism, effectively expanding fuzzy c-means clustering to distributed applications, greatly increasing the scale of the data processed by the algorithm. This improves the robustness of the algorithm and the adaptability of the algorithm to the shape and structure of the data, so that the parallel and scalable clustering algorithm can more effectively perform cluster analysis on big data. Three algorithms were simulated on MATLAB platform. We use simple data sets and complex two-dimensional data sets, and compare with the traditional fuzzy c-means algorithm and fuzzy c-means algorithm based on fuzzy entropy. Experiments show that the scalable parallel fuzzy c-means algorithm not only greatly improves the anti-noise performance, but also improves the convergence speed, and it can automatically determine the optimal number of clusters.","",""
143,"G. Marcus","The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",2020,"","","","",18,"2022-07-13 09:21:51","","","","",,,,,143,71.50,143,1,2,"Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.","",""
86,"Helin Yang, A. Alphones, Zehui Xiong, D. Niyato, Jun Zhao, Kaishun Wu","Artificial-Intelligence-Enabled Intelligent 6G Networks",2019,"","","","",19,"2022-07-13 09:21:51","","10.1109/MNET.011.2000195","","",,,,,86,28.67,14,6,3,"With the rapid development of smart terminals and infrastructures, as well as diversified applications (e.g., virtual and augmented reality, remote surgery and holographic projection) with colorful requirements, current networks (e.g., 4G and upcoming 5G networks) may not be able to completely meet quickly rising traffic demands. Accordingly, efforts from both industry and academia have already been put to the research on 6G networks. Recently, artificial intelligence (Ai) has been utilized as a new paradigm for the design and optimization of 6G networks with a high level of intelligence. Therefore, this article proposes an Ai-enabled intelligent architecture for 6G networks to realize knowledge discovery, smart resource management, automatic network adjustment and intelligent service provisioning, where the architecture is divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer. We then review and discuss the applications of Ai techniques for 6G networks and elaborate how to employ the Ai techniques to efficiently and effectively optimize the network performance, including Ai-empowered mobile edge computing, intelligent mobility and handover management, and smart spectrum management. We highlight important future research directions and potential solutions for Ai-enabled intelligent 6G networks, including computation efficiency, algorithms robustness, hardware development and energy management.","",""
7,"Redmond R. Shamshiri, Ibrahim A. Hameed, Kelly R. Thorp, Siva K. Balasundram, S. Shafian, Mohammad Fatemieh, M. Sultan, B. Mahns, S. Samiei","Greenhouse Automation Using Wireless Sensors and IoT Instruments Integrated with Artificial Intelligence",2021,"","","","",20,"2022-07-13 09:21:51","","10.5772/INTECHOPEN.97714","","",,,,,7,7.00,1,9,1,"Automation of greenhouse environment using simple timer-based actuators or by means of conventional control algorithms that require feedbacks from offline sensors for switching devices are not efficient solutions in large-scale modern greenhouses. Wireless instruments that are integrated with artificial intelligence (AI) algorithms and knowledge-based decision support systems have attracted growers’ attention due to their implementation flexibility, contribution to energy reduction, and yield predictability. Sustainable production of fruits and vegetables under greenhouse environments with reduced energy inputs entails proper integration of the existing climate control systems with IoT automation in order to incorporate real-time data transfer from multiple sensors into AI algorithms and crop growth models using cloud-based streaming systems. This chapter provides an overview of such an automation workflow in greenhouse environments by means of distributed wireless nodes that are custom-designed based on the powerful dual-core 32-bit microcontroller with LoRa modulation at 868 MHz. Sample results from commercial and research greenhouse experiments with the IoT hardware and software have been provided to show connection stability, robustness, and reliability. The presented setup allows deployment of AI on embedded hardware units such as CPUs and GPUs, or on cloud-based streaming systems that collect precise measurements from multiple sensors in different locations inside greenhouse environments.","",""
0,"S. Sadeghi, M. Amiri, Farzaneh Mansoori Mooseloo","Artificial Intelligence and Its Application in Optimization under Uncertainty",2021,"","","","",21,"2022-07-13 09:21:51","","10.5772/intechopen.98628","","",,,,,0,0.00,0,3,1,"Nowadays, the increase in data acquisition and availability and complexity around optimization make it imperative to jointly use artificial intelligence (AI) and optimization for devising data-driven and intelligent decision support systems (DSS). A DSS can be successful if large amounts of interactive data proceed fast and robustly and extract useful information and knowledge to help decision-making. In this context, the data-driven approach has gained prominence due to its provision of insights for decision-making and easy implementation. The data-driven approach can discover various database patterns without relying on prior knowledge while also handling flexible objectives and multiple scenarios. This chapter reviews recent advances in data-driven optimization, highlighting the promise of data-driven optimization that integrates mathematical programming and machine learning (ML) for decision-making under uncertainty and identifies potential research opportunities. This chapter provides guidelines and implications for researchers, managers, and practitioners in operations research who want to advance their decision-making capabilities under uncertainty concerning data-driven optimization. Then, a comprehensive review and classification of the relevant publications on the data-driven stochastic program, data-driven robust optimization, and data-driven chance-constrained are presented. This chapter also identifies fertile avenues for future research that focus on deep-data-driven optimization, deep data-driven models, as well as online learning-based data-driven optimization. Perspectives on reinforcement learning (RL)-based data-driven optimization and deep RL for solving NP-hard problems are discussed. We investigate the application of data-driven optimization in different case studies to demonstrate improvements in operational performance over conventional optimization methodology. Finally, some managerial implications and some future directions are provided.","",""
0,"Gang Li, Tongzhou Zhao","Approach of Intelligence Question-Answering System Based on Physical Fitness Knowledge Graph",2021,"","","","",22,"2022-07-13 09:21:51","","10.1109/RCAE53607.2021.9638824","","",,,,,0,0.00,0,2,1,"Artificial intelligence’s penetrating sports is a new development trend of modern sports. Physical Intelligence Question-Answering System (QAS) is a typical application of artificial intelligence in sports, which can quickly respond the physic fitness questions raised by people. This paper aims the construction method of physical fitness QAS based on knowledge graph. Firstly, the physical fitness knowledge graph is constructed based on the crawling data and expert knowledge. Secondly, several physical knowledge question templates are constructed. Thirdly, the Bayesian classifier is used to classify the questions and the Bidirectional Long Short-Term Memory (BiLSTM) combined with Conditional Random Fields (CRF) method is applied to extract contents from the input questions. Then a matching algorithm based on bidirectional slicing string and a statistical method are performed to implement the fuzzy query to enhance the accuracy and robustness of the QAS. The experiments show that the accuracy of physical fitness QAS can reach 93.5% when the question sentences are matched with the query templates, and 86.5% when not matched.","",""
5,"Ayodeji Oseni, Nour Moustafa, H. Janicke, Peng Liu, Z. Tari, A. Vasilakos","Security and Privacy for Artificial Intelligence: Opportunities and Challenges",2021,"","","","",23,"2022-07-13 09:21:51","","","","",,,,,5,5.00,1,6,1,"The increased adoption of Artificial Intelligence (AI) presents an opportunity to solve many socio-economic and environmental challenges; however, this cannot happen without securing AI-enabled technologies. In recent years, most AI models are vulnerable to advanced and sophisticated hacking techniques. This challenge has motivated concerted research efforts into adversarial AI, with the aim of developing robust machine and deep learning models that are resilient to different types of adversarial scenarios. In this paper, we present a holistic cyber security review that demonstrates adversarial attacks against AI applications, including aspects such as adversarial knowledge and capabilities, as well as existing methods for generating adversarial examples and existing cyber defence models. We explain mathematical AI models, especially new variants of reinforcement and federated learning, to demonstrate how attack vectors would exploit vulnerabilities of AI models. We also propose a systematic framework for demonstrating attack techniques against AI applications, and reviewed several cyber defences that would protect the AI applications against those attacks. We also highlight the importance of understanding the adversarial goals and their capabilities, especially the recent attacks against industry applications, to develop adaptive defences that assess to secure AI applications. Finally, we describe the main challenges and future research directions in the domain of security and privacy of AI technologies.","",""
4,"Shubham Yadav, S. Ganesh, Debanjan Das, U. Venkanna, R. Mahapatra, A. Shrivastava, Prantar Chakrabarti, A. Talukder","Suśruta: Artificial Intelligence and Bayesian Knowledge Network in Health Care - Smartphone Apps for Diagnosis and Differentiation of Anemias with Higher Accuracy at Resource Constrained Point-of-Care Settings",2019,"","","","",24,"2022-07-13 09:21:51","","10.1007/978-3-030-37188-3_10","","",,,,,4,1.33,1,8,3,"","",""
31,"I. Habli, T. Lawton, Zoe Porter","Artificial intelligence in health care: accountability and safety",2020,"","","","",25,"2022-07-13 09:21:51","","10.2471/BLT.19.237487","","",,,,,31,15.50,10,3,2,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.","",""
1,"M. Panahiazar, Nolan Chen, D. Lituiev, D. Hadley","Empowering study of breast cancer data with application of artificial intelligence technology: promises, challenges, and use cases",2021,"","","","",26,"2022-07-13 09:21:51","","10.1007/s10585-021-10125-8","","",,,,,1,1.00,0,4,1,"","",""
1,"Lana Sinapayen","Perspective: Purposeful Failure in Artificial Life and Artificial Intelligence",2021,"","","","",27,"2022-07-13 09:21:51","","","","",,,,,1,1.00,1,1,1,"Complex systems fail. I argue that failures can be a blueprint characterizing living organisms and biological intelligence, a control mechanism to increase complexity in evolutionary simulations, and an alternative to classical fitness optimization. Imitating biological successes in Artificial Life and Artificial Intelligence can be misleading; imitating failures offers a path towards understanding and emulating life it in artificial systems. Failure is Knowledge, Knowledge is Power You are handed a mysterious box containing the most complex object in the universe, and must find how the object works. Where do you start? “The human brain is the most complex object in the universe” is a well worn cliche (Constable (1918)). While the claim might not be true, the human brain is definitely very complex. In neuroscience and psychology, one of the most compelling ways to understand how the brain works is to study how it fails. Brain damage, irrational decisions, sensory illusions: internal or external changes that make the brain fail are how we find how the brain succeeds. Failure is used to understand complex systems beyond neuroscience: reverse-engineering computer software, understanding animal behavior, identifying solid materials... Failure even defines Science itself. an hypothesis is considered scientific if and only if it is “falsifiable”: if it can reproducibly fail (Popper (1934)). Why default to observing failures when we don’t know what is going on? Because the success-failure boundary is full of information. Let me define “failure” in the context of this discussion. Imagine being an ant dropped somewhere on top of Fig.1-(a). What is the fastest way to map your surroundings? Rather than walking every inch of the surface, find boundaries. When you are investigating a complex system that is working as expected, you are an ant dropped on Mount Success. To find the boundary, you have to push the system into failure mode. Staying inside the success space can inform you about the robustness of the system to perturbations (at best the system recovered from the perturbation, at worst your perturbation was irrelevant), but it is not explanatory. Neither is going from failure to failure. You can only investigate causes and effects if your intervention actually changes something: the failure boundary is not just more informative, it is a different kind of information altogether. Boundaries and failures are not exactly the same. If you are observing a function of the system that does not change when it crosses the failure boundary, you will not notice the transition. If you are observing the right function, you might see the system performance on that function become better or worse. Let us call “failure points” abrupt transitions from “some performance” to 0: they are the most salient of transitions. Going back to Fig.1, the ant might not notice the transition from a gentle slope to a flat terrain, but a cliff will be noticeable. Ideally, you would want to map the entire failure boundary; in practice, you will focus on failure points. ? Mount Success Failure Bog","",""
1,"Y. Sheng, Jiahan Zhang, Y. Ge, Xinyi Li, Wentao Wang, H. Stephens, F. Yin, Qiuwen Wu, Q. Wu","Artificial intelligence applications in intensity modulated radiation treatment planning: an overview.",2021,"","","","",28,"2022-07-13 09:21:51","","10.21037/qims-21-208","","",,,,,1,1.00,0,9,1,"Artificial intelligence (AI) refers to methods that improve and automate challenging human tasks by systematically capturing and applying relevant knowledge in these tasks. Over the past decades, a number of approaches have been developed to address different types and needs of system intelligence ranging from search strategies to knowledge representation and inference to robotic planning. In the context of radiation treatment planning, multiple AI approaches may be adopted to improve the planning quality and efficiency. For example, knowledge representation and inference methods may improve dose prescription by integrating and reasoning about the domain knowledge described in many clinical guidelines and clinical trials reports. In this review, we will focus on the most studied AI approach in intensity modulated radiation therapy (IMRT)/volumetric modulated arc therapy (VMAT)-machine learning (ML) and describe our recent efforts in applying ML to improve the quality, consistency, and efficiency of IMRT/VMAT planning. With the available high-quality data, we can build models to accurately predict critical variables for each step of the planning process and thus automate and improve its outcomes. Specific to the IMRT/VMAT planning process, we can build models for each of the four critical components in the process: dose-volume histogram (DVH), Dose, Fluence, and Human Planner. These models can be divided into two general groups. The first group focuses on encoding prior experience and knowledge through ML and more recently deep learning (DL) from prior clinical plans and using these models to predict the optimal DVH (DVH prediction model), or 3D dose distribution (dose prediction model), or fluence map (fluence map model). The goal of these models is to reduce or remove the trial-and-error process and guarantee consistently high-quality plans. The second group of models focuses on mimicking human planners' decision-making process (planning strategy model) during the iterative adjustments/guidance of the optimization engine. Each critical step of the IMRT/VMAT treatment planning process can be improved and automated by AI methods. As more training data becomes available and more sophisticated models are developed, we can expect that the AI methods in treatment planning will continue to improve accuracy, efficiency, and robustness.","",""
0,"James M. White, R. Lidskog","Ignorance and the regulation of artificial intelligence",2021,"","","","",29,"2022-07-13 09:21:51","","10.1080/13669877.2021.1957985","","",,,,,0,0.00,0,2,1,"Abstract Much has been written about the risks posed by artificial intelligence (AI). This article is interested not only in what is known about these risks, but what remains unknown and how that unknowing is and should be approached. By reviewing and expanding on the scientific literature, it explores how social knowledge contributes to the understanding of AI and its regulatory challenges. The analysis is conducted in three steps. First, the article investigates risks associated with AI and shows how social scientists have challenged technically-oriented approaches that treat the social instrumentally. It then identifies the invisible and visible characteristics of AI, and argues that not only is it hard for outsiders to comprehend risks attached to the technology, but also for developers and researchers. Finally, it asserts the need to better recognise ignorance of AI, and explores what this means for how their risks are handled. The article concludes by stressing that proper regulation demands not only independent social knowledge about the pervasiveness, economic embeddedness and fragmented regulation of AI, but a social non-knowledge that is attuned to its complexity, and inhuman and incomprehensible behaviour. In properly allowing for ignorance of its social implications, the regulation of AI can proceed in a more modest, situated, plural and ultimately robust manner.","",""
0,"Canan Tiftik","Investigation of Human Resources Dimension in Management and Organization Structure of the Effects of Artificial Intelligence",2021,"","","","",30,"2022-07-13 09:21:51","","10.21733/IBAD.833256","","",,,,,0,0.00,0,1,1,"In the competitive time, there has been a great deal of progress in the industry. It is one of the most serious obstacles to the industry in many industries that adopt contemporary technologies to manage continuous development and faster than ordinary jobs. Many of the scientists and researchers recommend using AI tools and digital technologies for industries. Machine language and artificial intelligence are used by many organizations in the human resources unit, where it undertakes an integrated task in recruiting, performance analysis, personnel selection, data collection for employees, providing real-time information and obtaining the right information. Artificial intelligence-based Human Resources (HR) applications have a solid potential to increase employee productivity and support HR experts to become knowledge and trained consultants that increase the success of the employee. HR applications authorized by artificial intelligence have the ability to analyze, predict, diagnose and seek and find more robust and capable resources.","",""
5,"E. Markopoulos, Ines Selma Kirane, Dea Balaj, H. Vanharanta","Artificial Intelligence and Blockchain Technology Adaptation for Human Resources Democratic Ergonomization on Team Management",2019,"","","","",31,"2022-07-13 09:21:51","","10.1007/978-3-030-27928-8_68","","",,,,,5,1.67,1,4,3,"","",""
0,"Qi Deng","Artificial Intelligence BlockCloud (AIBC) Technical Whitepaper",2018,"","","","",32,"2022-07-13 09:21:51","","10.2139/ssrn.3464239","","",,,,,0,0.00,0,1,4,"The AIBC is an Artificial Intelligence and blockchain technology based large-scale decentralized ecosystem that allows system-wide low-cost sharing of computing and storage resources. The AIBC consists of four layers: a fundamental layer, a resource layer, an application layer, and an ecosystem layer. The AIBC implements a two-consensus scheme to enforce upper-layer economic policies and achieve fundamental layer performance and robustness: the DPoEV incentive consensus on the application and resource layers, and the DABFT distributed consensus on the fundamental layer. The DABFT uses deep learning techniques to predict and select the most suitable BFT algorithm in order to achieve the best balance of performance, robustness, and security. The DPoEV uses the knowledge map algorithm to accurately assess the economic value of digital assets.","",""
0,"","Neural Network Training Using Genetic Algorithms Series In Machine Perception And Artificial Intelligence",2021,"","","","",33,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,0,1,"Knowledge-Based Intelligent Information and Engineering Systems 2Nature-inspired Methods in Chemometrics: Genetic Algorithms and Artificial Neural NetworksParallel Implementations of Backpropagation Neural Networks on TransputersEvolutionary Algorithms and Neural NetworksTraining Neural Networks Using Hybrids with Genetic AlgorithmsNeural Network Training Using Genetic AlgorithmsGene Expression ProgrammingTraining a Neural Network with a Genetic AlgorithmMethods and Applications of Artificial IntelligenceClassification and Learning Using Genetic AlgorithmsPractical Computer Vision Applications Using Deep Learning with CNNsIntelligent Hybrid SystemsNeurogenetic LearningAdvances in Neural Networks ISNN 2007Hybrid Intelligent SystemsEncyclopedia of Computer Science and TechnologyMachine LearningUsing a Genetic Algorithm in Training an Artificial Neural Network to Implement the XOR FunctionGenetic and Evolutionary Computation — GECCO 2004Handbook of Fuzzy ComputationNeural Network Data Analysis Using SimulnetTMArtificial Neural Nets and Genetic AlgorithmsApplied Soft Computing Technologies: The Challenge of ComplexityGenetic Algorithm for Artificial Neural Network Training for the Purpose of Automated Part RecognitionNEURAL NETWORKS, FUZZY LOGIC AND GENETIC ALGORITHMAutomatic Generation of Neural Network Architecture Using Evolutionary ComputationPGANETThe Sixth International Symposium on Neural Networks (ISNN 2009)Evolutionary Machine Learning TechniquesModeling Decisions for Artificial IntelligenceEmpirical Studies on the Utility of Genetic Algorithms for Training and Designing of Neural NetworksTraining Neural Networks Using Genetic AlgorithmsTraining feedforward neural networks using genetic algorithmsMetaheuristic Procedures for Training Neural NetworksArtificial Neural Nets and Genetic AlgorithmsNature-Inspired Computing: Concepts, Methodologies, Tools, and ApplicationsApplications of Evolutionary ComputingArtificial Intelligence and CreativityArtificial Neural Nets and Genetic AlgorithmsDeep Learning Using Genetic Algorithms Creativity is one of the least understood aspects of intelligence and is often seen as `intuitive' and not susceptible to rational enquiry. Recently, however, there has been a resurgence of interest in the area, principally in artificial intelligence and cognitive science, but also in psychology, philosophy, computer science, logic, mathematics, sociology, and architecture and design. This volume brings this work together and provides an overview of this rapidly developing field. It addresses a range of issues. Can computers be creative? Can they help us to understand human creativity? How can artificial intelligence (AI) enhance human creativity? How, in particular, can it contribute to the `sciences of the artificial', such as design? Does the new wave of AI (connectionism, geneticism and artificial life) offer more promise in these areas than classical, symbol-handling AI? What would the implications be for AI and cognitive science if computers could not be creative? These issues are explored in five interrelated parts, each of which is introducted and explained by a leading figure in the field. Prologue (Margaret Boden) Part I: Foundational Issues (Terry Dartnall) Part II: Creativity and Cognition (Graeme S. Halford and Robert Levinson) Part III: Creativity and Connectionism (Chris Thornton) Part IV: Creativity and Design (John Gero) Part V: Human Creativity Enhancement (Ernest Edmonds) Epilogue (Douglas Hofstadter) For researchers in AI, cognitive science, computer science, philosophy, psychology, mathematics, logic, sociology, and architecture and design; and anyone interested in the rapidly growing field of artificial intelligence and creativity.From the contents: Neural networks – theory and applications: NNs (= neural networks) classifier on continuous data domains– quantum associative memory – a new class of neuron-like discrete filters to image processing – modular NNs for improving generalisation properties – presynaptic inhibition modelling for image processing application – NN recognition system for a curvature primal sketch – NN based nonlinear temporalspatial noise rejection system – relaxation rate for improving Hopfield network – Oja's NN and influence of the learning gain on its dynamics Genetic algorithms – theory and applications: transposition: a biological-inspired mechanism to use with GAs (= genetic algorithms) – GA for decision tree induction – optimising decision classifications using GAs – scheduling tasks with intertask communication onto multiprocessors by GAs – design of robust networks with GA – effect of degenerate coding on GAs – multiple traffic signal control using a GA – evolving musical harmonisation – niched-penalty approach for constraint handling in GAs – GA with dynamic population size – GA with dynamic niche clustering for multimodal function optimisation Soft computing and uncertainty: self-adaptation of evolutionary constructed decision trees by information spreading – evolutionary programming of near optimal NNsArtificial neural networks and genetic algorithms both are areas of research","",""
1,"H. López-Fernández","Application of data mining and artificial intelligence techniques to mass spectrometry data for knowledge discovery",2016,"","","","",34,"2022-07-13 09:21:51","","","","",,,,,1,0.17,1,1,6,"Mass spectrometry using matrix assisted laser desorption ionization coupled to time of flight analyzers (MALDI-TOF MS) has become popular during the last decade due to its high speed, sensitivity and robustness for detecting proteins and peptides. This allows quickly analyzing large sets of samples are in one single batch and doing high-throughput proteomics. In this scenario, bioinformatics methods and computational tools play a key role in MALDI-TOF data analysis, as they are able handle the large amounts of raw data generated in order to extract new knowledge and useful conclusions. A typical MALDI-TOF MS data analysis workflow has three main stages: data acquisition, preprocessing and analysis. Although the most popular use of this technology is to identify proteins through their peptides, analyses that make use of artificial intelligence (AI), machine learning (ML), and statistical methods can be also carried out in order to perform biomarker discovery, automatic diagnosis, and knowledge discovery. In this research work, this workflow is deeply explored and new solutions based on the application of AI, ML, and statistical methods are proposed. In addition, an integrated software platform that supports the full MALDI-TOF MS data analysis workflow that facilitate the work of proteomics researchers without advanced bioinformatics skills has been developed and released to the scientific community.","",""
0,"Alex Mathew﻿","Artificial Intelligence and Cognitive Computing for 6G Communications & Networks﻿",2021,"","","","",35,"2022-07-13 09:21:51","","10.47760/IJCSMC.2021.V10I03.003","","",,,,,0,0.00,0,1,1,"With the fast improvement of smart infrastructures and terminals, as well as an enhanced applications (such as augmented and virtual reality, holographic projection and remote surgery) with vivid prerequisites, modern networks (forthcoming 5G and 4G networks) will most likely be unable to satisfy the rapidly rising traffic needs. Likewise, efforts from both the scholarly and academia realm have effectively been put to the examination on 6G systems. Lately, man-made intelligence (AI) has been widely used as another worldview for the plan and enhancement of 6G systems with an undeniable degree of knowledge. Accordingly, the paper proposes AI-empowered architecture engineering for 6G systems to acknowledge information discovery, intelligent service provisioning, mechanic system adjustment, and smart resource management where the network architecture if segregated in four layers: smart application layer, intelligent control layer, information search and logic layer, and intelligent sensing layer. The article further survey and examine the uses of AI techniques for 6G organizations and expand how to utilize the AI procedures to efficiently and viably streamline the exaction of networks, including smart spectrum management, handover management, intelligent mobility, and AI-empowered mobile edge computing. The paper also highlights crucial future study directions and possible solutions for 6G networks such as energy management, hardware development, algorithms robustness, and computation efficiency. Keywords— 6G networks, Artificial Intelligence, Remote networks, device-to-device (D2D) technologies, and massive machine-type communications (mMTC)","",""
0,"Chengbing Tan, Qun Chen","Application of an artificial intelligence algorithm model of memory retrieval and roaming in sorting Chinese medicinal materials",2021,"","","","",36,"2022-07-13 09:21:51","","10.3233/jcm-215477","","",,,,,0,0.00,0,2,1,"In order to capture autobiographical memory, inspired by the development of human intelligence, a computational AM model for autobiographical memory is proposed in this paper, which is a three-layer network structure, in which the bottom layer encodes the event-specific knowledge comprising 5W1H, and provides retrieval clues to the middle layer, encodes the related events, and the top layer encodes the event set. According to the bottom-up memory search process, the corresponding events and event sets can be identified in the middle layer and the top layer respectively; At the same time, AM model can simulate human memory roaming through the process of rule-based memory retrieval. The computational AM model proposed in this paper not only has robust and flexible memory retrieval, but also has better response performance to noisy memory retrieval cues than the commonly used memory retrieval model based on keyword query method, and can also imitate the roaming phenomenon in memory.","",""
0,"H. L. Fernández","Application of data mining and artificial intelligence techniques to mass spectrometry data for knowledge discovery",2016,"","","","",37,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,1,6,"Mass spectrometry using matrix assisted laser desorption ionization coupled to time of flight analyzers (MALDI-TOF MS) has become popular during the last decade due to its high speed, sensitivity and robustness for detecting proteins and peptides. This allows quickly analyzing large sets of samples are in one single batch and doing high-throughput proteomics. In this scenario, bioinformatics methods and computational tools play a key role in MALDI-TOF data analysis, as they are able handle the large amounts of raw data generated in order to extract new knowledge and useful conclusions. A typical MALDI-TOF MS data analysis workflow has three main stages: data acquisition, preprocessing and analysis. Although the most popular use of this technology is to identify proteins through their peptides, analyses that make use of artificial intelligence (AI), machine learning (ML), and statistical methods can be also carried out in order to perform biomarker discovery, automatic diagnosis, and knowledge discovery. In this research work, this workflow is deeply explored and new solutions based on the application of AI, ML, and statistical methods are proposed. In addition, an integrated software platform that supports the full MALDI-TOF MS data analysis workflow that facilitate the work of proteomics researchers without advanced bioinformatics skills has been developed and released to the scientific community.","",""
1,"T. Schmid","Batch-like Online Learning for More Robust Hybrid Artificial Intelligence: Deconstruction as a Machine Learning Process",2021,"","","","",38,"2022-07-13 09:21:51","","","","",,,,,1,1.00,1,1,1,"Continuous streams of data are a common, yet challenging phenomenon of modern information processing. Traditional approaches to adopt machine learning techniques to this setting, like offline and online learning, have demonstrated several critical drawbacks. In order to avoid known disadvantages of both approaches, we propose to combine their complementary advantages in a novel machine learning process called deconstruction. Similar to supervised and unsupervised learning, this novel process provides a fundamental learning functionality modeled after human learning. This functionality integrates mechanisms for partitioning training data, managing learned knowledge representations and integrating newly acquired knowledge with previously learned knowledge representations. A prerequisite for this concept is that learning data can be partitioned and that resulting knowledge partitions may be accessed by formal means. In the proposed approach, this is achieved by the recently introduced Constructivist Machine Learning framework, which allows to create, exploit and maintain a knowledge base. In this work, we highlight the design concepts for the implementation of such a deconstruction process. In particular, we describe required subprocesses and how they can be combined.","",""
0,"E. Cambouropoulos, Maximos A. Kaliakatsos-Papakostas","Cognitive Musicology and Artificial Intelligence: Harmonic Analysis, Learning, and Generation",2021,"","","","",39,"2022-07-13 09:21:51","","10.1007/978-3-030-72116-9_10","","",,,,,0,0.00,0,2,1,"","",""
24,"Maxime Sermesant, H. Delingette, H. Cochet, P. Jaïs, N. Ayache","Applications of artificial intelligence in cardiovascular imaging",2021,"","","","",40,"2022-07-13 09:21:51","","10.1038/s41569-021-00527-2","","",,,,,24,24.00,5,5,1,"","",""
9,"Kuansong Wang, Gang Yu, Chao Xu, Xiang-He Meng, Jian-hua Zhou, C. Zheng, Z. Deng, L. Shang, Ruijie Liu, S. Su, Xunjian Zhou, Qingling Li, Juanni Li, Jing Wang, K. Ma, J. Qi, Zhenmin Hu, P. Tang, Jeffrey Deng, X. Qiu, Bo Li, W. Shen, R. Quan, Juntao Yang, Lin Huang, Yao Xiao, Zhichun Yang, Zhongming Li, Shengchun Wang, Hongzheng Ren, C. Liang, Wei Guo, Yanchun Li, Heng Xiao, Yong-hong Gu, J. Yun, Dan Huang, Zhigang Song, Xiangshan Fan, Ling Chen, Xiaochu Yan, Zhi Li, Zhongjun Huang, Jufang Huang, Joseph Luttrell, Chaoyang Zhang, Weihua Zhou, Kun Zhang, C. Yi, Hui Shen","Accurate diagnosis of colorectal cancer based on histopathology images using artificial intelligence",2020,"","","","",41,"2022-07-13 09:21:51","","10.1186/s12916-021-01942-5","","",,,,,9,4.50,1,50,2,"","",""
43,"Zuoxu Wang, Chun-Hsien Chen, Pai Zheng, Xinyu Li, L. Khoo","A graph-based context-aware requirement elicitation approach in smart product-service systems",2019,"","","","",42,"2022-07-13 09:21:51","","10.1080/00207543.2019.1702227","","",,,,,43,14.33,9,5,3,"The paradigm of Smart product-service systems (Smart PSS) has emerged recently owing to the edge-cutting Information and Communication Technology (ICT) and artificial intelligence (AI) techniques. The unique features of Smart PSS including smartness and connectedness, value co-creation and data-driven design manner, enable the collection and analysis of large volume and heterogeneous contextual data to extract useful knowledge. Therefore, requirement elicitation, as a critical process for new solution (i.e. product-service) design, can be conducted in a rather context-aware manner, assured by those massive user-generated data and product-sensed data during the usage stage. Nevertheless, despite a few works on semantic modelling, scarcely any reports on such mechanism in today's smart, connected environment. Aiming to fill this gap, for the first time, a graph-based context-aware requirement elicitation approach considering contextual information within the Smart PSS is proposed. It leverages the pre-defined product, service, and condition ontologies together with Deepwalk technique, to formulate those concepts as nodes and their relationships as the edge of the proposed requirement graph. Implicit stakeholder requirements within a specific context can be further derived based on such interrelationships in a data-driven manner. To demonstrate its feasibility and effectiveness, an example of smart bike share system is addressed to illustrate the requirement elicitation process. It is hoped that this explorative study can offer valuable insights for the service providers who would like to extract requirements not only from the voice of customers but also from the user-generated data and product-sensed data.","",""
8,"I. Wiafe, F. N. Koranteng, Emmanuel Nyarko Obeng, Nana Assyne, Abigail Wiafe, S. Gulliver","Artificial Intelligence for Cybersecurity: A Systematic Mapping of Literature",2020,"","","","",43,"2022-07-13 09:21:51","","10.1109/ACCESS.2020.3013145","","",,,,,8,4.00,1,6,2,"Due to the ever-increasing complexities in cybercrimes, there is the need for cybersecurity methods to be more robust and intelligent. This will make defense mechanisms to be capable of making real-time decisions that can effectively respond to sophisticated attacks. To support this, both researchers and practitioners need to be familiar with current methods of ensuring cybersecurity (CyberSec). In particular, the use of artificial intelligence for combating cybercrimes. However, there is lack of summaries on artificial intelligent methods for combating cybercrimes. To address this knowledge gap, this study sampled 131 articles from two main scholarly databases (ACM digital library and IEEE Xplore). Using a systematic mapping, the articles were analyzed using quantitative and qualitative methods. It was observed that artificial intelligent methods have made remarkable contributions to combating cybercrimes with significant improvement in intrusion detection systems. It was also observed that there is a reduction in computational complexity, model training times and false alarms. However, there is a significant skewness within the domain. Most studies have focused on intrusion detection and prevention systems, and the most dominant technique used was support vector machines. The findings also revealed that majority of the studies were published in two journal outlets. It is therefore suggested that to enhance research in artificial intelligence for CyberSec, researchers need to adopt newer techniques and also publish in other related outlets.","",""
6,"Óscar Álvarez-Machancoses, Enrique J DeAndrés Galiana, A. Cernea, J. Fernández de la Viña, J. Fernández-Martínez","On the Role of Artificial Intelligence in Genomics to Enhance Precision Medicine",2020,"","","","",44,"2022-07-13 09:21:51","","10.2147/PGPM.S205082","","",,,,,6,3.00,1,5,2,"Abstract The complexity of orphan diseases, which are those that do not have an effective treatment, together with the high dimensionality of the genetic data used for their analysis and the high degree of uncertainty in the understanding of the mechanisms and genetic pathways which are involved in their development, motivate the use of advanced techniques of artificial intelligence and in-depth knowledge of molecular biology, which is crucial in order to find plausible solutions in drug design, including drug repositioning. Particularly, we show that the use of robust deep sampling methodologies of the altered genetics serves to obtain meaningful results and dramatically decreases the cost of research and development in drug design, influencing very positively the use of precision medicine and the outcomes in patients. The target-centric approach and the use of strong prior hypotheses that are not matched against reality (disease genetic data) are undoubtedly the cause of the high number of drug design failures and attrition rates. Sampling and prediction under uncertain conditions cannot be avoided in the development of precision medicine.","",""
1,"Joanna Black, Cody Fullerton","Digital Deceit: Fake News, Artificial Intelligence, and Censorship in Educational Research",2020,"","","","",45,"2022-07-13 09:21:51","","10.4236/jss.2020.87007","","",,,,,1,0.50,1,2,2,"Never has it been more urgent for educators to be aware of the perils of  research in education using digital searches in today’s world of  disinformation, misinformation, artificial intelligence and censorship. As a  result, we are more reliant on strong researchers than ever before. In the  discipline of Education, students are often asked to research issues pertaining  to curricula, pedagogy, educational information and theories. Pupils are using  Internet and digital library searches to gain knowledge within public and  private K-12 schools and within higher education. In this article, an  Educational Librarian and an Education Professor outline their approach to  educating all Faculty of Education students about using digital platforms in  relation to unmasking fake news, artificial intelligence (AI) usage,  and increasing Internet censorship. Using case study research, we  examined 34 Bachelor of Education students in training at the high school level who created environmental digital art  projects. Information/media literacy was taught in order to provide students with  the necessary tools to identify credible, diverse, well-informed, strong, and  robust research. In addition, they  needed to be able to discern when artificial intelligence was utilized. Outlined are students’ projects. Our findings include “top ten” practical suggestions for educators at all levels when teaching students about  effective researching in our current digital era.","",""
1,"A. Zarzeczny, P. Babyn, S. Adams, Justin Longo","Artificial intelligence-based imaging analytics and lung cancer diagnostics: Considerations for health system leaders",2020,"","","","",46,"2022-07-13 09:21:51","","10.1177/0840470420975062","","",,,,,1,0.50,0,4,2,"Lung cancer is a leading cause of cancer death in Canada, and accurate, early diagnosis are critical to improving clinical outcomes. Artificial Intelligence (AI)-based imaging analytics are a promising healthcare innovation that aim to improve the accuracy and efficiency of lung cancer diagnosis. Maximizing their clinical potential while mitigating their risks and limitations will require focused leadership informed by interdisciplinary expertise and system-wide insight. We convened a knowledge exchange workshop with diverse Saskatchewan health system leaders and stakeholders to explore issues surrounding the use of AI in diagnostic imaging for lung cancer, including implementation opportunities, challenges, and priorities. This technology is anticipated to improve patient outcomes, reduce unnecessary healthcare spending, and increase knowledge. However, health system leaders must also address the needs for robust data, financial investment, effective communication and collaboration between healthcare sectors, privacy and data protections, and continued interdisciplinary research to achieve this technology’s potential benefits.","",""
1,"Alicia Lai","Artificial Intelligence, LLC: Corporate Personhood as Tort Reform",2020,"","","","",47,"2022-07-13 09:21:51","","10.2139/ssrn.3677360","","",,,,,1,0.50,1,1,2,"Our legal system has long tried to fit the square peg of artificial intelligence (AI) technologies into the round hole of the current tort regime, overlooking the inability of traditional liability schemes to address the nuances of how AI technology creates harms. The current tort regime deals out rough justice—using strict liability for some AI products and using the negligence rule for other AI services—both of which are insufficiently tailored to achieve public policy objectives.    Under a strict liability regime where manufacturers are always held liable for the faults of their technology regardless of knowledge or precautionary measures, firms are incentivized to play it safe and stifle innovation. But even with this cautionary stance, the goals of strict liability cannot be met due to the unique nature of AI technology: its mistakes are merely “efficient errors”—they appropriately surpass the human baseline, they are game theory problems intended for a jury, they are necessary to train a robust system, or they are harmless but misclassified.    Under a negligence liability regime where the onus falls entirely on consumers to prove the element of causation, victimized consumers are left without sufficient recourse or compensation. Many critiques have been leveled against the “black-box” nature of algorithms.    This paper proposes a new framework to regulate artificial intelligence technologies: bestowing corporate personhood to AI systems. First, the corporate personality trait of “limited liability” strikes an optimal balance in determining liability—it would both compensate victims (for instance, through obligations to carry insurance and a straightforward burden of causation) while holding manufacturers responsible only when the infraction is egregious (for instance, through veil-piercing). Second, corporate personhood is “divisible”—meaning not all corporate personality traits need to be granted—which circumvents many of the philosophical criticisms of giving AI the complete set of rights of full legal personhood.","",""
75,"Qing Sun, Min Zhang, A. Mujumdar","Recent developments of artificial intelligence in drying of fresh food: A review",2019,"","","","",48,"2022-07-13 09:21:51","","10.1080/10408398.2018.1446900","","",,,,,75,25.00,25,3,3,"ABSTRACT Intellectualization is an important direction of drying development and artificial intelligence (AI) technologies have been widely used to solve problems of nonlinear function approximation, pattern detection, data interpretation, optimization, simulation, diagnosis, control, data sorting, clustering, and noise reduction in different food drying technologies due to the advantages of self-learning ability, adaptive ability, strong fault tolerance and high degree robustness to map the nonlinear structures of arbitrarily complex and dynamic phenomena. This article presents a comprehensive review on intelligent drying technologies and their applications. The paper starts with the introduction of basic theoretical knowledge of ANN, fuzzy logic and expert system. Then, we summarize the AI application of modeling, predicting, and optimization of heat and mass transfer, thermodynamic performance parameters, and quality indicators as well as physiochemical properties of dried products in artificial biomimetic technology (electronic nose, computer vision) and different conventional drying technologies. Furthermore, opportunities and limitations of AI technique in drying are also outlined to provide more ideas for researchers in this area.","",""
0,"Hebah Bubakr, Chris Baber","How sensemaking by people and artificial intelligence might involve different frames",2020,"","","","",49,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,2,2,"Sensemaking can involve selecting an appropriate frame to explain a given set of data. The selection of the frame (and the definition of its appropriateness) can depend on the prior experience of the sensemaker as much as on the availability of data. Moreover, artificial intelligence and machine learning systems are dependent on knowledge elicited from human experts, yet, if we trained these systems to perform and think in the same way as a human, most of the tools will be unacceptable to be used as criterion because people consider many personal parameters that a machine should not use. In this paper, we consider how an artificial intelligence system that can be used to filter curriculum vitae (or résumés) might apply frames that result in socially unacceptable decisions.","",""
0,"V. Manuel, E. Halperin, Jeffrey N. Chiang, Kodi Taraszka, Laura M Kim, N. Raja, C. Saigal, L. Roh, Eleazer Eskin","4375 Developing team science for practical applications of artificial intelligence in health systems to improve value and outcomes: A case study in reducing avoidable emergency department use",2020,"","","","",50,"2022-07-13 09:21:51","","10.1017/cts.2020.355","","",,,,,0,0.00,0,9,2,"OBJECTIVES/GOALS: Health care systems are complex, dynamic, and varied. Advances in artificial intelligence (AI) are enabling healthcare systems to use their own data to elicit patterns and design suitable interventions. To realize this potential, computer scientists and clinicians need an effective, practical, and replicable approach to collaboration METHODS/STUDY POPULATION: In this study, computer scientists partnered with clinicians to investigate predictors of avoidable emergency department use. The team sought an approach to computational medicine that could increase the relevance and impact of prediction to solve pressing problems in the health system. The team adopted an emergent architecture that engaged system leaders, computer scientists, data scientists, health services researchers, and practicing clinicians with deep ambulatory and inpatient knowledge to form the initial questions that shaped the prediction model; to understand nuances of coding and recording in source data and the implications for models; and to generate insights for promising points of intervention. The team recorded decisions and challenges as it progressed to analyze its function. RESULTS/ANTICIPATED RESULTS: Most avoidance models focus on a narrow time period around target events, or on high cost patients and events. This interdisciplinary team used their insights into the health system’s workflows and patient population to adopt a longitudinal approach to their prediction models. They used AI to build models of behavior in the system and consider prevention points across clinical units, time, and place. The holistic, systemwide focus enabled the team to generate insights that the system leaders and subsequently specific clinical units could apply to improve value and outcomes. A facilitated team process using learning system and cooperative network principles allowed a large and modular interdisciplinary team to build a transparent AI modeling process that yielded actionable insights into hypercomplex workflows. DISCUSSION/SIGNIFICANCE OF IMPACT: An architecture for involving diverse stakeholders in computational medicine projects can increase the relevance and impact of AI for solving care delivery problems in complex health systems. Translational science and computational medicine programs can foster this type of engagement and encourage a whole system perspective.","",""
0,"S. Prusty, U. K. Jena, Sidhanta Kumar Balabantaray","APPLICATION OF ARTIFICIAL INTELLIGENCE IN FUZZY LOGIC FOR CROP MANAGEMENT IN AGRICULTURE",2020,"","","","",51,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,3,2,"This paper provides a systematic implementation of th e techniques of artificial intelligence for agricultural crop man agement. Agriculture faces many challenges, such as disease a nd infestation of pests, unsuitable soil treatment, inadequate dr ainage and irrigation and many more. Such result in severe crop failure along with environmental hazards caused by excessive chemical use. Several researches were carried out to deal with these issues. With its robust learning capabilities, the fields of artificial intelligence have become a crucial technique for solving various agricultural related problems. Systems are being developed to assist the agricultural experts around the world in finding better solutions. The sector faces numerous challenges to optimize its production, including inadequate soil care, disease and infestation of pests, big data requirements, low output and knowledge gap between farmers and","",""
22,"L. Valiant","Knowledge Infusion: In Pursuit of Robustness in Artificial Intelligence",2008,"","","","",52,"2022-07-13 09:21:51","","10.4230/LIPIcs.FSTTCS.2008.1770","","",,,,,22,1.57,22,1,14,"Endowing computers with the ability to apply commonsense knowledge with human- level performance is a primary challenge for computer science, comparable in importance to past great challenges in other fields of science such as the sequencing of the human genome. The right approach to this problem is still under debate. Here we shall discuss and attempt to justify one ap- proach, that of knowledge infusion. This approach is based on the view that the fundamental objective that needs to be achieved is robustness in the following sense: a framework is needed in which a computer system can represent pieces of knowledge about the world, each piece having some un- certainty, and the interactions among the pieces having even more uncertainty, such that the system can nevertheless reason from these pieces so that the uncertainties in its conclusions are at least controlled. In knowledge infusion rules are learned from the world in a principled way so that sub- sequent reasoning using these rules will also be principled, and subject only to errors that can be bounded in terms of the inverse of the effort invested in the learning process.","",""
18,"J. Hellwig, Sarah Huggett, Mark Siebert","Data for report ""Artificial Intelligence: How knowledge is created, transferred, and used""",2019,"","","","",53,"2022-07-13 09:21:51","","10.17632/7YDFS62GD6.2","","",,,,,18,6.00,6,3,3,"The growing importance and relevance of artificial intelligence (AI) to humanity is undisputed. However, AI does not seem to have a universally agreed definition, and different sectors of society use very different vocabulary to describe AI. Using AI to define AI, we were able to detect the relevant body of research, further structure it in sub-fields, and give a comprehensive overview of the research landscape.    There are strong regional differences in AI activity:  • China aspires to lead globally in AI and focuses on computer vision. It shows a rapid rise in scholarly output and citation impact. A net brain gain of AI researchers to China also suggests an attractive research environment.  • Europe is the largest producer of AI scholarly output, but appears to be losing academic AI talent. The broad spectrum of AI research in Europe reflects the diversity of European countries, each with their own agenda and specialties.  • AI research in the United States is robust, both in terms of scholarly output and talent retention. The US benefits from a strong corporate sector. The corpus shows less diversity in AI research than Europe but more than China.    A key area of further development in AI research worldwide is on ethical issues pertaining to AI. While a major topic in daily conversation, there is surprisingly little formal research published on AI ethics to date. We believe there is a need for more AI ethics research, which would bring many benefits to the field, its development, and its applications.","",""
5,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: A Sensible Artificial Intelligence That Plays with Handicap and Targets High Scores in 9×9 Go",2020,"","","","",54,"2022-07-13 09:21:51","","10.3233/FAIA200119","","",,,,,5,2.50,1,6,2,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9×9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
73,"Valentina Bellemo, Gilbert Lim, T. Rim, G. Tan, C. Cheung, S. Sadda, M. He, A. Tufail, M. Lee, W. Hsu, D. Ting","Artificial Intelligence Screening for Diabetic Retinopathy: the Real-World Emerging Application",2019,"","","","",55,"2022-07-13 09:21:51","","10.1007/s11892-019-1189-3","","",,,,,73,24.33,7,11,3,"","",""
1,"O. Jenkins, D. Lopresti, M. Mitchell","Next Wave Artificial Intelligence: Robust, Explainable, Adaptable, Ethical, and Accountable",2020,"","","","",56,"2022-07-13 09:21:51","","","","",,,,,1,0.50,0,3,2,"The history of AI has included several ""waves"" of ideas. The first wave, from the mid-1950s to the 1980s, focused on logic and symbolic hand-encoded representations of knowledge, the foundations of so-called ""expert systems"". The second wave, starting in the 1990s, focused on statistics and machine learning, in which, instead of hand-programming rules for behavior, programmers constructed ""statistical learning algorithms"" that could be trained on large datasets. In the most recent wave research in AI has largely focused on deep (i.e., many-layered) neural networks, which are loosely inspired by the brain and trained by ""deep learning"" methods. However, while deep neural networks have led to many successes and new capabilities in computer vision, speech recognition, language processing, game-playing, and robotics, their potential for broad application remains limited by several factors.  A concerning limitation is that even the most successful of today's AI systems suffer from brittleness-they can fail in unexpected ways when faced with situations that differ sufficiently from ones they have been trained on. This lack of robustness also appears in the vulnerability of AI systems to adversarial attacks, in which an adversary can subtly manipulate data in a way to guarantee a specific wrong answer or action from an AI system. AI systems also can absorb biases-based on gender, race, or other factors-from their training data and further magnify these biases in their subsequent decision-making. Taken together, these various limitations have prevented AI systems such as automatic medical diagnosis or autonomous vehicles from being sufficiently trustworthy for wide deployment. The massive proliferation of AI across society will require radically new ideas to yield technology that will not sacrifice our productivity, our quality of life, or our values.","",""
0,"J. Blay, Jurgi Camblong, F. Sigaux","Artificial Intelligence Applied to Oncology",2020,"","","","",57,"2022-07-13 09:21:51","","10.1007/978-3-030-32161-1_24","","",,,,,0,0.00,0,3,2,"","",""
0,"Hamza Ejaz, Hari McGrath, Brian Lh Wong, Andrew Guise, Tom Kamiel Magda Vercauteren, J. Shapey","Artificial intelligence and medical education: A global mixed-methods study of medical students’ perspectives",2022,"","","","",58,"2022-07-13 09:21:51","","10.1177/20552076221089099","","",,,,,0,0.00,0,6,1,"Objective Medical students, as clinicians and healthcare leaders of the future, are key stakeholders in the clinical roll-out of artificial intelligence-driven technologies. The authors aim to provide the first report on the state of artificial intelligence in medical education globally by exploring the perspectives of medical students. Methods The authors carried out a mixed-methods study of focus groups and surveys with 128 medical students from 48 countries. The study explored knowledge around artificial intelligence as well as what students wished to learn about artificial intelligence and how they wished to learn this. A combined qualitative and quantitative analysis was used. Results Support for incorporating teaching on artificial intelligence into core curricula was ubiquitous across the globe, but few students had received teaching on artificial intelligence. Students showed knowledge on the applications of artificial intelligence in clinical medicine as well as on artificial intelligence ethics. They were interested in learning about clinical applications, algorithm development, coding and algorithm appraisal. Hackathon-style projects and multidisciplinary education involving computer science students were suggested for incorporation into the curriculum. Conclusions Medical students from all countries should be provided teaching on artificial intelligence as part of their curriculum to develop skills and knowledge around artificial intelligence to ensure a patient-centred digital future in medicine. This teaching should focus on the applications of artificial intelligence in clinical medicine. Students should also be given the opportunity to be involved in algorithm development. Students in low- and middle-income countries require the foundational technology as well as robust teaching on artificial intelligence to ensure that they can drive innovation in their healthcare settings.","",""
0,"Bukhoree Sahoh, Kanjana Haruehansapong, Mallika Kliangkhlao","Causal Artificial Intelligence for High-Stakes Decisions: The Design and Development of a Causal Machine Learning Model",2022,"","","","",59,"2022-07-13 09:21:51","","10.1109/access.2022.3155118","","",,,,,0,0.00,0,3,1,"A high-stakes decision requires deep thought to understand the complex factors that stop a situation from becoming worse. Such decisions are carried out under high pressure, with a lack of information, and in limited time. This research applies Causal Artificial Intelligence to high-stakes decisions, aiming to encode causal assumptions based on human-like intelligence, and thereby produce interpretable and argumentative knowledge. We develop a Causal Bayesian Networks model based on causal science using $d$ -separation and do-operations to discover the causal graph aligned with cognitive understanding. Causal odd ratios are used to measure the causal assumptions integrated with the real-world data to prove the proposed causal model compatibility. Causal effect relationships in the model are verified based on causal P-values and causal confident intervals and approved less than 1% by random chance. It shows that the causal model can encode cognitive understanding as precise, robust relationships. The concept of model design allows software agents to imitate human intelligence by inferring potential knowledge and be employed in high-stakes decision applications.","",""
0,"Chris Yang","Explainable Artificial Intelligence for Predictive Modeling in Healthcare",2022,"","","","",60,"2022-07-13 09:21:51","","10.1007/s41666-022-00114-1","","",,,,,0,0.00,0,1,1,"","",""
10,"S. Mukhopadhyay, Sumarga Kumar Sah Tyagi, N. Suryadevara, V. Piuri, F. Scotti, S. Zeadally","Artificial Intelligence-Based Sensors for Next Generation IoT Applications: A Review",2021,"","","","",61,"2022-07-13 09:21:51","","10.1109/JSEN.2021.3055618","","",,,,,10,10.00,2,6,1,"Sensors play a vital role in our daily lives and are an essential component for Internet of Things (IoT) based systems as they enable the IoT to collect data to take smart and intelligent decisions. Recent advances in IoT systems, applications, and technologies, including industrial Cyber-Physical Systems (CPSs), are being supported by a wide range of different types of sensors based on artificial intelligence (AI). These smart AI-based sensors are typically characterized by onboard intelligence and have the ability to communicate collaboratively or through the Internet. To achieve the high level of automation required in today’s smart IoT applications, sensors incorporated into nodes must be efficient, intelligent, context-aware, reliable, accurate, and connected. Such sensors must also be robust, safety- and privacy-aware for users interacting with them. Sensors leveraging advanced AI technologies, new capabilities have recently emerged which have the potential to detect, identify, and avoid performance degradation and discover new patterns. Along with knowledge from complex sensor datasets, they can promote product innovation, improve operation level, and open up novel business models. We review sensors, smart data processing, communication protocol, and artificial intelligence which will enable the deployment of AI-based sensors for next-generation IoT applications.","",""
19,"M. Komorowski","Clinical management of sepsis can be improved by artificial intelligence: yes",2019,"","","","",62,"2022-07-13 09:21:51","","10.1007/s00134-019-05898-2","","",,,,,19,6.33,19,1,3,"","",""
4,"Qi Deng","Blockchain Economical Models, Delegated Proof of Economic Value and Delegated Adaptive Byzantine Fault Tolerance and their implementation in Artificial Intelligence BlockCloud",2019,"","","","",63,"2022-07-13 09:21:51","","10.3390/jrfm12040177","","",,,,,4,1.33,4,1,3,"The Artificial Intelligence BlockCloud (AIBC) is an artificial intelligence and blockchain technology based large-scale decentralized ecosystem that allows system-wide low-cost sharing of computing and storage resources. The AIBC consists of four layers: a fundamental layer, a resource layer, an application layer, and an ecosystem layer (the latter three are the collective “upper-layers”). The AIBC layers have distinguished responsibilities and thus performance and robustness requirements. The upper layers need to follow a set of economic policies strictly and run on a deterministic and robust protocol. While the fundamental layer needs to follow a protocol with high throughput without sacrificing robustness. As such, the AIBC implements a two-consensus scheme to enforce economic policies and achieve performance and robustness: Delegated Proof of Economic Value (DPoEV) incentive consensus on the upper layers, and Delegated Adaptive Byzantine Fault Tolerance (DABFT) distributed consensus on the fundamental layer. The DPoEV uses the knowledge map algorithm to accurately assess the economic value of digital assets. The DABFT uses deep learning techniques to predict and select the most suitable BFT algorithm in order to enforce the DPoEV, as well as to achieve the best balance of performance, robustness, and security. The DPoEV-DABFT dual-consensus architecture, by design, makes the AIBC attack-proof against risks such as double-spending, short-range and 51% attacks; it has a built-in dynamic sharding feature that allows scalability and eliminates the single-shard takeover. Our contribution is four-fold: that we develop a set of innovative economic models governing the monetary, trading and supply-demand policies in the AIBC; that we establish an upper-layer DPoEV incentive consensus algorithm that implements the economic policies; that we provide a fundamental layer DABFT distributed consensus algorithm that executes the DPoEV with adaptability; and that we prove the economic models can be effectively enforced by AIBC’s DPoEV-DABFT dual-consensus architecture.","",""
3,"H. Mohammed, S. Ismail","Proposition of new computer artificial intelligence models for shear strength prediction of reinforced concrete beams",2021,"","","","",64,"2022-07-13 09:21:51","","10.1007/S00366-021-01400-Z","","",,,,,3,3.00,2,2,1,"","",""
3,"T. Kaur, Anirudra Diwakar, Kirandeep, Pranav Mirpuri, M. Tripathi, P. Chandra, T. Gandhi","Artificial Intelligence in Epilepsy",2021,"","","","",65,"2022-07-13 09:21:51","","10.4103/0028-3886.317233","","",,,,,3,3.00,0,7,1,"Background: The study of seizure patterns in electroencephalography (EEG) requires several years of intensive training. In addition, inadequate training and human error may lead to misinterpretation and incorrect diagnosis. Artificial intelligence (AI)-based automated seizure detection systems hold an exciting potential to create paradigms for proper diagnosis and interpretation. AI holds the promise to transform healthcare into a system where machines and humans can work together to provide an accurate, timely diagnosis, and treatment to the patients. Objective: This article presents a brief overview of research on the use of AI systems for pattern recognition in EEG for clinical diagnosis. Material and Methods: The article begins with the need for understanding nonstationary signals such as EEG and simplifying their complexity for accurate pattern recognition in medical diagnosis. It also explains the core concepts of AI, machine learning (ML), and deep learning (DL) methods. Results and Conclusions: In this present context of epilepsy diagnosis, AI may work in two ways; first by creating visual representations (e.g., color-coded paradigms), which allow persons with limited training to make a diagnosis. The second is by directly explaining a complete automated analysis, which of course requires more complex paradigms than the previous one. We also clarify that AI is not about replacing doctors and strongly emphasize the need for domain knowledge in building robust AI models that can work in real-time scenarios rendering good detection accuracy in a minimum amount of time.","",""
7,"David K. Spencer, Stephen Duncan, Adam Taliaferro","Operationalizing artificial intelligence for multi-domain operations: a first look",2019,"","","","",66,"2022-07-13 09:21:51","","10.1117/12.2524227","","",,,,,7,2.33,2,3,3,"Artificial Intelligence / Machine Learning (AI/ML) is a foundational requirement for Multi-Domain Operations (MDO). To solve some of MDO’s most critical problems, for example, penetrating and dis-integrating an adversary’s antiaccess/area denial (A2/AD) systems, the future force requires the ability to converge capabilities from across multiple domains at speeds and scales beyond human cognitive abilities. This requires robust, interoperable AI/ML that operates across multiple layers: from optimizing technologies and platforms, to fusing data from multiple sources, to transferring knowledge across joint functions to accomplish critical MDO tactical tasks. This paper provides an overview of ongoing work from the Unified Quest Future Study Plan and other events with the Army’s Futures and Concepts Center to operationalize AI/ML to address MDO problems with this layered approach. It includes insights and required AI/ML capabilities determined with subject matter experts from various organizations at these learning events over the past two years, as well as vignettes that illustrate how AI/ML can be operationalized to enable successful Multi-Domain Operations against a near peer adversary.","",""
0,"Jinyun Tang, W. Riley, Qing Zhu, T. Keenan","Using machine learning and artificial intelligence to improve model-data integrated earth system model predictions of water and carbon cycle extremes",2021,"","","","",67,"2022-07-13 09:21:51","","10.2172/1769794","","",,,,,0,0.00,0,4,1,"Jinyun Tang 1, William J Riley 1, Qing Zhu 1, Trevor Keenan 1, 2 1Lawrence Berkeley National Laboratory 2 University of California, Berkeley Focal Area(s) The research proposed here focuses on improving the predictive power of the land component of earth system models (ESMs) using (1) model-data fusion enabled by machine learning (ML) and artificial intelligence (AI), (2) predictive modeling through the combination of ML, AI, and big-data (comprising both model output and observations), and (3) insight of ESM structure and process mechanisms gleaned from complex data using ML and AI. Science Challenge Current efforts on water and carbon cycle benchmarking and improving ESM predictions focus on how well models capture (1) snapshots of climatology (e.g., the spatial pattern of land surface evapotranspiration), (2) time series of aggregated variables (e.g., interannual variability of net land carbon fluxes), and (3) one-vs-one variable correlations (e.g., the relationship between precipitation and evapotranspiration), all of which are less than three dimensional. However, ESM predictions are by nature of high dimension, beyond those spanned by space and time, when variables like vegetation diversity and human water use are considered. Moreover, in 10 years, with improved spatial-temporal resolution and the inclusion of more mechanistic processes, ESMs will very likely output more diverse data streams at much larger volume. Meanwhile, thanks to technological advancements, the amount of observations will also increase dramatically, in both type and spatial-temporal coverage. Current benchmark and model-data integration paradigms and methods are insufficient to address this big-data challenge. Further, current approaches are not of sufficient specificity or fidelity for evaluation at fine spatial resolutions (e.g., 1 km), nor do they provide comprehensive understanding of the casualty relationships that affect climate extremes. To address these challenges, research is proposed here to (1) make better uses of multiple scales of observations to concurrently analyze, evaluate, and reduce ESM uncertainty, and generate process knowledge of terrestrial processes, (2) achieve the ability to clearly integrate diverse observations, ML and AI, theory, and model predictive capabilities, (3) obtain robust quantification of multivariate functional relationships (e.g., net primary productivity to precipitation, temperature, and radiation) under a wide range of environmental conditions, and (4) provide high fidelity prediction and understanding of climate extreme events at fine spatial resolutions. Rationale ESM predictions are uncertain because (1) the earth system comprises many components, including atmosphere, land, ocean, biosphere, cryosphere, human activities, etc., each of which is insufficiently monitored and understood; (2) when the insufficient understanding of these earth system components are combined with the limited spatial-temporal resolution of ESMs,","",""
0,"C. Carpenter","The Future of Plunger Lift Control Using Artificial Intelligence",2021,"","","","",68,"2022-07-13 09:21:51","","10.2118/0321-0044-JPT","","",,,,,0,0.00,0,1,1,"This article, written by JPT Technology Editor Chris Carpenter, contains highlights of paper SPE 201132, “The Future of Plunger Lift Control Using Artificial Intelligence,” by Ferdinand Hingerl and Brian Arnst, SPE, Ambyint, and David Cosby, SPE, Shale Tec, et al., prepared for the 2020 SPE Virtual Artificial Lift Conference and Exhibition - Americas, 10-12 November. The paper has not been peer reviewed.  Dozens of plunger lift control algorithms have been developed to account for different well conditions and optimization protocols. However, challenges exist that prevent optimization at scale. To address these challenges, a plunger lift optimization software was developed. One aspect of this software is enabling set-point optimization at scale. This paper will present the methodology to do so, detailing three separate areas working in unison to offer significant value to plunger lift well operators.  Introduction  Even in vertical wells, plunger lift presents significant challenges to optimization. Despite their mechanical simplicity, plunger lifted wells produce large amounts of data, and the combinations of possible set points to optimize the well are many. Additionally, plunger lift wells can present a variety of different types of anomalies and problems that require a robust understanding of the underlying physics and mathematics.  Such problems then are amplified when applied to horizontal well applications. The underlying physics and mathematics applied throughout the years for vertical wells do not produce accurate results for horizontal wells. Additionally, the anomalies produced in horizontal wells are more complex. Finally, typical production engineers and well optimizers now regularly look after more than 150—and often more than 500—wells, creating additional resource constraints to optimizing a field of plunger lift wells.  The presented plunger lift optimization software was implemented by creating a secure connection between the operator’s supervisory control and data acquisition (SCADA) network and the cloud. As new data are generated by the SCADA network, they are automatically transmitted to the cloud and processed.  Plunger Lift Control Algorithm Overview  These algorithms are the software code that determines when the well opens and when the well closes. Even though the algorithms only control well open/close, the plunger moves through four stages of plunger operation to complete one cycle: plunger fall time, casing pressure build time, plunger rise, and after flow (or production). Optimizing each individual stage is critical to ideal well production.  Plunger fall time is the time required for the plunger to descend from the lubricator to the bottomhole assembly (BHA). Currently, operators use the manufacturer’s anticipated fall time, trial and error, previous knowledge, acoustical plunger tracking, and plunger fall applications to set the appropriate fall time in the controller. A “fudge factor” is often applied to help ensure that the fall timer does not expire before the plunger reaches the BHA. Plunger fall time is affected by many changing variables: plunger condition, tubing condition, liquid height, and gas and liquid density. These variables make it difficult for a fall timer set once to represent accurately the correct time required for the plunger to reach the BHA on every cycle.","",""
0,"Nigamanth Sridhar, Li Yang, J. Joshi, Victor P. Piotrowski","Cybersecurity Education in the Age of Artificial Intelligence",2021,"","","","",69,"2022-07-13 09:21:51","","10.1145/3408877.3439525","","",,,,,0,0.00,0,4,1,"The 2019 Federal Cybersecurity Research and Development Strategic Plan highlighted the mutual needs and benefits of artificial intelligence (AI) and cybersecurity. AI techniques are expected to enhance cybersecurity by assisting human system managers with automated monitoring, analysis, and responses to cybersecurity attacks. Conversely, it is essential to guard AI technologies from unintended uses and hostile exploitation by leveraging cybersecurity practices. Research results at the intersection of AI and cybersecurity can help us to be better equipped with tools and techniques to tackle the growing cybersecurity challenges, while also presenting an opportunity to devise fundamentally new ways to motivate and educate students about cybersecurity in the age of AI. Likewise, a June 2019 technical workshop on 'Artificial Intelligence and Cybersecurity: Opportunities and Challenges' noted how the interplay between AI, machine learning, and cybersecurity will continue to introduce new opportunities and challenges in the security of AI as well as AI for cybersecurity. Basic research at the intersection of AI, cybersecurity, and education has the potential to expand existing AI opportunities and resources in cybersecurity education and workforce development. Education efforts are needed to foster workforce knowledge and skills about applying AI expertise to cybersecurity as well as building robust and trustworthy AI. This BOF session will bring together researchers who are interested in these collaborative explorations.","",""
41,"Guangnan Zhang, Z. H. Ali, M. Aldlemy, Mohamed H. Mussa, Sinan Q. Salih, M. Hameed, Z. Al-khafaji, Z. Yaseen","Reinforced concrete deep beam shear strength capacity modelling using an integrative bio-inspired algorithm with an artificial intelligence model",2020,"","","","",70,"2022-07-13 09:21:51","","10.1007/s00366-020-01137-1","","",,,,,41,20.50,5,8,2,"","",""
4,"Kacper Sokol","Fairness, Accountability and Transparency in Artificial Intelligence: A Case Study of Logical Predictive Models",2019,"","","","",71,"2022-07-13 09:21:51","","10.1145/3306618.3314316","","",,,,,4,1.33,4,1,3,"Machine learning -- the part of artificial intelligence aimed at eliciting knowledge from data and automated decision making without explicit instructions -- is making great strides, with new algorithms being invented every day. These algorithms find myriads of applications, but their ubiquity often comes at the expense of limited interpretability, hidden biases and unexpected vulnerabilities. Whenever one of these factors is a priority, the learning algorithm of choice is often a method considered to be inherently interpretable, e.g. logical models such as decision trees. In my research I challenge this assumption and highlight (quite common) cases when the assumed interpretability fails to deliver. To restore interpretability of logical machine learning models (decision trees and their ensembles in particular) I propose to explain them with class-contrastive counterfactual statements, which are a very common type of explanation in human interactions, well-grounded in social science research. To evaluate transparency of such models I collate explainability desiderata that can be used to systematically assess and compare such methods as an addition to user studies. Given contrastive explanations, I investigate their influence on the model's security, in particular gaming and stealing the model. Finally, I evaluate model fairness, where I am interested in choosing the most fair model among all the models with equal performance.","",""
4,"A. Samareh, Xiangyu Chang, W. Lober, H. Evans, Zhangyang Wang, Xiaoning Qian, Shuai Huang","Artificial Intelligence Methods for Surgical Site Infection: Impacts on Detection, Monitoring, and Decision Making.",2019,"","","","",72,"2022-07-13 09:21:51","","10.1089/sur.2019.150","","",,,,,4,1.33,1,7,3,"Background: There has been tremendous growth in the amount of new surgical site infection (SSI) data generated. Key challenges exist in understanding the data for robust clinical decision-support. Limitations of traditional methodologies to handle these data led to the emergence of artificial intelligence (AI). This article emphasizes the capabilities of AI to identify patterns of SSI data. Method: Artificial intelligence comprises various subfields that present potential solutions to identify patterns of SSI data. Discussions on opportunities, challenges, and limitations of applying these methods to derive accurate SSI prediction are provided. Results: Four main challenges in dealing with SSI data were defined: (1) complexities in using SSI data, (2) disease knowledge, (3) decision support, and (4) heterogeneity. The implications of some of the recent advances in AI methods to optimize clinical effectiveness were discussed. Conclusions: Artificial intelligence has the potential to provide insight in detecting and decision-support of SSI. As we turn SSI data into intelligence about the disease, we increase the possibility of improving surgical practice with the promise of a future optimized for the highest quality patient care.","",""
6,"Yaron Einhorn, M. Einhorn, Adaia Kamshov, Oron Lev, A. Trabelsi, N. Paz-Yaacov, S. Gross","Gene-specific artificial intelligence-based variant classification engine: results of a time-capsule experiment",2019,"","","","",73,"2022-07-13 09:21:51","","10.21203/rs.2.11834/v1","","",,,,,6,2.00,1,7,3,"  Background: Interpretation of genetic variation remains an impediment to cost-effective application of genomics to medicine. An advanced artificial intelligence (AI)-based Variant Classification Engine (aiVCE), rooted in ACMG/AMP guidelines, employs data-driven methods to expedite gene-specific classification (franklin.genoox.com). In this blinded study, the aiVCE’s overall and rule-level performances were evaluated using ClinVar (v. 2018-10) variants with creation dates after 5/01/2017. By removing any prior knowledge of these variants from the aiVCE training data, they were treated as novel variants. Using a ‘Full’ dataset (75,801 variants with ≥1 star) and an ‘Increased-Certainty’ dataset (3,993 variants with ≥2 stars), the aiVCE classified variants as pathogenic (P), likely-pathogenic (LP), uncertain significance (VUS), likely-benign (LB), or benign (B). VUS with sufficient supporting data were subclassified as VUS-leaning benign or VUS-leaning pathogenic. aiVCE results were evaluated to determine concordance with final ClinVar classification and rule-level determinations. Results: The aiVCE demonstrated >97% concordance among Increased-Certainty variants. Concordance was >95% across variant effects (e.g., missense, null, splice region), and was >93.5% for the Full dataset. When assessing the aiVCE’s application of specific ACMG rules, significant differences were observed between ClinVar P/LP and B/LB variants rule-met proportions (all P<0.00001), thus supporting gene-specific rule selections. Evaluation of discordance between the aiVCE and ClinVar uncovered evidences that might have been unavailable to submitting laboratories, highlighting AI utility in variant classification. Conclusions: The aiVCE exhibited robust performance, despite lacking past evidence, in determining whether variants would be categorized as P/LP. Applying latest computational advances to existing guidelines may assist scientists and clinicians interpret variants with limited clinical information and greatly reduce analytical bottlenecks.","",""
1,"Sonal Modak, D. Sehgal, J. Valadi","Applications of Artificial Intelligence and Machine Learning in Viral Biology",2019,"","","","",74,"2022-07-13 09:21:51","","10.1007/978-3-030-29022-1_1","","",,,,,1,0.33,0,3,3,"","",""
0,"C. Carpenter","Augmented Artificial Intelligence Improves Data Analytics in Heavy-Oil Reservoirs",2019,"","","","",75,"2022-07-13 09:21:51","","10.2118/0519-0068-JPT","","",,,,,0,0.00,0,1,3,"This article, written by JPT Technology Editor Chris Carpenter, contains highlights of paper SPE 193650, “Augmented-Artificial-Intelligence Solutions for Heavy-Oil Reservoirs: Innovative Work Flows That Build From Smart Analytics, Machine Learning, and Expert-Based Systems,” by David Castineira, Xiang Zhai, and Hamed Darabi, Quantum Reservoir Impact Group, prepared for the 2018 SPE International Heavy Oil Conference and Exhibition, Kuwait City, Kuwait, 10–12 December. The paper has not been peer reviewed.  Recently, many heavy-oil fields have seen exponentially higher volumes of data made available as a result of omnipresent connectivity. Existing data platforms have focused traditionally on solving the problem of data storage and access. The more-complex problem of true knowledge discovery and systematic value creation from the massive amount of data is less frequently addressed. The authors of this paper propose a novel work flow for the problem of building intelligent data analytics in heavy-oil fields.  Introduction  Optimal reservoir management for heavy-oil reservoirs requires systematic solutions that combine both engineering ability and advanced analytics. The authors believe that this requirement is addressed by what they call augmented artificial intelligence (AAI), a process inspired by the intelligence-amplification concept in which machine learning and human expertise are combined to improve solutions derived by systems that learn without any type of input from engineers or geoscientists. Practical deployment of AAI will involve automated work flows that use solid technical expertise and proven processes to transform field data into more-effective reservoir-management solutions.  Even with rapid data-preprocessing solutions in place, developing an optimal reservoir-management framework for heavy-oil assets is inherently complex. Identifying key recovery obstacles (KROs) and field-development plans (FDPs) typically takes many months, involving a large team of experts and the construction of sophisticated full-field simulation models. The recommendation is that automated work flows and AAI solutions are combined to identify those KROs rapidly and prepare robust FDPs that increase production and optimize current operations.  Perhaps the less-intuitive step in developing systematic solutions for heavy-oil fields is the process of developing a quantitative reservoir diagnostic framework. This process must build from big-data analytics platforms and an array of analytical, numerical, and empirical models combined to deliver a catalog of KROs affecting field performance. To this end, the entire historical set of well, field, and reservoir data must be processed and input into this diagnostics platform. Once the KROs are understood, the next step is to translate the diagnostics into detailed action plans in the field that can generate production, reserves, or capital-efficiency improvements.  This paper aims to offer an alternative approach to traditional work flows that identify recovery obstacles and development opportunities in heavy-oil fields by labor-intensive solutions. In contrast, the authors propose a systematic framework that provides three key advantages:  Execution time is fast, and an initial opportunity inventory can be generated.  The user can choose from multiple algorithms and methods to customize the technology to unique field/reservoir complexities.  The core algorithms are data-driven, integrate multidisciplinary data sets, and leave little room for the biases of the user, which allows for a consistent and repeatable analysis.","",""
0,"Yaxin Peng, S. Du, T. Zeng","Preface: Special Issue on Optimization Models and Algorithms in Artificial Intelligence",2019,"","","","",76,"2022-07-13 09:21:51","","10.1007/s40305-019-00278-5","","",,,,,0,0.00,0,3,3,"","",""
82,"K. Porayska-Pomsta, M. Mavrikis, S. D’Mello, C. Conati, R. Baker","Knowledge Elicitation Methods for Affect Modelling in Education",2013,"","","","",77,"2022-07-13 09:21:51","","10.3233/JAI-130032","","",,,,,82,9.11,16,5,9,"Research on the relationship between affect and cognition in Artificial Intelligence in Education AIEd brings an important dimension to our understanding of how learning occurs and how it can be facilitated. Emotions are crucial to learning, but their nature, the conditions under which they occur, and their exact impact on learning for different learners in diverse contexts still needs to be mapped out. The study of affect during learning can be challenging, because emotions are subjective, fleeting phenomena that are often difficult for learners to report accurately and for observers to perceive reliably. Context forms an integral part of learners' affect and the study thereof. This review provides a synthesis of the current knowledge elicitation methods that are used to aid the study of learners' affect and to inform the design of intelligent technologies for learning. Advantages and disadvantages of the specific methods are discussed along with their respective potential for enhancing research in this area, and issues related to the interpretation of data that emerges as the result of their use. References to related research are also provided together with illustrative examples of where the individual methods have been used in the past. Therefore, this review is intended as a resource for methodological decision making for those who want to study emotions and their antecedents in AIEd contexts, i.e. where the aim is to inform the design and implementation of an intelligent learning environment or to evaluate its use and educational efficacy.","",""
6,"Eugenio Concepción, Pablo Gervás, Gonzalo Méndez, C. León","Using CNL for Knowledge Elicitation and Exchange Across Story Generation Systems",2016,"","","","",78,"2022-07-13 09:21:51","","10.1007/978-3-319-41498-0_8","","",,,,,6,1.00,2,4,6,"","",""
4,"C. Sauer","Knowledge elicitation and formalisation for context and explanation-aware computing with case-based recommender systems",2016,"","","","",79,"2022-07-13 09:21:51","","","","",,,,,4,0.67,4,1,6,"Case-based reasoning (CBR), as one of the problem solving paradigms in the field of Artificial Intelligence (AI), is an approach to the re-use of experience to solve problem. The aim of this research was to identify and evaluate existing and new approaches to elicit and formalise knowledge for context-aware systems as well as systems that are able to perform explanation-aware computing.  The research was centred on systems that employ the specific AI approach of CBR. The research identified positive and negative effects of knowledge formalisation as well as synergies of knowledge formalisation for context-awareness and explanation-aware computing. The research focused on a set of specific knowledge sources such as sensors, human experts, online sources such as web communities and social media as well as a combination of these sources. A set of knowledge formalisation approaches was evaluated during the implementation of six prototype systems, representing a series of product- and work-flow recommender systems. Example domains for the systems developed include CBR-based recommendation in audio mastering, gold ore refinement and travel medicine. Test data gathered from real-world use of the prototypes formed the basis for a quantitative and qualitative analysis to establish the performance and quality of the knowledge formalisation approaches used within the prototypes development. The outcome of this research work consists of new approaches to knowledge elicitation and formalisation for expert work-flow recommender systems, new approaches to context- and explanatory-knowledge formalisation in combination with software engineering techniques, new approaches to knowledge extraction and formalisation from web sources and contributions to the further development of the myCBR 3 software, an open source software for the rapid prototyping of CBR systems.","",""
2,"A. Nikitin, S. Kaski","Decision Rule Elicitation for Domain Adaptation",2021,"","","","",80,"2022-07-13 09:21:51","","10.1145/3397481.3450682","","",,,,,2,2.00,1,2,1,"Human-in-the-loop machine learning is widely used in artificial intelligence (AI) to elicit labels for data points from experts or to provide feedback on how close the predicted results are to the target. This simplifies away all the details of the decision-making process of the expert. In this work, we allow the experts to additionally produce decision rules describing their decision-making; the rules are expected to be imperfect but to give additional information. In particular, the rules can extend to new distributions, and hence enable significantly improving performance for cases where the training and testing distributions differ, such as in domain adaptation. We apply the proposed method to lifelong learning and domain adaptation problems and discuss applications in other branches of AI, such as knowledge acquisition problems in expert systems. In simulated and real-user studies, we show that decision rule elicitation improves domain adaptation of the algorithm and helps to propagate expert’s knowledge to the AI model.","",""
0,"Dhall Rohit, N. Rathod","WILL ARTIFICIAL INTELLIGENCE CHANGE FUTURE OF DENTISTRY!",2021,"","","","",81,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,2,1,"Humans have recreated intelligence for effective human deciding and to unburden themselves of the stupendous workload. AI can act as a supplemental tool to enhance diagnosis and treatment care but intelligent machines can never be 'human'. the sector of AI is comparatively young but has still come an extended way within the fields of drugs and dentistry. Hence, there's a requirement for the dentists to remember about its potential implications for a lucrative clinical practice within the future. IndexTerms AI , Neural Networks, symbolic logic , Hybrid Intelligent Systems, Dentistry. INTRODUCTION With an enormous increase in the documented patient data, intelligent software for its computation has become a necessity. Computer-based diagnosis is gaining momentum due to its ability to detect and diagnose lesions which may go unnoticed to the human eye. The conventional approaches have provided much information, but are subject to limitations.The deed of the constant search has given rise to AI (AI), which may be a highly evolved system capable of mimicking functioning of the human brain. This review will give an insight into the present concepts and uses of AI in various fields of dentistry. Artificial intelligence Alan Turing, a young British polymath devised the Turing test to suggest that machines can use available information and reason to solve problems like humans. The term artificial intelligence was coined by John McCarthy in 19564 and it is defined as ‘a field of science and engineering concerned with the computational understanding of what is commonly called intelligent behaviour, and with the creation of artifacts that exhibit such behaviour’. 5 Common terminologies utilized in AI Machine learning (ML) Machine learning is the subfield of artificial intelligence in which algorithms are trained to perform tasks by learning patterns from data rather than by explicit programming. Machine learning techniques invariably involve parameter tuning with regards to the underlying technique, such as, the amount of neurons, layers or epochs during a neural network technique; membership function selection in fuzzy logic; population size, selection strategy, mutation rate, crossover rate in genetic algorithms as well as in the hybrid techniques that use fuzzy logic or neural network or both. Various machine learning models, such as the Genetic Algorithm (GA), the Artificial Neural Network (ANN) and the Support Vector Machine (SVM), can actually ``learn'' and `be trained'' from the given data in order to execute many functions. Representation learning Is a subtype of ML during which the pc algorithm learns the features required to classify the provided data. This does not require a hand labelled data like ML. Deep learning (DL) The ML is a subset of AI, meanwhile, DL, in turn, is a subset of ML. That is DL is a facet of AI; the term deep learning refers to artificial neural networks (ANN) with complex multilayers. The distinction between deep learning and neural networks (NNs) like feedforward NNs and feed backward NNs lies in their characteristic. Deep learning has more complex ways of connecting layers, also has more neurons count than other networks to express complex models, with more computing power to train and further has automatic extraction of the feature.This algorithm uses multiple layers to detect simple features like line, edge and texture to complex shapes, lesions, or whole organs in a hierarchical structure. Clinical decision-support systems (CDSS) CDSS actually is any computer system designed to help healthcare professionals make clinical decisions through managing clinical data or medical knowledge.Most CDSS have four basic components: Inference Engine (IE), Knowledge Base (KB), Explanation Module and Working Memory. The Inference Engine (IE) is the main part of any such system, containing the knowledge about the patient from which to draw conclusions regarding certain conditions. The knowledge used by IE is represented in the knowledge base and tools that have been c reated to facilitate the © 2021 JETIR July 2021, Volume 8, Issue 7 www.jetir.org (ISSN-2349-5162) JETIR2107682 Journal of Emerging Technologies and Innovative Research (JETIR) www.jetir.org f411 acquisition and elicitation of this knowledge. The collected patient data may be stored in a database or may exist in the form of a message and is known as the working memory. The last component, the reason Module isn't present altogether CDSS. This module is responsible for composing justifications for the conclusions drawn by the IE in applying the knowledge in the KB against patient data in working memory. 12 Artificial neural networks (ANNS) Artificial neural networks are highly interconnected network of computer processors that are inspired by the biological nervous systems.McCulloch and Pitts (1943) invented the first artificial neurone using simple binary threshold functions. The next important milestone came when Frank Rosenblatt, a psychologist, developed the Perceptron in 1958 which worked on a multilayer feed forward mechanism. Another breakthrough during this technology came when Paul Werbos in 1974 introduced “backpropagation” learning. Today this ability of the computers programs is getting used to “learn” from newer information to aid health care for data processing and knowledge representation.1 ANN consists of a variable number of artificial neurons or nodes connected in hierarchical layers: an input layer, one or more hidden layers, and an output layer. Each node, with the exception of the input neurons, receives multiple weighted inputs and produces an output that is usually a nonlinear function of the inputs. 14 A neural network ‘learns’ through repeated adjustments of these weights. Their ability to learn from historical examples, analyse non-linear data, handle imprecise information and generalise enabling application of the model to independent data has made them a very attractive analytical tool in the field of medicine. They have been used in the clinical diagnosis, image analysis in radiology and histopathology, data interpretation in intensive care setting and waveform analysis. 5 Recent advances in neural networks Recently, several variations of artificial neural networks gained attention like convolutional neural networks (CNNs) for image classification challenges and dilated convolutional neural networks (DCNNs) for sematic scene segmentation challenges. Two main classes of CNNs prevail for volumetric prediction in general: Tiramisu and dilated convolutional neural networks (DCNNs) data. Tiramisu based models like U-net shine at predicting dose volumes that tend to be spatially according to reference to anatomy, such the dose volume to a prostate. Dilated convolutional neural networks (DCNNs) utilize convolutions that jump information during their encoding stage, to assist extend their field of view. DCNNs are often useful for predicting dose which will be mobile with reference to anatomy, as in head and neck cancer patients. It is likely that these methods will also soon become common in volumetric dose prediction for head and neck IMRT (intensity modulated radiation therapy).15 Fuzzy logic Fuzzy logic is the science of reasoning, thinking and inference that recognises and uses the real world phenomenon – that everything is a matter of degree. Instead of assuming everything is black and white (conventional logic), fuzzy logic recognises that in reality most things would fall somewhere in between, that is varying shades of grey.5 Evolutionary computation Evolutionary computation may be a general-purpose stochastic global optimization approach under the universally accepted neo-Darwinian paradigm, which may be a combination of the classical Darwinian evolutionary theory, the selectionism of Weismann, and the genetics of Mendel. Among all the evolutionary algorithms, Genetic algorithm (GA) is the most widely used. It was first introduced by Holland (1975). A simple GA consists of a population generator and selector, a fitness estimator, and three genetic operators, namely, selection, mutation, and crossover. It has been receiving increased attention due to a series of successful applications in different disciplines like biology, medicine and different branches of engineering.16 It has better application in medical field where they work by creating many random solutions to the matter at hand. Hybrid intelligent systems This synergetic system allows to accommodate common sense, extract knowledge from raw data, use human like reasoning mechanisms, deal with uncertainty and imprecision, and learn to adapt to a rapidly changing and unknown environment. The advantages of those technologies are often combined together to supply hybrid intelligent systems which may add a complementary manner. Many different hybrid systems available and therefore the popular ones are ANNs for designing fuzzy systems, fuzzy systems for designing ANNs, and Genetic Algorithms for automatically training and generating neural network architectures. Applications in dentistry 1. In dental education: With the recent incorporation of AI in intelligent tutoring systems like within the Unified Medical system (UMLS); there's an enormous improvement within the quality of feedback that the preclinical virtual patient provides the scholars . 2. ANN has sufficient precision for the planning and chairside manufacturing of dental prostheses, supported digital image acquisition following tooth cusps assessment. It can have an excellent potential in investigating the properties of dental materials like chemical stability, wear resistance, and flexural strength. 3. AI in Patient Management: It can assist in coordinating regular appointments and alerts the patients and dentists about checkups whenever any genetic or lifestyle information indicates increased susceptibility to dental diseases (eg: periodontal screening for patients with diabetes and carcinoma scree","",""
7,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","SAI: a Sensible Artificial Intelligence that plays with handicap and targets high scores in 9x9 Go (extended version)",2019,"","","","",82,"2022-07-13 09:21:51","","","","",,,,,7,2.33,1,6,3,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9x9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap, and to minimize suboptimal moves. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
6,"Herut Uzan, Shira Sardi, A. Goldental, R. Vardi, I. Kanter","Biological learning curves outperform existing ones in artificial intelligence algorithms",2019,"","","","",83,"2022-07-13 09:21:51","","10.1038/s41598-019-48016-4","","",,,,,6,2.00,1,5,3,"","",""
2,"M. Shahid, G. Abbas, Mohammad Rashid Hussain, M. Asad, U. Farooq, J. Gu, V. Balas, M. Uzair, A. Awan, T. Yazdan","Artificial Intelligence-Based Controller for DC-DC Flyback Converter",2019,"","","","",84,"2022-07-13 09:21:51","","10.3390/app9235108","","",,,,,2,0.67,0,10,3,"This paper presents an intelligent voltage controller designed on the basis of an adaptive neuro-fuzzy inference system (ANFIS) for a flyback converter (FC) working in continuous conduction mode (CCM). The union of fuzzy logic (FL) and adaptive neural networks (ANN) makes ANFIS more robust against model parameters’ uncertainties and perturbations in input voltage or load current. ANFIS inherits the advantages of structured knowledge representation from FL and learning capability from NN. Comparative analysis showed that the ANFIS controller offers not only the superior transient response characteristics, but also excellent steady-state characteristics compared to those of the FL controller (FLC) and proportional–integral–derivative (PID) controllers, thus validating its superiority over these traditional controllers. For this purpose, MATLAB/Simulink environment-based simulation results are presented for validation of the proposed converter compensated system under all operating conditions.","",""
4,"P. Ballester, J. Carmona","Artificial intelligence for the next generation of precision oncology",2021,"","","","",85,"2022-07-13 09:21:51","","10.1038/s41698-021-00216-w","","",,,,,4,4.00,2,2,1,"","",""
1,"L. Bori, M. Valera, D. Gilboa, R. Maor, I. Kottel, J. Remohi, D. Seidman, M. Meseguer","O-084 Computer vision can distinguish between euploid and aneuploid embryos. A novel artificial intelligence (AI) approach to measure cell division activity associated with chromosomal status",2021,"","","","",86,"2022-07-13 09:21:51","","10.1093/humrep/deab125.014","","",,,,,1,1.00,0,8,1,"      Can we distinguish between top-grade euploid and aneuploid embryos by AI measurement of cell edges in time-lapse videos?        Aneuploid embryos can be distinguished from euploid embryos by AI determination of a longer time to blastulation and higher cell activity.        Continuous monitoring of the embryo development has brought out morphokinetic parameters that are used to predict pre-implantation genetic testing (PGT) results. Previous publications showed that euploid embryos reach blastulation earlier than non-euploid embryos. However, time-lapse data are currently under-utilized in making predictions about embryo chromosomal content. AI and computer vision could take advantage of the massive amount of data embedded in the images of embryo development. This is the first attempt to distinguish between euploid and aneuploid embryos by computer vision in an objective and indirect way based on the measurement of cell edges as a proxy for cell activity.        We performed a retrospective analysis of 1,314 time-lapse videos from embryos cultured to the blastocyst stage with PGT results. This single-center study involved two phases; a comparison of the start time of blastulation between euploid (n = 544) and aneuploid embryos (n = 797). In phase two, we designed a novel methodology to examine whether precise measurement of cell edges over time could reflect cell activity differences in blastulation.        We assumed that the delay in blastulation is reflected by higher cell activity that could be determined accurately for the first time using computer vision and machine learning to measure the length of the edges (from t2 to t8). We compared computer vision based measurements of cell edges, reflecting cell number and size, in videos of 231 top-grade euploid (n = 111) and aneuploid (n = 120) embryos.        The mean and standard deviation of blastulation start time was 100.1±6.8 h for euploid embryos and 101.8±8.2 h for aneuploid embryos (p < 0.001). Regarding the measurement of cell activity, a computer vision algorithm identified the edges and provided a certainty score for each edge, higher when the algorithm is more certain that this is a cell edge (as opposed to noise in the images). A threshold was set to distinguish cell edges from noise using this score. The following results for top-grade embryos are shown as the sum of the edge lengths (µm) average of 160 pictures per embryo (frames between t2 and t8). The total length of the cell edges increased from two cells (420±85 µm) to eight cells (861±237 µm), in line with the mitosis events. Both the average total edge measured (450±162 µm for euploid embryos and 489±215 µm for aneuploid embryos, p < 0.01) and the average total of the difference between consecutive frames (135±47 µm for euploid embryos and 153±64 µm for aneuploid embryos, p < 0.01) were higher for aneuploid embryos than for euploid embryos. A regression model to differentiate between the two classes achieved 73% sensitivity and 73% specificity on this dataset.        The main limitation of this study is the difficulty to correlate our findings to other measure of cell activity. A more robust AI function (using not only cell edges lengths) would be required for future analysis to measure the cell activity in cell division up to the blastocyst stage.        Our results show for the first time that an AI based system can precisely measure microscopic cell edges in the dividing embryo. Using this novel method, we could distinguish between euploid and aneuploid embryos. This non-invasive method could further enhance our knowledge of the developing embryo.        Not Applicable ","",""
11,"K. Mudgal, Neelanjan Das","The ethical adoption of artificial intelligence in radiology",2019,"","","","",87,"2022-07-13 09:21:51","","10.1259/bjro.20190020","","",,,,,11,3.67,6,2,3,"Artificial intelligence (AI) is rapidly transforming healthcare—with radiology at the pioneering forefront. To be trustfully adopted, AI needs to be lawful, ethical and robust. This article covers the different aspects of a safe and sustainable deployment of AI in radiology during: training, integration and regulation. For training, data must be appropriately valued, and deals with AI companies must be centralized. Companies must clearly define anonymization and consent, and patients must be well-informed about their data usage. Data fed into algorithms must be made AI-ready by refining, purification, digitization and centralization. Finally, data must represent various demographics. AI needs to be safely integrated with radiologists-in-the-loop: guiding forming concepts of AI solutions and supervising training and feedback. To be well-regulated, AI systems must be approved by a health authority and agreements must be made upon liability for errors, roles of supervised and unsupervised AI and fair workforce distribution (between AI and radiologists), with a renewal of policy at regular intervals. Any errors made must have a root-cause analysis, with outcomes fedback to companies to close the loop—thus enabling a dynamic best prediction system. In the distant future, AI may act autonomously with little human supervision. Ethical training and integration can ensure a ""transparent"" technology that will allow insight: helping us reflect on our current understanding of imaging interpretation and fill knowledge gaps, eventually moulding radiological practice. This article proposes recommendations for ethical practise that can guide a nationalized framework to build a sustainable and transparent system.","",""
0,"Dan Jin, Son Le, M. Sebastian, Dongjiang Chen, Linchun Jin, D. Tran","IMMU-46. ARTIFICIAL INTELLIGENCE-DIRECTED, GENE THERAPY-BASED TRANSDIFFERENTIATION OF GLIOBLASTOMA TO FUNCTIONAL DENDRITIC CELLS AS NOVEL CANCER IMMUNOTHERAPY",2021,"","","","",88,"2022-07-13 09:21:51","","10.1093/neuonc/noab196.405","","",,,,,0,0.00,0,6,1,"      Despite recent advances in tumor immunotherapy in solid tumors, success in GBM remains elusive, likely due to its poor immunogenicity and CNS barriers limiting immune cell trafficking. Here we describe a novel approach of stimulating glioma-specific immunity by transdifferentiating GBM cells in situ to induced dendritic cells (iDCs).        We applied NETZEN, an integrated deep-learning and gene network-based ranking computational platform and identified cell fate determinants (CFDs) to convert GBM cells to DCs. CFDs were delivered using a viral vector. Transdifferentiation was assessed by immunophenotyping and iDCs functionally validated by their ability to prime naive T cells.        A four CFDs subnetwork anchored by PU.1 was sufficient to transdifferentiate mouse GBM cells to CD45+MHCII+ cells with high co-stimulatory CD80 expression and to induce nearly 98% of GBM cells to express 100-fold higher levels of MHCI. Consistent with a new identity of antigen-presenting cells (APC), the induced immune cells are growth arrested, exhibit 3-fold higher phagocytic activity and upregulate the canonical antigen processing and presenting machineries by 10-40 folds, resulting in 40-fold greater efficiency at processing ovalbumin and presenting SIINFEKL on MHCI compared to native GBM cells. Importantly, SIINFEKL-loaded iAPCs are capable of activating naive OTII-CD4+ and OTI-CD8+ T cells, indicating that they are DC-like. In addition, iDCs efficiently present tumor cell-intrinsic antigens and elicit >20-fold higher activation and cytotoxicity in tumor-specific T cells compared to native GBM cells. Lastly, intratumoral GBM-DC transdifferentiation in a syngeneic orthotopic GBM model produces a robust memory T cell response in deep cervical draining lymph nodes compared to control animals.        Our results comfirm that GBM-derived iDCs acquire functions similar to native DCs, and thus, lay the foundation for a novel therapeutic approach in which poorly immunogenic tumors like GBM may be forced to generate their own immunity from within through cell fate transdifferentiation. ","",""
0,"F. Morandin, G. Amato, M. Fantozzi, R. Gini, C. Metta, M. Parton","Sensible Artificial Intelligence that plays with handicap and targets high scores in 9 × 9",2019,"","","","",89,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,6,3,"We develop a new model that can be applied to any perfect information two-player zero-sum game to target a high score, and thus a perfect play. We integrate this model into the Monte Carlo tree search-policy iteration learning pipeline introduced by Google DeepMind with AlphaGo. Training this model on 9×9 Go produces a superhuman Go player, thus proving that it is stable and robust. We show that this model can be used to effectively play with both positional and score handicap. We develop a family of agents that can target high scores against any opponent, and recover from very severe disadvantage against weak opponents. To the best of our knowledge, these are the first effective achievements in this direction.","",""
7,"Ashley Kras, L. Celi, John B. Miller","Accelerating ophthalmic artificial intelligence research: the role of an open access data repository.",2020,"","","","",90,"2022-07-13 09:21:51","","10.1097/ICU.0000000000000678","","",,,,,7,3.50,2,3,2,"PURPOSE OF REVIEW Artificial intelligence has already provided multiple clinically relevant applications in ophthalmology. Yet, the explosion of nonstandardized reporting of high-performing algorithms are rendered useless without robust and streamlined implementation guidelines. The development of protocols and checklists will accelerate the translation of research publications to impact on patient care.   RECENT FINDINGS Beyond technological scepticism, we lack uniformity in analysing algorithmic performance generalizability, and benchmarking impacts across clinical settings. No regulatory guardrails have been set to minimize bias or optimize interpretability; no consensus clinical acceptability thresholds or systematized postdeployment monitoring has been set. Moreover, stakeholders with misaligned incentives deepen the landscape complexity especially when it comes to the requisite data integration and harmonization to advance the field. Therefore, despite increasing algorithmic accuracy and commoditization, the infamous 'implementation gap' persists. Open clinical data repositories have been shown to rapidly accelerate research, minimize redundancies and disseminate the expertise and knowledge required to overcome existing barriers. Drawing upon the longstanding success of existing governance frameworks and robust data use and sharing agreements, the ophthalmic community has tremendous opportunity in ushering artificial intelligence into medicine. By collaboratively building a powerful resource of open, anonymized multimodal ophthalmic data, the next generation of clinicians can advance data-driven eye care in unprecedented ways.   SUMMARY This piece demonstrates that with readily accessible data, immense progress can be achieved clinically and methodologically to realize artificial intelligence's impact on clinical care. Exponentially progressive network effects can be seen by consolidating, curating and distributing data amongst both clinicians and data scientists.","",""
1,"Latifa Mrisho, N. Mbilinyi, Mathias Ndalahwa, Amanda Ramcharan, Annalyse Kehs, Peter McCloskey, H. Murithi, David P. Hughes, J. Legg","Evaluating the accuracy of a smartphone-based artificial intelligence system, PlantVillage Nuru, in diagnosing of the viral diseases of cassava",2020,"","","","",91,"2022-07-13 09:21:51","","10.1101/2020.01.26.919449","","",,,,,1,0.50,0,9,2,"Premise of the study Nuru is an artificial intelligence system for diagnosis of plant diseases and pests developed as a public good by PlantVillage (Penn State University), FAO, IITA and CIMMYT. It provides a simple, inexpensive and robust means of conducting in-field diagnosis without requiring internet connection and provides real-time results and advice. The present work evaluates the effectiveness of Nuru as an in-field diagnostic tool by comparing the diagnosis capability of Nuru to that of cassava experts (researchers trained on cassava pests and diseases), agricultural extension agents and farmers. Methods The diagnosis capability of Nuru and that of the assessed individuals was determined by inspecting cassava plants in-field and by using the cassava symptom recognition assessment tool (CaSRAT) to score images of cassava leaves. Results Nuru’s accuracy for symptom recognition when using six leaves (74 - 88%, depending on the condition) was similar to that of experts, 1.5-times higher than agricultural extension agents and two-times higher than farmers. Discussion These findings suggests that Nuru can be an effective tool for in-field diagnosis of cassava diseases and has a potential of being a quick and cost-effective means of disseminating knowledge from researchers to agricultural extension agents and farmers.","",""
0,"A. Paic","Policies for Artificial Intelligence in Science and Innovation",2020,"","","","",92,"2022-07-13 09:21:51","","10.22323/1.372.0045","","",,,,,0,0.00,0,1,2,"This contribution synthesizes the discussions of the special session on policies for Artificial Intelligence in Science and Innovation, organized by the OECD’s Directorate for Science, Technology and Innovation. The session was opened by Dr Judith Arrieta, Minister of the Foreign Service at the Chief of Staff’s Office of the Secretary of Foreign Affairs of Mexico, and the two panels included speakers from governments, industry and civil society from European countries, USA,Canada China and Australia. Participants discussed the disruptive nature of AI and the formidable challenges it poses. Most of the discussion focused under the umbrella title of ethics, but they span very different issues of human-centered values, fairness, transparency, explainability, and many more. Other challenges include employment, education, SME policy, enabling environment, access to data and computing technology. Responses by governments were also discussed with a particular focus on national strategies, whose main pillars are oriented toward knowledge creation through AI research, knowledge diffusion through linkages to the private sector, development of human capital which will underpin the development of the sector, and a strong values, ethical and regulatory framework to create the conditions for the development of trustworthy AI.  In a world of finite resources, discussants concluded that one cannot apply very stringent requirements to all AI decisions, and there is clearly a need to require more transparency, explainability and robustness from systems which have the greatest impact on human lives. Therefore an approach based on algorithmic impact assessment seems reasonable. Such an approach needs to be further developed and standardized.","",""
0,"R. Brachman, David Gunning, Murray Burke","Integrated Artificial Intelligence Systems",2020,"","","","",93,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,3,2,"Copyright © 2020, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 66 AI MAGAZINE When one thinks about what it might take to build an intelligent system, it is evident that multiple capabilities will be required. Intelligence is generally considered to be reflected in the ability of a system to learn and understand the world around it, and to deal successfully with new or challenging situations. A closer look at what it might take to accomplish this reveals a surprisingly complex set of abilities that must work together. There are many variations on these themes, but roughly speaking, a robustly intelligent, autonomous agent embedded in the real world will need perceptual capabilities to sense and help interpret external signals and phenomena; a set of beliefs about the world, including itself and other agents, cause and effect, and a host of other things relevant to its survival and success in achieving its goals; a variety of reasoning capabilities to determine implications of its beliefs, understand its environment, plan ahead, solve problems, and so forth; a wide array of learning and adaptation capabilities; the ability to affect the world through action; and, some kind of rich communication mechanism along the lines of natural human language generation and understanding.  From Shakey the Robot to self-driving cars, from the personal computer to personal assistants on our phones, the Defense Advanced Research Projects Agency (DARPA) has led the development of integrated artificial intelligence (AI) systems for more than half a century. From the earliest days of AI, it was apparent that a robust, generally intelligent system should include a complete set of capabilities: perception, memory, reasoning, learning, planning, and action; and when DARPA initiated AI research in the 1960s, ambitious projects such as Shakey the Robot went after the complete package. As DARPA realized the challenges, they backed away from the ultimate goal of integrated AI and tried to make progress on the individual problems of image understanding, speech and language understanding, knowledge representation and reasoning, planning and decision aids, machine learning, and robotic manipulation. Yet, even as researchers struggled to make progress in these subdisciplines, DARPA periodically resurrected the challenge of integrated intelligent systems and pushed the community to try again. In the 1980s, DARPA’s Strategic Computing Initiative took on challenges of integrated AI projects such as the Autonomous Land Vehicle and the Pilot’s Associate. These did not succeed, but instead set the stage for the several decades of more siloed research that followed, until it was time to try again. In the 2000s, DARPA took on the integrated AI problem again with its Grand Challenges, which led to the first self-driving cars, and projects such as the Personalized Assistant that Learns, which produced Apple’s Siri. These efforts created complex, richlyintegrated systems that represented quantum leaps ahead in machine intelligence. The integration of sophisticated capabilities in a fundamental way is the key to general intelligence. This is the story of DARPA’s persistent long-term support for this essential premise of AI. Integrated Artificial Intelligence Systems","",""
0,"Shivali Agarwal, Jayachandu Bandlamudi, Atri Mandal, Anupama Ray, G. Sridhara","Automated Assignment of Helpdesk Email Tickets: An Artificial Intelligence Life-Cycle Case Study",2020,"","","","",94,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,5,2,"Copyright © 2020, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 Fall 2020 45 The landscape of modern information technology service delivery is changing, with increased focus on automation and optimization. Most information technology vendors today have service platforms aimed toward end-to-end automation for carrying out mundane, repetitive labor-intensive tasks and even for tasks requiring human cognizance. One such task is ticket assignment and dispatch, where the service requests submitted by the end-users to the vendor in the form of tickets are reviewed by a centralized dispatch team and assigned to the appropriate service team and resolver group. The dispatch of a ticket to the correct group of practitioners is a critical step in the speedy resolution of a ticket. Incorrect dispatch decisions can significantly increase the total turnaround time for ticket resolution, as observed in a study of an actual production system (agarwal, Sindhgatta, and Sengupta 2012). When such delays occur, it causes customer dissatisfaction as well as monetary penalties for the vendor due to service-level-agreement breaches. Several factors make the dispatcher’s job challenging, namely the need for in-depth knowledge of the roles and responsibilities of various groups, the heterogeneous and informal nature of email text, and the high attrition rate in service delivery teams (Mandal et al. 2018). Given the fact that inefficiencies in dispatch have serious business consequences, there has been a lot of interest in automating the assignment process. a number of different approaches have been proposed for automating ticket dispatch (agarwal, Sindhgatta, and Sengupta 2012; Shao et al. 2008a, 2008b; Parvin, Bose, and Van Oyen 2009).  In this article, we present an endto-end automated helpdesk email ticket assignment system driven by high accuracy, coverage, business continuity, scalability, and optimal usage of computational resources. The primary objective of the system is to determine the problem mentioned in an incoming email ticket and then automatically dispatch it to an appropriate resolver group with high accuracy. While meeting this objective, it should also meet the objective of being able to operate at desired accuracy levels in the face of changing business needs by automatically adapting to the changes. The proposed system uses a system of classifiers with separate strategies for handling frequent and sparse resolver groups augmented with a semiautomatic rule engine and retraining strategies to ensure that it is accurate, robust, and adaptive to changing business needs. Our system has been deployed in the production of six major service providers in diverse service domains and currently assigns 100,000 emails per month, on an average, with an accuracy close to ninety percent and covering at least ninety percent of email tickets. This translates to achieving human-level accuracy and results in a net savings of more than 50,000 man-hours of effort per annum. To date, our deployed system has already served more than two million tickets in production. Automated Assignment of Helpdesk Email Tickets: An Artificial Intelligence Life-Cycle Case Study","",""
0,"S. Bandyopadhyay, R. Mukherjee, S. Sarkar","A Report on the First Workshop on Software Engineering for Artificial Intelligence (SE4AI 2020)",2020,"","","","",95,"2022-07-13 09:21:51","","10.1145/3385032.3385055","","",,,,,0,0.00,0,3,2,"With advancement in technology-driven decision making, the software-intensive systems for decisions have become more robust, dynamic, adaptive, context-aware, dependable. Architectural designs of such systems crave for new approaches where the data-driven decision making has to be incorporated in the solution. Methods for recommendation mechanism, prediction of operation failures, dealing with unsafe conditions etc are going to be part of the solution itself. Integrating such features to conceive an intelligent system that will directly influence the business solution is mostly appreciated. This would not have been possible without the direct interference of Artificial Intelligence which has been a standard procedure of industrial repertoire since 1980s. The direct impact of AI on social and economic life has been been felt mostly in last decade (since 2007) with the advent of smart phone, which contribute largely to ""big data"". The era of ""big data"" has witnessed the efficacy of Machine Learning and there is a need of the hour to combine data-driven machine intelligence with human intelligence (insights and domain knowledge) to effectively make the software development (requirement, design, testing, deployment and operation management) intelligent. The research community has shown a keen interest in this emerging field. In this report, we present a pre-organization summary of the workshop to be held on February 27, 2020, at IIIT Jabbalpur (India), co-located with the 13th Innovations in Software Engineering Conference (ISEC 2020).","",""
0,"S. Cuddy","THE BENEFITS AND DANGERS OF USING ARTIFICIAL INTELLIGENCE IN PETROPHYSICS",2020,"","","","",96,"2022-07-13 09:21:51","","10.30632/spwla-5066","","",,,,,0,0.00,0,1,2,"Abstract Artificial Intelligence, or AI, is a method of data analysis that learns from data, identify patterns and makes predictions with the minimal human intervention. AI is bringing many benefits to petrophysical evaluation. Using case studies, this paper describes several successful applications. The future of AI has even more potential. However, if used carelessly there are potentially grave consequences. A complex Middle East Carbonate field needed a bespoke shaly water saturation equation. AI was used to ‘evolve’ an ideal equation, together with field specific saturation and cementation exponents. One UKCS gas field had an ‘oil problem’. Here, AI was used to unlock the hidden fluid information in the NMR T1 and T2 spectra and successfully differentiate oil and gas zones in real time. A North Sea field with 30 wells had shear velocity data (Vs) in only 4 wells. Vs was required for reservoir modelling and well bore stability prediction. AI was used to predict Vs in all 30 wells. Incorporating high vertical resolution data, the Vs predictions were even better than the recorded logs. As it is not economic to take core data on every well, AI is used to discover the relationships between logs, core, litho-facies and permeability in multi-dimensional data space. As a consequence, all wells in a field were populated with these data to build a robust reservoir model. In addition, the AI predicted data upscaled correctly unlike many conventional techniques. AI gives impressive results when automatically log quality controlling (LQC) and repairing electrical logs for bad hole and sections of missing data. AI doesn’t require prior knowledge of the petrophysical response equations and is self-calibrating. There are no parameters to pick or cross-plots to make. There is very little user intervention and AI avoids the problem of ‘garbage in, garbage out’ (GIGO), by ignoring noise and outliers. AI programs work with an unlimited number of electrical logs, core and gas chromatography data; and don’t ‘fall-over’ if some of those inputs are missing. AI programs currently being developed include ones where their machine code evolves using similar rules used by life’s DNA code. These AI programs pose considerable dangers far beyond the oil industry as described in this paper. A ‘risk assessment’ is essential on all AI programs so that all hazards and risk factors, that could cause harm, are identified and mitigated.","",""
10,"M. Alomar, M. Hameed, N. Al‐Ansari, M. Alsaadi","Data-Driven Model for the Prediction of Total Dissolved Gas: Robust Artificial Intelligence Approach",2020,"","","","",97,"2022-07-13 09:21:51","","10.1155/2020/6618842","","",,,,,10,5.00,3,4,2,"Saturated total dissolved gas (TDG) is recently considered as a serious issue in the environmental engineering field since it stands behind the reasons for increasing the mortality rates of fish and aquatic organisms. The accurate and more reliable prediction of TDG has a very significant role in preserving the diversity of aquatic organisms and reducing the phenomenon of fish deaths. Herein, two machine learning approaches called support vector regression (SVR) and extreme learning machine (ELM) have been applied to predict the saturated TDG% at USGS 14150000 and USGS 14181500 stations which are located in the USA. For the USGS 14150000 station, the recorded samples from 13 October 2016 to 14 March 2019 (75%) were used for training set, and the rest from 15 March 2019 to 13 October 2019 (25%) were used for testing requirements. Similarly, for USGS 14181500 station, the hourly data samples which covered the period from 9 June 2017 till 11 March 2019 were used for calibrating the models and from 12 March 2019 until 9 October 2019 were used for testing the predictive models. Eight input combinations based on different parameters have been established as well as nine statistical performance measures have been used for evaluating the accuracy of adopted models, for instance, not limited, correlation of determination (        R      2        ), mean absolute relative error (MAE), and uncertainty at 95% (        U      95        ). The obtained results of the study for both stations revealed that the ELM managed efficiently to estimate the TDG in comparison to SVR technique. For USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.986 (0.986), MAE of 0.316 (0.441), and         U      95        of 3.592 (3.869). Lastly, for USGS 14181500 station, the statistical measures for ELM (SVR) were, respectively, reported as         R      2        of 0.991 (0.991), MAE of 0.338 (0.396), and         U      95        of 0.832 (0.837). In addition, ELM’s training process computational time is stated to be much shorter than that of SVM. The results also showed that the temperature parameter was the most significant variable that influenced TDG relative to the other parameters. Overall, the proposed model (ELM) proved to be an appropriate and efficient computer-assisted technology for saturated TDG modeling that will contribute to the basic knowledge of environmental considerations.","",""
47,"Chengjie Zheng, T. V. Johnson, Aakriti Garg, Michael V. Boland","Artificial intelligence in glaucoma",2019,"","","","",98,"2022-07-13 09:21:51","","10.1097/ICU.0000000000000552","","",,,,,47,15.67,12,4,3,"Purpose of review The use of computers has become increasingly relevant to medical decision-making, and artificial intelligence methods have recently demonstrated significant advances in medicine. We therefore provide an overview of current artificial intelligence methods and their applications, to help the practicing ophthalmologist understand their potential impact on glaucoma care. Recent findings Techniques used in artificial intelligence can successfully analyze and categorize data from visual fields, optic nerve structure [e.g., optical coherence tomography (OCT) and fundus photography], ocular biomechanical properties, and a combination thereof to identify disease severity, determine disease progression, and/or recommend referral for specialized care. Algorithms have become increasingly complex in recent years, utilizing both supervised and unsupervised methods of artificial intelligence. Impressive performance of these algorithms on previously unseen data has been reported, often outperforming standard global indices and expert observers. However, there remains no clearly defined gold standard for determining the presence and severity of glaucoma, which undermines the training of these algorithms. To improve upon existing methodologies, future work must employ more robust definitions of disease, optimize data inputs for artificial intelligence analysis, and improve methods of extracting knowledge from learned results. Summary Artificial intelligence has the potential to revolutionize the screening, diagnosis, and classification of glaucoma, both through the automated processing of large data sets, and by earlier detection of new disease patterns. In addition, artificial intelligence holds promise for fundamentally changing research aimed at understanding the development, progression, and treatment of glaucoma, by identifying novel risk factors and by evaluating the importance of existing ones.","",""
10,"Porayska-PomstaKaśka, MavrikisManolis, D'melloSidney, ConatiCristina, BakerRyan S. J. d.","Knowledge Elicitation Methods for Affect Modelling in Education",2013,"","","","",99,"2022-07-13 09:21:51","","","","",,,,,10,1.11,2,5,9,"Research on the relationship between affect and cognition in Artificial Intelligence in Education AIEd brings an important dimension to our understanding of how learning occurs and how it can be fa...","",""
19,"P. Svenmarck, L. Luotsinen, Mattias Nilsson, J. Schubert","Possibilities and Challenges for Artificial Intelligence in Military Applications",2018,"","","","",100,"2022-07-13 09:21:51","","","","",,,,,19,4.75,5,4,4,"Recent developments in artificial intelligence (AI) have resulted in a breakthrough for many classical AIapplications, such as computer vision, natural language processing, robotics, and data mining. Therefore, there are many efforts to exploit these developments for military applications, such as surveillance, reconnaissance, threat evaluation, underwater mine warfare, cyber security, intelligence analysis, command and control, and education and training. However, despite the possibilities for AI in military applications, there are many challenges to consider. For instance, 1) high risks means that military AI-systems need to be transparent to gain decision maker trust and to facilitate risk analysis; this is a challenge since many AItechniques are black boxes that lack sufficient transparency, 2) military AI-systems need to be robust and reliable; this is a challenge since it has been shown that AI-techniques may be vulnerable to imperceptible manipulations of input data even without any knowledge about the AI-technique that is used, and 3) many AItechniques are based on machine learning that requires large amounts of training data; this is challenge since there is often a lack of sufficient data in military applications. This paper present results from ongoing projects to identity possibilities for AI in military applications, as well as how to address these challenges.","",""
0,"F. Renna, Miguel L. Martins, Alexandre Neto, António Cunha, D. Libânio, M. Dinis-Ribeiro, M. Coimbra","Artificial Intelligence for Upper Gastrointestinal Endoscopy: A Roadmap from Technology Development to Clinical Practice",2022,"","","","",101,"2022-07-13 09:21:51","","10.3390/diagnostics12051278","","",,,,,0,0.00,0,7,1,"Stomach cancer is the third deadliest type of cancer in the world (0.86 million deaths in 2017). In 2035, a 20% increase will be observed both in incidence and mortality due to demographic effects if no interventions are foreseen. Upper GI endoscopy (UGIE) plays a paramount role in early diagnosis and, therefore, improved survival rates. On the other hand, human and technical factors can contribute to misdiagnosis while performing UGIE. In this scenario, artificial intelligence (AI) has recently shown its potential in compensating for the pitfalls of UGIE, by leveraging deep learning architectures able to efficiently recognize endoscopic patterns from UGIE video data. This work presents a review of the current state-of-the-art algorithms in the application of AI to gastroscopy. It focuses specifically on the threefold tasks of assuring exam completeness (i.e., detecting the presence of blind spots) and assisting in the detection and characterization of clinical findings, both gastric precancerous conditions and neoplastic lesion changes. Early and promising results have already been obtained using well-known deep learning architectures for computer vision, but many algorithmic challenges remain in achieving the vision of AI-assisted UGIE. Future challenges in the roadmap for the effective integration of AI tools within the UGIE clinical practice are discussed, namely the adoption of more robust deep learning architectures and methods able to embed domain knowledge into image/video classifiers as well as the availability of large, annotated datasets.","",""
30,"S. Elkatatny, Zeeshan Tariq, M. Mahmoud, I. Mohamed, A. Abdulraheem","Development of New Mathematical Model for Compressional and Shear Sonic Times from Wireline Log Data Using Artificial Intelligence Neural Networks (White Box)",2018,"","","","",102,"2022-07-13 09:21:51","","10.1007/S13369-018-3094-5","","",,,,,30,7.50,6,5,4,"","",""
0,"","ACTIVITY REPORT Project-Team Models and Algorithms for Artiﬁcial Intelligence",2022,"","","","",103,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,0,1,"The expectation-maximization (EM) algorithm is a powerful computational technique for maximum likelihood estimation in incomplete data models. When the expectation step cannot be performed in closed form, a stochastic approximation of EM (SAEM) can be used. The convergence of the SAEM toward critical points of the observed likelihood has been proved and its numerical efﬁciency has been demonstrated. However, sampling from the posterior distribution may be intractable or have a high computational cost. Moreover, despite appealing features, the limit position of this algorithm can strongly depend on its starting one. To cope with this two issues, we propose in [11] new stochastic approximation version of the EM in which we do not sample from the exact distribution in the expectation phase of the procedure. We ﬁrst prove the convergence of this algorithm toward critical points of the observed likelihood. Then, we propose an instantiation of this general procedure to favor convergence toward global maxima. Experiments on synthetic and real data highlight the performance of this algorithm in comparison to the SAEM and the EM when feasible. of subject-speciﬁc weights characterizing partial membership across clusters. With this ﬂexibility come challenges in uniquely identifying, estimating, and interpreting the parameters. In [40], we propose a new class of Dimension-Grouped MMMs (Gro-M 3 s) for multivariate categorical data, which improve parsimony and interpretability. In Gro-M 3 s, observed variables are partitioned into groups such that the latent membership is constant for variables within a group but can differ across groups. Traditional latent class models are obtained when all variables are in one group, while traditional MMMs are obtained when each variable is in its own group. The new model corresponds to a novel decomposition of probability tensors. Theoretically, we derive transparent identiﬁability conditions for both the unknown grouping structure and model parameters in general settings. Methodologically, we propose a Bayesian approach for Dirichlet Gro-M3 s to inferring the variable grouping structure and estimating model parameters. Simulation results demonstrate good computational performance and empirically conﬁrm the identiﬁability results. We illustrate the new methodology through an application to a functional disability dataset. from this natural partition. In a Bayesian context, this is achieved by considering the Dirichlet cluster proportion prior parameter α as a regularisation term controlling the granularity of the clustering. This second step allows the exploration of the clustering at coarser scales and the ordering of the clusters an important output for the visual representations of the clustering results. The clustering results obtained with the proposed approach, on simulated as well as real settings, are compared with existing strategies and are shown to be particularly relevant. This work is implemented in the R package greed and Figure 2 illustrates the main idea of the method. In this applied work [19], we use the Fisher-EM algorithm for clustering for the unsupervised classiﬁcation of 702, 248 spectra of galaxies and quasars with resdshifts smaller than 0.25 that were retrieved from the Sloan Digital Sky Survey (SDSS) database, release 7. The spectra were ﬁrst corrected for the redshift, then wavelet-ﬁltered to reduce the noise, and ﬁnally binned to obtain about 1437 wavelengths per spectrum. Fisher-EM, an unsupervised clustering discriminative latent mixture model algorithm, was applied on these corrected spectra, considering the full set as well as several subsets of 100,000 and 300,000 spectra. The optimum number of classes given by a penalized likelihood criterion is 86 classes, the 37 most populated ones gathering 99% of the sample. These classes are established from a subset of 302144 spectra. Using several cross-validation techniques we ﬁnd that this classiﬁcation is in agreement with the results obtained on the other subsets with an average misclassiﬁcation error of about 15%. The large number of very small classes tends to increase this error rate. This is the ﬁrst time that an automatic, objective and robust unsupervised classiﬁcation is established on such a large amount of spectra of galaxies. The mean spectra of the classes can be used as templates for a large majority of galaxies in our Universe. Figure 7 illustrates the obtained results. Recurrent Neural Networks, Deep linguistic patterns the of a of of to the is this linguistic that becomes valuable for our descriptive approach through deep as it allows us to observe complex lexico-grammatical structures, that potentially associate several levels of text representation in the same structure. The convolutional model used until now must therefore be adapted to integrate this additional information in order to obtain an even ﬁner description of the textual salience of a corpus. the relevant features used by the CNN to perform the classiﬁcation task. We empirically demonstrate the efﬁciency of our approach on corpora from two different languages: English and French. On all datasets, wTDS automatically encodes complex linguistic objects based on co-occurrences and possibly on grammatical and syntax analysis. relationships between the concepts in the metadata by analyzing the contrast between the concepts similarities in the Joconde’s semantic model and other vocabularies and we tried to improve the model prediction scores based on the semantic relations. Our results show that cross-fertilization between symbolic AI and machine learning can indeed provide the tools to address the challenges of the museum curators work describing the artwork pieces and searching for the relevant images. that combines a geometric approach for decision rules with existing post hoc solutions for machine learning models to generate an intuitive feature ranking tailored to the end user. We show that established model-agnostic approaches produce poor results in this framework. Figure 13 illustrates this work. Algorithms involving Gaussian processes or determinantal point processes typically require computing the determinant of a kernel matrix. Frequently, the latter is computed from the Cholesky decomposition, an algorithm of cubic complexity in the size of the matrix. We show that, under mild assumptions, it is possible to estimate the determinant from only a sub-matrix, with probabilistic guarantee on the relative error. In [37], we present an augmentation of the Cholesky decomposition that stops under certain conditions before processing the whole matrix. Experiments demonstrate that this can save a considerable amount of time while having an overhead of less than 5% when not stopping early. More generally, we present a probabilistic stopping strategy for the approximation of a sum of known length where addends are revealed sequentially. We do not assume independence between addends, only that they are bounded from below and decrease in conditional expectation. of there is a signiﬁcant from combining and audio data in detecting active speakers. either of the modalities can potentially mislead audiovisual fusion by inducing unreliable or deceptive information. outlines active speaker detection as a multi-objective learning problem to leverage best of each modalities using a novel self-attention, uncertainty-based multimodal fusion scheme. Results obtained show that the proposed multi-objective learning architecture outperforms traditional approaches in improving both mAP and AUC scores. We further demonstrate that our fusion strategy surpasses, in active speaker detection, other modality fusion methods reported in various disciplines. We ﬁnally show that the proposed method signiﬁcantly improves the state-of-the-art on the AVA-ActiveSpeaker dataset. This paper explores the problem of summarizing professional soccer matches as automatically as possible using both the event-stream data collected from the ﬁeld and the content broadcasted on TV. We have designed an architecture, introducing ﬁrst (1) a Multiple Instance Learning method that takes into account the sequential dependency among events and then (2) a hierarchical multimodal attention layer that grasps the importance of each event in an action [31]. We evaluate our approach on matches from two professional European soccer leagues, showing its capability to identify the best actions for automatic summarization by comparing with real summaries made by human operators. Figure 18 illustrates the general schema of the approach. We a coherent framework for studying longitudinal manifold-valued data. We introduce a Bayesian mixed-effects model which allows estimating both a group-representative piecewise-geodesic creating clusters of similar sentences. The ideal practice is to obtain a cluster with only positive blocks and another with only negative ones. Comparing to the supervised approach (Bag of words + Logistic Regression Classiﬁer) with its f1-score as 0.8234 and f2-score as 0.8316, we found that both S-Bert [58] (with a f1-score of 0.6250 and f2-score of 0.6192) and BioBert [57] (f1-score as 0.7004 and f2 as 0.6955) can achieves relatively good results and latter even outperformed the former due to its domain speciﬁc knowledge. around 13 billion euros per year to European citizens [52]. In the ﬁeld of healthcare insurance, in France the compulsory scheme detected over 261.2 million euros of fraudulent services in 2018, mainly due to healthcare professionals and healthcare establishments [50]. In the United States, according to the FBI, medicare fraud costs insurance companies between 21 billion and 71 billion US dollars per year [55]. In a context where reducing management costs is a real issue for healthcare insurers, the ﬁght against fraud is a real expectation of the customers of professionals in the sector so that everyone receives a fair return for their contributions. This stud","",""
3,"Nevien Moawad, Kecheng Liu, Mohammed El-Helly","Knowledge elicitation and representation in a normative approach-a case study in diagnosis of plant diseases in Egypt",2012,"","","","",104,"2022-07-13 09:21:51","","10.1109/IS.2012.6335186","","",,,,,3,0.30,1,3,10,"Knowledge becomes a pivotal factor for intelligence to support decision making. Elicitation, representation and use of knowledge are major areas of research in the field of Artificial Intelligence, leading to development of knowledge bases and expert systems. Knowledge base system (KBS) development is complex, expensive, and time consuming process that needs to be applied in an organized manner. There are powerful tools for eliciting and representing KBSs. Using these tools becomes a very difficult task for users without specific knowledge in Artificial Intelligence. The aim of our research is to use a normative approach to elicit and represent the knowledge. To achieve this we build an elicitation and representation tool NormEST which allows the domain experts and the non-technical users are able to build their own KBSs. NormEST can be considering as a new approach in eliciting and representing the knowledge. NormEST is designed based on the concepts of Organisational Semiotics and evaluated by group of agriculture domain experts, the Delphi technique used as evaluation method to illustrate the top 10 ranked benefits of using NormEST. NormEST is demonstrated using a case study in fungal diseases in cucumber in Egypt. The results indicate that the NormEST is able to facilitate effective elicitation of parameters needed for an agriculture diagnostic experts system.","",""
1,"D. Handelman, Corban G. Rivera, R. St. Amant, Emma Holmes, Andrew R. Badger, Bryanna Y. Yeh","Adaptive human-robot teaming through integrated symbolic and subsymbolic artificial intelligence: preliminary results",2022,"","","","",105,"2022-07-13 09:21:51","","10.1117/12.2618686","","",,,,,1,1.00,0,6,1,"As the autonomy of intelligent systems continues to increase, the ability of humans to maintain control over machine behavior, work effectively in concert with them, and trust them, becomes paramount. Ideally, a machine’s plan of action would be accessible to and understandable by human team members, and machine behavior would be modifiable in real time, in the field, to accommodate unanticipated situations. The ability of machines to adapt to new situations quickly and reliably based on both human input and autonomous learning has the potential to enhance numerous human-machine teaming scenarios. Our research focuses on the question, “Can robots become competent and adaptive teammates by emulating human skill acquisition strategies?” In this paper we describe the Robotic Skill Acquisition (RSA) cognitive architecture and show preliminary results of teaming experiments involving a human wearing an augmented reality headset and a quadruped robot performing tasks related to reconnaissance. The goal is to combine instruction and discovery by integrating declarative symbolic AI and reflexive neural network learning to produce robust, explainable and trusted robot behavior, adjustable autonomy, and adaptive human-robot teaming. Humans and robots start with a playbook of modifiable hierarchical task descriptions that encode explicit task knowledge. Neural network based feedback error learning enables human-directed behavior shaping, and reinforcement learning enables discovery of novel subtask control strategies. It is anticipated that modifications to and transitions between symbolic and subsymbolic processing will enable highly adaptive behavior in support of enhanced situational awareness and operational effectiveness of human-robot teams.","",""
7,"G. Mazzini","A System of Governance for Artificial Intelligence through the Lens of Emerging Intersections between AI and EU Law",2019,"","","","",106,"2022-07-13 09:21:51","","","","",,,,,7,2.33,7,1,3,"The work provides an overview and a comment of the Communication on Artificial Intelligence (AI) adopted by the European Commission in April 2018. By offering a bird’s-eye view of those law and policy areas potentially relevant for or affected by AI, the AI Communication sets the stage for understanding how pervasively and extensively AI is likely to be mainstreamed in our economies and societies. Whether it is about safety of products, liability, consumer protection, personal data protection or the foundational values, principles and rights on which the European project is based on, AI is very rapidly cutting across domains. The work identifies and investigates some of the many intersections between AI and EU law. Two main “disrupting” trends emerge.    According to the first trend, AI seems to exercise some pressure on existing regulatory frameworks, such as in the areas of product safety, liability and consumer protection.    As regards product safety, the main concerns seem to revolve around the unpredictability risk of AI. While certain factual characteristics (possibly limitations) of AI as it functions today cannot and should not be denied, the policy debate on AI safety should focus on what potential risks brought about by AI (or rather by specific AI applications) can be considered as socially acceptable when weighed against potential benefits. Even though the challenges posed by AI may generate some pressure on the existing EU product safety frameworks, it seems that EU safety law as a broader normative field has at its disposal a varied set of regulatory tools and approaches that can be relevant sources of inspiration and reference for a discussion on the safety of AI-powered products.    In the field of product liability, although one should note that the Product Liability Directive (PLD) is not necessarily the only tool that can be invoked by victims in case of risks and damages linked to AI-powered products, there seem to be elements suggesting that AI (in general or with regard to certain of its product specific applications) may put under stress the continued suitability of the technology neutral design of the PLD - or at least some provisions thereof - to the extent that the PLD is expected to apply, in its current form, to both “smart” and “non-smart” products.    The protection of consumers in the context of profiling and targeting practices in the business-to-consumers transactions is an area where the General Data Protection Regulation (GDPR) is particularly relevant. To the extent GDPR rules effectively enhance the data subjects’ empowerment vis-a-vis traders and/or curtail the ability of traders to engage in manipulative and unfair practices, then there may be less need for a fine-tuning of dedicated consumer law instruments (such as the Unfair Commercial Practices Directive, the Consumer Rights Directive and the Directive on Unfair Terms in Consumer Contracts) in order to take account of the specificities of commercial transactions mediated by sophisticated algorithms. At the same time, consumer protection could be an interesting testing ground for the potential of AI to empower consumers and civil society in general: the very same tools, techniques and methods used by companies to pursue their commercial interests could also serve the purpose to re-balance the traditional asymmetry of information, power and knowledge impacting negatively on consumers.    Contrary to what happens in the legal domains mentioned above, a different “disrupting” trend emerges in the field of the protection of personal data. Here, the several intersections between AI and the GDPR can essentially be framed in terms of the law disrupting certain technological uses and applications of AI. Due to the fact that AI uses and applications in the context of commercial transactions, and, more generally, of the algorithm-mediated economic, social and political life of individuals extensively rely on and process personal data, the GDPR emerges as a key piece of legislation in the space. While the data protection authorities and the courts will certainly specify and fine-tune its principles and provisions as appropriate, the GDPR presents itself as a robust framework poised to capture and effectively curb at least those uses and applications of AI that appear most egregious and intolerable in light of the degree of legal protection for individual rights and freedoms that is currently expected by citizens in our European society.    The work argues that, even if each legal or policy area where AI surfaces is confronted with distinct normative questions that may not necessarily be relevant for other areas, a connecting tissue is needed. This should take the form of a system of AI governance or cabine de regie which should combine - on an ongoing basis - up-to-date scientific and technical knowledge, internal legal and policy expertise specific to each sector and the authority to impart policy direction and to arbitrate, across the board, between the societal opportunities and the societal concerns that underlie the composite interaction between AI and the law.","",""
1,"Massoud Sokouti, B. Sokouti","Applying the Science of Systematic Review and Meta-Analysis to Retrospective Artificial Intelligence Based Studies: The importance of performance evaluation",2019,"","","","",107,"2022-07-13 09:21:51","","","","",,,,,1,0.33,1,2,3,"The rationale behind the meta-analysis goes back to the 17th century studies of astronomy which then Karl Pearson performed a study based on meta-analysis using the data for typhoid inoculation in 1904. After, William Cochran applied this type of analysis to medical researches by taking the advantage of multiple previous studies. For more information and details on the history, the readers are referred to. To emerge the important role of systematic and metaanalysis studies even in the area of artificial intelligence systems, it is an anticipated that more reliable results can be driven from previous research studies alongside a simple review of such studies from which most of them may be ignored or not included as a matter of their nonsystematical type of reviews. The meta-analysis technique uses various types of statistics tools and methodologies to commonly derive a predictive diagnostic or non-diagnostic performance result of their compared corresponding approaches on the target defined disorders using information included in different datasets of previous studies. Although, a meta-analysis study can be regarded as a review of previous studies, however, it thoroughly targets not only the achieving results of those studies but also determine the in-common and non-commonpatterns of those researches as well as biases of the performance results whether they have been inserted intentionally or unintentionally. The importance of meta-analysis has been vastly discussed in medical sciences and therefore, been conducted rigorously through various studies, mostly on clinical trial ones. However, this technique is one of those less valued tools imported in to biomedical engineering studies and hence, their related algorithms mostly on the performance of artificial intelligence approaches. One of those studies to mention is the one performed on classification algorithms for pattern recognition by So Young Sohn in 1999 based on some in-house implemented statistics tools without considering the meta-analysis software. Moreover, in 2015,Horn et al have conducted a systematic review on functional brain imaging studies on assessing the familiarity of artificial neural networks and discussed their pros and cons in terms of their experimental conflicting results based on a meta-analysis on 68 publishedarticles. In another recent study, the role of real-time biomedical systems has been evaluated by a meta-analysis approach on 134 real-times papers in terms of computational complexity, delay and speed up considering various types of algorithms and hardware implementation. Recently, two types of systematic review and analysis have been performed which shows the potential non-mature trends of this approach in artificial intelligence based researches.In the first one the authors studied the performance of different machine learning algorithms for heart disease diagnosis; however, the metaanalysis part was not performed due to the existence of heterogeneity in the final included studies through the PRISMA (Preferred reporting items for systematic reviews and meta-analyses) checklist. And in the second one, the performance of several DNA based encryption algorithms based according to the results obtained from previous publications has been proposed where, it has been found out that there were no improvements in the proposed algorithms and it has been suggested that a dataset of images should be available in order to test and evaluate the performance of methodologies. However, the methodologies should also be available for public use. Moreover, the analyses section can be carried out through a simple statistical student’s t test analysisor the metaanalysis procedure using available tools such as MetaDisc, MIX, and Meta-Analyst. While comparing the two environments (i.e., clinical and computational), there are in-common units for decision making in diagnosing symptoms which are human (brain system and some data) and computer (artificial intelligence systems and some data). This outstanding feature and the abovementioned examples makes the meta-analysis studies applicable to the researches performed based on artificial intelligence systems, too. This will open a new view on interactions between the results obtained from previous studies while considering their special algorithms, different datasets, and possible biases. One more thing to emphasize for the future research studies is on publicizing the datasets and the implemented algorithms in terms of web servers, Java, C++ and Matlab libraries or R packages to make the results re-generable using new datasets which make them more comparable with new designed methodologies to ease the metaanalysis robust studies. As, it is also clear, most of the webservers and datasets in the medical parts coupled with data derived from bioscience knowledge are publicly.","",""
12,"S. Craw, A. Aamodt","Case Based Reasoning as a Model for Cognitive Artificial Intelligence",2018,"","","","",108,"2022-07-13 09:21:51","","10.1007/978-3-030-01081-2_5","","",,,,,12,3.00,6,2,4,"","",""
15,"Yun-he Pan","Special issue on artificial intelligence 2.0",2017,"","","","",109,"2022-07-13 09:21:51","","10.1631/FITEE.1710000","","",,,,,15,3.00,15,1,5,"With the ever-growing popularization of the Internet, universal existence of sensors, emergence of big data, development of e-commerce, rise of the information community, and interconnection and fusion of data and knowledge in human society, physical space, and cyberspace, the information environment surrounding artificial intelligence (AI) development has changed profoundly, leading to a new evolutionary stage: AI 2.0. The emergence of new technologies also promotes AI to a new stage (Pan, 2016). The next-generation AI, namely AI 2.0, is a more explainable, robust, open, and general AI with the following attractive merits: It effectively integrates data-driven machine learning approaches (bottom-up) with knowledge-guided methods (top-down). In addition, it can employ data with different modalities (e.g., visual, auditory, and natural language processing) to perform cross-media learning and inference. Furthermore, there will be a step from the pursuit of an intelligent machine to the hybridaugmented intelligence (i.e., high-level man-machine collaboration and fusion). AI 2.0 will also promote crowd-based intelligence and autonomous-intelligent systems. In the next decades, AI2.0 will probably achieve remarkable progress in aforementioned trends, and therefore significantly change our cities, products, services, economics, environments, even how we advance our society. This special issue aims at reporting recent re-thinking of AI 2.0 from aforementioned aspects as well as practical methodologies, efficient implementations, and applications of AI 2.0. The papers in this special issue can be categorized into two groups. The first group consists of six review papers and the second group five research papers. In the first group, Zhuang et al. (2017) reviewed recent emerging theoretical and technological advances of AI in big data settings. The authors concluded that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI. Li W et al. (2017) described the concepts of crowd intelligence, and explained its relationship to the existing related concepts, e.g., crowdsourcing and human computation. In addition, the authors introduced four categories of representative crowd intelligence platforms. Peng et al. (2017) presented approaches, advances, and future directions in cross-media analysis and reasoning. This paper covers cross-media representation, mining, reasoning, and cross-media knowledge evolution. Tian et al. (2017) reviewed the state-of-the-art research of the perception in terms of visual perception, auditory perception, and speech perception. It also covered perceptual information processing and learning engines. Zhang et al. (2017) introduced the trends in the development of intelligent unmanned autonomous systems. It covered unmanned vehicles, unmanned aerial vehicles, service robots, space robots, marine robots, and unmanned Editorial: Frontiers of Information Technology & Electronic Engineering www.zju.edu.cn/jzus; engineering.cae.cn; www.springerlink.com ISSN 2095-9184 (print); ISSN 2095-9230 (online) E-mail: jzus@zju.edu.cn","",""
20,"FarzinPiltan, MarziehKamgari, SaeedZare, FatemehShahryarZadeh, M. Mansoorzadeh","Design Novel Model Reference Artificial Intelligence Based Methodology to Optimized Fuel Ratio in IC Engine",2013,"","","","",110,"2022-07-13 09:21:51","","10.5815/IJIEEB.2013.02.07","","",,,,,20,2.22,4,5,9,"In this research, model reference fuzzy based control is presented as robust controls for IC engine. The objective of the study is to design controls for IC engines without the knowledge of the boundary of uncertainties and dynamic information by using fuzzy model reference PD p lus mass of air while improve the robustness of the PD p lus mass of air control. A PD plus mass of air provides for eliminate the mass of air and ultimate accuracy in the presence of the bounded disturbance/uncertainties, although this methods also causes some oscillation. The fuzzy PD plus mass of air is proposed as a solution to the problems crated by unstability. Th is method has a good performance in presence of uncertainty.","",""
92,"A. Annoni, P. Benczúr, P. Bertoldi, Blagoj Delipetrev, Giuditta De Prato, C. Feijóo, Enrique Fernández-Macías, E. Gutiérrez, M. Portela, H. Junklewitz, M. L. Cobo, B. Martens, Susana Nascimento, S. Nativi, Alexandre Pólvora, Jose Ignacio Sanchez Martin, Songuel Tolan, I. Tuomi, Lucia Vesnić Alujević","Artificial Intelligence: A European Perspective",2018,"","","","",111,"2022-07-13 09:21:51","","10.2760/11251","","",,,,,92,23.00,9,19,4,"We are only at the beginning of a rapid period of transformation of our economy and society due to the convergence of many digital technologies. Artificial Intelligence (AI) is central to this change and offers major opportunities to improve our lives. The recent developments in AI are the result of increased processing power, improvements in algorithms and the exponential growth in the volume and variety of digital data. Many applications of AI have started entering into our every-day lives, from machine translations, to image recognition, and music generation, and are increasingly deployed in industry, government, and commerce. Connected and autonomous vehicles, and AI-supported medical diagnostics are areas of application that will soon be commonplace. There is strong global competition on AI among the US, China, and Europe. The US leads for now but China is catching up fast and aims to lead by 2030. For the EU, it is not so much a question of winning or losing a race but of finding the way of embracing the opportunities offered by AI in a way that is human-centred, ethical, secure, and true to our core values. The EU Member States and the European Commission are developing coordinated national and European strategies, recognising that only together we can succeed. We can build on our areas of strength including excellent research, leadership in some industrial sectors like automotive and robotics, a solid legal and regulatory framework, and very rich cultural diversity also at regional and sub-regional levels. It is generally recognised that AI can flourish only if supported by a robust computing infrastructure and good quality data: â€¢ With respect to computing, we identified a window of opportunity for Europe to invest in the emerging new paradigm of computing distributed towards the edges of the network, in addition to centralised facilities. This will support also the future deployment of 5G and the Internet of Things. â€¢ With respect to data, we argue in favour of learning from successful Internet companies, opening access to data and developing interactivity with the users rather than just broadcasting data. In this way, we can develop ecosystems of public administrations, firms, and civil society enriching the data to make it fit for AI applications responding to European needs. We should embrace the opportunities afforded by AI but not uncritically. The black box characteristics of most leading AI techniques make them opaque even to specialists. AI systems are currently limited to narrow and well-defined tasks, and their technologies inherit imperfections from their human creators, such as the well-recognised bias effect present in data. We should challenge the shortcomings of AI and work towards strong evaluation strategies, transparent and reliable systems, and good human-AI interactions. Ethical and secure-by-design algorithms are crucial to build trust in this disruptive technology, but we also need a broader engagement of civil society on the values to be embedded in AI and the directions for future development. This social engagement should be part of the effort to strengthen our resilience at all levels from local, to national and European, across institutions, industry and civil society. Developing local ecosystems of skills, computing, data, and applications can foster the engagement of local communities, respond to their needs, harness local creativity and knowledge, and build a human-centred, diverse, and socially driven AI. We still know very little about how AI will impact the way we think, make decisions, relate to each other, and how it will affect our jobs. This uncertainty can be a source of concern but is also a sign of opportunity. The future is not yet written. We can shape it based on our collective vision of what future we would like to have. But we need to act together and act fast.","",""
0,"赵雪轩, 朱子霖, 施炯明, 郑钢铁","Translucent automatic Pilot artificial intelligence system and vehicle",2017,"","","","",112,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,4,5,"The invention discloses a kind of translucent automatic Pilot artificial intelligence system and vehicle, wherein system to include：Sensor assembly, for gathering a variety of environmental informations, wherein, sensor assembly includes photostat module and indirect sensors module, multiple photostat modules gather present vehicle information in a variety of environmental informations, and indirect sensors module obtains present road information and other information of vehicles in a variety of environmental informations；Decision-making module, for according to a variety of environmental informations by adding the decision-making translucentization of the deep learning network vehicle of mankind's professional knowledge.The system can pass through the decision-making translucentization for the deep learning network vehicle for adding mankind's professional knowledge, not only reduce the hardware condition needed for automatic Pilot, and training effectiveness is improved, and then the safety and reliability of vehicle is effectively ensured, strengthen the robustness of vehicle.","",""
0,"John Kalantari","A general purpose artificial intelligence framework for the analysis of complex biological systems",2017,"","","","",113,"2022-07-13 09:21:51","","10.17077/ETD.4ESKIJ3M","","",,,,,0,0.00,0,1,5,"This thesis encompasses research on Artificial Intelligence in support of automating scientific discovery in the fields of biology and medicine. At the core of this research is the ongoing development of a general-purpose artificial intelligence framework emulating various facets of human-level intelligence necessary for building cross-domain knowledge that may lead to new insights and discoveries. To learn and buildmodels in a data-drivenmanner, we develop a general-purpose learning framework called Syntactic Nonparametric Analysis of Complex Systems (SYNACX), which uses tools from Bayesian nonparametric inference to learn the statistical and syntactic properties of biological phenomena from sequence data. We show that the models learned by SYNACX offer performance comparable to that of standard neural network architectures. For complex biological systems or processes consisting of several heterogeneous components with spatio-temporal interdependencies across multiple scales, learning frameworks like SYNACX can become unwieldy due to the the resultant combinatorial complexity. Thus we also investigate ways to robustly reduce data dimensionality by introducing a new data abstraction. In particular, we extend traditional string and graph grammars in a new modeling formalism which we call Simplicial Grammar. This formalism integrates the topological properties of the simplicial complex with the expressive power of stochastic grammars in a computation abstraction with which we can decompose complex system behavior, into a finite set of modular grammar rules which parsimoniously describe the spatial/temporal structure and dynamics of patterns inferred from sequence data.","",""
0,"Zhijie Lu, Changzhu Zhang, Hao Zhang, Zhuping Wang, Chao Huang, Yuxiong Ji","Deep Reinforcement Learning Based Autonomous Racing Car Control With Priori Knowledge",2021,"","","","",114,"2022-07-13 09:21:51","","10.1109/cac53003.2021.9728289","","",,,,,0,0.00,0,6,1,"In the community of artificial intelligence, re-searchers have devoted much effort to the application of deep reinforcement learning algorithms for autonomous driving. Under deep reinforcement learning framework, it is important for the racing car agent to interact with its external environment to accumulate enough driving experience. However, the inter-action process is usually inefficient, risky and time-consuming. Furthermore, it is a common problem in relevant studies that brake policy is difficult to master. In this paper, we adopt some priori knowledge about vehicle dynamics to design the brake force and update it to the actor-critic network by soft-learning strategy. In addition, some effective strategies are developed to improve the training efficiency and control performance. The Open Racing Car Simulator(TORCS) is adopted to evaluate our algorithm. The simulation results show the effectiveness of our proposed algorithm with better learning efficiency, robustness and generalization performance.","",""
2,"D. Riaño","Knowledge Management for Health Care Procedures: From Knowledge to Global Care, AIME 2007 Workshop K4CARE 2007, Amsterdam, The Netherlands, July 7, 2007, ... / Lecture Notes in Artificial Intelligence)",2008,"","","","",115,"2022-07-13 09:21:51","","","","",,,,,2,0.14,2,1,14,"This book constitutes the thoroughly refereed post-workshop proceedings of the first AIME 2007 workshop From Knowledge to Global Care, K4CARE 2007, held in Amsterdam, The Netherlands, in July 2007, in conjunction with the 11th International Conference on Artificial Intelligence in Medicine, AIME 2007. The 10 revised full papers presented together with 2 invited papers were carefully selected during a second round of reviewing and improvement from 14 lectures given at the workshop and are presented in extended version in the book. The papers are organized in topical sections on health care knowledge management, health care knowledge elicitation, health care knowledge transformation, and health care intelligent systems.","",""
15,"Qianqian Song, Jing Su, Wei Zhang","scGCN is a graph convolutional networks algorithm for knowledge transfer in single cell omics",2021,"","","","",116,"2022-07-13 09:21:51","","10.1038/s41467-021-24172-y","","",,,,,15,15.00,5,3,1,"","",""
0,"Lucas B. Miguel, D. Takabayashi, Jose R. Pizani, Tiago Andrade, Brody West","Marvin - Open source artificial intelligence platform",2018,"","","","",117,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,5,4,"Marvin is an open source project that focuses on empowering data science teams to deliver industrial-grade applications supported by a high-scale, low-latency, language agnostic and standardized architecture platform, while simplifying the process of exploration and modeling. Building model-dependent applications in a robust way is not trivial, one is required to have knowledge in advanced areas of sciences like computing, statistics and math. Marvin aims at abstracting the complexities in the creation process of scalable, highly available, interoperable and maintainable predictive software.","",""
3,"Shreta Sharma, S. K. Pandey","Integrating AI Techniques in Requirements Elicitation",2019,"","","","",118,"2022-07-13 09:21:51","","10.2139/ssrn.3462954","","",,,,,3,1.00,2,2,3,"Requirements elicitation is known as most acute knowledge intensive activity of the procedure of software. The quality of the requirements supports in the success of any software development. The review of literature reveals that scientists have prepared major supports by emerging various tools and methods of requirement elicitation process. However, there are still many challenges faced by requirements engineers in order to carry out requirements elicitation activity in the entire process. Some of the key challenges are poor communication between user and analyst, support tools and stakeholder involvement. These issues may lead to inefficient result and the end of the system development. The previous research history exposes that Artificial Intelligence (AI) methods may help in this regard by providing effective communication between user and analyst by proposing several methods/tools to computerize certain procedures up to a certain extent. The intention of this study is to classify the issues in every phase of the requirements elicitation and explore of AI techniques to solve these recognized challenges. Additionally, the study also discovers the connection between these challenges and their potential AI explanation/s through Venn-Diagram. This study is an addition towards our prior efforts and here, an attempt is made to incorporate and describe AI techniques in many requirements elicitation techniques.","",""
20,"A. Okon, S. Adewole, Emmanuel M. Uguma","Artificial neural network model for reservoir petrophysical properties: porosity, permeability and water saturation prediction",2020,"","","","",119,"2022-07-13 09:21:51","","10.1007/s40808-020-01012-4","","",,,,,20,10.00,7,3,2,"","",""
1,"S. Mohamed","Artificial intelligence (AI) support for knowledge management in construction",2002,"","","","",120,"2022-07-13 09:21:51","","","","",,,,,1,0.05,1,1,20,"This study focus on the investigation of the opportunities on the application of established artificial intelligence (AI) tools and techniques for the elicitation and representation of knowledge. This has been achieved by initially reviewing the development of knowledge management and artificial intelligence in general and also the context of construction industry. Case studies are used to show the situations of knowledge management systems in the construction organisations. From the results of the case studies and current researches, this report attempts to show the usefulness of deploying artificial intelligence tools and techniques in capturing and representation knowledge in the context of the construction industry. The study found protocol analysis and structure interview method are suitable to capture tacit knowledge (lessons learnt and best practices) in the construction organisations. In contrast, concept sorting method is appropriate tools to capture explicit knowledge. In the knowledge representation context, the combination of frames method and semantic network method are suitable to represent tacit knowledge (knowledge of people and processes). The Web-based technology also can be used to facilitate knowledge elicitation and representation in the construction organisations. In conclusion, all the above information are closely scrutinised and conclusions drawn that established artificial intelligence (AI) tools and techniques have significant effects in supporting end-users of knowledge management systems in construction industry context.","",""
0,"A. Giordani","Artificial Intelligence in Customs Risk Management for e-Commerce: Design of a Web-crawling Architecture for the Dutch Customs Administration",2018,"","","","",121,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,1,4,"The last decade saw the rise of e-commerce trade and the shift of the manufacturing industry to the emerging economies, China first of all. In this context, the European Customs Authorities experienced an explosion of small parcels coming from e-commerce websites, often from China, and faced difficulties to detect fiscal frauds and security threats using their conventional risk management systems. To address this problem, the European project PROFILE brings together the customs administrations of Netherlands, Belgium, Sweden, Norway, and Estonia, aiming to provide the EU with a shared platform for: (1) accurately assessing customs risks; (2) optimizing operation and logistics by integrating multiple sources of information; (3) developing a shared data platform to share customs risk management (CRM) practices. As part of this project, the Dutch Customs Administration (DCA) and International Business Machines (IBM) Corporation are collaborating to deploy the cutting-edge technologies of artificial intelligence to automatically cross-check the customs declarations coming from Chinese e- commerce against online information. Through a Design Science approach, I carried out this research for the Delft University of Technology, written in collaboration with IBM Netherlands, aiming to deliver a preparatory study for the developing team before the PROFILE project begins. This includes knowledge brokering between the Dutch Customs Administration and IBM Netherlands so that a more precise problem scope can be defined, and the requirements elicited. In particular, this research focuses on the first part of the project: the development of an adaptive web-crawler for e-commerce, able to compare the declarations documents against online information. According to the Dutch Customs Administration, the web-crawling system should gather the description of the goods from declarations, search the product on the web, find its price of sale on the e-commerce platforms, compare it with the value declared in the declaration, and return a risk indicator of green/red flag to the targeting officer. The design process of this system follows approaches coming from the systems engineering discipline, starting with the requirement analysis, addressing them with the state-of-the-art big data analytics, and finally deriving the logical components of the system, whose design is presented through a logical architecture. First, the application domain is investigated. When goods entry the Netherlands need an entry declaration. These goods arrive at the harbor of Rotterdam or airport of Schiphol, where some of these are imported into the country and become import/export, and others stop temporarily as transit waiting to be shipped somewhere else. The Dutch Customs Administration monitors these processes through risk management systems aiming to stop non-compliant goods. This research describes these practices, with a higher focus on the e-commerce risk targeting. About the e- commerce world, a study of the e-commerce processes behind an online purchase is also carried out through a real purchase on Chinese e-commerce. This was used to observe how the Chinese sender described the item, and how the Dutch Customs assessed the risk and decided on the duties to be paid. This led to reflect on the possible frauds scenarios and how to address them. Finally, the Dutch Customs also reported that the products descriptions are often vague and ambiguous, and a more accurate formulation of the problem is described. Secondly, an in-depth literature on the fields of web-crawling and big data analytics techniques is carried out. The possible technologies that could be useful to address the requirements and the problem formulation are investigated. Starting with an analysis of the existing literature on the field of big data analytics, this research also covers the recent trends of machine learning and artificial intelligence. To avoid reporting a too big literature, the topics reported have been accurately chosen, for instance describing only the techniques for web analytics and text analytics. This literature on big data analytics is further broken in two sub-topics, one more theoretical, which classifies the types of analytics methods and defines the technology of machine learning and natural language processing, including the last paradigms of deep learning and reinforcement learning, and one more practical, where guidelines for the design, development, and implementation of machine learning techniques are proposed. It is here that a theoretical framework to systematically reflect on the challenges of the field of big data analytics has been identified. This framework is then used to systematically collect the main technological challenges of the use case under analysis and translate them into non-functional requirements. Finally, the last part of the literature describes what a web-crawler is and what web- crawling/web-craping means. This later extends to the concepts of focused web-crawling and smart, intelligent, adaptive web-crawling, where machine learning techniques are deployed to improve performance. The literature concludes by providing related works of machine learning techniques implemented in smart web-crawling of the e-commerce websites and stating the knowledge gap that needs to be bridged to address the use case under analysis. After the application domain and the literature review, the knowledge from these previous phases combines in a continuous iterative process according to the design science methodology (Hevner, 2014). Through unstructured interviews with the DCA and IBM experts, the requirements elicitation is carried out. The approach by Armstrong and Sage (2000) deriving from the field of systems engineering is used. The main objective of the system to be developed is broken down into a series of sub-activities that must be carefully structured to formulate the requirements. About the non-functional requirements, instead of reflecting on the different domains – technological, environment, law compliance, etc. – as it is proposed by the same systems engineering approach mentioned earlier, this research uses the framework identified in the literature review about the main challenges of big data project (Sivarajah, 2016). To derive the components of the architecture from the requirements and customer needs, the methodology proposed by Suh (1998) called Axiomatic Design has been used, mapping the requirements into architectural components in a rigorous manner. In this way, the design domains proposed by this methodology – customer, functional, physical and process domains – are taken as the reference point for the design process: first, the business needs are identified, then these are translated into requirements, which are mapped into design features. The process domain is left out of this research and will be addressed by the IBM development team in Ireland. The design cycle leads to the design of a web-crawling system represented through a service- oriented architecture (SOA). Its block diagram and black-box description of each application service are provided. Furthermore, the architecture functionality is described with an architecture walk-through and a sequence diagram in the unified modeling language (UML). The result is an innovative real-time web-crawling system to identify the value of a given product on the e-commerce websites. It deploys natural language process models to filter the non-relevant search results, and other machine learning models to best matching the remaining relevant results with a given item description. The design and architecture description of this innovative web-crawling system is the main artifact of this research, while the mixed methodology of systems engineering methodologies and big data frameworks is another important scientific contribution.","",""
8,"P. Mittal, Y. Singh","Development of Intelligent Transportation System for Improving Average Moving and Waiting time with Artificial Intelligence",2016,"","","","",122,"2022-07-13 09:21:51","","10.17485/IJST/2016/V9I3/84156","","",,,,,8,1.33,4,2,6,"Background: Real time traffic control is an important tool of Intelligent Transportation System (ITS). The development of system for controlling the urban traffic dynamically provides not only the safety for traffic, but also saves the time, money and provides polluted free environment. This paper describes the development of dynamic and robust traffic management system based on fuzzy logic approach. Method: Knowledge based system have been extensively adopted as approach for real time decision making system. Findings: As the conventional dynamic controllers were used sensors which are having certain limitations, so these limitations can be overcome by vision sensors i.e. camera. Also image and vision computing plays an important role in monitoring and measuring the traffic density on road. Problems were identified with the current traffic control system at the intersection on road and this necessitated the design and implementation of a new system to solve the congestion problems. Improvements: The performance of the proposed framework is evaluated with LabVIEW and MATLAB test bed. The results of extensive simulations using the proposed approach indicate that the system improves the average moving time and decrease the average waiting time than the controllers with conventional sensors.","",""
8,"Quan Zhou, Dezong Zhao, B. Shuai, Yanfei Li, Huw Williams, Hongming Xu","Knowledge Implementation and Transfer With an Adaptive Learning Network for Real-Time Power Management of the Plug-in Hybrid Vehicle",2021,"","","","",123,"2022-07-13 09:21:51","","10.1109/TNNLS.2021.3093429","","",,,,,8,8.00,1,6,1,"Essential decision-making tasks such as power management in future vehicles will benefit from the development of artificial intelligence technology for safe and energy-efficient operations. To develop the technique of using neural network and deep learning in energy management of the plug-in hybrid vehicle and evaluate its advantage, this article proposes a new adaptive learning network that incorporates a deep deterministic policy gradient (DDPG) network with an adaptive neuro-fuzzy inference system (ANFIS) network. First, the ANFIS network is built using a new global K-fold fuzzy learning (GKFL) method for real-time implementation of the offline dynamic programming result. Then, the DDPG network is developed to regulate the input of the ANFIS network with the real-world reinforcement signal. The ANFIS and DDPG networks are integrated to maximize the control utility (CU), which is a function of the vehicle’s energy efficiency and the battery state-of-charge. Experimental studies are conducted to testify the performance and robustness of the DDPG-ANFIS network. It has shown that the studied vehicle with the DDPG-ANFIS network achieves 8% higher CU than using the MATLAB ANFIS toolbox on the studied vehicle. In five simulated real-world driving conditions, the DDPG-ANFIS network increased the maximum mean CU value by 138% over the ANFIS-only network and 5% over the DDPG-only network.","",""
0,"Khadijeh Karamzadeh, H. Moharrami","Survey of robust artificial intelligence classifier proper for various digital data",2015,"","","","",124,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,2,7,"Artificial intelligence or machine intelligence should be considered as the vast domain of junction of many knowledge, sciences and old and new technics. Today, classification of documents is adopted extensively in information recovery for organizing documents. In the method of document supervised classification some correct information about documents that previously have been classified are available for us and based on these information we classify these documents. Thus, we will examine methods such as: expert systems, artificial neural network, Genetic algorithm and fuzzy logics and so on. In this project we examine documents thematically and then using existing algorithms we predict a theme for a new document.","",""
2,"Aidan Murphy, Gráinne Murphy, Jorge Amaral, D. M. Dias, Enrique Naredo, C. Ryan","Towards Incorporating Human Knowledge in Fuzzy Pattern Tree Evolution",2021,"","","","",125,"2022-07-13 09:21:51","","10.1007/978-3-030-72812-0_5","","",,,,,2,2.00,0,6,1,"","",""
31,"Shijie Jiang, Yi Zheng, D. Solomatine","Improving AI System Awareness of Geoscience Knowledge: Symbiotic Integration of Physical Approaches and Deep Learning",2020,"","","","",126,"2022-07-13 09:21:51","","10.1029/2020GL088229","","",,,,,31,15.50,10,3,2,"Modeling dynamic geophysical phenomena is at the core of Earth and environmental studies. The geoscientific community relying mainly on physical representations may want to consider much deeper adoption of artificial intelligence (AI) instruments in the context of AI's global success and emergence of big Earth data. A new perspective of using hybrid physics‐AI approaches is a grand vision, but actualizing such approaches remains an open question in geoscience. This study develops a general approach to improving AI geoscientific awareness, wherein physical approaches such as temporal dynamic geoscientific models are included as special recurrent neural layers in a deep learning architecture. The illustrative case of runoff modeling across the conterminous United States demonstrates that the physics‐aware DL model has enhanced prediction accuracy, robust transferability, and good intelligence for inferring unobserved processes. This study represents a firm step toward realizing the vision of tackling Earth system challenges by physics‐AI integration.","",""
1,"Divya, A. Jain, Gagandeep Singh","Classification of Big Data Through Artificial Intelligence",2015,"","","","",127,"2022-07-13 09:21:51","","","","",,,,,1,0.14,0,3,7,"By technology innovations, there has been a large increase within the utilization of Bigdata knowledge, joined of the foremost most well-liked styles of media thanks to its content richness, for several vital applications. To sustain Associate in Nursing current ascension of knowledge Bigdata, there's Associate in Nursing rising demand for a complicated content-based knowledge classification system. Thanks to the chop-chop increasing massive knowledge, abundant analysis effort has been dedicated to develop classification primarily based massive knowledge retrieval ways which may efficiently retrieve knowledge of interest. Considering the restricted man-power, it's abundant expected to develop retrieval ways that use options mechanically extracted from massive knowledge. Through Architecture-Algorithm co-design for Bigdata processing Applications, a scalable. Manycore processor consists of classification of heterogeneous cores with stream process capabilities, and zero-overhead inter-process communication through computer science with a hardware-software mechanism has been designed. This is often designed for achieving superior and low-power consumption, particularly thus on cut back access needed for Bigdata processing Applications. Keywords— classification , Bigdata , PBO(pollination based optimization ) , BBO(biogeography based optimization ) , Apriori. Divya et al, International Journal of Computer Science and Mobile Computing, Vol.4 Issue.8, August2015, pg. 17-25 © 2015, IJCSMC All Rights Reserved 18 INTRODUCTION Big data technologies are important in providing more accurate analysis, which may lead to more concrete decision-making resulting in greater operational efficiencies, cost reductions, and reduced risks for the business. To harness the power of big data, you would require an infrastructure that can manage and process huge volumes of structured and unstructured data in real time and can protect data privacy and security. There are various technologies in the market from different vendors including Amazon, IBM, Microsoft, etc., to handle big data. While looking into the technologies that handle big data, we examine the following two classes of technology: A. Operational Big Data This includes systems like Mongo DB that provide operational capabilities for real-time, interactive workloads where data is primarily captured and stored. NoSQL Big Data systems are designed to take advantage of new cloud computing architectures that have emerged over the past decade to allow massive computations to be run inexpensively and efficiently. This makes operational big data workloads much easier to manage, cheaper, and faster to implement. Some NoSQL systems can provide insights into patterns and trends based on realtime data with minimal coding and without the need for data scientists and additional infrastructure. B. Analytical Big Data This includes systems like Massively Parallel Processing (MPP) database systems and MapReduce that provide analytical capabilities for retrospective and complex analysis that may touch most or all of the data. MapReduce provides a new method of analyzing data that is complementary to the capabilities provided by SQL, and a system based on MapReduce that can be scaled up from single servers to thousands of high and low end machines. These two classes of technology are complementary and frequently deployed together. BENEFITS OF BIG DATA Big data is really critical to our life and its emerging as one of the most important technologies in modern world. Follow are just few benefits which are very much known to all of us: USING THE INFORMATION KEPT IN THE SOCIAL NETWORK LIKE FACEBOOK, THE MARKETING AGENCIES ARE LEARNING ABOUT THE RESPONSE FOR THEIR CAMPAIGNS, PROMOTIONS, AND OTHER ADVERTISING MEDIUMS. USING THE INFORMATION IN THE SOCIAL MEDIA LIKE PREFERENCES AND PRODUCT PERCEPTION OF THEIR CONSUMERS, PRODUCT COMPANIES AND RETAIL ORGANIZATIONS ARE PLANNING THEIR PRODUCTION. USING THE DATA REGARDING THE PREVIOUS MEDICAL HISTORY OF PATIENTS, HOSPITALS ARE PROVIDING BETTER AND QUICK SERVICE. REVIEW Behrouz et. al.[15] A combination of multiple classifiers leads to a significant improvement in classification performance. Furthermore, by learning an appropriate weighting of the features used via a genetic algorithm (GA), we further improve prediction accuracy. The GA is demonstrated to successfully improve the accuracy of combined classifier performance, about Divya et al, International Journal of Computer Science and Mobile Computing, Vol.4 Issue.8, August2015, pg. 17-25 © 2015, IJCSMC All Rights Reserved 19 10 To 12% when comparing to non-GA classifier. This method may be of considerable usefulness in identifying students at risk early, especially in very large classes, and allow the instructor to provide appropriate advising in a timely manner. Riccardo et al. [14] proposed cognitive, and behavioural aspects of distance students. Course Vis is presented in the paper, and several examples of pictorial representations generated by the tool. Luo et. al. [21] Efficient meaning for sampling of data, reduction of data also needed to develop. Newly develop mining technique and searching algorithms that are suitable for extracting more different or complex relationship between fields. Youssef M.ESSA et. al. [25] The proposed framework is developed by using mobile agent and MapReduce paradigm under Java Agent Development Framework (JADE). JADE is a promising middleware based on the agent paradigm because it supports generic services such as communication support, resource discovery, content delivery, data encoding and agents mobility. Indeed, there are seven reasons for using mobile agents as follows: (1) Reduce the network load, (2) Overcome network latency, (3) Encapsulate protocols, (4) Execute asynchronously and autonomously, (5) Adapt dynamically, (6) Naturally heterogeneous and robust, and","",""
5,"Runchi Zhang, Zhiyi Qiu","Optimizing hyper-parameters of neural networks with swarm intelligence: A novel framework for credit scoring",2020,"","","","",128,"2022-07-13 09:21:51","","10.1371/journal.pone.0234254","","",,,,,5,2.50,3,2,2,"Neural networks are widely used in automatic credit scoring systems with high accuracy and outstanding efficiency. However, in the absence of prior knowledge, it is difficult to determine the set of hyper-parameters, which makes its application limited in practice. This paper presents a novel framework of credit-scoring model based on neural networks trained by the optimal swarm intelligence (SI) algorithm. This framework incorporates three procedures. Step 1, pre-processing, including imputation, normalization, and re-ordering of the samples. Step 2, training, where SI algorithms optimize hyper-parameters of back-propagation artificial neural networks (BP-ANN) with the area under curve (AUC) as the evaluation function. Step 3, test, applying the optimized model in Step 2 to predict new samples. The results show that the framework proposed in this paper searches the hyper-parameter space efficiently and finds the optimal set of hyper parameters with appropriate time complexity, which enhances the fitting and generalization ability of BP-ANN. Compared with existing credit-scoring models, the model in this paper predicts with a higher accuracy. Additionally, the model enjoys a greater robustness, for the difference of performance between training and testing phases.","",""
26,"Giuseppe Futia, Antonio Vetrò","On the Integration of Knowledge Graphs into Deep Learning Models for a More Comprehensible AI - Three Challenges for Future Research",2020,"","","","",129,"2022-07-13 09:21:51","","10.3390/info11020122","","",,,,,26,13.00,13,2,2,"Deep learning models contributed to reaching unprecedented results in prediction and classification tasks of Artificial Intelligence (AI) systems. However, alongside this notable progress, they do not provide human-understandable insights on how a specific result was achieved. In contexts where the impact of AI on human life is relevant (e.g., recruitment tools, medical diagnoses, etc.), explainability is not only a desirable property, but it is -or, in some cases, it will be soon-a legal requirement. Most of the available approaches to implement eXplainable Artificial Intelligence (XAI) focus on technical solutions usable only by experts able to manipulate the recursive mathematical functions in deep learning algorithms. A complementary approach is represented by symbolic AI, where symbols are elements of a lingua franca between humans and deep learning. In this context, Knowledge Graphs (KGs) and their underlying semantic technologies are the modern implementation of symbolic AI—while being less flexible and robust to noise compared to deep learning models, KGs are natively developed to be explainable. In this paper, we review the main XAI approaches existing in the literature, underlying their strengths and limitations, and we propose neural-symbolic integration as a cornerstone to design an AI which is closer to non-insiders comprehension. Within such a general direction, we identify three specific challenges for future research—knowledge matching, cross-disciplinary explanations and interactive explanations.","",""
0,"R. Melli","ARTIFICIAL INTELLIGENCE IN COMPONENT DESIGN",2011,"","","","",130,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,1,11,"ion (for ill-structured problems) Classification (for well-structured problems) Analogy (comparison with other solutions of similar problems) Error Handling Hierarchical Knowledge Elicitation","",""
22,"Xi Lin, Jun Wu, A. Bashir, Jianhua Li, Wu Yang, Jalil Piran","Blockchain-Based Incentive Energy-Knowledge Trading in IoT: Joint Power Transfer and AI Design",2020,"","","","",131,"2022-07-13 09:21:51","","10.1109/jiot.2020.3024246","","",,,,,22,11.00,4,6,2,"Recently, edge artificial intelligence techniques (e.g., federated edge learning) are emerged to unleash the potential of big data from Internet of Things (IoT). By learning knowledge on local devices, data privacy-preserving and quality of service (QoS) are guaranteed. Nevertheless, the dilemma between the limited on-device battery capacities and the high energy demands in learning is not resolved. When the on-device battery is exhausted, the edge learning process will have to be interrupted. In this paper, we propose a novel Wirelessly Powered Edge intelliGence (WPEG) framework, which aims to achieve a stable, robust, and sustainable edge intelligence by energy harvesting (EH) methods. Firstly, we build a permissioned edge blockchain to secure the peer-to-peer (P2P) energy and knowledge sharing in our framework. To maximize edge intelligence efficiency, we then investigate the wirelessly-powered multi-agent edge learning model and design the optimal edge learning strategy. Moreover, by constructing a two-stage Stackelberg game, the underlying energy-knowledge trading incentive mechanisms are also proposed with the optimal economic incentives and power transmission strategies. Finally, simulation results show that our incentive strategies could optimize the utilities of both parties compared with classic schemes, and our optimal learning design could realize the optimal learning efficiency.","",""
2,"Sandra Medenjak, B. Klicek, Dobrica Pavlinušić","Knowledge elicitation using Multimedia Polling Techniques",1998,"","","","",132,"2022-07-13 09:21:51","","","","",,,,,2,0.08,1,3,24,"This paper deals with usage of multimedia in the field of knowledge elicitation. It introduces multimedia poll as a technique suitable for knowledge elicitation that would otherwise use classic poll technique. Problems in implementation are discussed using our system as an example and possible solutions to those problems are offered. Artificial intelligence techniques can be added to multimedia poll techniques for creation semi-structured interviews (like genetic algorithms and decision trees), and data mining techniques for further analysis of results. Pro and con analysis of using multimedia is also presented.","",""
6,"S. Sham","The QED experience: knowledge elicitation in structural design",1991,"","","","",133,"2022-07-13 09:21:51","","10.1080/02630259108970609","","",,,,,6,0.19,6,1,31,"Abstract This paper presents the experimentation conducted in knowledge elicitation, with special reference to bridge design, as part of a much greater research effort in the computational modelling of conceptual design using artificial intelligence techniques. The extent of the knowledge elicitation encompasses the entire process of extracting, characterizing and crafting design knowledge into an exploitable form. The merits and shortcomings of the methods used in the experimentation are compared and contrasted; the problems involved in acquiring knowledge in a multiple expert environment are discussed.","",""
0,"J. Christian","Data Acquisition and Expert Knowledge Elicitation for Expert Systems in Construction",1991,"","","","",134,"2022-07-13 09:21:51","","10.1007/978-94-011-3648-8_54","","",,,,,0,0.00,0,1,31,"","",""
4,"Alan Liu, J. Tsai","A Method for Requirements Analysis and Knowledge Elicitation",1996,"","","","",135,"2022-07-13 09:21:51","","10.1142/S0218213096000122","","",,,,,4,0.15,2,2,26,"Requirements analysis is a knowledge intensive task and it requires an expert to understand what the clients need. In this paper, we introduce a method which contains different artificial intelligence techniques to perform this task, and a prototype knowledge-based requirements analysis system, RAKES, is presented to explain our approach. In this approach, not only the ordinary functional requirements are collected, but also some non-traditional information, such as non-functional requirements like the quality of operations or the background information for constructing the requirements, is gathered through a knowledge-based support. Different kinds of information collected are stored and organized in a knowledge base and can be used as the source of the user input in the latter phases of software development. Algorithms and procedures have been developed for constructing the interface language, organizing the knowledge base, and applying the knowledge base to different tasks. RAKES is integrated to an on-going research, called the FRORL methodology, to offer a systematic way toward requirements analysis, specification production, prototype generation, specification debugging, and code transformation.","",""
6,"P. Chand","Development of an Artificial Intelligence System for the Instruction and Control of Cooperating Mobile Robots",2012,"","","","",136,"2022-07-13 09:21:51","","10.26686/wgtn.16992466","","",,,,,6,0.60,6,1,10,"This thesis focuses on the development of an artificial intelligence system for a heterogeneous ensemble of mobile robots. Many robots in the ensemble may have limited processing, communication, sensing, and/or actuation capabilities. This means that each robot may not be able to execute all tasks that are input to the system. A hierarchical system is proposed to permit robots with superior processing and communication abilities to assign tasks and coordinate the less computationally able robots. The limited processing robots may also utilise the resources of superior robots during task execution. Effective task allocation and coordination should result in efficient execution of a global task. Many existing approaches to robot task allocation assume expert knowledge for task specification. This is not ideal if a non-expert human user wants to modify the task requirements. A novel reduced human user input task allocation and feedback coordination technique for limited capability mobile robots is developed and implemented. Unlike existing approaches, the presented method focuses on expressing tasks and robots in terms of processing, communication, sensing, and actuation physical resources. This has the potential to allow non-expert human users to specify tasks to the team of robots. Fuzzy inference systems are utilised to simplify detailed robot information for comparison with simple human user inputs that represent task resource requirements. Like many existing task allocation methods, a greedy algorithm is employed to select robots. This can result in suboptimal task allocation. In addition to this, the non-expert user’s task specifications might be erroneous in some instances. Hence, a feedback coordination component monitors robot performance during task execution. In this thesis, a customised multi-robot mapping and exploration task is utilised as a model task to test the effectiveness of the developed task allocation and feedback coordination strategy. Extensive simulation experiments with various robot team configurations are executed in environments of varying sizes and obstacle densities to assess the performance of the technique. Task allocation is able to identify suitable robots and is robust to selection weight variation. The task allocation process is subjective to fuzzy membership function parameters which may vary for different This thesis focuses on the development of an artificial intelligence system for a heterogeneous ensemble of mobile robots. Many robots in the ensemble may have limited processing, communication, sensing, and/or actuation capabilities. This means that each robot may not be able to execute all tasks that are input to the system. A hierarchical system is proposed to permit robots with superior processing and communication abilities to assign tasks and coordinate the less computationally able robots. The limited processing robots may also utilise the resources of superior robots during task execution. Effective task allocation and coordination should result in efficient execution of a global task. Many existing approaches to robot task allocation assume expert knowledge for task specification. This is not ideal if a non-expert human user wants to modify the task requirements. A novel reduced human user input task allocation and feedback coordination technique for limited capability mobile robots is developed and implemented. Unlike existing approaches, the presented method focuses on expressing tasks and robots in terms of processing, communication, sensing, and actuation physical resources. This has the potential to allow non-expert human users to specify tasks to the team of robots. Fuzzy inference systems are utilised to simplify detailed robot information for comparison with simple human user inputs that represent task resource requirements. Like many existing task allocation methods, a greedy algorithm is employed to select robots. This can result in suboptimal task allocation. In addition to this, the non-expert user’s task specifications might be erroneous in some instances. Hence, a feedback coordination component monitors robot performance during task execution. In this thesis, a customised multi-robot mapping and exploration task is utilised as a model task to test the effectiveness of the developed task allocation and feedback coordination strategy. Extensive simulation experiments with various robot team configurations are executed in environments of varying sizes and obstacle densities to assess the performance of the technique. Task allocation is able to identify suitable robots and is robust to selection weight variation. The task allocation process is subjective to fuzzy membership function parameters which may vary for different users. Feedback coordination is robust to variation in weights and thresholds for failure detection. This permits the correction of suboptimal allocations arising from greedy task allocation, incorrect initial task specifications or unexpected failures. By being robust within the tested limits, weights and thresholds can be intuitively selected. However, other parameters such as ideal achievement data can be difficult to accurately characterise in some instances. A hierarchical hybrid deliberative-reactive navigation system for memory constrained heterogeneous robots to navigate obstructed environments is developed. Deliberative control is developed using a modified version of the A* algorithm and a rectangular occupancy grid map. A novel two-tiered path planner executes on limited memory mobile robots utilising the memory of a computationally powerful robot to enable navigation beyond localised regions of a large environment. Reactive control is developed using a modified dynamic window approach and a polar histogram technique to remove the need for periodic path planning. A range of simulation experiments in different sized environments is conducted to assess the performance of the two-tiered path planning strategy. The path planner is able to achieve superior or comparable execution times to non-memory constrained path planning when small sized local maps are employed in large global environments. Performance of hybrid deliberative-reactive navigation is assessed in a range of simulated environments and is also validated on a real robot. The developed reactive control system outperforms the dynamic window method.","",""
1,"Kiet Van Nguyen, Phong Nguyen-Thuan Do, Nhat Duy Nguyen, T. Huynh, A. Nguyen, N. Nguyen","XLMRQA: Open-Domain Question Answering on Vietnamese Wikipedia-based Textual Knowledge Source",2022,"","","","",137,"2022-07-13 09:21:51","","10.48550/arXiv.2204.07002","","",,,,,1,1.00,0,6,1,". Question answering (QA) is a natural language understanding task within the fields of information retrieval and information extraction that has attracted much attention from the computational linguistics and artificial intelligence research community in recent years because of the strong development of machine reading comprehension-based models. A reader-based QA system is a high-level search engine that can find correct answers to queries or questions in open-domain or domain-specific texts using machine reading comprehension (MRC) techniques. The majority of advancements in data resources and machine-learning approaches in the MRC and QA systems, on the other hand, especially in two resource-rich languages such as English and Chinese. A low-resource language like Vietnamese has witnessed a scarcity of research on QA systems. This paper presents XLMRQA, the first Vietnamese QA system using a supervised transformer-based reader on the Wikipedia-based textual knowledge source (using the UIT-ViQuAD corpus), outperforming the two robust QA systems using deep neural network models: DrQA and BERTserini with 24.46% and 6.28%, respectively. From the results obtained on the three systems, we analyze the influence of question types on the performance of the QA systems.","",""
4,"Glaucia C. Pereira","Genomics and Artificial Intelligence Working Together in Drug Discovery and Repositioning: The Advent of Adaptive Pharmacogenomics in Glioblastoma and Chronic Arterial Inflammation Therapies",2017,"","","","",138,"2022-07-13 09:21:51","","10.1007/978-3-319-53880-8_11","","",,,,,4,0.80,4,1,5,"","",""
2,"Sankalp Khanna, A. Sattar, David Hansen","Advances in artificial intelligence research in health.",2012,"","","","",139,"2022-07-13 09:21:51","","10.4066/AMJ.2012.1352","","",,,,,2,0.20,1,3,10,"The business of health delivery is complex. Employing over 850,000 people, and delivering services to 21.3 million residents, the Australian health care system is currently strained to the maximum in dealing with increasing demand for services and an acute shortage of skilled professionals. The National e–Health Strategy drives a nationwide research agenda to provide the infrastructure and tools required to support the planning, management and delivery of health care services.    Deriving principles from the disciplines of computer science, mathematics, philosophy and physiology, and consisting of different fields, from machine vision to expert systems, the field of Artificial Intelligence (AI) deals with the creation of ""machines that can think"". Focused on traits of reasoning, knowledge representation, planning, learning, communication, perception and social intelligence, AI has been widely applied to augment the state of the art in Health Informatics.    This special issue reports on the latest developments in the field of AI motivated research in the health domain. The special issue arose from the inaugural Australian Workshop on Artificial Intelligence in Health (AIH 2011). It was held in conjunction with the 24th Australasian Joint Conference On Artificial Intelligence (AI2011), in Perth, Australia, in December 2011. The AIH 2011 workshop was a first of its kind, national initiative that aimed to bring together scholars and practitioners in the field of AI–driven health informatics to present and discuss their research, share their knowledge and experiences, define key research challenges and explore possible collaborations to advance e–Health development nationally and internationally. Therefore, the affiliation of AIH 2011 with AI2011 was both timely and mutually beneficial for the communities involved in these events.    AIH 2011 received 16 full paper submissions and each paper was reviewed by three program committee members. Six papers were accepted as full papers and five as short papers accompanied with posters.    The workshop brought together researchers from a variety of disciplines across various parts of the country and provided an excellent forum for discussion and exchange of ideas. In addition to presentation of papers, the workshop featured two keynote addresses, a poster session during lunch, and a panel discussion.    The first keynote address, “Using Artificial Intelligence to transform the management of Chronic Disease”, was delivered by Professor Michael Georgeff. In addition to presenting ongoing research efforts to apply AI techniques to better manage chronic disease, Professor Georgeff discussed the greatest innovations in healthcare from a medical practitioner’s viewpoint and focussed on how AI could be leveraged to transform healthcare.    The second keynote address, “Knowledge Acquisition Issues in Interpreting Laboratory Data”, was presented by Professor Paul Compton and posed a number of questions related to large–scale knowledge acquisition for decision– support systems in medicine, drawing lessons from experience in working with knowledge acquisition tools that support over 300 million diagnostics laboratory reports.    The workshop concluded with a panel discussion in which Professor Abdul Sattar and Professor Yogi Kanagasingam joined the keynote speakers to address the topic “AI for eHealth: 2012 and Beyond”. The discussion that ensued was very energetic and actively engaged audience interaction. Topics discussed ranged from the emerging contribution of AI over the past five decades, current issues with the marketing and uptake of AI–based solutions in mainstream healthcare, and the challenges for AI–based research and application in years to come. The panel and audience also acknowledged the key role a workshop like this would play in driving collaborative research efforts between AI and health informatics research communities.    All accepted papers were also invited to revise and submit their manuscripts for inclusion in this special issue of the Australasian Medical Journal (AMJ). Seven papers and a letter to the editor have been accepted for publication in the journal.    The first paper, by Bevan Koopman, Peter Bruza, Laurianne Sitbon and Michael Lawley, titled “Towards Semantic Search and Inference in Electronic Medical Records”, presents concept–based information retrieval for searching electronic medical records and demonstrates that the approach outperforms keyword–based search, working especially well for queries where the latter performs poorly. This paper was awarded the best paper prize at the workshop.    The second paper, by Kinzang Chhogyal, Abhaya Nayak, Rolf Schwitter and Abdul Sattar, titled “A Causal Model for Fluctuating Sugar Levels in Diabetes Patients”, investigates the use of fixed distance based belief revision to improve causal models. A simple scenario for fluctuating blood sugar levels in a diabetes patient is used to demonstrate the efficacy of this approach.    The third paper, by Alexander Krumpholz, David Hawking, Richard Jones, Tom Gedeon and Hugh Greville, titled “Automated Medical Literature Retrieval”, describes a system for the retrieval of relevant medical publications using queries generated automatically from data present in an electronic patient record. Integrated into an electronic record system, such a system would proactively support medical practitioners in the delivery of care.    The fourth paper, by Abeed Sarker, Diego Molla and Cecile Paris, titled “Extractive Summarisation of Medical Documents”, proposes a query focused approach for automatically summarising medical documents and helping medical practitioners find relevant information.    The fifth paper, by Diego Molla and Maria Elena Santiago– Martinez, titled “A Corpus for Evidence Based Summarisation”, presents a corpus of clinical questions and answers designed for training and testing automated text summarisers to support evidence–based medicine.    The sixth paper, by Di Xiao, Janardhan Vignarajan, Jane Lock, Shaun Frost, Mei–Ling Tay–Kearney and Yogi Kanagasingam, titled “Retinal Image Registration and Comparison for Clinical Decision Support”, proposes a set of accurate and robust retinal image registration solutions for longitudinal retinal image alignment and comparison    The seventh paper, by Amol Wagholikar, Maggie Fung and Colleen Nelson, titled “Improving Self–Care of Patients with Chronic Disease using Online Personal Health Record”, employs a case–based reasoning approach to self care for advanced prostate cancer patients in an online patient health record environment.    A letter to the editor, by Anthony Nguyen, Yue Kimi Sun, Laurianne Sitbon and Shlomo Geva, titled “Representation Of Assertions In Clinical Free Text Using SNOMED CT,” explores the use of the SNOMED CT terminology for representing medical concepts and their assertions in clinical free text. The authors demonstrate that that populating assertions as attribute values using SNOMED CT allows over 93% of assertions in their experimental dataset to be represented.    We hope that the breadth and diversity of the papers presented at the workshop and published in this special issue will foster further collaboration and AI driven research in health.    This workshop would not have been possible without the contributions of numerous fine people. First, we are greatly indebted to Professor Aditya Ghose, Professor Anthony Maeder, Professor Wayne Wobcke, Professor Mehmet Orgun, and Dr Yogesan (Yogi) Kanagasingam for their guidance and support. We would also like to thank the organising committee of the 24th Australasian Joint Conference on AI, the Institute of Integrated and Intelligent Systems, Griffith University for supporting the workshop, and the CSIRO Australian e–Health Research Centre for their support and sponsorship of travel scholarships and the best paper prize. Thanks are also due to Professor Moyez Jiwa and the AMJ for supporting the workshop and inviting accepted papers for inclusion into this special issue. Finally, we are indebted to the authors who responded to the invitation to submit their papers, and the reviewers who generously donated their time and expertise and provided very comprehensive reviews of the submitted papers.","",""
2,"D. Grejner-Brzezinska, C. Toth, J. N. Markiel, S. Moafipoor, K. Czarnecka","Integration of Image-Based and Artificial Intelligence Algorithms: A Novel Approach to Personal Navigation",2012,"","","","",140,"2022-07-13 09:21:51","","10.1007/978-3-642-20338-1_120","","",,,,,2,0.20,0,5,10,"","",""
1,"N. Zakaria, Rohayanti Hassan, M. R. Othman, Z. Zakaria, S. Kasim","A Review on Classification of the Urban Poverty Using the Artificial Intelligence Method",2017,"","","","",141,"2022-07-13 09:21:51","","10.18488/JOURNAL.2.2017.711.450.458","","",,,,,1,0.20,0,5,5,"Poverty and how it has been assessed and measured is a frequently discussed topic by policy makers and social developers. The identification process in poverty measurement is indeed essential towards acknowledging the poor in the population; hence this needs to be clarified. Malaysia measures poverty by means of poverty line, indicating the unidimensional and inflexible distribution of poor and non-poor especially in urban areas. Many researchers have used fuzzy logic to solve the problem of rigid poor/non-poor dichotomy. This current trend has been able to augment the gap between the rigid and inflexible classification of poor and non-poor. However, there are still several shortcomings that need attention. For instance, the classification of the poor in fuzzy logic that is based on the average income of households still does not cover on the different range of disadvantage on non-monetary items. Based on these trends, ANFIS is proposed to resolve on the highlighted issues. The winning features of ANFIS, which include on simplicity in implementation, understandable explanation facilities through fuzzy rules, and ease of incorporation of both linguistic and numeric knowledge for problem solving may help in producing better result in classification of the urban poor. Essentially, the neural network is proposed to complement the fuzzy system, hence overcoming the limitations of both fuzzy systems and neural networks. As such, ANFIS method is used in this study to better classify on the poor and non-poor compared to fuzzy rule-based system which is lacking in prediction error rate due to too many variables used. However, this method deteriorates from misclassified poverty indicators; hence this study proposed on ensemble ANFIS to produce more accurate and robust classification results. An ensemble model is usually employed to address the problems of over-fitting, high dimensionality or missing features in the training data. Generally, combining multiple classification models increases predictive performance compared to the use of an individual model alone. Therefore, based on these current trends, this study is aimed to do a review on classification of the urban poverty using the artificial intelligence method.","",""
0,"P. Janssen, Maciej Wichrowski","Automating Operational Business Decisions Using Artificial Intelligence: an Industrial Case Study",2012,"","","","",142,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,2,10,"The process of making business decisions is increasingly reliant upon analyzing very large data-sets. Due to the amount of decisions having to be made on a daily basis, this becomes time-consuming and expensive to carry out manually. The purpose of this thesis was to determine whether using Artificial Intelligence to automate business decisions is feasible. This was done by carrying out a proof of concept project at IFS World, a software company developing Enterprise Resource Planning systems. Procurement decision making was chosen as a case for this study. Automating these decisions can not only result in speeding up the decision making process, but also in making more accurate decisions. To achieve this, three machine learning algorithms were proposed. Their goal was to learn preferences from historical procurement data and apply this knowledge to new situations. Prototyped versions of the algorithms were developed, tested and compared using both real-world and artificial datasets. The results showed that after a short period of supervised learning, two algorithms were able to make decisions automatically, with a low error-rate. Furthermore, sensitivity analysis showed that the algorithms are robust enough to recover from errors in the training data. The study also revealed several constraints and prerequisites related to feature selection, data freshness, and completeness. It was concluded that automating operational business decisions using Artificial Intelligence is achievable if certain preconditions are met. It can provide several advantages over manual decision making: it will speed up the decision making process, and can, in certain scenarios, improve the quality of the decisions.","",""
0,"S. Robinson, Thanos Alifantis, J. Edwards, J. Ladbrook, A. Waller","Institutional Repository Knowledge-based improvement : simulation and arti cial intelligence for identifying and improving human decision-making in an operations system",2017,"","","","",143,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,5,5,"The performance of most operations systems is significantly affected by the interaction of human decision-makers. A methodology, based on the use of visual interactive simulation (VIS) and artificial intelligence (AI), is described that aims to identify and improve human decision-making in operations systems. The methodology, known as 'knowledge based improvement' (KBI), elicits knowledge from a decision-maker via a VIS and then uses AI methods to represent the decision-making. By linking the VIS and AI representation it is possible to predict the performance of the operations system under different decision-making strategies and to search for improved strategies. The KBI methodology is applied to the decision-making surrounding unplanned maintenance operations at a Ford Motor Company engine assembly plant.","",""
0,"R. Stottler, J. Mao","Automatic Satellite Telemetry Analysis for SSA using Artificial Intelligence Techniques",2017,"","","","",144,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,2,5,"In April 2016, General Hyten, commander of Air Force Space Command, announced the Space Enterprise Vision (SEV) (http://www.af.mil/News/Article-Display/Article/719941/hyten-announces-space-enterprise-vision/). The SEV addresses increasing threats to space-related systems. The vision includes an integrated approach across all mission areas (communications, positioning, navigation and timing, missile warning, and weather data) and emphasizes improved access to data across the entire enterprise and the ability to protect space-related assets and capabilities. ""The future space enterprise will maintain our nation's ability to deliver critical space effects throughout all phases of conflict,"" Hyten said. Satellite telemetry is going to become available to a new audience. While that telemetry information should be valuable for achieving Space Situational Awareness (SSA), these new satellite telemetry data consumers will not know how to utilize it. We were tasked with applying AI techniques to build an infrastructure to process satellite telemetry into higher abstraction level symbolic space situational awareness and to initially populate that infrastructure with useful data analysis methods. We are working with two organizations, Montana State University (MSU) and the Air Force Academy, both of whom control satellites and therefore currently analyze satellite telemetry to assess the health and circumstances of their satellites. The design which has resulted from our knowledge elicitation and cognitive task analysis is a hybrid approach which combines symbolic processing techniques of Case-Based Reasoning (CBR) and Behavior Transition Networks (BTNs) with current Machine Learning approaches. BTNs are used to represent the process and associated formulas to check telemetry values against anticipated problems and issues. CBR is used to represent and retrieve BTNs that represent an investigative process that should be applied to the telemetry in certain circumstances. Machine Learning is used to learn normal patterns of telemetry, learn pre-mission simulated telemetry patterns that represent known problems, and detect both pre-trained known and unknown abnormalities in real-time. The operational system is currently being implemented and applied to real satellite telemetry data. This paper presents the design, examples, and results of the first version as well as planned future work.","",""
2,"M. S. Yakoot, A. Ragab, O. Mahmoud","Multi-Class Taxonomy of Well Integrity Anomalies Applying Inductive Learning Algorithms: Analytical Approach for Artificial-Lift Wells",2021,"","","","",145,"2022-07-13 09:21:51","","10.2118/206129-ms","","",,,,,2,2.00,1,3,1,"  Well integrity has become a crucial field with increased focus and being published intensively in industry researches. It is important to maintain the integrity of the individual well to ensure that wells operate as expected for their designated life (or higher) with all risks kept as low as reasonably practicable, or as specified. Machine learning (ML) and artificial intelligence (AI) models are used intensively in oil and gas industry nowadays. ML concept is based on powerful algorithms and robust database. Developing an efficient classification model for well integrity (WI) anomalies is now feasible because of having enormous number of well failures and well barrier integrity tests, and analyses in the database.  Circa 9000 dataset points were collected from WI tests performed for 800 wells in Gulf of Suez, Egypt for almost 10 years. Moreover, those data have been quality-controlled and quality-assured by experienced engineers. The data contain different forms of WI failures. The contributing parameter set includes a total of 23 barrier elements.  Data were structured and fed into 11 different ML algorithms to build an automated systematic tool for calculating imposed risk category of any well. Comparison analysis for the deployed models was performed to infer the best predictive model that can be relied on. 11 models include both supervised and ensemble learning algorithms such as random forest, support vector machine (SVM), decision tree and scalable boosting techniques. Out of 11 models, the results showed that extreme gradient boosting (XGB), categorical boosting (CatBoost), and decision tree are the most reliable algorithms. Moreover, novel evaluation metrics for confusion matrix of each model have been introduced to overcome the problem of existing metrics which don't consider domain knowledge during model evaluation.  The innovated model will help to utilize company resources efficiently and dedicate personnel efforts to wells with the high-risk. As a result, progressive improvements on business, safety, environment, and performance of the business. This paper would be a milestone in the design and creation of the Well Integrity Database Management Program through the combination of integrity and ML.","",""
29,"S. Robinson, Thanos Alifantis, J. Edwards, J. Ladbrook, A. Waller","Knowledge-based improvement: simulation and artificial intelligence for identifying and improving human decision-making in an operations system",2005,"","","","",146,"2022-07-13 09:21:51","","10.1057/palgrave.jors.2601915","","",,,,,29,1.71,6,5,17,"","",""
2,"I. Becerra-Fernandez","Findings from the Florida Artificial Intelligence Research Symposium (FLAIRS) Knowledge Management Track",1999,"","","","",147,"2022-07-13 09:21:51","","","","",,,,,2,0.09,2,1,23,"This paper presents a summary of the invited presentations at the 1999 Florida Artificial Intelligence Research Symposium (FLAIRS) Knowledge Management (KM) track. This track focuses on the effective design and development of state of the art KM applications. The goal of this track is to continue a longterm effort in integrating works that address important issues and current unsolved problems with regard to research in KM, and publicizing the contribution of AI in KM by maintaining contacts and advertising sharable resources (mailing list, archives, Web site, etc.). Furthermore this track attempts to determine what is common in all Knowledge Management domains so that the KM community can further this work. It has been observed that KM Systems underway at most organizations fall into three categories: Educational KM systems, Knowledge repositories, and Problem solving KM systems. State of the art applications in all three categories were presented in this track. The applications presented included an invited presentation on a research tool to elicit and capture the knowledge of experts, a paper on the development of an application to identify experts in the State of Florida State University System, and a paper on the use of Conversational Case-Based Reasoning for Problem-Solving Knowledge Management Systems. Finally, the track included an invited presentation describing KM initiatives at NASAKennedy Space Center.","",""
24,"Sebastian Bader, P. Hitzler, Steffen Hölldobler","The Integration of Connectionism and First-Order Knowledge Representation and Reasoning as a Challenge for Artificial Intelligence",2004,"","","","",148,"2022-07-13 09:21:51","","","","",,,,,24,1.33,8,3,18,"Intelligent systems based on first-order logic on the one hand, and on artificial neural networks (also called connectionist systems) on the other, differ substantially. It would be very desirable to combine the robust neural networking machinery with symbolic knowledge representation and reasoning paradigms like logic programming in such a way that the strengths of either paradigm will be retained. Current state-of-the-art research, however, fails by far to achieve this ultimate goal. As one of the main obstacles to be overcome we perceive the question how symbolic knowledge can be encoded by means of connectionist systems: Satisfactory answers to this will naturally lead the way to knowledge extraction algorithms and to integrated neural-symbolic systems.","",""
101,"J. Mira, José Ramón Álvarez-Sánchez","Artificial Intelligence and Knowledge Engineering Applications: A Bioinspired Approach: First International Work-Conference on the Interplay Between Natural and Artificial Computation, IWINAC 2005, Las Palmas, Canary Islands, Spain, June 15-18, 2005, Proceedings, Part II",2005,"","","","",149,"2022-07-13 09:21:51","","10.1007/b137296","","",,,,,101,5.94,51,2,17,"","",""
150,"C. Yan, Liang Li, Chunjie Zhang, Bingtao Liu, Yongdong Zhang, Qionghai Dai","Cross-Modality Bridging and Knowledge Transferring for Image Understanding",2019,"","","","",150,"2022-07-13 09:21:51","","10.1109/TMM.2019.2903448","","",,,,,150,50.00,25,6,3,"The understanding of web images has been a hot research topic in both artificial intelligence and multimedia content analysis domains. The web images are composed of various complex foregrounds and backgrounds, which makes the design of an accurate and robust learning algorithm a challenging task. To solve the above significant problem, first, we learn a cross-modality bridging dictionary for the deep and complete understanding of a vast quantity of web images. The proposed algorithm leverages the visual features into the semantic concept probability distribution, which can construct a global semantic description for images while preserving the local geometric structure. To discover and model the occurrence patterns between intra- and inter-categories, multi-task learning is introduced for formulating the objective formulation with Capped-$\ell _{1}$ penalty, which can obtain the optimal solution with a higher probability and outperform the traditional convex function-based methods. Second, we propose a knowledge-based concept transferring algorithm to discover the underlying relations of different categories. This distribution probability transferring among categories can bring the more robust global feature representation, and enable the image semantic representation to generalize better as the scenario becomes larger. Experimental comparisons and performance discussion with classical methods on the ImageNet, Caltech-256, SUN397, and Scene15 datasets show the effectiveness of our proposed method at three traditional image understanding tasks.","",""
9,"R. Das, Ameya Godbole, S. Dhuliawala, M. Zaheer, A. McCallum","A Simple Approach to Case-Based Reasoning in Knowledge Bases",2020,"","","","",151,"2022-07-13 09:21:51","","10.24432/C52S3K","","",,,,,9,4.50,2,5,2,"We present a surprisingly simple yet accurate approach to reasoning in knowledge graphs (KGs) that requires \emph{no training}, and is reminiscent of case-based reasoning in classical artificial intelligence (AI).  Consider the task of finding a target entity given a source entity and a binary relation.  Our approach finds multiple \textit{graph path patterns} that connect similar source entities through the given relation, and looks for pattern matches starting from the query source.  Using our method, we obtain new state-of-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122.  We also demonstrate that our model is robust in low data settings, outperforming recently proposed meta-learning approaches.","",""
12,"Xinxin Jiang, Shirui Pan, Guodong Long, Fei Xiong, Jing Jiang, Chengqi Zhang","Cost-Sensitive Parallel Learning Framework for Insurance Intelligence Operation",2019,"","","","",152,"2022-07-13 09:21:51","","10.1109/TIE.2018.2873526","","",,,,,12,4.00,2,6,3,"Recent advancements in artificial intelligence are providing the insurance industry with new opportunities to create tailored solutions and services based on newfound knowledge of consumers, and the execution of enhanced operations and business functions. However, insurance data are heterogeneous, and imbalanced class distribution with low frequency and high dimensions, which presents four major challenges to machine learning in real-world business. Traditional machine learning algorithms can typically apply to standard data sets, which are normally homogeneous and balanced. In this paper, we focus on an efficient cost-sensitive parallel learning framework (CPLF) to enhance insurance operations with a deep learning approach that does not require preprocessing. Our approach comprises a novel, unified, end-to-end cost-sensitive parallel neural network that learns real-world heterogeneous data. A specifically designed cost-sensitive matrix then automatically generates a robust model for learning minority classifications, and the parameters of both the cost-sensitive matrix and the hybrid neural network are alternately but jointly optimized during training. We also study the CPLF-based architecture for a real-world insurance intelligence operation system, and demonstrate fraud detection and policy renewal experiments on this system. The results of comparative experiments on real-world insurance data sets reflecting actual business cases demonstrate the effectiveness of our design.","",""
0,"E. Gibaja, R. Pérez","3 KNOWLEDGE ACQUISITION AND ELICITATION",2010,"","","","",153,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,2,12,"The application of Artificial Intelligence (AI) techniques to the problem of botanical identification is not particularly widespread even less so on Internet. There are several interactive identification systems but they usually deal with raw knowledge so it appears that “research and development of web-based expert systems are still in their early stage” (Li et al., 2002). In this paper we present the G.R.E.E.N. (Gymnosperms Remote Expert Executed over Network) system as an expert system for the identification of Iberian Gymnosperms which allows on-line uncertainty queries to be made. The system is operative and it can be consulted in http://drimys.ugr.es/experto/index.html.","",""
0,"V. Lemaire, J. Lamirel, Pascal Cuxac","AIL Active and Incremental Learning August 27 , 2012 , Montpellier , France ECAI 2012 – 20 TH European Conference on Artificial Intelligence",2012,"","","","",154,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,3,10,"Most machine learning techniques assume, either explicitly or implicitly, that the data-generating process is stationary. This assumption guarantees that the model learnt during the initial training phase remains valid over time and that its performance is in line with our expectations. Unfortunately, this assumption does not truly hold in the real world representing, in many cases, a simplistic approximation of the reality. The talk will describe the Just-In-Time (JIT) approach that is a flexible tool implementing the detection/adaptation paradigm to cope with evolving processes. Solutions following this approach improve the knowledge about the model in stationary conditions by exploiting additional information coming from the field during the operational life. Differently, in nonstationary conditions, as soon as a change in the data-generating process is detected, the learnt model is discarded and a suitable one activated to keep the performance. As a valuable and challenging application of the proposed approach, JIT classifiers for concept drift will be detailed and discussed. Incremental Decision Tree based on order statistics Christophe Salperwyck1 and Vincent Lemaire2 Abstract. New application domains generate data which are not persistent anymore but volatile: network management, web profile modeling... These data arrive quickly, massively and are visible just once. Thus they necessarily have to be learnt according to their arrival orders. For classification problems online decision trees are known to perform well and are widely used on streaming data. In this paper, we propose a new decision tree method based on order statistics. The construction of an online tree usually needs summaries in the leaves. Our solution uses bounded error quantiles summaries. A robust and performing discretization or grouping method uses these summaries to provide, at the same time, a criterion to find the best split and better density estimations. This estimation is then used to build a naı̈ve Bayes classifier in the leaves to improve the prediction in the early learning stage. New application domains generate data which are not persistent anymore but volatile: network management, web profile modeling... These data arrive quickly, massively and are visible just once. Thus they necessarily have to be learnt according to their arrival orders. For classification problems online decision trees are known to perform well and are widely used on streaming data. In this paper, we propose a new decision tree method based on order statistics. The construction of an online tree usually needs summaries in the leaves. Our solution uses bounded error quantiles summaries. A robust and performing discretization or grouping method uses these summaries to provide, at the same time, a criterion to find the best split and better density estimations. This estimation is then used to build a naı̈ve Bayes classifier in the leaves to improve the prediction in the early learning stage.","",""
7,"Qianqian Song, Jing Su, Wei Zhang","scGCN: a Graph Convolutional Networks Algorithm for Knowledge Transfer in Single Cell Omics",2020,"","","","",155,"2022-07-13 09:21:51","","10.1101/2020.09.13.295535","","",,,,,7,3.50,2,3,2,"Single-cell omics represent the fastest-growing genomics data type in the literature and the public genomics repositories. Leveraging the growing repository of labeled datasets and transferring labels from existing datasets to newly generated datasets will empower the exploration of the single-cell omics. The current label transfer methods have limited performance, largely due to the intrinsic heterogeneity and extrinsic differences between datasets. Here, we present a robust graph-based artificial intelligence model, single-cell Graph Convolutional Network (scGCN), to achieve effective knowledge transfer across disparate datasets. Benchmarked with other label transfer methods on totally 30 single cell omics datasets, scGCN has consistently demonstrated superior accuracy on leveraging cells from different tissues, platforms, and species, as well as cells profiled at different molecular layers. scGCN is implemented as an integrated workflow as a python software, which is available at https://github.com/QSong-github/scGCN.","",""
4,"M. Gates, Mukesh Ambani","Non-Parametric Reasoning on Knowledge Bases",2020,"","","","",156,"2022-07-13 09:21:51","","","","",,,,,4,2.00,2,2,2,"We present a surprisingly simple yet accurate approach to reasoning in knowledge graphs (KGs) that requires no training, and is reminiscent of case-based reasoning in classical artificial intelligence (AI). Consider the task of finding a target entity given a source entity and a binary relation. Our approach finds multiple graph path patterns that connect similar source entities through the given relation, and looks for pattern matches starting from the query source. Using our method, we obtain new state-of-the-art accuracy, outperforming all previous models, on NELL-995 and FB-122. We also demonstrate that our model is robust in low data settings, outperforming recently proposed meta-learning approaches.","",""
6,"Yuchuan Fu, Changle Li, F. Yu, T. Luan, Yao Zhang","An Autonomous Lane-Changing System With Knowledge Accumulation and Transfer Assisted by Vehicular Blockchain",2020,"","","","",157,"2022-07-13 09:21:51","","10.1109/JIOT.2020.2994975","","",,,,,6,3.00,1,5,2,"Inappropriate lane following and changing behaviors of connected and autonomous vehicles (CAVs) can result in accidents, such as rear-end collision and side collision. To remedy that, the use of deep reinforcement learning (DRL) for autonomous driving decisions is currently a widely used promising solution. In this case, the accuracy and effectiveness of such a machine learning (ML) model is quite essential for this artificial intelligence (AI)-enabled CAVs. This article proposes a blockchain-based collective learning (BCL) framework for autonomous lane-changing systems. Four key issues, namely, learning efficiency, data security, users’ privacy, as well as communication burden, are addressed by applying collective learning, vehicular blockchain, and knowledge transfer. First, we model the lane-changing problem as a DRL process and learn the autonomous lane-changing strategy through the deep deterministic policy gradient (DDPG) algorithm. Second, a single CAV involves a limited number of driving scenarios, and the independent learning method has the problem of inefficiency. Therefore, we propose a collective learning framework to utilize the “collective intelligence” shared by CAVs. Third, a vehicular blockchain is then applied to ensure the security and privacy of the user and data. In addition, the introduction of the blockchain can incentivize more users to participate in collective learning. Finally, in order to accelerate the learning process and achieve higher level performance while further reducing the communication burden, we use the corresponding knowledge extracted from the ML model such as human learning, as privileged information for sharing instead of directly sharing local ML models. Extensive simulation results validate the effectiveness and efficiency of our proposal in terms of learning efficiency, driving safety, as well as system security and robustness.","",""
44,"O. Santos, J. Boticario","User‐centred design and educational data mining support during the recommendations elicitation process in social online learning environments",2015,"","","","",158,"2022-07-13 09:21:51","","10.1111/exsy.12041","","",,,,,44,6.29,22,2,7,"Social online learning environments provide new recommendation opportunities to meet users' needs. However, current educational recommender systems do not usually take advantage of these opportunities. To progress on this issue, we have proposed a knowledge engineering approach based on human–computer interaction (i.e. user‐centred design as defined by the standard ISO 9241‐210:2010) and artificial intelligence techniques (i.e. data mining) that involve educators in the process of eliciting educational oriented recommendations. To date, this approach differs from most recommenders in education in focusing on identifying relevant actions to be recommended on e‐learning services from a user‐centric perspective, thus widening the range of recommendation types. This approach has been used to identify 32 recommendations that consider several types of actions, which focus on promoting active participation of learners and on strengthening the sharing of experiences among peers through the usage of the social services provided by the learning environment. The paper describes where data mining techniques have been applied to complement the user‐centred design methods to produce social oriented recommendations in online learning environments.","",""
4,"Natalie Clewley, L. Dodd, Victoria Smy, Annamaria Witheridge, P. Louvieris","Eliciting Expert Knowledge to Inform Training Design",2019,"","","","",159,"2022-07-13 09:21:51","","10.1145/3335082.3335091","","",,,,,4,1.33,1,5,3,"Purpose: To determine the elicitation methodologies best placed to uncover and capture the expert operator’s reflective cognitive judgements in complex and dynamic military operating environments (e.g., explosive ordinance disposal) in order to develop the specification for a reflective eXplainable Artificial Intelligence (XAI) agent to support the training of domain novices. Approach: A bounded literature review of the latest developments in expert knowledge elicitation was undertaken to determine the ’art-of-the-possible’ in respects to uncovering an expert’s cognitive judgements in complex and dynamic environments. Candidate methodologies were systematically and critically reviewed in order to identify the most promising methodologies for uncovering expert situational awareness and metacognitive evaluations in pursuit of actionable threat mitigation strategies in high-risk contexts. Research outputs are synthesized into an interview protocol for eliciting and understanding the in-situ actions and decisions of experts in high-risk, complex operating environments. Practical implications: Trainees entering high-risk operating environments can benefit from exposure to expert reflective strategies whilst learning the trade. Typical operator training focuses on technical aspects of threat mitigation but often overlooks reflective self-evaluation. The present study represents an initial step towards determining the feasibility of designing a reflective XAI agent to augment the performance of trainees entering high-risk operations. Outputs of the expert knowledge elicitation protocol documented here shall be used to refine a theoretical framework of expert operator judgement, in order to determine decision support strategies of benefit to domain novices.","",""
1,"Sukumar Rajendran, Prabhu Jayagopal","Learnability of Interestingness with Semantic Similarity and Reasoning in the Knowledge Base of Decision Support Systems",2020,"","","","",160,"2022-07-13 09:21:51","","10.4018/ijwp.2020010103","","",,,,,1,0.50,1,2,2,"The evolution of deep learning blended with GPU/TPU has elicited faster computation and assimilation of Big Data at a rapid pace with the exponential learning rate of models. Mobile technologies and cloud-based services are yielding massive data irrespective of geographic location at a rapid pace. Integrating the available plethora of data to find a semantic similarity while providing a rapid response without compromising on the quantity and quality of data is a prime concern. Learning from semantic similarity, utility algorithms turn this data into machine perceivable information, through learnability and utilization of Senticnet. The retainability of knowledge still has its own set of specific needs in terms of different machine learning and artificial intelligence algorithms. Utilization of the semantic similarity for ontology-based learning with interoperability helps preserve privacy for decoding the control attributes. The aspect of learning may further extend for rapidly generated sensor data through things and mobile devices.","",""
0,"Gregory A. Luhan","Scaling Intelligence",2021,"","","","",161,"2022-07-13 09:21:51","","10.1080/24751448.2021.1967048","","",,,,,0,0.00,0,1,1,"T A D 5 : 2 Intelligence without action is inert. As the solicited contributions to this volume demonstrate, actionable intelligence relies on a common ground from which architecture and allied disciplines can leverage depths and breadths of knowledge to mobilize new technologies. The Op/Positions essays examine preexisting local knowledge in historical places, enhance discovery through systems-based workflows, and foster the transformational shift from invisible smartness to holistic, design trade-offs that produce more humane and cooperative cities. As Jyoti Hosagrahar notes, place-intelligence provides current generations with a scalable and reflective framework that values the past, promotes deeper foundations, and connects resilient community design and well-being to informed decision-making. Similarly, Azam Khan posits a systems-based approach for leveraging existing knowledge to solve increasingly complex problems holistically. The emergent metaheuristic tools expand architectural design ability, enhance discovery, and yield more energy-efficient and less wasteful buildings. Norbert Streitz advocates for resetting priorities at an urban scale and generating principles that simultaneously privilege the individual and the collective. The resulting types of affordances and ethical alignments could balance data harvesting with people’s need for interactive, communicative, and cooperative spaces and places. The Research Methodology contributions critically examine a site’s latent potential and propose challenging new ways for testing and improving the lived condition at all scales. Whether at the intimate scale of one human-robot interaction or applied to industry-level protocols or full-scale testing scenarios, real-world applied research design necessitates collecting and analyzing large data sets. Jim Tørresen examines predictive intelligent system design, comprising ethical sensor data collection, robot interaction, and human-centric artificial intelligence to anticipate and respond to elderly care needs. Integrating artificial intelligence and problem-solving best practices can interactively adapt to a user’s needs and draw upon years of industry-based construction knowledge. Lukas Kirner, Elisa Lublasser, and Sigrid Brell-Cokcan developed enhanced methods for elevating existing construction industry processes through interdisciplinary collaboration, robot-assisted interaction, laboratory experimentation, factoryto-field investigation, and full-scale testing. The jump from laboratory experiments to full-scale prototyping requires the refinement of previous data exchanges and information flows to produce generalizable results. Maintaining quantitative and qualitative data research design, controlled trials, and procedural rigor requires close monitoring and comparison of real-time data collections and digital simulations. In their Details+ contribution, Jonathan Heppner and Thomas Robinson deployed intelligent testing on an innovative post-tensioned, gravity-resistant, and lateral force-resistant rocking wall system at full scale and detail level. The lab-tested results generated valuable insights into damage-resistant construction methods, informed broader building practices, and demonstrated that their previously unproven assembly could prevent massive failure and save lives. Increasing the use of enhanced digital/computational methods brings renewed attention to gaining greater control over the software and tools used to generate and validate design decisions at all scales. Re/Views addresses these issues, examines interoperable software platforms, compares gaming engines, integrates sensors, and surveys current, emerging, and projected use of autonomous robots across the AEC industry. Karen Kensek presents strategies for improving workflows and overcoming software limitations through customizable add-in solutions for existing Building Information Modeling processes. Enhanced parametric interoperability and data functionality, streamlined procedures, and verified code-compliance bolster deliberative intelligence. Christopher Morse compares game engines that combine visualization, communication, and design in robust, adaptable, flexible, real-time, and interactive environments. Immersive, customizable, connective, and cloud-based integration inform architectural research and professional practice. Peter Kerr investigates scalable interactions with technology, examining affordances and benefits of sensor nodes connected via intelligent Building Management Systems (iBMS). Alvise Simondetti, Nicholas Bachand, Aifric Delahunty, James Griffith, and Julius Sustarevas examine the unfolding paradigm shift toward autonomous robotics, artificial intelligence, and machine learning as architecture moves beyond task-specific operations to inform scalable and sustainable design that augment and complement human capabilities. As shown by these authors, in its performative function, and when viewed through the prismatic lenses of technology, architecture, and design, scaling intelligence successfully narrows the gap between empirical observation, applied research, and professional practice. Scaling Intelligence","",""
3,"F. Lécué, B. Abeloos, Jonathan Anctil, Manuel Bergeron, Damien Dalla-Rosa, Simon Corbeil-Letourneau, Florian Martet, Tanguy Pommellet, L. Salvan, Simon Veilleux, M. Ziaeefard","Thales XAI Platform: Adaptable Explanation of Machine Learning Systems - A Knowledge Graphs Perspective",2019,"","","","",162,"2022-07-13 09:21:51","","","","",,,,,3,1.00,0,11,3,"Explanation in Machine Learning systems has been identified to be the main asset to have for large scale deployment of Artificial Intelligence (AI) in critical systems. Explanations could be example-, features-, semantics-based or even counterfactual to potentially action on an AI system; they could be represented in many different ways e.g., textual, graphical, or visual. All representations serve different means, purpose and operators. We built the first-of-its-kind XAI (eXplainable AI) platform for critical systems i.e., Thales XAI Platform which aims at serving explanations through various forms. This paper emphasizes on the semantics-based explanations for Machine Learning systems. 1 Explainable AI in Critical Systems Motivation: The current hype of Artificial Intelligence (AI) mostly refers to the success of Machine Learning (ML) and its sub-domain of deep learning. However industries operating with critical systems are either highly regulated, or require high level of certification and robustness. Therefore, such industry constraints do limit the adoption of non deterministic and ML systems. Answers to the question of explainability will be intrinsically connected to the adoption of AI in industry at scale. Indeed explanation, which could be used for debugging intelligent systems or deciding to follow a recommendation in real-time, will increase acceptance and (business) user trust. Explainable AI (XAI) is now referring to the core backup for industry to apply AI in products at scale, particularly for industries operating with critical systems. Focus: Thales XAI Platform is designed to provide explanation for a ML task (classification, regression, object detection, segmentation). Although Thales XAI Platform does provide different levels of explanation e.g., example-based, featuresbased, counterfactual using textual and visual representations, we emphasis only on the semantics-based explanation through knowledge graphs. ? Copyright c © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). Critical Applications: From adapting a plane trajectory, stopping a train, refitting a boat to reconfiguring a satellite, all are examples of critical situations where explanation is a must-to-have to follow an AI system decision. 2 Why Knowledge Graphs for Explainable AI? State-of-the-Art Limitations: Most approaches limits explanation of ML systems to features involved in the data and model, or at best to examples, prototypes or counterfactuals. Explanation should go beyond correlation (features importance) and numerical similarity (local explanation). Opportunity: By expanding and linking initial (training, validation and test) data with entities in knowledge graphs, (i) context is encoded, (ii) connections and relations are exposed, and (iii) inference and causation are natively supported. Knowledge graphs are used for encoding better representation of data, structuring a ML model in a more interpretable way, and adopt a semantic similarity for local (instance-based) and global (model-based) explanation. 3 Thales XAI Platform: A Knowledge Graph Perspective (Semantic) Perspective: The platform is combining ML and reasoning functionalities to expose a human-like rational as explanation when (i) recognizing an object (in a raw image) of any class in a knowledge graph, (ii) predicting a link in a knowledge graph. Thales XAI Platform is using state-of-the-art Semantic Web tools for enriching input, output (class) data with DBpedia (4, 233, 000 resources) and domain-specific knowledge graphs, usually enterprise knowledge graphs. This is a crucial step for contextualizing training, validation, test data. Explainable ML Classifications: Starting from raw images, as unstructured data, but with class labels augmented with a domain knowledge graph, Thales XAI Platform relies on existing neural network architectures to build the most appropriate models. All confidence scores of output classes on any input image are updated based on the semantic description of the output classes. For instance, an input classified as a car will have a higher overall confidence score in case some properties of car in the knowledge graph are retrieved e.g., having wheels, being on a road. In addition the platform is embedding naturally explanation i.e., properties of the objects retrieved in both the raw data and knowledge graph. Explainable Relational Learning: Starting from relational data, structured as graph, and augmented with a domain knowledge graph, Thales XAI Platform relies on existing knowledge graph embeddings frameworks to build the most appropriate models. Explanation of any link prediction is retrieved by identifying representative hotspots in the knowledge graph i.e., connected parts of the graphs that negatively impact prediction accuracy when removed.","",""
1,"Yijie Peng, Li Xiao, B. Heidergott, L. Hong, H. Lam","A New Likelihood Ratio Method for Training Artificial Neural Networks",2021,"","","","",163,"2022-07-13 09:21:51","","10.1287/ijoc.2021.1088","","",,,,,1,1.00,0,5,1,"We investigate a new approach to compute the gradients of artificial neural networks (ANNs), based on the so-called push-out likelihood ratio method. Unlike the widely used backpropagation (BP) method that requires continuity of the loss function and the activation function, our approach bypasses this requirement by injecting artificial noises into the signals passed along the neurons. We show how this approach has a similar computational complexity as BP, and moreover is more advantageous in terms of removing the backward recursion and eliciting transparent formulas. We also formalize the connection between BP, a pivotal technique for training ANNs, and infinitesimal perturbation analysis, a classic path-wise derivative estimation approach, so that both our new proposed methods and BP can be better understood in the context of stochastic gradient estimation. Our approach allows efficient training for ANNs with more flexibility on the loss and activation functions, and shows empirical improvements on the robustness of ANNs under adversarial attacks and corruptions of natural noises. Summary of Contribution: Stochastic gradient estimation has been studied actively in simulation for decades and becomes more important in the era of machine learning and artificial intelligence. The stochastic gradient descent is a standard technique for training the artificial neural networks (ANNs), a pivotal problem in deep learning. The most popular stochastic gradient estimation technique is the backpropagation method. We find that the backpropagation method lies in the family of infinitesimal perturbation analysis, a path-wise gradient estimation technique in simulation. Moreover, we develop a new likelihood ratio-based method, another popular family of gradient estimation technique in simulation, for training more general ANNs, and demonstrate that the new training method can improve the robustness of the ANN.","",""
8,"R. Seidlová, J. Poživil, Jaromír Seidl","Marketing and business intelligence with help of ant colony algorithm",2019,"","","","",164,"2022-07-13 09:21:51","","10.1080/0965254X.2018.1430058","","",,,,,8,2.67,3,3,3,"Abstract Recently, there is increasing need of banks for targeting and acquiring new customers, for fraud detection in real time and for segmentation products through analysis of the customers. Doing it, they can serve their customers better, and can increase the effectiveness of the company. For this purpose, various data mining methods are used which enable extraction of interesting, nontrivial, implicit, previously unknown, and potentially useful patterns or knowledge from huge amounts of data. Traditional data mining methods include classification rule tasks, for their solution there are a number of methods. Among them can be mentioned, for example, Random forest algorithm or C4.5 algorithm. However, accuracy of these methods significantly reduces in the event that some data in databases is missing. These methods are always not optimal for very large databases. The aim of our work is to verify a possible solution of these problems by using the algorithm based on artificial ant colonies. This algorithm was successful in other areas. Therefore, we tested its applicability and accuracy in marketing and business intelligence and compared it with so far used methods. The experimental results showed that the presented algorithm is very effective, robust, and suitable for processing of very large files. It was also found that this algorithm overcomes the previously used algorithms in accuracy. Algorithm is easily implementable on different platforms and can be recommended for using in banking and business intelligence.","",""
0,"P. Grenier, I. Álvarez, Jean-Marie Roger, V. Steinmetz","ARTIFICIAL INTELLIGENCE IN WINE-MAKING L ’ INTELLIGENCE ARTIFICIELLE EN ŒNOLOGIE",2008,"","","","",165,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,4,14,"In this paper, some terms of Artificial Intelligence are defined. Some present and potential applications of knowledge based systems are presented in the field of wine-making. Areas of concern were: multi sensor fusion, prediction by model cooperation, and diagnosis. Artificial intelligence techniques can indeed be applied for aiding the wine-maker in his choices. They facilitate the combination between experience and recent progress in technology. When associated with statistical processing, they allow knowledge sources to be used more effectively. Beyond wine-making, the prospects of artificial intelligence are promising for research and food industry, especially for improving the robustness of measurement systems (multi-sensors, sensors interpreted or validated by models), and for process diagnosis (risk prediction, action proposal). Résumé : Certains termes d’Intelligence Artificielle (IA) sont définis dans cette publication. Quelques applications en cours ou potentielles de systèmes fondés sur la connaissance sont présentés dans le domaine de la vinification. Les domaines d’étude sont : la fusion multi-capteurs, la prédiction par coopération de modèles, et le diagnostic. Les techniques IA peuvent aider le vinificateur dans ses choix par une symbiose entre expérience et progrès technologiques. En association avec des traitements statistiques, ces techniques permettent une utilisation plus efficace des sources de connaissances. Au-delà de la vinification, les perpectives de l’intelligence artificielle sont prometteuses en industrie alimentaire, en particulier pour améliorer la robustesse d’un système de mesure (fustion de capteurs, validation d’un capteur par un modèle) ou pour élaborer un diagnostic sur l’évolution d’un procédé (prédiction de risques, proposition d’intervention).","",""
63,"Alexander Gelbukh, C. Reyes-García","MICAI 2006: Advances in Artificial Intelligence, 5th Mexican International Conference on Artificial Intelligence, Apizaco, Mexico, November 13-17, 2006, Proceedings",2006,"","","","",166,"2022-07-13 09:21:51","","10.1007/11925231","","",,,,,63,3.94,32,2,16,"","",""
199,"R. Luckin, Wayne Holmes","Intelligence Unleashed: An argument for AI in Education",2016,"","","","",167,"2022-07-13 09:21:51","","","","",,,,,199,33.17,100,2,6,"This paper on artificial intelligence in education (AIEd) has two aims. The first: to explain to a non-specialist, interested, reader what AIEd is: its goals, how it is built, and how it works. The second: to set out the argument for what AIEd can offer teaching and learning, both now and in the future, with an eye towards improving learning and life outcomes for all. Computer systems that are artificially intelligent interact with the world using capabilities (such as speech recognition) and intelligent behaviours (such as using available information to take the most sensible actions toward a stated goal) that we would think of as essentially human. At the heart of artificial intelligence in education is the scientific goal to make knowledge, which is often left implicit, computationally precise and explicit. In other words, in addition to being the engine behind much ‘smart’ ed tech, AIEd is also designed to be a powerful tool to open up what is sometimes called the ‘black box of learning,’ giving us more fine-grained understandings of how learning actually happens. Although some might find the concept of AIEd alienating, the algorithms and models that underpin ed tech powered by AIEd form the basis of an essentially human endeavor. Using AIEd, teachers will be able to offer learners educational experiences that are more personalised, flexible, inclusive and engaging. Crucially, we do not see a future in which AIEd replaces teachers. What we do see is a future in which the extraordinary expertise of teachers is better leveraged and augmented through the thoughtful deployment of well designed AIEd. We have available, right now, AIEd tools that could support student learning at a scale previously unimaginable by providing one-on-one tutoring to every student, in every subject. Existing technologies also have the capacity to provide intelligent support to learners working in a group, and to create authentic virtual learning environments where students have the right support, at the right time, to tackle real-life problems and puzzles. In the near future, we expect that teaching and learning will increasingly be supported by the thoughtful application of AIEd tools. For example, by lifelong learning companions powered by AI that can accompany and support individual learners throughout their studies - in and beyond school - and new forms of assessment that measure learning while it is taking place, shaping the learning experience in real time. If we are ultimately successful, we predict that AIEd will help us address some of the most intractable problems in education, including achievement gaps and teacher retention. AIEd will also help us respond to the most significant social challenge that AI has already brought - the steady replacement of jobs and occupations with clever algorithms and robots. It is our view that this provides a new innovation imperative in education, which can be expressed simply: as humans live and work alongside increasingly smart machines, our education systems will need to achieve at levels that none have managed to date. True progress will require the development of an AIEd infrastructure. This will not, however, be a single monolithic AIEd system. Instead, it will resemble the marketplace that has developed for smartphone apps: hundreds and then thousands of individual AIEd components, developed in collaboration with educators, conformed to uniform international data standards, and shared with researchers and developers worldwide. These standards will also enable system-level data collation and analysis that will help us to learn much more about learning itself – and how to improve it. Moving forward, we will need to pay close attention to three powerful forces as we map the future of artificial intelligence in education, namely pedagogy, technology, and system change. Paying attention to the pedagogy will mean that the design of new edtech should always start with what we know about learning. It also means that the system for funding this work must be simultaneously opened up and refocused, moving away from isolated pockets of R&D and toward collaborative enterprises that prioritise areas known to make a real difference to teaching and learning. Paying attention to the technology will mean creating smarter demand for commercial grade AIEd products that work. It also means the development of a robust, component-based AIEd infrastructure, similar to the smartphone app marketplace, where researchers and developers can access standardised components that have been developed in collaboration with educators. Paying attention to system change will mean involving teachers, students, and parents in co-designing new tools, so that AIEd will appropriately address the inherent “messiness” of real classroom, university, and workplace learning environments. It also means the development of data standards that promote the safe and ethical use of data. Said succinctly, we need intelligent technologies that embody what we know about great teaching and learning, embodied in enticing consumer grade products, which are then used effectively in real-life settings that combine the best of human and machine. We do not underestimate the new-thinking, inevitable wrong-turns, and effort required to realise these recommendations. However, if we are to properly unleash the intelligence of AIEd, we must do things differently - via new collaborations, sensible funding, and (always) a keen eye on the pedagogy. The potential prize is too great to act otherwise.","",""
0,"Khalid Rabeyee","Computing intelligence technique and multiresolution data processing for condition monitoring",2019,"","","","",168,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,1,3,"Condition monitoring (CM) of rotary machines has gained increasing importance and extensive research in recent years. Due to the rapid growth of data volume, automated data processing is necessary in order to deal with massive data efficiently to produce timely and accurate diagnostic results. Artificial intelligence (AI) and adaptive data processing approaches can be promising solutions to the challenge of large data volume. Unfortunately, the majority of AI-based techniques in CM have been developed for only the post-processing (classification) stage, whereas the critical tasks including feature extraction and selection are still manually processed, which often require considerable time and efforts but also yield a performance depending on prior knowledge and diagnostic expertise.    To achieve an automatic data processing, the research of this PhD project provides an integrated framework with two main approaches. Firstly, it focuses on extending AI techniques in all phases, including feature extraction by applying Componential Coding Neural Network (CCNN) which has been found to have unique properties of being trained through unsupervised learning, capable of dealing with raw datasets, translation invariance and high computational efficiency. These advantages of CCNN make it particularly suitable for automated analyzing of the vibration data arisen from typical machine components such as the rolling element bearings which exhibit periodic phenomena with high non-stationary and strong noise contamination. Then, once an anomaly is detected, a further analysis technique to identify the fault is proposed using a multiresolution data analysis approach based on Double-Density Discrete Wavelet Transform (DD-DWT) which was grounded on over-sampled filter banks with smooth tight frames. This makes it nearly shift-invariant which is important for extracting non-stationary periodical peaks. Also, in order to denoise and enhance the diagnostic features, a novel level-dependant adaptive thresholding method based on harmonic to signal ratio (HSR) is developed and implemented on the selected wavelet coefficients. This method has been developed to be a semi-automated (adaptive) approach to facilitate the process of fault diagnosis. The developed framework has been evaluated using both simulated and measured datasets from typical healthy and defective tapered roller bearings which are critical parts of all rotating machines. The results have demonstrated that the CCNN is a robust technique for early fault detection, and also showed that adaptive DD-DWT is a robust technique for diagnosing the faults induced to test bearings. The developed framework has achieved multi-objectives of high detection sensitivity, reliable diagnosis and minimized computing complexity.","",""
6,"G. Grimes, U. Tanik","Artificial intelligence design framework for optical backplane engineering",2006,"","","","",169,"2022-07-13 09:21:51","","","","",,,,,6,0.38,3,2,16,"The core contribution of this work is a new framework for architecture-driven software engineering of large-scale, agent-based, complex systems for Knowledge-Based Engineering (KBE). This reconfigurable and scalable framework fills a niche between traditional requirements elicitation and design tool implementation. The new architectural framework model, referred to as the Artificial Intelligence Design Framework (AIDF), allows KBE system architects to achieve intellectual control over the high-level development process. Therefore, structural modelers using object-oriented languages can specify the coding requirements based on hierarchical decomposition of functional requirements using axiomatic design principles. The engine block defined by the framework has the capability to utilize networked knowledge repositories available through intelligent agents acting on Web Services for the purpose of design risk mitigation for reliability engineering.  KBE systems produced based on the new architecture framework automates the design and inference processes for reliability engineering using an interlaced dual engine block, developed during the National Aeronautics and Space Administration (NASA) Fellowship. This type of intelligent automation of design support for product engineering can save on development cost and time, while improving on quality. A comprehensive solution is proposed to address this risk mitigation need for reliability engineering using a System-of-Systems (SoS) approach, which consists of a synergistic overlap of many broad topics such as design, agent modeling, and systems engineering. A case study implementation of the AIDF is developed using Acclaro Design for Six Sigma (DFSS) architectural development tool for configuring an optical backplane engineering application with design matrix, optimization, and verification techniques.  The Generic Architecture for Upgradeable Real-time Dependable Systems validation framework is introduced as a validation strategy for post-deployment expansion, after applying DFSS front-end validation during pre-deployment development. In addition to architecture validation, a comprehensive validation approach for a KBE SoS applications using the Synergistic Validation Methodology (SVM) for the AIDF has been developed. In conclusion, an AIDF-SVM is introduced as an architectural framework with a recommended validation methodology that functions as a platform for developing large-scale, reconfigurable and scalable KBE SoS applications.","",""
1,"R. Chbeir, E. Exposito, P. Aniorté","Computational Collective Intelligence: 11th International Conference, ICCCI 2019, Hendaye, France, September 4–6, 2019, Proceedings, Part I",2019,"","","","",170,"2022-07-13 09:21:51","","10.1007/978-3-030-28377-3","","",,,,,1,0.33,0,3,3,"","",""
51,"J. Finlay, A. Dix","An Introduction to Artificial Intelligence",1996,"","","","",171,"2022-07-13 09:21:51","","10.1201/9781003072485","","",,,,,51,1.96,26,2,26,"KNOWLEDGE IN AI Overview Introduction Representing Knowledge Metrics for Assessing Knowledge Representation Schemes Logic Representations Procedural Representation Network Representations Structured Representations General Knowledge The Frame Problem Knowledge Elicitation Summary Exercises Recommended Further Reading REASONING Overview What is Reasoning? Forward and Backward Reasoning Reasoning with Uncertainty Summary Exercises Recommended Further Reading SEARCH Introduction Exhaustive Search and Simple Pruning Heuristic Search Knowledge-Rich Search Summary Exercises Recommended Further Reading MACHINE LEARNING Overview Why Do We Want Machine Learning? How Machines Learn Deductive Learning Inductive Learning Explanation-Based Learning Example: Query-by-Browsing Summary Recommended Further Reading GAME PLAYING Overview Introduction Characteristics of Game Playing Standard Games Non-Zero-Sum Games and Simultaneous Play The Adversary is Life! Probability Summary Exercises Recommended Further Reading EXPERT SYSTEMS Overview What Are Expert Systems? Uses of Expert Systems Architecture of an Expert System Examples of Four Expert Systems Building an Expert System Limitations of Expert Systems Summary Exercises Recommended Further Reading NATURAL LANGUAGE UNDERSTANDING Overview What is Natural Language Understanding? Why Do We Need Natural Language Understanding? Why Is Natural Language Understanding Difficult? An Early Attempt at Natural Language Understanding: SHRDLU How Does Natural Language Understanding Work? Syntactic Analysis Semantic Analysis Pragmatic Analysis Summary Exercises Recommended Further Reading Solution to SHRDLU Problem COMPUTER VISION Overview Introduction Digitization and Signal Processing Edge Detection Region Detection Reconstructing Objects Identifying Objects Multiple Images Summary Exercises Recommended Further Reading PLANNING AND ROBOTICS Overview Introduction Global Planning Local Planning Limbs, Legs, and Eyes Practical Robotics Summary Exercises Recommended Further Reading AGENTS Overview Software Agents Co-operating Agents and Distributed AI Summary Exercises Recommended Further Reading MODELS OF THE MIND Overview Introduction What is the Human Mind? Production System Models Connectionist Models of Cognition Summary Exercises Recommended Further Reading Notes EPILOGUE: PHILOSOPHICAL AND SOCIOLOGICAL ISSUES Overview Intelligent Machines or Engineering Tools? What Is Intelligence? Computational Argument vs. Searle's Chinese Room Who Is Responsible? Morals and Emotions Social Implications Summary Recommended Further Reading","",""
1,"Dr. Pierre Dillenbourg","The role of artificial intelligence techniques in training software",2006,"","","","",172,"2022-07-13 09:21:51","","","","",,,,,1,0.06,1,1,16,"Different motivations led scientists to apply artificial intelligence (AI) techniques to educational software and training software. On one hand, courseware developers were seeking for more powerful techniques for building systems. On the other hand, researchers in computer science and in cognitive psychology found an opportunity to develop and test new techniques or new theoretical models. This second line has probably been the most influential during the eighties. It led to major scientific contributions. For instance, designers transformed the expert system design to develop systems which fulfil the educational functions (explanation, diagnosis, ...) expected in a training software. This work contributed to the elicitation of strategic levels in expertise (Clancey, 1987) and, later, to the emergence of second generation expert systems (Steels, 1990). In others words, research on educational applications helped to develop the methodology for analyzing expertise (knowledge engineering). Similar contributions have been produced in cognitive psychology. The work on learner modelling (trying to infer what the learner knows or misunderstands) has been central to the formalisation and evaluation of cognitive models (Anderson et al, 1989).","",""
110,"C. Kulikowski","Artificial intelligence methods and systems for medical consultation",1980,"","","","",173,"2022-07-13 09:21:51","","10.1109/TPAMI.1980.6592368","","",,,,,110,2.62,110,1,42,"The major AI problems that arise in designing a consultation program involve choices of knowledge representations, diagnostic interpretation strategies, and treatment planning strategies. The need to justify decisions and update the knowledge base in the light of new research findings places a premium on the modularity of a representation and the ease with which its reasoning procedures can be explained. In both diagnosis and treatment decisions, the relative advantages and disadvantages of different schemes for quantifying the uncertainty of inferences raises difficult issues of a formal logical nature, as well as many specific practical problems of system design. An important insight that has resulted from the design of several artificial intelligence systems is that robustness of performance in the presence of many uncertainty relationships can be achieved by eliciting from the expert a segmentation of knowledge that will also provide a rich network of deterministic relationships to interweave the space of hypotheses.","",""
0,"Y. D. Valle, N. Hampton","APPLICATION OF ARTIFICIAL INTELLIGENCE TO THE PROBLEM OF SELECTING THE APPROPRIATE DIAGNOSTIC FOR CABLE SYSTEMS",2011,"","","","",174,"2022-07-13 09:21:51","","","","",,,,,0,0.00,0,2,11,"Cable System Management requires an assessment of the health of the cables system. It is increasingly common for the assessment of aged cable systems to be made through the application of diagnostics measurements. There are a plethora of these techniques and embodiments; such that even an informed user has great difficulty making a rational choice on the most appropriate technique. To aid this decision making a Knowledge Based System has been developed that takes the knowledge of many diverse experts and delivers a robust framework by which rational, reproducible and transparent choices may be made. This paper discusses the development of the system and provides a number of illustrative case studies.","",""
6,"P. Swaby","Integrating Artificial Intelligence and Graphics in a Tool for Microfossil Identification for Use in the Petroleum Industry",1990,"","","","",175,"2022-07-13 09:21:51","","","","",,,,,6,0.19,6,1,32,"This chapter describes an expert system for the identification of micro-fossils. This graphic expert system shell was designed to allow users to enter information about a fossil in pictorial form: On the basis of this information, the system selects a best-match set of fossils. By computerizing knowledge elicitation and entry into the system, it was possible to reduce development time and cost. As a result, the system is cost effective as well as powerful, flexible, and easy to use. The system described here, called Vides (visual identification expert system), was developed to support the process of identifying microfos-sils, including those of Phylum Conodonta (Higgins and Austin 1985) and Phylum Foraminifera (Haynes 1981). Microfossils are the remains of small animals that lived hundreds of millions of years ago and are found in the rock layers during the drilling process of oil exploration.","",""
2,"Sara Rantamäki, J. Antfolk, P. Granhag, P. Santtila, S. Oleszkiewicz","Eliciting intelligence from sources informed about counter‐interrogation strategies: An experimental study on the Scharff technique",2020,"","","","",176,"2022-07-13 09:21:51","","10.1002/jip.1542","","",,,,,2,1.00,0,5,2,"The Scharff technique aims to elicit information by affecting the source's perception of the interviewer's existing knowledge. Although the technique has been found to be effective for gathering new information, countermeasures to the technique have not been examined. In a 2 × 2 between-subjects experiment, we informed half of the 120 sources about the counter-interrogation strategy of carefully considering the interviewer's prior knowledge and the tactic of providing information perceived as already known to the interviewer. After this, sources were interviewed with the Scharff technique or the Direct approach, widely used in human intelligence-gathering situations and consisting of open-ended and direct questions. We found that “informed sources” did not succeed in revealing information already known to the interviewer, where informed sources and uninformed sources revealed known information to a similar degree (1.62 pieces vs. 1.65 pieces). Sources interviewed with the Direct approach (vs. Scharff technique) revealed a larger amount of information previously known to the interviewer (2.18 pieces vs. 1.08 pieces). When interviewed with the Scharff technique, sources informed about the counter-interrogation strategy attempted to adopt more counter-interrogation strategies. The present study replicates earlier research on the Scharff technique as a technique effective in affecting the source's perception of the interviewer's prior knowledge. The results of the current study indicate that both the Scharff technique and the Direct approach might be similarly robust against counter-interrogation strategies, in terms of gathering new information. Future studies should focus on implementing more comprehensive training in counter-interrogation strategies for the sources.","",""
1,"G. Rzevski, R. Adey, D. Russell","Applications of artificial intelligence in engineering IX : proceedings of the ninth international conference, held in Pennsylvania, USA, 19th-21st July, 1994",1994,"","","","",177,"2022-07-13 09:21:51","","","","",,,,,1,0.04,0,3,28,"Neural networks - neural networks in engineering knowledge-based and expert systems - knowledge elicitation for material design expert systems object-oriented design - an object-oriented representation of environmental cracking genetic algorithms - design of HDL programmes for digital systems using genetic algorithms CIM and manufacturing - an active information systems approach to industrial planning scheduling, logic and reasoning - combining evidence in probabilistic reasoning design. (Part contents).","",""
2,"J. Hilton","Some semiotic reflections on the future of artificial intelligence",1993,"","","","",178,"2022-07-13 09:21:51","","10.1080/08839519308949972","","",,,,,2,0.07,2,1,29,"Abstract In this brief article I shall reflect first on the development of a theoretical model of knowledge elicitation and knowledge representation, derived from semiotic theory and from theatrical performance analysis (Hilton, 1989) and then on the application of some of these concepts in the MEDICA project, part of the European Commission AIM program. *These in mm lead to a possible schematization of a complementary three-stage development strategy for Al systems: (1) an expert system, (2) a cognitive support system, and (3) a reflective support system.","",""
0,"John L. Beaven","Dictionary of artificial intelligence by Dennis Mercadal, Chapman and Hall, London, 1990, pp 334, £19.50. ISBN 0 442 00451 6",1991,"","","","",179,"2022-07-13 09:21:51","","10.1017/S0269888900005944","","",,,,,0,0.00,0,1,31,"Dictionary of artificial intelligence reviewed by John L. Beaven, Department of Artificial Intelligence, Edinburgh University, 80 South Bridge, Edinburgh EH1 1HN, UK. Knowledge representation: an approach to artificial intelligence reviewed by John Washbrook, Department of Computer Science, University College, London, UK. An introduction to neural computing reviewed by S Parfitt, Research Fellow, IBM UK Scientific Centre, Winchester, UK. Expert knowledge and explanation reviewed by Professor FH George, Bureau of Information Science, Seer Green, Bucks, UK. Knowledge Elicitation reviewed by Professor FH George, Bureau of Information Science, Seer Green, Bucks, UK. Computers and thought reviewed by Professor FH George, Bureau of Information Science, Seer Green, Bucks, UK. Perspectives in artificial intelligence-Volume 2: Machine translation reviewed by Professor FH George, Bureau of Information Science, Seer Green, Bucks, UK. Computing reviewed by Professor FH George, Bureau of Information Science, Seer Green, Bucks, UK. Expert systems—a manager's guide reviewed by Robert Milne, Intelligent Applications Ltd, Scotland. Artificial experts: social knowledge and intelligent machines reviewed by Richard Ennals, Kingston Business School, Kingston-upon-Thames, UK. Catalogue of artificial intelligence techniques (3rd Edn) reviewed by Simon Parsons, Department of Electronic Engineering, Queen Mary and Westfield College, Mile End Road, London El 4NS, UK. Computational logic reviewed by Simon Parsons, Department of Electronic Engineering, Queen Mary and Westfield College, Mile End Road, London El 4NS, UK. Handbook of genetic algorithms reviewed by GV Conroy, Computation Department, UMIST, Manchester, UK. The integration of expert systems into mainstream software reviewed by Professor R Rada, Department of Computer Science, The University of Liverpool, Liverpool, UK. Knowledge-based approaches for structural design reviewed by Bimal Kumar*, Design Computing Unit, University of Sydney, Sydney NSW 2006, Australia (*On leave from Department of Civil Engineering, Strathclyde University, Glasgow, UK).","",""
5,"M. Selfridge, D. J. Dickerson, S. F. Biggs","Cognitive Expert Systems and Machine Learning: Artificial Intelligence Research at the University of Connecticut",1987,"","","","",180,"2022-07-13 09:21:51","","10.1609/AIMAG.V8I1.577","","",,,,,5,0.14,2,3,35,"In order for next-generation expert systems to demonstrate the performance, robustness, flexibility, and learning ability of human experts, they will have to be based on cognitive models of expert human reasoning and learning. We call such next-generation systems cognitive expert systems. Research at the Artificial Intelligence Laboratory at the University of Connecticut is directed toward understanding the principles underlying cognitive expert systems and developing computer programs embodying those principles. The Causal Model Acquisition System (CMACS) learns causal models of physical mechanisms by understanding real-world natural language explanations of those mechanisms. The going Concern Expert ( GCX) uses business and environmental knowledge to assess whether a company will remain in business for at least the following year. The Business Information System (BIS) acquires business and environmental knowledge from in-depth reading of real-world news stories. These systems are based on theories of expert human reasoning and learning, and thus represent steps toward next-generation cognitive expert systems.","",""
2,"O. Deutsch","Artificial intelligence design challenge - Background, analysis, andrelative performance of algorithms",1988,"","","","",181,"2022-07-13 09:21:51","","10.2514/3.20326","","",,,,,2,0.06,2,1,34,"The Artificial Intelligence Design Challenge was an attempt to stimulate interest in a common problem involving the application of artificial intelligence technology to problems likely to be encountered in planning, scheduling, and battle management. These problems are characterized by high combinatorial complexity, uncertainty, constraints, and, in some cases, requirements for real-time performance on finite-speed processors. Participants in the design challenge submitted competing, alternative approaches, implemented in computer code executable on desktop microcomputers, for assessment and relative evaluation over a range of problems. The range of problems was generated by variation of an input data file at the time of contest judging. The participants were given a priori knowledge of only the range of data variations, and not the specific details. In this manner, robustness to problem variations was evaluated, as was normalized performance of competing algorithms and implementations.","",""
1,"P. Grenier, I. Álvarez, Jean-Marie Roger, V. Steinmetz, P. Barré, J. Sablayrolles","ARTIFICIAL INTELLIGENCE IN WINE-MAKING",2000,"","","","",182,"2022-07-13 09:21:51","","10.20870/OENO-ONE.2000.34.2.1007","","",,,,,1,0.05,0,6,22,"In this paper, some terms of Artificial Intelligence are defined. Some present and potential applications of knowledge based systems are presented in the field of wine-making. Areas of concern were: multi sensor fusion, prediction by model cooperation, and diagnosis. Artificial intelligence techniques can indeed be applied for aiding the wine-maker in his choices. They facilitate the combination between experience and recent progress in technology. When associated with statistical processing, they allow knowledge sources to be used more effectively. Beyond wine-making, the prospects of artificial intelligence are promising for research and food industry, especially for improving the robustness of measurement systems (multi-sensors, sensors interpreted or validated by models), and for process diagnosis (risk prediction, action proposal).","",""
3,"D. Schutzer","Applications of Artificial Intelligence to Military Communications",1983,"","","","",183,"2022-07-13 09:21:51","","10.1109/MILCOM.1983.4794808","","",,,,,3,0.08,3,1,39,"This paper explores the field of artificial intelligence with respect to its application to military communication design problems. In particular it is shown how natural processing languages and knowledge-based system technologies can be used to reduce the required communications capacity and to improve a communication systems robustness and tolerance of errors by trading-off computation for communication. These technologies are also shown to improve the security of a military communications system operation. Other applications of artificial technology include the use of expert system technology to the operation, control and maintenance, and training areas.","",""
1,"J. Delgado-Frias, W. Moore","A wafer-scale architecture for artificial intelligence",1989,"","","","",184,"2022-07-13 09:21:51","","10.1109/WAFER.1989.47543","","",,,,,1,0.03,1,2,33,"The architecture presented exploits the advantages of wafer-scale integration technology and has a defect-tolerant scheme to overcome silicon defects. It is in principle a two-dimensional array that is suited to process semantic network knowledge bases. The defect-tolerance approach is based on a combination of hardware redundancy and robust algorithms run on the architecture. The application that is presented here is the scene labeling that is used in computer vision. Due to the robustness of the scene labeling algorithms the machine can tolerate some hardware faults at run time.<<ETX>>","",""
1,"U. Pai, K. K. Prasad","Open Source Intelligence and its Applications in Next Generation Cyber Security - A Literature Review",2021,"","","","",185,"2022-07-13 09:21:51","","10.47992/ijaeml.2581.7000.0100","","",,,,,1,1.00,1,2,1,"Purpose: Research serves as a springboard for new ideas, and every scholarly research begins with a review of the literature. This literature review to familiarize oneself with the domain of research and to establish the credibility of the work. It also aids in the integration and summarization of the subject. Methodology: The necessary literature on the chosen topic have been gathered from multiple secondary data sources such as journals, conference proceedings, books, research papers published in various reputable publications, and then shortlisted the literature which are relevant for the work. The shortlisted literatures were carefully evaluated by reading each paper and taking notes as needed. The information gathered is then analyzed in order to identify the problem areas that may exist in the chosen topic. Findings/Result: It has been observed that the chosen topic, Opensource Intelligence (OSINT) practice requires more robust and intelligent solutions from AI and its subfields. The capability of OSINT for intelligent analysis strengthens tightly integrating machine learning and automated reasoning techniques. To avoid human errors, the dependency on humans in decision-making ought to reduce. To eradicate any incorrect information, a truth discovery process is mandatory. OSINT is able to discover new knowledge by correlating intelligence from other OSINT sources. Even though Artificial Intelligence has entered the OSINT field, there is still a long way to go before OSINT fully prepares for the much-anticipated Web 3.0. Originality: A literature review have had been carried out using secondary data gathered from various online sources, and new knowledge in the form of findings was derived in order to construct a theoretical framework and methodology for future research. It has been ensured that no judgments or decisions are made with a biased mindset or under the influence of any predetermined mentality. A concerted effort has been made to identify a research topic for further investigation. Paper Type: Literature Review.","",""
18,"D. Ovalle, Diana C. Restrepo, A. Montoya","Artificial Intelligence for Wireless Sensor Networks Enhancement",2010,"","","","",186,"2022-07-13 09:21:51","","10.5772/12962","","",,,,,18,1.50,6,3,12,"Whereas the main objective of Artificial Intelligence is to develop systems that emulate the intellectual and interaction abilities of a human being the Distributed Artificial Intelligence pursues the same objective but focusing on human being societies (O’Hare et al., 2006). A paradigm in current use for the development of Distributed Artificial Intelligence is based on the notion of multi-agent systems. A multi-agent system is formed by a number of interacting intelligent systems called agents, and can be implemented as a software program, as a dedicated computer, or as a robot (Russell & Norving, 2003). Intelligent agents in a multi-agent system interact among each other to organize their structure, assign tasks, and interchange knowledge. Concepts related to multi-agent systems, artificial societies, and simulated organizations, create a new and rising paradigm in computingwhich involves issues as cooperation and competition, coordination, collaboration, communication and language protocols, negotiation, consensus development, conflict detection and resolution, collective intelligence activities conducted by agents (e.g. problem resolution, planning, learning, and decision making in a distributed manner), cognitive multiple intelligence activities, social and dynamic structuring, decentralized administration and control, safety, reliability, and robustness (service quality parameters). Distributed intelligent sensor networks can be seen from the perspective of a system composed by multiple agents (sensor nodes), with sensors working among themselves and forming a collective system which function is to collect data from physical variables of systems. Thus, sensor networks can be seen as multi-agent systems or as artificial organized societies that can perceive their environment through sensors. But, the question is how to implement Artificial Intelligence mechanisms withinWireless Sensor Networks (WSNs)? There are two possible approaches to the problem: according to the first approach, designers have in mind the global objective to be accomplished and design both, the agents and the interaction mechanism of the multi-agent system. In the second approach, the designer conceives and constructs a set of self-interested agents whose then evolve and interact in a stable manner, in their structure, through evolutionary techniques for learning. The same difficulty applies when working with a WSN perspective seen from the 4","",""
4,"S. Back, Seongju Lee, Sungho Shin, Yeonguk Yu, Taekyeong Yuk, Saepomi Jong, Seungjun Ryu, Kyoobin Lee","Robust Skin Disease Classification by Distilling Deep Neural Network Ensemble for the Mobile Diagnosis of Herpes Zoster",2021,"","","","",187,"2022-07-13 09:21:51","","10.1109/ACCESS.2021.3054403","","",,,,,4,4.00,1,8,1,"Herpes zoster (HZ) is a common cutaneous disease affecting one out of five people; hence, early diagnosis of HZ is crucial as it can progress to chronic pain syndrome if antiviral treatment is not provided within 72 hr. Mobile diagnosis of HZ with the assistance of artificial intelligence can prevent neuropathic pain while reducing clinicians’ fatigue and diagnosis cost. However, the clinical images captured from daily mobile devices likely contain visual corruptions, such as motion blur and noise, which can easily mislead the automated system. Hence, this paper aims to train a robust and mobile deep neural network (DNN) that can distinguish HZ from other skin diseases using user-submitted images. To enhance robustness while retaining low computational cost, we propose a knowledge distillation from ensemble via curriculum training (KDE-CT) wherein a student network learns from a stronger teacher network progressively. We established skin diseases dataset for HZ diagnosis and evaluated the robustness against 75 types of corruption. A total of 13 different DNNs was evaluated on both clean and corrupted images. The experiment result shows that the proposed KDE-CT significantly improves corruption robustness when compared with other methods. Our trained MobileNetV3-Small achieved more robust performance (93.5% overall accuracy, 67.6 mean corruption error) than the DNN ensemble with smaller computation (549x fewer multiply-and-accumulate operations), which makes it suitable for mobile skin lesion analysis.","",""
7,"T. Gavrilova, D. Kudryavtsev, Elvira Grinberg","Aesthetic Knowledge Diagrams: Bridging Understanding and Communication",2019,"","","","",188,"2022-07-13 09:21:51","","10.1007/978-3-030-10922-6_6","","",,,,,7,2.33,2,3,3,"","",""
75,"Shaofeng Liu, M. Leat, Jonathan D. Moizer, P. Megicks, Dulekha Kasturiratne","A decision-focused knowledge management framework to support collaborative decision making for lean supply chain management",2013,"","","","",189,"2022-07-13 09:21:51","","10.1080/00207543.2012.709646","","",,,,,75,8.33,15,5,9,"Lean supply chain management is a relatively new concept resulting from the integration of lean philosophy into supply chain management. Decision making in a lean supply chain context is challenging because of the complexity, dynamics, and uncertainty inherent to both supply networks and the types of waste (defined as any processes, including use of resources, which do not add value to customers). Efficient knowledge management has been identified as one of the key requirements to achieve integrated support for lean supply chain decisions. This paper proposes a decision-focused knowledge framework including a multi-layer knowledge model (to capture the know-why and know-with together with the know-what and know-how), a knowledge matrix for knowledge elicitation, and a decision tree for the design of the knowledge base. A knowledge system for lean supply chain management (KSLSCM) has been developed using artificial intelligence system shells VisiRule and Flex. The KSLSCM has five core components: a supply chain decision network manager, a waste elimination knowledge base, a knowledge refinement module, an inference engine, and a decision justifier. The knowledge framework and the KSLSCM have been evaluated through an industrial decision case. It has been demonstrated through the KSLSCM that the decision-focused knowledge framework can provide efficient and effective support for collaborative decision making in supply chain waste elimination.","",""
2,"Laura von Rueden, T. Wirtz, Fabian Hueger, Jan David Schneider, N. Piatkowski, C. Bauckhage","Street-Map Based Validation of Semantic Segmentation in Autonomous Driving",2021,"","","","",190,"2022-07-13 09:21:51","","10.1109/ICPR48806.2021.9413292","","",,,,,2,2.00,0,6,1,"Artificial intelligence for autonomous driving must meet strict requirements on safety and robustness, which motivates the thorough validation of learned models. However, current validation approaches mostly require ground truth data and are thus both cost-intensive and limited in their applicability. We propose to overcome these limitations by a model agnostic validation using a-priori knowledge from street maps. In particular, we show how to validate semantic segmentation masks and demonstrate the potential of our approach using OpenStreetMap. We introduce validation metrics that indicate false positive or negative road segments. Besides the validation approach, we present a method to correct the vehicle's GPS position so that a more accurate localization can be used for the street-map based validation. Lastly, we present quantitative results on the Cityscapes dataset indicating that our validation approach can indeed uncover errors in semantic segmentation masks.","",""
0,"E. Hugonnard, C. Garbay","From knowledge modelling to expertise elicitation in cytology",1992,"","","","",191,"2022-07-13 09:21:51","","10.1109/IEMBS.1992.5761291","","",,,,,0,0.00,0,2,30,"This paper deals with the design of a multi-agent knowledge acquisition environment dedicated to cytology. This environment is intended to remain compatible with a robust theory of knowledge and the distributed artificial Intelligence concepts. The design, based on three cooperating modes (elicitation, presentation and resolution), is first of all introduced. Two elicitation forms are then described, which fit the cytological expertise. Finally, the user interface is presented before discussing the main points of the approach.","",""
73,"Yueting Zhuang, Fei Wu, Chun Chen, Yunhe Pan","Challenges and opportunities: from big data to knowledge in AI 2.0",2017,"","","","",192,"2022-07-13 09:21:51","","10.1631/FITEE.1601883","","",,,,,73,14.60,18,4,5,"In this paper, we review recent emerging theoretical and technological advances of artificial intelligence (AI) in the big data settings. We conclude that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI, as follows: from shallow computation to deep neural reasoning; from merely data-driven model to data-driven with structured logic rules models; from task-oriented (domain-specific) intelligence (adherence to explicit instructions) to artificial general intelligence in a general context (the capability to learn from experience). Motivated by such endeavors, the next generation of AI, namely AI 2.0, is positioned to reinvent computing itself, to transform big data into structured knowledge, and to enable better decision-making for our society.","",""
29,"A. Umbrico, A. Cesta, Gabriella Cortellessa, Andrea Orlandini","A Holistic Approach to Behavior Adaptation for Socially Assistive Robots",2020,"","","","",193,"2022-07-13 09:21:51","","10.1007/s12369-019-00617-9","","",,,,,29,14.50,7,4,2,"","",""
0,"C. Fallon, Eva Brayfindley, Katherine Arneson, R. Brigantic, Mallory C. Stites, Liza Kittinger","A Methodology for Assessing Risk to Inform Technology Integration",2021,"","","","",194,"2022-07-13 09:21:51","","10.1109/RWS52686.2021.9611794","","",,,,,0,0.00,0,6,1,"When new technology, such as artificial intelligence (AI), is introduced into an existing workflow it may impact risk by mitigating some vulnerabilities and threats in the workflow while introducing others. We present a versatile methodology for assessing the vulnerabilities and threats that impact overall risk in a workflow to inform technology integration. Our method involves a four step assessment of risk including a qualitative expert knowledge elicitation, identification of risk components, quantitative data collection and analysis based on a formula for generating a risk score. The quantification of risk can be used to guide technology integration. We describe our methodology and demonstrate its utility by applying it to the Derivative Classification review process. This work was funded by the Department of Energy (DOE).","",""
5,"Philippe Lemoisson, Clarel M. H. Rakotondrahaja, Aroniaina Safidy Précieux Andriamialison, Harish A. Sankar, S. Cerri","VWA: ViewpointS Web Application to Assess Collective Knowledge Building",2019,"","","","",195,"2022-07-13 09:21:51","","10.1007/978-3-030-28377-3_1","","",,,,,5,1.67,1,5,3,"","",""
0,"Yunpeng Sun, Jin Guo, Shan Shan, Y. Khan","Wheat Futures Prices Prediction in China: A Hybrid Approach",2021,"","","","",196,"2022-07-13 09:21:51","","10.1155/2021/5545802","","",,,,,0,0.00,0,4,1,"Stocks markets play their financial roles of price shocks and hedging just when they are proficient. The imperative highlights of productive market are that one cannot make extraordinary profit from the stocks markets. This research investigates whether China wheat futures price can be predicted by employing artificial intelligence neural network. This would add to our knowledge whether wheat futures market is resourceful and would enable traders, sellers, and investors to improve cost-effective trading strategy. We utilize the traditional financial model to forecast the wheat futures price and acquire out of sample point estimates. We additionally assess the robustness of our outcomes by applying several alternative forecasting techniques such as artificial intelligence with one hidden layer and autoregressive integrated moving average (ARIMA) model. Furthermore, the statistical significance of our point estimation was further tested through the Mariano and Diebold test. Considering random walk forecast as the bench mark, we used a number of economic indicators, trader’s expectation towards futures prices, and lagged value of futures price of wheat in order to forecast the evaluation of wheat futures price. The computable significance of out of sample estimations recommends that our ANN with one hidden layer has the best anticipating presentation among all the models considered in this exploration and has the estimating power in foreseeing wheat futures returns. Furthermore, this investigation discovers that the futures price of wheat can be predicted, and the wheat futures market of China is not productive.","",""
0,"Shamim Akhtar, M. Z. Sujod, Syed Sajjad Hussain Rizvi","A Novel Deep Learning Architecture for Data-Driven Energy Efficiency Management (D2EEM) - Systematic Survey",2021,"","","","",197,"2022-07-13 09:21:51","","10.1109/ICEET53442.2021.9659737","","",,,,,0,0.00,0,3,1,"The Energy Management System (EMS) is the cost-effectiveness, robustness, and flexible approach for energy efficiency management (EEM). Data-Driven Energy Efficiency Management (D2EEM) is a recent advancement in EMS. The D2EEM is the blend of data science and artificial intelligence for EEM. Due to the highly tolerant to the performance plateau and unconstraint to the feature extraction, Deep Learning (DL) facilitates handling big data-driven problems of EEM. To the best of the knowledge, the accurate and robust D2EEM is the pressing need. Moreover, the accurate pre-trained DL network for EEM is not available in the recent literature. In this work, a comprehensive study is presented to devise a D2EEM. Moreover, the architecture is suggested in connection to the research gap.","",""
0,"Linna Zhu, Wei Li, Yongchuan Tang","Hierarchical Concept Learning by Fuzzy Semantic Cells",2021,"","","","",198,"2022-07-13 09:21:51","","10.3390/app112210723","","",,,,,0,0.00,0,3,1,"Concept modeling and learning have been important research topics in artificial intelligence and knowledge discovery. This paper studies a hierarchical concept learning method that requires a small amount of data to achieve competitive performances. The method starts from a set of fuzzy prototypes called Fuzzy Semantic Cells (FSCs). As a result of FSC parameter optimization, it creates a hierarchical structure of data–prototype–concept. Experiments are conducted to demonstrate the effectiveness of our approach in a classification problem. In particular, when faced with limited training data, our proposed method is comparable with traditional techniques in terms of robustness and generalization ability.","",""
0,"Zixuan Li, Xiaolong Li","Target Tracking Research Hotspots and Frontier Trends Based on Citespace",2021,"","","","",199,"2022-07-13 09:21:51","","10.1109/ICDSBA53075.2021.00106","","",,,,,0,0.00,0,2,1,"With the continuous development of artificial intelligence technology, target tracking is a hot problem in the field of computer vision, which has a wide range of application prospects in industrial, military, transportation, medical and other fields. In this paper, Citespace software is used to conduct descriptive statistical analysis and knowledge mapping analysis of target tracking based on domestic CNKI database literature, and to explore the development status and frontier trends in the field of target tracking in China. On this basis, point out three shortcomings of current research: low accuracy of target tracking in complex environments, poor real-time target tracking, and few application directions, and give suggestions to improve algorithm robustness, real-time, accelerate engineering implementation, and focus on future research trends.","",""
26,"R. Serra, R. Cucchiara","AI*IA 2009: Emergent Perspectives in Artificial Intelligence, XIth International Conference of the Italian Association for Artificial Intelligence, Reggio Emilia, Italy, December 9-12, 2009, Proceedings",2009,"","","","",200,"2022-07-13 09:21:51","","10.1007/978-3-642-10291-2","","",,,,,26,2.00,13,2,13,"","",""
