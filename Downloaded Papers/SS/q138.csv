Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
0,"K. Supekar, S. Ryali, R. Yuan, D. Kumar, C. de los Angeles, V. Menon","Identification of robust and interpretable brain signatures of autism and clinical symptom severity using a dynamic time-series deep neural network",2021,"","","","",1,"2022-07-13 10:08:47","","10.1192/j.eurpsy.2021.397","","",,,,,0,0.00,0,6,1,"Introduction Autism spectrum disorder (ASD) is among the most common and pervasive neurodevelopmental disorders. Yet, despite decades of research, the neurobiology of ASD is still poorly understood, as inconsistent findings preclude the identification of robust and interpretable neurobiological markers and predictors of clinical symptoms. Objectives Identify robust and interpretable dynamic brain markers that distinguish children with ASD from typically-developing (TD) children and predict clinical symptom severity. Methods We leverage multiple functional brain imaging cohorts (ABIDE, Stanford; N = 1004) and exciting recent advances in explainable artificial intelligence (xAI), to develop a novel multivariate time series deep neural network model that extracts informative brain dynamics features that accurately distinguish between ASD and TD children, and predict clinical symptom severity. Results Our model achieved consistently high classification accuracies in cross-validation analysis of data from the ABIDE cohort. Crucially, despite the differences in symptom profiles, age, and data acquisition protocols, our model also accurately classified data from an independent Stanford cohort without additional training. xAI analyses revealed that brain features associated with the default mode network, and the human voice/face processing and communication systems, most clearly distinguished ASD from TD children in both cohorts. Furthermore, the posterior cingulate cortex emerged as robust predictor of the severity of social and communication deficits in ASD in both cohorts. Conclusions Our findings, replicated across two independent cohorts, reveal robust and neurobiologically interpretable brain features that detect ASD and predict core phenotypic features of ASD, and have the potential to transform our understanding of the etiology and treatment of the disorder. Disclosure No significant relationships.","",""
7,"Yuzhe Li, Shiyi Cheng, Yujia Xue, L. Tian","Displacement-agnostic coherent imaging through scatter with an interpretable deep neural network.",2020,"","","","",2,"2022-07-13 10:08:47","","10.1364/oe.411291","","",,,,,7,3.50,2,4,2,"Coherent imaging through scatter is a challenging task. Both model-based and data-driven approaches have been explored to solve the inverse scattering problem. In our previous work, we have shown that a deep learning approach can make high-quality and highly generalizable predictions through unseen diffusers. Here, we propose a new deep neural network model that is agnostic to a broader class of perturbations including scatterer change, displacements, and system defocus up to 10× depth of field. In addition, we develop a new analysis framework for interpreting the mechanism of our deep learning model and visualizing its generalizability based on an unsupervised dimension reduction technique. We show that our model can unmix the scattering-specific information and extract the object-specific information and achieve generalization under different scattering conditions. Our work paves the way to a robust and interpretable deep learning approach to imaging through scattering media.","",""
4,"Jacob M. Springer, M. Mitchell, Garrett T. Kenyon","Adversarial Perturbations Are Not So Weird: Entanglement of Robust and Non-Robust Features in Neural Network Classifiers",2021,"","","","",3,"2022-07-13 10:08:47","","10.2172/1823733","","",,,,,4,4.00,1,3,1,"Neural networks trained on visual data are wellknown to be vulnerable to often imperceptible adversarial perturbations. The reasons for this vulnerability are still being debated in the literature. Recently Ilyas et al. (2019) showed that this vulnerability arises, in part, because neural network classifiers rely on highly predictive but brittle “non-robust” features. In this paper we extend the work of Ilyas et al. by investigating the nature of the input patterns that give rise to these features. In particular, we hypothesize that in a neural network trained in a standard way, non-robust features respond to small, “non-semantic” patterns that are typically entangled with larger, robust patterns, known to be more human-interpretable, as opposed to solely responding to statistical artifacts in a dataset. Thus, adversarial examples can be formed via minimal perturbations to these small, entangled patterns. In addition, we demonstrate a corollary of our hypothesis: robust classifiers are more effective than standard (non-robust) ones as a source for generating transferable adversarial examples in both the untargeted and targeted settings. The results we present in this paper provide new insight into the nature of the non-robust features responsible for adversarial vulnerability of neural network classifiers.","",""
41,"Sreyas Mohan, Zahra Kadkhodaie, Eero P. Simoncelli, C. Fernandez-Granda","Robust and interpretable blind image denoising via bias-free convolutional neural networks",2019,"","","","",4,"2022-07-13 10:08:47","","","","",,,,,41,13.67,10,4,3,"Deep convolutional networks often append additive constant (""bias"") terms to their convolution operations, enabling a richer repertoire of functional mappings. Biases are also used to facilitate training, by subtracting mean response over batches of training images (a component of ""batch normalization""). Recent state-of-the-art blind denoising methods (e.g., DnCNN) seem to require these terms for their success. Here, however, we show that these networks systematically overfit the noise levels for which they are trained: when deployed at noise levels outside the training range, performance degrades dramatically. In contrast, a bias-free architecture -- obtained by removing the constant terms in every layer of the network, including those used for batch normalization-- generalizes robustly across noise levels, while preserving state-of-the-art performance within the training range. Locally, the bias-free network acts linearly on the noisy image, enabling direct analysis of network behavior via standard linear-algebraic tools. These analyses provide interpretations of network functionality in terms of nonlinear adaptive filtering, and projection onto a union of low-dimensional subspaces, connecting the learning-based method to more traditional denoising methodology.","",""
2,"Gurpreet Singh, Soumyajit Gupta, Matt Lease, Clint N. Dawson","TIME: A Transparent, Interpretable, Model-Adaptive and Explainable Neural Network for Dynamic Physical Processes",2020,"","","","",5,"2022-07-13 10:08:47","","","","",,,,,2,1.00,1,4,2,"Partial Differential Equations are infinite dimensional encoded representations of physical processes. However, imbibing multiple observation data towards a coupled representation presents significant challenges. We present a fully convolutional architecture that captures the invariant structure of the domain to reconstruct the observable system. The proposed architecture is significantly low-weight compared to other networks for such problems. Our intent is to learn coupled dynamic processes interpreted as deviations from true kernels representing isolated processes for model-adaptivity. Experimental analysis shows that our architecture is robust and transparent in capturing process kernels and system anomalies. We also show that high weights representation is not only redundant but also impacts network interpretability. Our design is guided by domain knowledge, with isolated process representations serving as ground truths for verification. These allow us to identify redundant kernels and their manifestations in activation maps to guide better designs that are both interpretable and explainable unlike traditional deep-nets.","",""
4,"Taeheon Lee, Jeonghwan Hwang, Honggu Lee","TRIER: Template-Guided Neural Networks for Robust and Interpretable Sleep Stage Identification from EEG Recordings",2020,"","","","",6,"2022-07-13 10:08:47","","","","",,,,,4,2.00,1,3,2,"Neural networks often obtain sub-optimal representations during training, which degrade robustness as well as classification performances. This is a severe problem in applying deep learning to bio-medical domains, since models are vulnerable to being harmed by irregularities and scarcities in data. In this study, we propose a pre-training technique that handles this challenge in sleep staging tasks. Inspired by conventional methods that experienced physicians have used to classify sleep states from the existence of characteristic waveform shapes, or template patterns, our method introduces a cosine similarity based convolutional neural network to extract representative waveforms from training data. Afterwards, these features guide a model to construct representations based on template patterns. Through extensive experiments, we demonstrated that guiding a neural network with template patterns is an effective approach for sleep staging, since (1) classification performances are significantly enhanced and (2) robustness in several aspects are improved. Last but not least, interpretations on models showed that notable features exploited by trained experts are correctly addressed during prediction in the proposed method.","",""
1,"Huijun Wu, Chen Wang, R. Nock, Wei Wang, Jie Yin, Kai Lu, Liming Zhu","SMINT: Toward Interpretable and Robust Model Sharing for Deep Neural Networks",2020,"","","","",7,"2022-07-13 10:08:47","","10.1145/3381833","","",,,,,1,0.50,0,7,2,"Sharing a pre-trained machine learning model, particularly a deep neural network via prediction APIs, is becoming a common practice on machine learning as a service (MLaaS) platforms nowadays. Although deep neural networks (DNN) have shown remarkable successes in many tasks, they are also criticized for the lack of interpretability and transparency. Interpreting a shared DNN model faces two additional challenges compared with interpreting a general model. (1) Limited training data can be disclosed to users. (2) The internal structure of the models may not be available. These two challenges impede the application of most existing interpretability approaches, such as saliency maps or influence functions, for DNN models. Case-based reasoning methods have been used for interpreting decisions; however, how to select and organize the data points under the constraints of shared DNN models is not discussed. Moreover, simply providing cases as explanations may not be sufficient for supporting instance level interpretability. Meanwhile, existing interpretation methods for DNN models generally lack the means to evaluate the reliability of the interpretation. In this article, we propose a framework named Shared Model INTerpreter (SMINT) to address the above limitations. We propose a new data structure called a boundary graph to organize training points to mimic the predictions of DNN models. We integrate local features, such as saliency maps and interpretable input masks, into the data structure to help users to infer the model decision boundaries. We show that the boundary graph is able to address the reliability issues in many local interpretation methods. We further design an algorithm named hidden-layer aware p-test to measure the reliability of the interpretations. Our experiments show that SMINT is able to achieve above 99% fidelity to corresponding DNN models on both MNIST and ImageNet by sharing only a tiny fraction of training data to make these models interpretable. The human pilot study demonstrates that SMINT provides better interpretability compared with existing methods. Moreover, we demonstrate that SMINT is able to assist model tuning for better performance on different user data.","",""
0,"Zahra Kadkhodaie, Sreyas Mohan, Eero P. Simoncelli, C. Fernandez-Granda","Interpretable and robust blind image denoising with bias-free convolutional neural networks",2019,"","","","",8,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,4,3,"Deep convolutional networks often append additive constant (""bias"") terms to their convolution operations, enabling a richer repertoire of functional mappings. Biases are also used to facilitate training, by subtracting mean response over batches of training images (a component of ""batch normalization""). Recent state-of-the-art blind denoising methods seem to require these terms for their success. Here, however, we show that bias terms used in most CNNs (additive constants, including those used for batch normalization) interfere with the interpretability of these networks, do not help performance, and in fact prevent generalization of performance to noise levels not including in the training data. In particular, bias-free CNNs (BF-CNNs) are locally linear, and hence amenable to direct analysis with linear-algebraic tools. These analyses provide interpretations of network functionality in terms of projection onto a union of low-dimensional subspaces, connecting the learning-based method to more traditional denoising methodology. Additionally, BF-CNNs generalize robustly, achieving near-state-of-the-art performance at noise levels well beyond the range over which they have been trained.","",""
1,"Y. Lu, Ilgiz Murzakhanov, Spyros Chatzivasileiadis","Neural network interpretability for forecasting of aggregated renewable generation",2021,"","","","",9,"2022-07-13 10:08:47","","10.1109/SmartGridComm51999.2021.9631993","","",,,,,1,1.00,0,3,1,"With the rapid growth of renewable energy, lots of small photovoltaic (PV) prosumers emerge. Due to the uncertainty of solar power generation, there is a need for aggregated prosumers to predict solar power generation and whether solar power generation will be larger than load. This paper presents two interpretable neural networks to solve the problem: one binary classification neural network and one regression neural network. The neural networks are built using TensorFlow. The global feature importance and local feature contributions are examined by three gradient-based methods: Integrated Gradients, Expected Gradients, and DeepLIFT. Moreover, we detect abnormal cases when predictions might fail by estimating the prediction uncertainty using Bayesian neural networks. Neural networks, which are interpreted by the gradient-based methods and complemented with uncertainty estimation, provide robust and explainable forecasting for decision-makers.","",""
0,"Nikola Janjusevic, Amirhossein Khalilian-Gourtani, Yao Wang","CDLNet: Robust and Interpretable Denoising Through Deep Convolutional Dictionary Learning",2021,"","","","",10,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,3,1,"Deep learning based methods hold state-of-the-art results in image denoising, but remain difficult to interpret due to their construction from poorly understood building blocks such as batch-normalization, residual learning, and feature domain processing. Unrolled optimization networks propose an interpretable alternative to constructing deep neural networks by deriving their architecture from classical iterative optimization methods, without use of tricks from the standard deep learning tool-box. So far, such methods have demonstrated performance close to that of state-of-the-art models while using their interpretable construction to achieve a comparably low learned parameter count. In this work, we propose an unrolled convolutional dictionary learning network (CDLNet) and demonstrate its competitive denoising performance in both low and high parameter count regimes. Specifically, we show that the proposed model outperforms the state-of-the-art denoising models when scaled to similar parameter count. In addition, we leverage the model’s interpretable construction to propose an augmentation of the network’s thresholds that enables state-of-the-art blind denoising performance and near-perfect generalization on noiselevels unseen during training.","",""
6,"D. Raimondi, J. Simm, A. Arany, P. Fariselli, I. Cleynen, Y. Moreau","An interpretable low-complexity machine learning framework for robust exome-based in-silico diagnosis of Crohn’s disease patients",2020,"","","","",11,"2022-07-13 10:08:47","","10.1093/nargab/lqaa011","","",,,,,6,3.00,1,6,2,"Abstract Whole exome sequencing (WES) data are allowing researchers to pinpoint the causes of many Mendelian disorders. In time, sequencing data will be crucial to solve the genome interpretation puzzle, which aims at uncovering the genotype-to-phenotype relationship, but for the moment many conceptual and technical problems need to be addressed. In particular, very few attempts at the in-silico diagnosis of oligo-to-polygenic disorders have been made so far, due to the complexity of the challenge, the relative scarcity of the data and issues such as batch effects and data heterogeneity, which are confounder factors for machine learning (ML) methods. Here, we propose a method for the exome-based in-silico diagnosis of Crohn’s disease (CD) patients which addresses many of the current methodological issues. First, we devise a rational ML-friendly feature representation for WES data based on the gene mutational burden concept, which is suitable for small sample sizes datasets. Second, we propose a Neural Network (NN) with parameter tying and heavy regularization, in order to limit its complexity and thus the risk of over-fitting. We trained and tested our NN on 3 CD case-controls datasets, comparing the performance with the participants of previous CAGI challenges. We show that, notwithstanding the limited NN complexity, it outperforms the previous approaches. Moreover, we interpret the NN predictions by analyzing the learned patterns at the variant and gene level and investigating the decision process leading to each prediction.","",""
4,"S. Yu, Yulei Niu, Shuohang Wang, Jing Jiang, Qianru Sun","Counterfactual Variable Control for Robust and Interpretable Question Answering",2020,"","","","",12,"2022-07-13 10:08:47","","","","",,,,,4,2.00,1,5,2,"Deep neural network based question answering (QA) models are neither robust nor explainable in many cases. For example, a multiple-choice QA model, tested without any input of question, is surprisingly ""capable"" to predict the most of correct options. In this paper, we inspect such spurious ""capability"" of QA models using causal inference. We find the crux is the shortcut correlation, e.g., unrobust word alignment between passage and options learned by the models. We propose a novel approach called Counterfactual Variable Control (CVC) that explicitly mitigates any shortcut correlation and preserves the comprehensive reasoning for robust QA. Specifically, we leverage multi-branch architecture that allows us to disentangle robust and shortcut correlations in the training process of QA. We then conduct two novel CVC inference methods (on trained models) to capture the effect of comprehensive reasoning as the final prediction. For evaluation, we conduct extensive experiments using two BERT backbones on both multi-choice and span-extraction QA benchmarks. The results show that our CVC achieves high robustness against a variety of adversarial attacks in QA while maintaining good interpretation ability.","",""
1,"Zhucheng Zhan, Noshad Hossenei, Olivier B. Poirion, M. Westerhoff, Eun-Young Choi, T. Ching, L. Garmire","Two-stage Neural-network based Prognosis Models using Pathological Image and Transcriptomic Data: An Application in Hepatocellular Carcinoma Patient Survival Prediction",2020,"","","","",13,"2022-07-13 10:08:47","","10.1101/2020.01.25.20016832","","",,,,,1,0.50,0,7,2,"Pathological images are easily accessible data type with potential as prognostic biomarkers. Here we extend Cox-nnet, a neural network based prognosis method previously used for transcriptomics data, to predict patient survival using hepatocellular carcinoma (HCC) pathological images. Cox-nnet based imaging predictions are more robust and accurate than Cox-PH. Moreover, using a novel two-stage Cox-nnet complex model, we are able to combine pathology image and transcriptomics RNA-Seq data to make impressively accurate prognosis predictions, with C-index close to 0.90 and log-ranked p-value of 4e-21 in the testing dataset. This work provides a new, biologically relevant and relatively interpretable solution to the challenge of integrating multi-modal and multiple types of data, particularly for survival prediction.","",""
1,"Ying L. Becker, Lingfeng Guo, Odilbek Nurmamatov","Assessing Asset Tail Risk with Artificial Intelligence: The Application of Artificial Neural Network",2020,"","","","",14,"2022-07-13 10:08:47","","10.1108/s2514-465020200000008002","","",,,,,1,0.50,0,3,2,"Value at risk (VaR) and expected shortfall (ES) are popular market risk measurements. The former is not coherent but robust, whereas the latter is coherent but less interpretable, only conditionally backtestable and less robust. In this chapter, we compare an innovative artificial neural network (ANN) model with a time series model in the context of forecasting VaR and ES of the univariate time series of four asset classes: US large capitalization equity index, European large cap equity index, US bond index, and US dollar versus euro exchange rate price index for the period of January 4, 1999, to December 31, 2018. In general, the ANN model has more favorable backtesting results as compared to the autoregressive moving average, generalized autoregressive conditional heteroscedasticity (ARMA-GARCH) time series model. In terms of forecasting accuracy, the ANN model has much fewer in-sample and out-of-sample exceptions than those of the ARMA-GARCH model.","",""
5,"Tsung-Yen Yang, Karthik Narasimham","Robust and Interpretable Grounding of Spatial References with Relation Networks",2020,"","","","",15,"2022-07-13 10:08:47","","10.18653/v1/2020.findings-emnlp.172","","",,,,,5,2.50,3,2,2,"Learning representations of spatial references in natural language is a key challenge in tasks like autonomous navigation and robotic manipulation. Recent work has investigated various neural architectures for learning multi-modal representations for spatial concepts. However, the lack of explicit reasoning over entities makes such approaches vulnerable to noise in input text or state observations. In this paper, we develop effective models for understanding spatial references in text that are robust and interpretable, without sacrificing performance. We design a text-conditioned relation network whose parameters are dynamically computed with a cross-modal attention module to capture fine-grained spatial relations between entities. This design choice provides interpretability of learned intermediate outputs. Experiments across three tasks demonstrate that our model achieves superior performance, with a 17% improvement in predicting goal locations and a 15% improvement in robustness compared to state-of-the-art systems.","",""
5,"Zicheng Hu, A. Tang, Jaiveer Singh, Sanchita Bhattacharya, A. Butte","A robust and interpretable, end-to-end deep learning model for cytometry data",2020,"","","","",16,"2022-07-13 10:08:47","","10.1101/2020.02.05.934521","","",,,,,5,2.50,1,5,2,"Cytometry technologies are essential tools for immunology research, providing high-throughput measurements of the immune cells at the single-cell level. Traditional approaches in interpreting and using cytometry measurements include manual or automated gating to identify cell subsets from the cytometry data, providing highly intuitive results but may lead to significant information loss, in that additional details in measured or correlated cell signals might be missed. In this study, we propose and test a deep convolutional neural network for analyzing cytometry data in an end-to-end fashion, allowing a direct association between raw cytometry data and the clinical outcome of interest. Using nine large CyTOF studies from the open-access ImmPort database, we demonstrated that the deep convolutional neural network model can accurately diagnose the latent cytomegalovirus (CMV) in healthy individuals, even when using highly heterogeneous data from different studies. In addition, we developed a permutation-based method for interpreting the deep convolutional neural network model and identified a CD27-CD94+ CD8+ T cell population significantly associated with latent CMV infection. Finally, we provide a tutorial for creating, training and interpreting the tailored deep learning model for cytometry data using Keras and TensorFlow (github.com/hzc363/DeepLearningCyTOF).","",""
1,"André Ferreira, S. Madeira, M. Gromicho, M. Carvalho, S. Vinga, Alexandra M. Carvalho","Predictive Medicine Using Interpretable Recurrent Neural Networks",2020,"","","","",17,"2022-07-13 10:08:47","","10.1007/978-3-030-68763-2_14","","",,,,,1,0.50,0,6,2,"","",""
4,"Z. Xue, Lixin Duan, Wen Li, Lin Chen, Jiebo Luo","Region Comparison Network for Interpretable Few-shot Image Classification",2020,"","","","",18,"2022-07-13 10:08:47","","","","",,,,,4,2.00,1,5,2,"While deep learning has been successfully applied to many real-world computer vision tasks, training robust classifiers usually requires a large amount of well-labeled data. However, the annotation is often expensive and time-consuming. Few-shot image classification has thus been proposed to effectively use only a limited number of labeled examples to train models for new classes. Recent works based on transferable metric learning methods have achieved promising classification performance through learning the similarity between the features of samples from the query and support sets. However, rare of them explicitly considers the model interpretability, which can actually be revealed during the training phase.  For that, in this work, we propose a metric learning based method named Region Comparison Network (RCN), which is able to reveal how few-shot learning works as in a neural network as well as to find out specific regions that are related to each other in images coming from the query and support sets. Moreover, we also present a visualization strategy named Region Activation Mapping (RAM) to intuitively explain what our method has learned by visualizing intermediate variables in our network. We also present a new way to generalize the interpretability from the level of tasks to categories, which can also be viewed as a method to find the prototypical parts for supporting the final decision of our RCN. Extensive experiments on four benchmark datasets clearly show the effectiveness of our method over existing baselines.","",""
38,"Hassan Ismail Fawaz, G. Forestier, J. Weber, L. Idoumghar, Pierre-Alain Muller","Accurate and interpretable evaluation of surgical skills from kinematic data using fully convolutional neural networks",2019,"","","","",19,"2022-07-13 10:08:47","","10.1007/s11548-019-02039-4","","",,,,,38,12.67,8,5,3,"","",""
180,"Noah D. Brenowitz, C. Bretherton","Prognostic Validation of a Neural Network Unified Physics Parameterization",2018,"","","","",20,"2022-07-13 10:08:47","","10.1029/2018GL078510","","",,,,,180,45.00,90,2,4,"Weather and climate models approximate diabatic and sub‐grid‐scale processes in terms of grid‐scale variables using parameterizations. Current parameterizations are designed by humans based on physical understanding, observations, and process modeling. As a result, they are numerically efficient and interpretable, but potentially oversimplified. However, the advent of global high‐resolution simulations and observations enables a more robust approach based on machine learning. In this letter, a neural network‐based parameterization is trained using a near‐global aqua‐planet simulation with a 4‐km resolution (NG‐Aqua). The neural network predicts the apparent sources of heat and moisture averaged onto (160 km)2 grid boxes. A numerically stable scheme is obtained by minimizing the prediction error over multiple time steps rather than single one. In prognostic single‐column model tests, this scheme matches both the fluctuations and equilibrium of NG‐Aqua simulation better than the Community Atmosphere Model does.","",""
7,"Ashkan Khakzar, Shadi Albarqouni, Nassir Navab","Learning Interpretable Features via Adversarially Robust Optimization",2019,"","","","",21,"2022-07-13 10:08:47","","10.1007/978-3-030-32226-7_88","","",,,,,7,2.33,2,3,3,"","",""
0,"Bingxin Zhou, Yuanhong Jiang, Yu Guang Wang, Jingwei Liang, Junbin Gao, Shirui Pan, Xiaoqun Zhang","Graph Neural Network for Local Corruption Recovery",2022,"","","","",22,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,7,1,"Graph neural networks (GNNs) have seen a surge of development for exploiting the relational information of input graphs. Nevertheless, messages propagating through a graph contain both interpretable patterns and small perturbations. Despite global noise could be distributed over the entire graph data, it is not uncommon that corruptions appear well-concealed and merely pollute local regions while still having a vital influence on the GNN learning and prediction performance. This work tackles the graph recovery problem from local poisons by a robustness representation learning. Our developed strategy identifies regional graph perturbations and formulates a robust hidden feature representation for GNNs. A mask function pinpointed the anomalies without prior knowledge, and an `p,q regularizer defends local poisonings through pursuing sparsity in the framelet domain while maintaining a conditional closeness between the observation and new representation. The proposed robust computational unit alleviates the inertial alternating direction method of multipliers to achieve an efficient solution. Extensive experiments show that our new model recovers graph representations from local pollution and achieves excellent performance.","",""
1,"Letao Liu, Martin Saerbeck, J. Dauwels","Affine Disentangled GAN for Interpretable and Robust AV Perception",2019,"","","","",23,"2022-07-13 10:08:47","","","","",,,,,1,0.33,0,3,3,"Autonomous vehicles (AV) have progressed rapidly with the advancements in computer vision algorithms. The deep convolutional neural network as the main contributor to this advancement has boosted the classification accuracy dramatically. However, the discovery of adversarial examples reveals the generalization gap between dataset and the real world. Furthermore, affine transformations may also confuse computer vision based object detectors. The degradation of the perception system is undesirable for safety critical systems such as autonomous vehicles. In this paper, a deep learning system is proposed: Affine Disentangled GAN (ADIS-GAN), which is robust against affine transformations and adversarial attacks. It is demonstrated that conventional data augmentation for affine transformation and adversarial attacks are orthogonal, while ADIS-GAN can handle both attacks at the same time. Useful information such as image rotation angle and scaling factor are also generated in ADIS-GAN. On MNIST dataset, ADIS-GAN can achieve over 98 percent classification accuracy within 30 degrees rotation, and over 90 percent classification accuracy against FGSM and PGD adversarial attack.","",""
1,"H. Cooper, G. Iyengar, Ching-Yung Lin","Deep Influence Diagrams: An Interpretable and Robust Decision Support System",2019,"","","","",24,"2022-07-13 10:08:47","","10.1007/978-3-030-20485-3_35","","",,,,,1,0.33,0,3,3,"","",""
1,"Christian Etmann, Maximilian Schmidt, Jens Behrmann, T. Boskamp, L. Hauberg-Lotte, Annette Peter, R. Casadonte, J. Kriegsmann, P. Maass","Deep Relevance Regularization: Interpretable and Robust Tumor Typing of Imaging Mass Spectrometry Data",2019,"","","","",25,"2022-07-13 10:08:47","","","","",,,,,1,0.33,0,9,3,"Neural networks have recently been established as a viable classification method for imaging mass spectrometry data for tumor typing. For multi-laboratory scenarios however, certain confounding factors may strongly impede their performance. In this work, we introduce Deep Relevance Regularization, a method of restricting what the neural network can focus on during classification, in order to improve the classification performance. We demonstrate how Deep Relevance Regularization robustifies neural networks against confounding factors on a challenging inter-lab dataset consisting of breast and ovarian carcinoma. We further show that this makes the relevance map -- a way of visualizing the discriminative parts of the mass spectrum -- sparser, thereby making the classifier easier to interpret","",""
2,"S. Tan, Runpei Dong, Kaisheng Ma","Multi-Glimpse Network: A Robust and Efficient Classification Architecture based on Recurrent Downsampled Attention",2021,"","","","",26,"2022-07-13 10:08:47","","","","",,,,,2,2.00,1,3,1,"Most feedforward convolutional neural networks spend roughly the same efforts for each pixel. Yet human visual recognition is an interaction between eye movements and spatial attention, which we will have several glimpses of an object in different regions. Inspired by this observation, we propose an end-to-end trainable M ulti- G limpse N etwork ( MGNet ) which aims to tackle the challenges of high computation and the lack of robustness based on recurrent downsampled attention mechanism. Speciﬁcally, MGNet sequentially selects task-relevant regions of an image to focus on and then adaptively combines all collected information for the ﬁnal prediction. MGNet expresses higher resistance against adversarial attacks and common corruptions with less computation. Also, MGNet is inherently more interpretable as it explicitly informs us where it focuses during each iteration. Our experiments on ImageNet100 demonstrate the potential of recurrent downsampled attention mechanisms to improve a single feedforward manner. For example, MGNet improves 4.76% accuracy on average in common corruptions with only 36.9% computational cost. Moreover, while the baseline incurs an accuracy drop to 7.6%, MGNet manages to maintain 44.2% accuracy in the same PGD attack strength with ResNet-50 backbone. Our code is available at https: //github.com/siahuat0727/MGNet .","",""
13,"S. Saralajew, Lars Holdijk, Maike Rees, T. Villmann","Prototype-based Neural Network Layers: Incorporating Vector Quantization",2018,"","","","",27,"2022-07-13 10:08:47","","","","",,,,,13,3.25,3,4,4,"Neural networks currently dominate the machine learning community and they do so for good reasons. Their accuracy on complex tasks such as image classification is unrivaled at the moment and with recent improvements they are reasonably easy to train. Nevertheless, neural networks are lacking robustness and interpretability. Prototype-based vector quantization methods on the other hand are known for being robust and interpretable. For this reason, we propose techniques and strategies to merge both approaches. This contribution will particularly highlight the similarities between them and outline how to construct a prototype-based classification layer for multilayer networks. Additionally, we provide an alternative, prototype-based, approach to the classical convolution operation. Numerical results are not part of this report, instead the focus lays on establishing a strong theoretical framework. By publishing our framework and the respective theoretical considerations and justifications before finalizing our numerical experiments we hope to jump-start the incorporation of prototype-based learning in neural networks and vice versa.","",""
2,"H. Cooper, G. Iyengar, Ching-Yung Lin","Interpretable Robust Decision Making",2018,"","","","",28,"2022-07-13 10:08:47","","","","",,,,,2,0.50,1,3,4,"Interpretable decision making frameworks allow us to easily endow agents with specific goals, risk tolerances, and understanding. Existing decision making systems either forgo interpretability, or pay for it with severely reduced efficiency and large memory requirements. In this paper, we outline DeepID, a neural network approximation of Influence Diagrams, that avoids both pitfalls.","",""
2,"Shushan He, H. Zha, X. Ye","Network Diffusions via Neural Mean-Field Dynamics",2020,"","","","",29,"2022-07-13 10:08:47","","","","",,,,,2,1.00,1,3,2,"We propose a novel learning framework based on neural mean-field dynamics for inference and estimation problems of diffusion on networks. Our new framework is derived from the Mori-Zwanzig formalism to obtain an exact evolution of the node infection probabilities, which renders a delay differential equation with memory integral approximated by learnable time convolution operators, resulting in a highly structured and interpretable RNN. Directly using cascade data, our framework can jointly learn the structure of the diffusion network and the evolution of infection probabilities, which are cornerstone to important downstream applications such as influence maximization. Connections between parameter learning and optimal control are also established. Empirical study shows that our approach is versatile and robust to variations of the underlying diffusion network models, and significantly outperform existing approaches in accuracy and efficiency on both synthetic and real-world data.","",""
3,"Juhong Min, Seungwook Kim, Minsu Cho","Convolutional Hough Matching Networks for Robust and Efficient Visual Correspondence",2021,"","","","",30,"2022-07-13 10:08:47","","","","",,,,,3,3.00,1,3,1,"Despite advances in feature representation, leveraging geometric relations is crucial for establishing reliable visual correspondences under large variations of images. In this work we introduce a Hough transform perspective on convolutional matching and propose an effective geometric matching algorithm, dubbed Convolutional Hough Matching (CHM). The method distributes similarities of candidate matches over a geometric transformation space and evaluates them in a convolutional manner. We cast it into a trainable neural layer with a semi-isotropic high-dimensional kernel, which learns non-rigid matching with a small number of interpretable parameters. To further improve the efficiency of high-dimensional voting, we also propose to use an efficient kernel decomposition with center-pivot neighbors, which significantly sparsifies the proposed semi-isotropic kernels without performance degradation. To validate the proposed techniques, we develop the neural network with CHM layers that perform convolutional matching in the space of translation and scaling. Our method sets a new state of the art on standard benchmarks for semantic visual correspondence, proving its strong robustness to challenging intra-class variations.","",""
1,"Chih-Hsu Lin, O. Lichtarge","Using interpretable deep learning to model cancer dependencies",2021,"","","","",31,"2022-07-13 10:08:47","","10.1093/bioinformatics/btab137","","",,,,,1,1.00,1,2,1,"Abstract Motivation Cancer dependencies provide potential drug targets. Unfortunately, dependencies differ among cancers and even individuals. To this end, visible neural networks (VNNs) are promising due to robust performance and the interpretability required for the biomedical field. Results We design Biological visible neural network (BioVNN) using pathway knowledge to predict cancer dependencies. Despite having fewer parameters, BioVNN marginally outperforms traditional neural networks (NNs) and converges faster. BioVNN also outperforms an NN based on randomized pathways. More importantly, dependency predictions can be explained by correlating with the neuron output states of relevant pathways, which suggest dependency mechanisms. In feature importance analysis, BioVNN recapitulates known reaction partners and proposes new ones. Such robust and interpretable VNNs may facilitate the understanding of cancer dependency and the development of targeted therapies. Availability and implementation Code and data are available at https://github.com/LichtargeLab/BioVNN Supplementary information Supplementary data are available at Bioinformatics online.","",""
0,"Keke Du, Shane Chang, Huixiang Wen, Hao Zhang","Fighting Adversarial Images With Interpretable Gradients",2021,"","","","",32,"2022-07-13 10:08:47","","10.1145/3472634.3472644","","",,,,,0,0.00,0,4,1,"Adversarial images are specifically designed to fool neural networks into making a wrong decision about what they are looking at, which severely degrade neural network accuracy. Recently, empirical and theoretical evidence suggests that robust neural network models tend to have better interpretable gradients. Therefore, we speculate that improving the interpretability of the gradients of the neural network models may also help to improve the robustness of the models. Two methods are used to add gradient-dependent constraint terms to the loss function of neural network models and both improve the robustness of the models. The first method adds the fussed lasso penalty term of the saliency maps to the loss function of the neural network models, which makes the saliency maps arrange in a natural way to improve the interpretability of the saliency maps, and uses the gradient enhancement for relu instead of relu to strengthen the constraint of regularization term on saliency maps. In the second method, the cosine similarity penalty term between the input gradients and the image contour is added to the loss function of the model to constrain the approximation between the input gradients and the image contour. This method has a certain biological significance, because the contour information of the image is used in the human visual system to recognize the image. Both methods improve the interpretability of model‘s gradients and the first method exceeds most regularization methods except adversarial training on MNIST and the second method even exceeds the adversarial training under white-box attacks on CIFAR-10 and CIFAR-100.","",""
18,"Renu Sharma, A. Ross","D-NetPAD: An Explainable and Interpretable Iris Presentation Attack Detector",2020,"","","","",33,"2022-07-13 10:08:47","","10.1109/IJCB48548.2020.9304880","","",,,,,18,9.00,9,2,2,"An iris recognition system is vulnerable to presentation attacks, or PAs, where an adversary presents artifacts such as printed eyes, plastic eyes, or cosmetic contact lenses to circumvent the system. In this work, we propose an effective and robust iris PA detector called D-NetPAD based on the DenseNet convolutional neural network architecture. It demonstrates generalizability across PA artifacts, sensors and datasets. Experiments conducted on a proprietary dataset and a publicly available dataset (LivDet-2017) substantiate the effectiveness of the proposed method for iris PA detection. The proposed method results in a true detection rate of 98.58% at a false detection rate of 0.2% on the proprietary dataset and outperforms state-of-the-art methods on the LivDet-2017 dataset. We visualize intermediate feature distributions and fixation heatmaps using t-SNE plots and Grad-CAM, respectively, in order to explain the performance of D-NetPAD. Further, we conduct a frequency analysis to explain the nature of features being extracted by the network. The source code and trained model are available at https://github.com/iPRoBe-lab/D-NetPAD.","",""
30,"Run Wang, Felix Juefei-Xu, Yihao Huang, Qing Guo, Xiaofei Xie, L. Ma, Yang Liu","DeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake Voices",2020,"","","","",34,"2022-07-13 10:08:47","","10.1145/3394171.3413716","","",,,,,30,15.00,4,7,2,"With the recent advances in voice synthesis, AI-synthesized fake voices are indistinguishable to human ears and widely are applied to produce realistic and natural DeepFakes, exhibiting real threats to our society. However, effective and robust detectors for synthesized fake voices are still in their infancy and are not ready to fully tackle this emerging threat. In this paper, we devise a novel approach, named DeepSonar, based on monitoring neuron behaviors of speaker recognition (SR) system, i.e., a deep neural network (DNN), to discern AI-synthesized fake voices. Layer-wise neuron behaviors provide an important insight to meticulously catch the differences among inputs, which are widely employed for building safety, robust, and interpretable DNNs. In this work, we leverage the power of layer-wise neuron activation patterns with a conjecture that they can capture the subtle differences between real and AI-synthesized fake voices, in providing a cleaner signal to classifiers than raw inputs. Experiments are conducted on three datasets (including commercial products from Google, Baidu, etc) containing both English and Chinese languages to corroborate the high detection rates (98.1% average accuracy) and low false alarm rates (about 2% error rate) of DeepSonar in discerning fake voices. Furthermore, extensive experimental results also demonstrate its robustness against manipulation attacks (e.g., voice conversion and additive real-world noises). Our work further poses a new insight into adopting neuron behaviors for effective and robust AI aided multimedia fakes forensics as an inside-out approach instead of being motivated and swayed by various artifacts introduced in synthesizing fakes.","",""
1,"Z. Gou, C. Fyfe","A robust canonical correlation neural network",2002,"","","","",35,"2022-07-13 10:08:47","","10.1109/NNSP.2002.1030035","","",,,,,1,0.05,1,2,20,"We review a neural implementation of canonical correlation analysis and show, using ideas suggested by ridge regression, how to make the algorithm robust. The network is shown to operate on data sets which exhibit multicollinearity. We develop a second model which not only performs as well on multicollinear data but also on general data sets. This model allows us to vary a single parameter so that the network is capable of performing partial least squares regression (at one extreme) to canonical correlation analysis (at the other) and every intermediate operation between the two. On multicollinear data, the parameter setting is shown to be important but on more general data no particular parameter setting is required. Finally, the algorithm acts on such data as a smoother in that the resulting weight vectors are much smoother and more interpretable than the weights without the robustification term.","",""
3,"Andreas Leitherer, A. Ziletti, L. Ghiringhelli","Robust recognition and exploratory analysis of crystal structures via Bayesian deep learning",2021,"","","","",36,"2022-07-13 10:08:47","","10.1038/s41467-021-26511-5","","",,,,,3,3.00,1,3,1,"","",""
10,"L. Cong, Ke Tang, Jingyuan Wang, Yang Zhang","AlphaPortfolio: Direct Construction Through Deep Reinforcement Learning and Interpretable AI",2020,"","","","",37,"2022-07-13 10:08:47","","10.2139/ssrn.3554486","","",,,,,10,5.00,3,4,2,"We propose direct optimization of investors' objectives via reinforcement learning, an alternative to the widely adopted two-step portfolio-management paradigm entailing estimating distributions of asset returns. Building upon recent breakthroughs in AI, we develop neural-network-based multi-sequence models tailored to distinguishing features of economic and financial data. The resulting AlphaPortfolio yields stellar out-of-sample performances (e.g., Sharpe ratio above two) that are robust under various economic and trading restrictions. Moreover, we use polynomial-feature-sensitivity and textual-factor analyses to project the model onto linear regression and natural language spaces uncover key market signals, firms' financials, etc., including their rotation and non-linearity, that drive investment performance. Overall, we highlight the utility of reinforcement deep learning in social sciences, especially finance, and provide novel ``economic distillation'' procedures for interpreting AI and big data models.","",""
5,"Xinjian Gao, Tingting Mu, J. Y. Goulermas, Jeyarajan Thiyagalingam, Meng Wang","An Interpretable Deep Architecture for Similarity Learning Built Upon Hierarchical Concepts",2020,"","","","",38,"2022-07-13 10:08:47","","10.1109/TIP.2020.2965275","","",,,,,5,2.50,1,5,2,"In general, development of adequately complex mathematical models, such as deep neural networks, can be an effective way to improve the accuracy of learning models. However, this is achieved at the cost of reduced post-hoc model interpretability, because what is learned by the model can become less intelligible and tractable to humans as the model complexity increases. In this paper, we target a similarity learning task in the context of image retrieval, with a focus on the model interpretability issue. An effective similarity neural network (SNN) is proposed not only to seek robust retrieval performance but also to achieve satisfactory post-hoc interpretability. The network is designed by linking the neuron architecture with the organization of a concept tree and by formulating neuron operations to pass similarity information between concepts. Various ways of understanding and visualizing what is learned by the SNN neurons are proposed. We also exhaustively evaluate the proposed approach using a number of relevant datasets against a number of state-of-the-art approaches to demonstrate the effectiveness of the proposed network. Our results show that the proposed approach can offer superior performance when compared against state-of-the-art approaches. Neuron visualization results are demonstrated to support the understanding of the trained neurons.","",""
3,"A. Habibnia, E. Maasoumi","Forecasting in Big Data Environments: an Adaptable and Automated Shrinkage Estimation of Neural Networks (AAShNet)",2019,"","","","",39,"2022-07-13 10:08:47","","10.1007/s40953-021-00275-7","","",,,,,3,1.00,2,2,3,"","",""
0,"Tongzhou Mu, Kaixiang Lin, Fei Niu, G. Thattai","Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement Learning",2022,"","","","",40,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,4,1,"We present a two-step hybrid reinforcement learning (RL) policy that is designed to generate interpretable and robust hierarchical policies on the RL problem with graph-based input. Unlike prior deep reinforcement learning policies parameterized by an end-to-end black-box graph neural network, our approach disentangles the decision-making process into two steps. The first step is a simplified classification problem that maps the graph input to an action group where all actions share a similar semantic meaning. The second step implements a sophisticated rule-miner that conducts explicit one-hop reasoning over the graph and identifies decisive edges in the graph input without the necessity of heavy domain knowledge. This two-step hybrid policy presents human-friendly interpretations and achieves better performance in terms of generalization and robustness. Extensive experimental studies on four levels of complex text-based games have demonstrated the superiority of the proposed method compared to the state-of-the-art.","",""
0,"M. Serrurier, F. Mamalet, Thomas Fel, Louis B'ethune, Thibaut Boissin","When adversarial attacks become interpretable counterfactual explanations",2022,"","","","",41,"2022-07-13 10:08:47","","10.48550/arXiv.2206.06854","","",,,,,0,0.00,0,5,1,"We argue that, when learning a 1-Lipschitz neural network with the dual loss of an optimal transportation problem, the gradient of the model is both the direction of the transportation plan and the direction to the closest adversarial attack. Traveling along the gradient to the decision boundary is no more an adversarial attack but becomes a counterfactual explanation, explicitly transporting from one class to the other. Through extensive experiments on XAI metrics, we find that the simple saliency map method, applied on such networks, becomes a reliable explanation, and outperforms the state-of-the-art explanation approaches on unconstrained models. The proposed networks were already known to be certifiably robust, and we prove that they are also explainable with a fast and simple method.","",""
1,"Yang Lu, Wenbo Guo, Xinyu Xing, William Stafford Noble","Robust Decoy-enhanced Saliency Maps.",2020,"","","","",42,"2022-07-13 10:08:47","","","","",,,,,1,0.50,0,4,2,"Saliency methods can make deep neural network predictions more interpretable by identifying a set of critical features in an input sample, such as pixels that contribute most strongly to a prediction made by an image classifier. Unfortunately, recent evidence suggests that many saliency methods poorly perform, especially in situations where gradients are saturated, inputs contain adversarial perturbations, or predictions rely upon inter-feature dependence. To address these issues, we propose a framework that improves the robustness of saliency methods by following a two-step procedure. First, we introduce a perturbation mechanism that subtly varies the input sample without changing its intermediate representations. Using this approach, we can gather a corpus of perturbed data samples while ensuring that the perturbed and original input samples follow the same distribution. Second, we compute saliency maps for the perturbed samples and propose a new method to aggregate saliency maps. With this design, we offset the gradient saturation influence upon interpretation. From a theoretical perspective, we show the aggregated saliency map could not only capture inter-feature dependence but, more importantly, robustify interpretation against previously described adversarial perturbation methods. Following our theoretical analysis, we present experimental results suggesting that, both qualitatively and quantitatively, our saliency method outperforms existing methods.","",""
1,"Y. Lu, Wenbo Guo, Xinyu Xing, William Stafford Noble","Robust saliency maps with decoy-enhanced saliency score",2020,"","","","",43,"2022-07-13 10:08:47","","","","",,,,,1,0.50,0,4,2,"Saliency methods help to make deep neural network predictions more interpretable by identifying particular features, such as pixels in an image, that contribute most strongly to the network's prediction. Unfortunately, recent evidence suggests that many saliency methods perform poorly when gradients are saturated or in the presence of strong inter-feature dependence or noise injected by an adversarial attack. In this work, we propose to infer robust saliency scores by integrating the saliency scores of a set of decoys with a novel decoy-enhanced saliency score, in which the decoys are generated by either solving an optimization problem or blurring the original input. We theoretically analyze that our method compensates for gradient saturation and considers joint activation patterns of pixels. We also apply our method to three different CNNs---VGGNet, AlexNet, and ResNet trained on ImageNet data set. The empirical results show both qualitatively and quantitatively that our method outperforms raw scores produced by three existing saliency methods, even in the presence of adversarial attacks.","",""
14,"J. Griffiths, S. Kleinegesse, D. Saunders, R. Taylor, A. Vacheret","Pulse shape discrimination and exploration of scintillation signals using convolutional neural networks",2018,"","","","",44,"2022-07-13 10:08:47","","10.1088/2632-2153/abb781","","",,,,,14,3.50,3,5,4,"We demonstrate the use of a convolutional neural network to perform neutron-gamma pulse shape discrimination, where the only inputs to the network are the raw digitised SiPM signals from a dual scintillator detector element made of 6LiF:ZnS(Ag) scintillator and PVT plastic. A realistic labelled dataset was created to train the network by exposing the detector to an AmBe source, and a data-driven method utilsing a separate PMT was used to assign labels to the recorded signals. This approach is compared to the charge integration and continuous wavelet transform methods and is found to provide superior levels of discrimination, achieving an AUC of 0.995 +/- 0.003. We find that the neural network is capable of extracting interpretable features directly from the raw data. In addition, by visualising the high-dimensional representations of the network with the t-SNE algorithm, we discover that not only is this method robust to minor mislabeling of the training dataset but that it is possible to identify an underlying substructure within the signals that goes beyond the original labelling. This technique could be utilised to explore and cluster complex, raw detector data in a novel way that may reveal more insights than standard analysis methods.","",""
0,"Pongpisit Thanasutives, Takeshi Morita, M. Numao, Ken-ichi Fukui","Noise-aware Physics-informed Machine Learning for Robust PDE Discovery",2022,"","","","",45,"2022-07-13 10:08:47","","10.48550/arXiv.2206.12901","","",,,,,0,0.00,0,4,1,"—This work is concerned with discovering the gov- erning partial differential equation (PDE) of a physical system. Existing methods have demonstrated the PDE identiﬁcation from ﬁnite observations but failed to maintain satisfying performance against noisy data, partly owing to suboptimal estimated deriva- tives and found PDE coefﬁcients. We address the issues by introducing a noise-aware physics-informed machine learning (nPIML) framework to discover the governing PDE from data following arbitrary distributions. Our proposals are twofold. First, we propose a couple of neural networks, namely solver and preselector, which yield an interpretable neural representation of the hidden physical constraint. After they are jointly trained, the solver network approximates potential candidates, e.g., partial derivatives, which are then fed to the sparse regression algorithm that initially unveils the most likely parsimonious PDE, decided according to the information criterion. Second, we propose the denoising physics-informed neural networks (dPINNs), based on Discrete Fourier Transform (DFT), to deliver a set of the optimal ﬁnetuned PDE coefﬁcients respecting the noise-reduced variables. The denoising PINNs’ structures are compartmentalized into forefront projection networks and a PINN, by which the formerly learned solver initializes. Our extensive experiments on ﬁve canonical PDEs afﬁrm that the proposed framework presents a robust and interpretable approach for PDE discovery, applicable to a wide range of systems, possibly complicated by noise. and model while suppressing paved towards the applications of interpretable artiﬁcial intelligence (AI) to enhance the understandability of physical sciences.","",""
0,"Rongzhen Zhao, Zheyu Yang, Hao Zheng, Yujie Wu, Faqiang Liu, Zhenzhi Wu, Lukai Li, Feng Chen, Seng Song, Jun Zhu, Wenli Zhang, Haoyu Huang, M. Xu, Kaifeng Sheng, Qianbo Yin, Jing Pei, Guoqi Li, Youhui Zhang, Mingguo Zhao, Luping Shi","A framework for the general design and computation of hybrid neural networks",2022,"","","","",46,"2022-07-13 10:08:47","","10.1038/s41467-022-30964-7","","",,,,,0,0.00,0,20,1,"","",""
9,"Adam Noack, Isaac Ahern, D. Dou, Boyang Li","An Empirical Study on the Relation Between Network Interpretability and Adversarial Robustness",2020,"","","","",47,"2022-07-13 10:08:47","","10.1007/s42979-020-00390-x","","",,,,,9,4.50,2,4,2,"","",""
19,"M. Da Lio, D. Bortoluzzi, G. P. Rosati Papini","Modelling longitudinal vehicle dynamics with neural networks",2020,"","","","",48,"2022-07-13 10:08:47","","10.1080/00423114.2019.1638947","","",,,,,19,9.50,6,3,2,"This paper studies neural network models of vehicle dynamics. We consider both models with a generic layer architecture and models with specialised topologies that hard-wire physics principles. Network pre-wiring is limited to universal laws; hence it does not limit the network modelling abilities on one side but allows more robust and interpretable models on the other side. Four different network types (with and without pre-wired structure, recursive and non-recursive) are compared for the longitudinal dynamics of a car with gears and two controls (brake and engine). Results show that pre-wiring effectively improves the performance. Non-recursive networks also look to be preferable for several reasons.","",""
19,"Wei-Ning Hsu, Hao Tang, James R. Glass","Unsupervised Adaptation with Interpretable Disentangled Representations for Distant Conversational Speech Recognition",2018,"","","","",49,"2022-07-13 10:08:47","","10.21437/Interspeech.2018-1097","","",,,,,19,4.75,6,3,4,"The current trend in automatic speech recognition is to leverage large amounts of labeled data to train supervised neural network models. Unfortunately, obtaining data for a wide range of domains to train robust models can be costly. However, it is relatively inexpensive to collect large amounts of unlabeled data from domains that we want the models to generalize to. In this paper, we propose a novel unsupervised adaptation method that learns to synthesize labeled data for the target domain from unlabeled in-domain data and labeled out-of-domain data. We first learn without supervision an interpretable latent representation of speech that encodes linguistic and nuisance factors (e.g., speaker and channel) using different latent variables. To transform a labeled out-of-domain utterance without altering its transcript, we transform the latent nuisance variables while maintaining the linguistic variables. To demonstrate our approach, we focus on a channel mismatch setting, where the domain of interest is distant conversational speech, and labels are only available for close-talking speech. Our proposed method is evaluated on the AMI dataset, outperforming all baselines and bridging the gap between unadapted and in-domain models by over 77% without using any parallel data.","",""
38,"Phu Mon Htut, Kyunghyun Cho, Samuel R. Bowman","Grammar Induction with Neural Language Models: An Unusual Replication",2018,"","","","",50,"2022-07-13 10:08:47","","10.18653/v1/D18-1544","","",,,,,38,9.50,13,3,4,"A substantial thread of recent work on latent tree learning has attempted to develop neural network models with parse-valued latent variables and train them on non-parsing tasks, in the hope of having them discover interpretable tree structure. In a recent paper, Shen et al. (2018) introduce such a model and report near-state-of-the-art results on the target task of language modeling, and the first strong latent tree learning result on constituency parsing. In an attempt to reproduce these results, we discover issues that make the original results hard to trust, including tuning and even training on what is effectively the test set. Here, we attempt to reproduce these results in a fair experiment and to extend them to two new datasets. We find that the results of this work are robust: All variants of the model under study outperform all latent tree learning baselines, and perform competitively with symbolic grammar induction systems. We find that this model represents the first empirical success for latent tree learning, and that neural network language modeling warrants further study as a setting for grammar induction.","",""
8,"Chi Zhang, S. A. Hosseini, S. Moeller, Sebastian Weingärtner, K. Uğurbil, M. Akçakaya","Scan-Specific Residual Convolutional Neural Networks for Fast MRI Using Residual RAKI",2019,"","","","",51,"2022-07-13 10:08:47","","10.1109/IEEECONF44664.2019.9048706","","",,,,,8,2.67,1,6,3,"Parallel imaging is a widely-used acceleration technique for magnetic resonance imaging (MRI). Conventional linear reconstruction approaches in parallel imaging suffer from noise amplification. Recently, a non-linear method that utilizes subject- specific convolutional neural networks for k-space reconstruction, Robust Artificial-neural-networks for k-space Interpolation (RAKI) was proposed and shown to improve noise resilience over linear methods. However, the linear convolutions still provide a sufficient baseline image quality and interpretability. In this paper, we sought to utilize a residual network architecture to combine the benefits of both the linear and non-linear RAKI reconstructions. This hybrid method, called residual RAKI (rRAKI) offers significant improvement in image quality compared to linear method, and improves upon RAKI in highly- accelerated simultaneous multi-slice imaging. Furthermore, it establishes an interpretable view for the use of CNNs in parallel imaging, as the CNN component in the residual network removes the noise amplification arising from the linear part.","",""
2,"M. O'Brien, Michael Medoff, J. Bukowski, Gregory Hager","Network Generalization Prediction for Safety Critical Tasks in Novel Operating Domains",2021,"","","","",52,"2022-07-13 10:08:47","","10.1109/WACV51458.2022.00190","","",,,,,2,2.00,1,4,1,"It is well known that Neural Network (network) performance often degrades when a network is used in novel operating domains that differ from its training and testing domains. This is a major limitation, as networks are being integrated into safety critical, cyber-physical systems that must work in unconstrained environments, e.g., perception for autonomous vehicles. Training networks that generalize to novel operating domains and that extract robust features is an active area of research, but previous work fails to predict what the network performance will be in novel operating domains. We propose the task Network Generalization Prediction: predicting the expected network performance in novel operating domains. We describe the network performance in terms of an interpretable Context Subspace, and we propose a methodology for selecting the features of the Context Subspace that provide the most information about the network performance. We identify the Context Subspace for a pretrained Faster RCNN network performing pedestrian detection on the Berkeley Deep Drive (BDD) Dataset, and demonstrate Network Generalization Prediction accuracy within 5% of observed performance. We also demonstrate that the Context Subspace from the BDD Dataset is informative for completely unseen datasets, JAAD and Cityscapes, where predictions have a bias of 10% or less.","",""
9,"Zachary A. Daniels, Dimitris N. Metaxas","ScenarioNet: An Interpretable Data-Driven Model for Scene Understanding",2018,"","","","",53,"2022-07-13 10:08:47","","","","",,,,,9,2.25,5,2,4,"The ability for computational agents to reason about the high-level content of real world scene images is important for many applications. Existing attempts at complex scene understanding lack representational power, efficiency, and the ability to create robust metaknowledge about scenes. We introduce scenarios as a new way of representing scenes. The scenario is an interpretable, low-dimensional, data-driven representation consisting of sets of frequently co-occurring objects that is useful for a wide range of scene understanding tasks. Scenarios are learned from data using a novel matrix factorization method which is integrated into a new neural network architecture, the ScenarioNet. Using ScenarioNet, we can recover semantic information about real world scene images at three levels of granularity: 1) scene categories, 2) scenarios, and 3) objects. Training a single ScenarioNet model enables us to perform scene classification, scenario recognition, multi-object recognition, content-based scene image retrieval, and content-based image comparison. ScenarioNet is efficient because it requires significantly fewer parameters than other CNNs while achieving similar performance on benchmark tasks, and it is interpretable because it produces evidence in an understandable format for every decision it makes. We validate the utility of scenarios and ScenarioNet on a diverse set of scene understanding tasks on several benchmark datasets.","",""
0,"M. Causse, C. James, M. Masmoudi, Houcine Turki","Parsimonious Neural Networks",2019,"","","","",54,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,4,3,"Redundancy is the backbone of state-of-the-art deep neural networks. It ensures that the learning process avoids being trapped in local minima. According to [5] “In practice, poor local minima are rarely a problem with large networks.” We are introducing a new approach of deep learning based on parsimony. The number of links to be identified by the learning process is reduced. But we enrich the structure of the neural network: any neural cell can be connected to any preceding cell. We are far from the classical layered architecture. Parsimonious approaches outperform state-of-the-art method, particularly when the response of the model is continuous, like dynamic prediction. This approach solves most of the drawbacks of existing neural network algorithms: carbon footprint is drastically reduced, the prediction capability is improved, the prediction is robust and resists to DeepFool [7] attacks. Local Interpretable Model-Agnostic Explanations (LIME) [8] is a major contribution that improves understanding of why machine learning models behave the way they do. We will show that parsimonious models offer a better interpretation. Moreover, the so created neural networks can be embedded easily and achieve real time responses using reduced computing resources and energy consumption.","",""
5,"I. Zubarev, Rasmus Zetter, Hanna-Leena Halme, L. Parkkonen","Robust and highly adaptable brain-computer interface with convolutional net architecture based on a generative model of neuromagnetic measurements",2018,"","","","",55,"2022-07-13 10:08:47","","","","",,,,,5,1.25,1,4,4,"Deep Neural Networks have been applied very successfully in image recognition and natural language processing. Recently these powerful methods have received attention also in the brain-computer interface (BCI) community. Here, we introduce a convolutional neural network (CNN) architecture optimized for classification of brain states from non-invasive magnetoencephalographic (MEG) measurements. The model structure is motivated by a state-of-the-art generative model of the MEG signal and is thus readily interpretable in neurophysiological terms. We demonstrate that the proposed model is highly accurate in decoding event-related responses as well as modulations of oscillatory brain activity, and is robust with respect to inter-individual differences. Importantly, the model generalizes well across users: when trained on data pooled from previous users, it can successfully perform on new users. Thus, the time-consuming BCI calibration can be omitted. Moreover, the model can be incrementally updated, resulting in +8.9% average accuracy improvement in offline experiments and +17.0% in a real-time BCI. We argue that this model can be used in practical BCIs and basic neuroscience research.","",""
0,"Hong Liugen, Wenzhong Wang, Yanhui Pang, Huai Hu, Jin Tang","Interpretable Verification of Visually Similar Vehicle Images Using Convolutional Networks",2018,"","","","",56,"2022-07-13 10:08:47","","10.1007/978-981-13-2922-7_13","","",,,,,0,0.00,0,5,4,"","",""
28,"Jin‐Song Pei, A. Smyth","New Approach to Designing Multilayer Feedforward Neural Network Architecture for Modeling Nonlinear Restoring Forces. I: Formulation",2006,"","","","",57,"2022-07-13 10:08:47","","10.1061/(ASCE)0733-9399(2006)132:12(1290)","","",,,,,28,1.75,14,2,16,"Based on the basic formulation developed in a companion paper, the writers now present the application of an artificial neural network approach to designing streamlined network models to simulate and identify the nonlinear dynamic response of single-degree-of-freedom oscillators using the restoring force-state mapping interpretation. The neural networks which use sigmoidal activation functions are shown to be highly robust in modeling a wide variety of commonly observed nonlinear structural dynamic response behaviors. By streamlining the networks, individual network model parameters take on physically or geometrically interpretable meaning, and hence, the network initialization can be achieved through an engineered approach rather than through less physically meaningful numerical initialization schemes. Although not proven in general, examples show that by starting with a more meaningful initial design, identification convergence is improved, and the final identified model parameters are seen to have a more physical meaning. A set of model architecture prototypes is developed to capture commonly observed nonlinear response behaviors.","",""
8,"K. Revett, F. Gorunescu, M. Gorunescu, M. Ene","Mining A Primary Biliary Cirrhosis Dataset Using Rough Sets and a Probabilistic Neural Network",2006,"","","","",58,"2022-07-13 10:08:47","","10.1109/IS.2006.348432","","",,,,,8,0.50,2,4,16,"In this paper, a decision support system based on rough sets and a probabilistic neural network is presented. Rough sets were employed as they have the capacity to reduce the dimensionality of the dataset and also produce a set of readily understandable rules. A probabilistic neural network was also employed to classify this dataset, comparing the classification accuracy to that obtained with rough sets. We firstly evaluate the effectiveness of these machine learning algorithms on a real-life small biomedical dataset. The classification results indicate that both classifiers produce a high level of accuracy (87% or better). The rough sets algorithm produced a set of rules that are readily interpretable by a domain expert. The PNN algorithm produced a classifier that was robust to noise and missing values. These preliminary results indicate that the both rough sets and PNN machine learning approaches can be successfully applied synergistically to biomedical datasets that contain a variety of attribute types, missing values and multiple decision classes","",""
8,"Simone Magnolini, Anna Feltracco, B. Magnini","FBK-HLT-NLP at SemEval-2016 Task 2: A Multitask, Deep Learning Approach for Interpretable Semantic Textual Similarity",2016,"","","","",59,"2022-07-13 10:08:47","","10.18653/v1/S16-1121","","",,,,,8,1.33,3,3,6,"We present the system developed at FBK for the SemEval 2016 Shared Task 2 ”Interpretable Semantic Textual Similarity” as well as the results of the submitted runs. We use a single neural network classification model for predicting the alignment at chunk level, the relation type of the alignment and the similarity scores. Our best run was ranked as first in one the subtracks (i.e. raw input data, Student Answers), among 12 runs submitted, and the approach proved to be very robust across the different datasets.","",""
0,"James Henderson","Estimating a Probabilistic Grammar Using a Neural Network",2000,"","","","",60,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,1,22,"Previous work has demonstrated the viability of a particular neural network archi tecture, Simple Synchrony Networks (SSNs), for syntactic parsing (Henderson & Lane, 1998), (Henderson, 2000). However the output was interpreted as a score, only interpretable in a heuristic way relative to other scores of the same type. In this paper we discuss a SSN parser trained using a method that allows us to interpret the output as probability estimates. T hese estimates are then used in a chart parser to find the most probable complete parse. This syst em compares favorably to one where the probability estimates are calculated from head bi gram counts, and to a simple Probabilistic Context Free Grammar. We argue that this is due to the weaker independence assumptions necessary for training the SSN relative to statisti cal models based on frequency counts. If so, then such neural network architectures are a potential a lternative to statistical smoothing techniques for developing robust statistical parsers .","",""
2,"R. Silva, T. Ludermir","Neural network methods for rule induction",1999,"","","","",61,"2022-07-13 10:08:47","","10.1109/IJCNN.1999.830845","","",,,,,2,0.09,1,2,23,"Local basis function networks are a useful category of classifiers, with known variations developed in neural networks, machine learning and statistics communities. The localized range of activation of the hidden units have many similarities with rule-based representations. Neurofuzzy systems are a common example of a framework that explicitly integrates these approaches. Following this concept, we study alternatives for the development of hybrid rule-neural systems with the purpose of inducing robust and interpretable classifiers. Local fitting of parameters is done by a gradient descent optimization that modifies the covering produced by a rule induction algorithm. Two tasks are accomplished: how to select a small number of rules and how to improve precision. The use of this architecture is better suited when one wants to achieve a good compromise between classification performance and simplicity.","",""
869,"E. Chichilnisky","A simple white noise analysis of neuronal light responses",2001,"","","","",62,"2022-07-13 10:08:47","","10.1080/net.12.2.199.213","","",,,,,869,41.38,869,1,21,"A white noise technique is presented for estimating the response properties of spiking visual system neurons. The technique is simple, robust, efficient and well suited to simultaneous recordings from multiple neurons. It provides a complete and easily interpretable model of light responses even for neurons that display a common form of response nonlinearity that precludes classical linear systems analysis. A theoretical justification of the technique is presented that relies only on elementary linear algebra and statistics. Implementation is described with examples. The technique and the underlying model of neural responses are validated using recordings from retinal ganglion cells, and in principle are applicable to other neurons. Advantages and disadvantages of the technique relative to classical approaches are discussed.","",""
23,"Lizhi Wang, Chen Sun, Maoqing Zhang, Ying Fu, Hua Huang","DNU: Deep Non-Local Unrolling for Computational Spectral Imaging",2020,"","","","",63,"2022-07-13 10:08:47","","10.1109/cvpr42600.2020.00173","","",,,,,23,11.50,5,5,2,"Computational spectral imaging has been striving to capture the spectral information of the dynamic world in the last few decades. In this paper, we propose an interpretable neural network for computational spectral imaging. First, we introduce a novel data-driven prior that can adaptively exploit both the local and non-local correlations among the spectral image. Our data-driven prior is integrated as a regularizer into the reconstruction problem. Then, we propose to unroll the reconstruction problem into an optimization-inspired deep neural network. The architecture of the network has high interpretability by explicitly characterizing the image correlation and the system imaging model. Finally, we learn the complete parameters in the network through end-to-end training, enabling robust performance with high spatial-spectral fidelity. Extensive simulation and hardware experiments validate the superior performance of our method over state-of-the-art methods.","",""
3,"Sahil Singla, Surbhi Singla, S. Feizi","Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100",2021,"","","","",64,"2022-07-13 10:08:47","","","","",,,,,3,3.00,1,3,1,"Training convolutional neural networks (CNNs) with a strict Lipschitz constraint under the l2 norm is useful for provable adversarial robustness, interpretable gradients and stable training. While 1-Lipschitz CNNs can be designed by enforcing a 1-Lipschitz constraint on each layer, training such networks requires each layer to have an orthogonal Jacobian matrix (for all inputs) to prevent the gradients from vanishing during backpropagation. A layer with this property is said to be Gradient Norm Preserving (GNP). In this work, we introduce a procedure to certify the robustness of 1-Lipschitz CNNs by relaxing the orthogonalization of the last linear layer of the network that significantly advances the state of the art for both standard and provable robust accuracies on CIFAR-100 (gains of 4.80% and 4.71%, respectively). We further boost their robustness by introducing (i) a novel Gradient Norm preserving activation function called the Householder activation function (that includes every GroupSort activation) and (ii) a certificate regularization. On CIFAR-10, we achieve significant improvements over prior works in provable robust accuracy (5.81%) with only a minor drop in standard accuracy (−0.29%). Code for reproducing all experiments in the paper is available at https://github.com/singlasahil14/SOC.","",""
1,"R. Cosentino, Anirvan M. Sengupta, S. Avestimehr, M. Soltanolkotabi, Antonio Ortega, Ted L. Willke, Mariano Tepper","Toward a Geometrical Understanding of Self-supervised Contrastive Learning",2022,"","","","",65,"2022-07-13 10:08:47","","10.48550/arXiv.2205.06926","","",,,,,1,1.00,0,7,1,"Self-supervised learning (SSL) is currently one of the premier techniques to create data representations that are actionable for transfer learning in the absence of human annotations. Despite their success, the underlying geometry of these representations remains elusive, which obfuscates the quest for more robust, trustworthy, and interpretable models. In particular, mainstream SSL techniques rely on a speciﬁc deep neural network architecture with two cascaded neural networks: the encoder and the projector. When used for transfer learning, the projector is discarded since empirical results show that its representation gen-eralizes more poorly than the encoder’s. In this paper, we investigate this curious phenomenon and analyze how the strength of the data augmentation policies affects the data embedding. We discover a non-trivial relation between the encoder, the projector, and the data augmentation strength: with increasingly larger augmentation policies, the projector, rather than the encoder, is more strongly driven to become invariant to the augmentations. It does so by eliminating crucial information about the data by learning to project it into a low-dimensional space, a noisy estimate of the data manifold tangent plane in the encoder representation. This analysis is substantiated through a geometrical perspective with theoretical and empirical results. by using the representation extracted in the encoder space . Large, moderate, and small augmentations refer to the strength of the data augmentation applied to the input samples (see Table 2 for each conﬁguration). The smaller the strength of the data augmentation policy, the less the projector suffers from dimensional collapse. However, when the projector is affected by a substantial dimensional collapse, the encoder representation becomes suitable for the downstream task. In this work, we demys-tify this intriguing relationship between augmentation strengths, encoder embedding, and projector geometry.","",""
1,"S. Chao, M. Brenner, N. Hacohen","Identifying Cell Type-Specific Chemokine Correlates with Hierarchical Signal Extraction from Single-Cell Transcriptomes.",2021,"","","","",66,"2022-07-13 10:08:47","","10.1142/9789811250477_0024","","",,,,,1,1.00,0,3,1,"Biological data is inherently heterogeneous and high-dimensional. Single-cell sequencing of transcripts in a tissue sample generates data for thousands of cells, each of which is characterized by upwards of tens of thousands of genes. How to identify the subsets of cells and genes that are associated with a label of interest remains an open question. In this paper, we integrate a signal-extractive neural network architecture with axiomatic feature attribution to classify tissue samples based on single-cell gene expression profiles. This approach is not only interpretable but also robust to noise, requiring just 5% of genes and 23% of cells in an in silico tissue sample to encode signal in order to distinguish signal from noise with greater than 70% accuracy. We demonstrate its applicability in two real-world settings for discovering cell type-specific chemokine correlates: predicting response to immune checkpoint inhibitors in multiple tissue types and classifying DNA mismatch repair status in colorectal cancer. Our approach not only significantly outperforms traditional machine learning classifiers but also presents actionable biological hypotheses of chemokinemediated tumor immunogenicity.","",""
1,"Ginevra Carbone, G. Sanguinetti, L. Bortolussi","Resilience of Bayesian Layer-Wise Explanations under Adversarial Attacks",2021,"","","","",67,"2022-07-13 10:08:47","","","","",,,,,1,1.00,0,3,1,"—We consider the problem of the stability of saliency- based explanations of Neural Network predictions under adversarial attacks in a classiﬁcation task. Saliency interpretations of deterministic Neural Networks are remarkably brittle even when the attacks fail, i.e. for attacks that do not change the classiﬁcation label. We empirically show that interpretations provided by Bayesian Neural Networks are considerably more stable under adversarial perturbations of the inputs and even under direct attacks to the explanations. By leveraging recent results, we also provide a theoretical explanation of this result in terms of the geometry of the data manifold. Additionally, we discuss the stability of the interpretations of high level representations of the inputs in the internal layers of a Network. Our results demonstrate that Bayesian methods, in addition to being more robust to adversarial attacks, have the potential to provide more stable and interpretable assessments of Neural Network predictions.","",""
0,"Yazan Qarout, Yordan P. Raykov, M. Little","Few-shot time series segmentation using prototype-defined infinite hidden Markov models",2021,"","","","",68,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,3,1,"We propose a robust framework for interpretable, few-shot analysis of non-stationary sequential data based on flexible graphical models to express the structured distribution of sequential events, using prototype radial basis function (RBF) neural network emissions. A motivational link is demonstrated between prototypical neural network architectures for few-shot learning and the proposed RBF network infinite hidden Markov model (RBF-iHMM). We show that RBF networks can be efficiently specified via prototypes allowing us to express complex nonstationary patterns, while hidden Markov models are used to infer principled high-level Markov dynamics. The utility of the framework is demonstrated on biomedical signal processing applications such as automated seizure detection from EEG data where RBF networks achieve state-of-the-art performance using a fraction of the data needed to train long-short-term memory variational autoencoders.","",""
0,"Henry Eigen, Amir Sadovnik","TopKConv: Increased Adversarial Robustness Through Deeper Interpretability",2021,"","","","",69,"2022-07-13 10:08:47","","10.1109/ICMLA52953.2021.00011","","",,,,,0,0.00,0,2,1,"Vulnerability to adversarial inputs remains an issue for deep neural networks. Attackers can slightly modify inputs in order to cause adverse behavior in otherwise highly accurate networks. In addition to making these networks less secure for real world applications, this also emphasizes a misalignment between the features the network uses to make decisions and the ones humans use. In this work we propose that more interpretable networks should yield more robust ones since they are able to rely on features that are more understandable to humans. More specifically, we take inspiration from interpretability based approaches to adversarial robustness, and propose a sparsity based defense to counter the impact of overparameterization on adversarial vulnerability. Building off of the work of the Dynamic-K algorithm, which introduces dynamic routing to fully connected layers in order to encourage sparse, interpretable predictions, we propose TopKConv, a novel method of reducing the number of activation channels used to construct each convolutional feature map. The incorporation of TopKConv alongside Dynamic-k results in a significant increase in adversarial accuracy at no cost to benign accuracy. Further, this is achieved with no fine tuning of or adversarial training.","",""
35,"A. Malinin","Uncertainty estimation in deep learning with application to spoken language assessment",2019,"","","","",70,"2022-07-13 10:08:47","","10.17863/CAM.45912","","",,,,,35,11.67,35,1,3,"Since convolutional neural networks (CNNs) achieved top performance on the ImageNet task in 2012, deep learning has become the preferred approach to addressing computer vision, natural language processing, speech recognition and bio-informatics tasks. However, despite impressive performance, neural networks tend to make over-confident predictions. Thus, it is necessary to investigate robust, interpretable and tractable estimates of uncertainty in a model’s predictions in order to construct safer Machine Learning systems. This is crucial to applications where the cost of an error is high, such as in autonomous vehicle control, high-stakes automatic proficiency assessment and in the medical, financial and legal fields. In the first part of this thesis uncertainty estimation via ensemble and single-model approaches is discussed in detail and a new class of models for uncertainty estimation, called Prior Networks, is proposed. Prior Networks are able to emulate an ensemble of models using a single deterministic neural network, which allows sources of uncertainty to be determined within the same probabilistic framework as in ensemble-based approaches, but with the computational simplicity and ease of training of single-model approaches. Thus, Prior Networks combine the advantages of ensemble and single-model approaches to estimating uncertainty. In this thesis Prior Networks are evaluated on a range classification datasets, where they are shown to outperform baseline approaches, such as Monte-Carlo dropout, on the task of detecting out-of-distribution inputs. In the second part of this thesis deep learning and uncertainty estimation approaches are applied to the area of automatic assessment of non-native spoken language proficiency. Specifically deep-learning based graders and spoken response relevance assessment systems are constructed using data from the BULATS and LinguaSkill exams, provided by Cambridge English Language Assessment. Baseline approaches for uncertainty estimation discussed and evaluated in the first half of the thesis are then applied to these models and assessed on the task of rejecting predictions to be graded by human examiners and detecting misclassifications.","",""
7,"K. Koneripalli, Suhas Lohit, Rushil Anirudh, P. Turaga","Rate-Invariant Autoencoding of Time-Series",2020,"","","","",71,"2022-07-13 10:08:47","","10.1109/ICASSP40776.2020.9053983","","",,,,,7,3.50,2,4,2,"For time-series classification and retrieval applications, an important requirement is to develop representations/metrics that are robust to re-parametrization of the time-axis. Temporal re-parametrization as a model can account for variability in the underlying generative process, sampling rate variations, or plain temporal mis-alignment. In this paper, we extend prior work in disentangling latent spaces of autoencoding models, to design a novel architecture to learn rate-invariant latent codes in a completely unsupervised fashion. Unlike conventional neural network architectures, this method allows to explicitly disentangle temporal parameters in the form of order-preserving diffeomorphisms with respect to a learnable template. This makes the latent space more easily interpretable. We show the efficacy of our approach on a synthetic dataset and a real dataset for hand action-recognition.","",""
7,"Jiankai Sun, Haowei Sun, Tian Han, Bolei Zhou","Neuro-Symbolic Program Search for Autonomous Driving Decision Module Design",2020,"","","","",72,"2022-07-13 10:08:47","","","","",,,,,7,3.50,2,4,2,"As a promising topic in cognitive robotics, neuro-symbolic modeling integrates symbolic reasoning and neural representation altogether. However, previous neuro-symbolic models usually wire their structures and the connections manually, making the underlying parameters sub-optimal. In this work, we propose the Neuro-Symbolic Program Search (NSPS) to improve the autonomous driving system design. NSPS is a novel automated search method that synthesizes the Neuro-Symbolic Programs. It can produce robust and expressive Neuro-Symbolic Programs and automatically tune the hyper-parameters. We validate NSPS in the CARLA driving simulation environment. The resulting Neuro-Symbolic Decision Programs successfully handle multiple traffic scenarios. Compared with previous neural-network-based driving and rule-based methods, our neuro-symbolic driving pipeline achieves more stable and safer behaviors in complex driving scenarios while maintaining an interpretable symbolic decision-making process.","",""
5,"Tianchen Ji, S. Vuppala, Girish Chowdhary, K. Driggs-Campbell","Multi-Modal Anomaly Detection for Unstructured and Uncertain Environments",2020,"","","","",73,"2022-07-13 10:08:47","","","","",,,,,5,2.50,1,4,2,"To achieve high-levels of autonomy, modern robots require the ability to detect and recover from anomalies and failures with minimal human supervision. Multi-modal sensor signals could provide more information for such anomaly detection tasks; however, the fusion of high-dimensional and heterogeneous sensor modalities remains a challenging problem. We propose a deep learning neural network: supervised variational autoencoder (SVAE), for failure identification in unstructured and uncertain environments. Our model leverages the representational power of VAE to extract robust features from high-dimensional inputs for supervised learning tasks. The training objective unifies the generative model and the discriminative model, thus making the learning a one-stage procedure. Our experiments on real field robot data demonstrate superior failure identification performance than baseline methods, and that our model learns interpretable representations. Videos of our results are available on our website: this https URL .","",""
5,"Blake Ruprecht, Wenlong Wu, M. Islam, Derek T. Anderson, James M. Keller, G. Scott, Curt Davis, F. Petry, P. Elmore, Kristen Nock, Elizabeth Gilmour","Possibilistic Clustering Enabled Neuro Fuzzy Logic",2020,"","","","",74,"2022-07-13 10:08:47","","10.1109/FUZZ48607.2020.9177593","","",,,,,5,2.50,1,11,2,"Artificial neural networks are a dominant force in our modern era of data-driven artificial intelligence. The adaptive neuro fuzzy inference system (ANFIS) is a neural network based on fuzzy logic versus a more traditional premise like convolution. Advantages of ANFIS include the ability to encode and potentially understand machine learned neural information in the pursuit of explainable, interpretable, and ultimately trustworthy artificial intelligence. However, real-world data is almost always imperfect, e.g., incomplete or noisy, and ANFIS is not naturally robust. Specifically, ANFIS is susceptible to over inflated uncertainty, poor antecedent (fuzzy set) data alignment, degenerate optimization conditions, and hard to interpret logic, to name a few factors. Herein, we explore the use of possibilistic clustering to identify outliers, specifically typicality degrees, to increase the robustness of ANFIS; or any fuzzy logic neuron/network. Experiments are presented that demonstrate the need and quality of the proposed solutions in the pursuit of robust interpretable machine learned neuro fuzzy logic solutions.","",""
3,"Chen Wang, Chengyuan Deng, Vladimir A. Ivanov","SAG-VAE: End-to-end Joint Inference of Data Representations and Feature Relations",2019,"","","","",75,"2022-07-13 10:08:47","","10.1109/IJCNN48605.2020.9207154","","",,,,,3,1.00,1,3,3,"The ability to capture relations within data can provide the much needed inductive bias for robust and interpretable Machine Learning algorithms. Variational Autoencoder (VAE) is a promising candidate for such purpose thanks to their power in data representation inference, but its vanilla form and common variations cannot process feature relations. In this paper, inspired by recent advances in relational learning with graph neural networks, we propose the Self-Attention Graph Variational AutoEncoder (SAG-VAE) model which can simultaneously learn feature relations and data representations in an end-to-end manner. The SAG-VAE is trained by jointly inferring the posterior distribution of two types of latent variables, which respectively represent the data and the feature relations. The feature relations are represented as a graph structure, and the presence of each edge is determined by a Gumbel-Softmax distribution. The generative model is accordingly parameterized by a graph neural network with a special attention mechanism we introduced in the paper. Therefore, the SAG-VAE model can generate via graph convolution and be trained via backpropagation. Experiments based on graphs show that SAG-VAE is capable of approximately retrieving edges and links between vertices based entirely on feature observations. Furthermore, experiments on image data illustrate that the learned feature relations can provide the SAG-VAE robustness against perturbations in image reconstruction and sampling. The learned feature relations as graph adjacency matrices are observed to be structured, which provides intuitive interpretability of the models.","",""
1,"Arindam Mitra, Sanjay Narayana, Chitta Baral","Deeply Embedded Knowledge Representation & Reasoning For Natural Language Question Answering: A Practitioner’s Perspective",2020,"","","","",76,"2022-07-13 10:08:47","","10.18653/v1/2020.spnlp-1.12","","",,,,,1,0.50,0,3,2,"Successful application of Knowledge Representation and Reasoning (KR) in Natural Language Understanding (NLU) is largely limited by the availability of a robust and general purpose natural language parser. Even though several projects have been launched in the pursuit of developing a universal meaning representation language, the existence of an accurate universal parser is far from reality. This has severely limited the application of knowledge representation and reasoning (KR) in the field of NLP and also prevented a proper evaluation of KR based NLU systems. Our goal is to build KR based systems for Natural Language Understanding without relying on a parser. Towards this we propose a method named Deeply Embedded Knowledge Representation & Reasoning (DeepEKR) where we replace the parser by a neural network, soften the symbolic representation so that a deterministic mapping exists between the parser neural network and the interpretable logical form, and finally replace the symbolic solver by an equivalent neural network, so the model can be trained end-to-end. We evaluate our method with respect to the task of Qualitative Word Problem Solving on the two available datasets (QuaRTz and QuaRel). Our system achieves same accuracy as that of the state-of-the-art accuracy on QuaRTz, outperforms the state-of-the-art on QuaRel and severely outperforms a traditional KR based system. The results show that the bias introduced by a KR solution does not prevent it from doing a better job at the end task. Moreover, our method is interpretable due to the bias introduced by the KR approach.","",""
13,"Jiaxin Shi, Chen Liang, Lei Hou, Juan-Zi Li, Zhiyuan Liu, Hanwang Zhang","DeepChannel: Salience Estimation by Contrastive Learning for Extractive Document Summarization",2018,"","","","",77,"2022-07-13 10:08:47","","10.1609/aaai.v33i01.33016999","","",,,,,13,3.25,2,6,4,"We propose DeepChannel, a robust, data-efficient, and interpretable neural model for extractive document summarization. Given any document-summary pair, we estimate a salience score, which is modeled using an attention-based deep neural network, to represent the salience degree of the summary for yielding the document. We devise a contrastive training strategy to learn the salience estimation network, and then use the learned salience score as a guide and iteratively extract the most salient sentences from the document as our generated summary. In experiments, our model not only achieves state-of-the-art ROUGE scores on CNN/Daily Mail dataset, but also shows strong robustness in the out-of-domain test on DUC2007 test set. Moreover, our model reaches a ROUGE-1 F-1 score of 39.41 on CNN/Daily Mail test set with merely 1/100 training set, demonstrating a tremendous data efficiency.","",""
4,"Zhenyu Yang, Guojing Liu","Hierarchical Sequence-to-Sequence Model for Multi-Label Text Classification",2019,"","","","",78,"2022-07-13 10:08:47","","10.1109/ACCESS.2019.2948855","","",,,,,4,1.33,2,2,3,"We propose a novel sequence-to-sequence model for multi-label text classification, based on a “parallel encoding, serial decoding” strategy. The model combines a convolutional neural network and self-attention in parallel as the encoder to extract fine-grained local neighborhood information and global interaction information from the source text. We design a hierarchical decoder to decode and generate the label sequence. Our method not only gives full consideration to the interpretable fine-gained information in the source text but also effectively utilizes the information to generate the label sequence. We conducted a large number of comparative experiments on three datasets. The results show that the proposed model has significant advantages over the state-of-the-art baseline model. In addition, our analysis demonstrates that our model is competitive with the RNN-based Seq2Seq models and that it is more robust at handling datasets with a high label/sample ratio.","",""
2,"Aishwarya H. Balwani, Eva L. Dyer","Modeling Variability in Brain Architecture with Deep Feature Learning",2019,"","","","",79,"2022-07-13 10:08:47","","10.1109/IEEECONF44664.2019.9048805","","",,,,,2,0.67,1,2,3,"The brain has long been divided into distinct areas based upon its local microstructure, or patterned composition of cells, genes, and proteins. While this taxonomy is incredibly useful and provides an essential roadmap for comparing two brains, there is also immense anatomical variability within areas that must be incorporated into models of brain architecture. In this work we leverage the expressive power of deep neural networks to create a data-driven model of intra- and inter-brain area variability. To this end, we train a convolutional neural network that learns relevant microstructural features directly from brain imagery. We then extract features from the network and fit a simple classifier to them, thus creating a simple, robust, and interpretable model of brain architecture. We further propose and show preliminary results for the use of features from deep neural networks in conjunction with unsupervised learning techniques to find fine-grained structure within brain areas. We apply our methods to micron-scale X-ray microtomography images spanning multiple regions in the mouse brain and demonstrate that our deep feature-based model can reliably discriminate between brain areas, is robust to noise, and can be used to reveal anatomically relevant patterns in neural architecture that the network wasn’t trained to find.","",""
51,"David Filliat, Emmanuel Battesti, S. Bazeille, G. Duceux, A. Gepperth, Lotfi Harrath, Islem Jebari, Rafael Pereira, A. Tapus, Cedric Meyer, S. Ieng, R. Benosman, Eddy Cizeron, Jean-Charles Mamanna, Benoit Pothier","RGBD object recognition and visual texture classification for indoor semantic mapping",2012,"","","","",80,"2022-07-13 10:08:47","","10.1109/TePRA.2012.6215666","","",,,,,51,5.10,5,15,10,"We present a mobile robot whose goal is to autonomously explore an unknown indoor environment and to build a semantic map containing high-level information similar to those extracted by humans. This information includes the rooms, their connectivity, the objects they contain and the material of the walls and ground. This robot was developed in order to participate in a French exploration and mapping contest called CAROTTE whose goal is to produce easily interpretable maps of an unknown environment. In particular we present our object detection approach based on a color+depth camera that fuse 3D, color and texture information through a neural network for robust object recognition. We also present the material recognition approach based on machine learning applied to vision. We demonstrate the performances of these modules on image databases and provide examples on the full system working in real environments.","",""
13,"Fabian Sachara, Thomas Kopinski, A. Gepperth, U. Handmann","Free-hand gesture recognition with 3D-CNNs for in-car infotainment control in real-time",2017,"","","","",81,"2022-07-13 10:08:47","","10.1109/ITSC.2017.8317684","","",,,,,13,2.60,3,4,5,"In this contribution we present a novel approach to transform data from time-of-flight (ToF) sensors to be interpretable by Convolutional Neural Networks (CNNs). As ToF data tends to be overly noisy depending on various factors such as illumination, reflection coefficient and distance, the need for a robust algorithmic approach becomes evident. By spanning a three-dimensional grid of fixed size around each point cloud we are able to transform three-dimensional input to become processable by CNNs. This simple and effective neighborhood-preserving methodology demonstrates that CNNs are indeed able to extract the relevant information and learn a set of filters, enabling them to differentiate a complex set of ten different gestures obtained from 20 different individuals and containing 600.000 samples overall. Our 20-fold cross-validation shows the generalization performance of the network, achieving an accuracy of up to 98.5% on validation sets comprising 20.000 data samples. The real-time applicability of our system is demonstrated via an interactive validation on an infotainment system running with up to 40fps on an iPad in the vehicle interior.","",""
19,"W. Shoombuatong, V. Prachayasittikul, V. Prachayasittikul, C. Nantasenamat","Prediction of aromatase inhibitory activity using the efficient linear method (ELM)",2015,"","","","",82,"2022-07-13 10:08:47","","10.17179/excli2015-140","","",,,,,19,2.71,5,4,7,"Aromatase inhibition is an effective treatment strategy for breast cancer. Currently, several in silico methods have been developed for the prediction of aromatase inhibitors (AIs) using artificial neural network (ANN) or support vector machine (SVM). In spite of this, there are ample opportunities for further improvements by developing a simple and interpretable quantitative structure-activity relationship (QSAR) method. Herein, an efficient linear method (ELM) is proposed for constructing a highly predictive QSAR model containing a spontaneous feature importance estimator. Briefly, ELM is a linear-based model with optimal parameters derived from genetic algorithm. Results showed that the simple ELM method displayed robust performance with 10-fold cross-validation MCC values of 0.64 and 0.56 for steroidal and non-steroidal AIs, respectively. Comparative analyses with other machine learning methods (i.e. ANN, SVM and decision tree) were also performed. A thorough analysis of informative molecular descriptors for both steroidal and non-steroidal AIs provided insights into the mechanism of action of compounds. Our findings suggest that the shape and polarizability of compounds may govern the inhibitory activity of both steroidal and non-steroidal types whereas the terminal primary C(sp3) functional group and electronegativity may be required for non-steroidal AIs. The R code of the ELM method is available at http://dx.doi.org/10.6084/m9.figshare.1274030.","",""
1,"Kai Yi, Shi-tao Chen, Yu Chen, Chao Xia, N. Zheng","Cognition-Based Deep Learning: Progresses and Perspectives",2018,"","","","",83,"2022-07-13 10:08:47","","10.1007/978-3-319-92007-8_11","","",,,,,1,0.25,0,5,4,"","",""
19,"Mohsen Hajiloo, H. Rabiee, Mahdi Anooshahpour","Fuzzy support vector machine: an efficient rule-based classification technique for microarrays",2013,"","","","",84,"2022-07-13 10:08:47","","10.1186/1471-2105-14-S13-S4","","",,,,,19,2.11,6,3,9,"","",""
3,"A. Chan, Yang Yang, Francis K. W. Wong, Daniel W. M. Chan, E. W. Lam","Wearing comfort of two construction work uniforms",2015,"","","","",85,"2022-07-13 10:08:47","","10.1108/CI-06-2015-0037","","",,,,,3,0.43,1,5,7,"Purpose – The aim of this study is to investigate wearing comfort of summer work uniforms judged by construction workers. Design/methodology/approach – A total of 189 male construction workers participated in a series of wear trials and questionnaire surveys in the summer of 2014. They were asked to randomly wear two types of work uniforms (i.e. uniforms A and B) in the two-day field survey and the subjective attributes of these uniforms were assessed. Three analytical techniques, namely, multiple regression, artificial neural network and fuzzy logic were used to predict wearing comfort affected by the six subjective sensations. Findings – The results revealed that fuzzy logic was a robust and practical tool for predicting wearing comfort in terms of better prediction performance and more interpretable results than the other models. Pressure attributes were further found to exert a greater effect than thermal–wet attributes on wearing comfort. Overall, the use of uniform B exhibited profound benefits on w...","",""
2,"John Z. Shi, F. Gu, B. Lennox, A. Ball","A Grey-box Modelling and Its Application in Model-based Fault Detection",2009,"","","","",86,"2022-07-13 10:08:47","","","","",,,,,2,0.15,1,4,13,"In order to provide an accurate and robust model with model-based fault detection, this paper combines a mathematical model and neural networks to develop a grey-box model. In the grey-box model, the mathematical model represents the dominant behaviour of the system, leaving the mismatch part of the system to be approximated by neural networks. The output of the grey-box model is used for residual generation in the model-based fault detection approach. Because the neural network compensates the model error from the mathematical model, a high accuracy model can be obtained and the residual generated under normal conditions can also be minimised by the combination. On the other hand, because most of the mathematical model mismatches exist in transients, the working load of the neural network can be reduced and the network structure can be simplified by the combination. Moreover, the grey box model provides more robust residual than black-box model and it enables the residual signatures to be physically interpretable. The capability of this grey-box model-based approach is evaluated in model accuracy and sensitivity in detecting faults introduced on an electro-hydraulic control system.","",""
6,"W. Ji, R. Naguib, John. Macall, D. Petrović, E. Gaura, M. Ghoneim","Prognostic prediction of bilharziasis-related bladder cancer by neuro-fuzzy classifier",2003,"","","","",87,"2022-07-13 10:08:47","","10.1109/ITAB.2003.1222505","","",,,,,6,0.32,1,6,19,"Cancer prognostic prediction requires a classification system that is robust to the interaction and uncertainty of input factors, as well as being interpretable on the decision made. In this paper, a hybrid neuro-fuzzy classifier is applied to determine the long-term outcome of patients with bilharziasis-related bladder cancer. The same data set is also analysed by a multi-layer perception neural network (MLPNN) and logistic regression, which are both widely used in the area of medical decision-making. In order to better assess the value of this neuro-fuzzy classifier, a benchmark data set used in this area of oncology, the Wisconsin breast cancer data (WBCD), is examined by the above three methods. The study demonstrates that the hybrid neuro-fuzzy classifier is efficient in cancer data analysis and it yields a high classification rate of 97.1% for WBCD, and 84.9% for the bladder cancer data, respectively.","",""
2,"Zuo Li","Data Mining and Speech Driven Face Animation",2002,"","","","",88,"2022-07-13 10:08:47","","","","",,,,,2,0.10,2,1,20,"We present a data-mining framework in audio-visual interaction. Several methods including neural network, unsupervised clustering and statistical method are used to learn synchronous pattern for speech driven face animation from large recorded audio-visual database, then apply this with an audio to produce realistic whole-face action, including lip-syncing and upper-face expression, with correct dynamics and co-articulation. The proposed method not only automatically incorporates vocal and facial dynamics such co-articulation,but also is characterized with easy training, more robust, extensible and interpretable. The performance of our system shows that the proposed learning algorithm is suitable, which greatly improves the realism of face animation during speech.","",""
22,"Adam Kortylewski, Qing Liu, Angtian Wang, Yihong Sun, A. Yuille","Compositional Convolutional Neural Networks: A Robust and Interpretable Model for Object Recognition under Occlusion",2020,"","","","",89,"2022-07-13 10:08:47","","10.1007/s11263-020-01401-3","","",,,,,22,11.00,4,5,2,"","",""
6,"Kaveri A. Thakoor, Sharath C. Koorathota, D. Hood, P. Sajda","Robust and Interpretable Convolutional Neural Networks to Detect Glaucoma in Optical Coherence Tomography Images",2020,"","","","",90,"2022-07-13 10:08:47","","10.1109/tbme.2020.3043215","","",,,,,6,3.00,2,4,2,"Recent studies suggest that deep learning systems can now achieve performance on par with medical experts in diagnosis of disease. A prime example is in the field of ophthalmology, where convolutional neural networks (CNNs) have been used to detect retinal and ocular diseases. However, this type of artificial intelligence (AI) has yet to be adopted clinically due to questions regarding robustness of the algorithms to datasets collected at new clinical sites and a lack of explainability of AI-based predictions, especially relative to those of human expert counterparts. In this work, we develop CNN architectures that demonstrate robust detection of glaucoma in optical coherence tomography (OCT) images and test with concept activation vectors (TCAVs) to infer what image concepts CNNs use to generate predictions. Furthermore, we compare TCAV results to eye fixations of clinicians, to identify common decision-making features used by both AI and human experts. We find that employing fine-tuned transfer learning and CNN ensemble learning create end-to-end deep learning models with superior robustness compared to previously reported hybrid deep-learning/machine-learning models, and TCAV/eye-fixation comparison suggests the importance of three OCT report sub-images that are consistent with areas of interest fixated upon by OCT experts to detect glaucoma. The pipeline described here for evaluating CNN robustness and validating interpretable image concepts used by CNNs with eye movements of experts has the potential to help standardize the acceptance of new AI tools for use in the clinic.","",""
5,"Hui Guo, Shu Hu, Xin Wang, Ming-Ching Chang, Siwei Lyu","Robust Attentive Deep Neural Network for Exposing GAN-generated Faces",2021,"","","","",91,"2022-07-13 10:08:47","","","","",,,,,5,5.00,1,5,1,"GAN-based techniques that generate and synthesize realistic faces have caused severe social concerns and security problems. Existing methods for detecting GAN-generated faces can perform well on limited public datasets. However, images from existing public datasets do not represent real-world scenarios well enough in terms of view variations and data distributions (where real faces largely outnumber synthetic faces). The stateof-the-art methods do not generalize well in real-world problems and lack the interpretability of detection results. Performance of existing GAN-face detection models degrades significantly when facing imbalanced data distributions. To address these shortcomings, we propose a robust, attentive, end-to-end network that can spot GAN-generated faces by analyzing their eye inconsistencies. Specifically, our model learns to identify inconsistent eye components by localizing and comparing the iris artifacts between the two eyes automatically. Our deep network addresses the imbalance learning issues by considering the AUC loss and the traditional cross-entropy loss jointly. Comprehensive evaluations of the FFHQ dataset in terms of both balanced and imbalanced scenarios demonstrate the superiority of the proposed method.","",""
22,"Hantao Huang, Jingye Zhou, Qingxun Di, Jiawei Zhou, Jiawang Li","Robust neural network–based tracking control and stabilization of a wheeled mobile robot with input saturation",2018,"","","","",92,"2022-07-13 10:08:47","","10.1002/rnc.4396","","",,,,,22,5.50,4,5,4,"This paper presents a robust neural network–based control scheme to deal with the problem of tracking and stabilization simultaneously for a wheeled mobile robot subject to parametric uncertainties, external disturbances, and input saturation. At first, a new error‐state transformation scheme is designed by introducing some auxiliary variables as an additional virtual control signals to reduce the adverse effect caused by the underactuation. These variables can change their structures for different desired trajectories to be tracked. Then, a robust control law is proposed combining with a kinematic controller and a dynamic controller, while a three‐layer neural network system is applied to approximate model uncertainties. Stability analysis via the Lyapunov theory shows that the proposed controller can make tracking errors converge to bounded neighborhoods of the origin. Finally, some simulation results are illustrated to verify the effectiveness of the proposed control strategy.","",""
11,"Peter K. Koo, Sharon Qian, Gal Kaplun, Verena Volf, Dimitris Kalimeris","Robust Neural Networks are More Interpretable for Genomics",2019,"","","","",93,"2022-07-13 10:08:47","","10.1101/657437","","",,,,,11,3.67,2,5,3,"Deep neural networks (DNNs) have been applied to a variety of regulatory genomics tasks. For interpretability, attribution methods are employed to provide importance scores for each nucleotide in a given sequence. However, even with state-of-the-art DNNs, there is no guarantee that these methods can recover interpretable, biological representations. Here we perform systematic experiments on synthetic genomic data to raise awareness of this issue. We find that deeper networks have better generalization performance, but attribution methods recover less interpretable representations. Then, we show training methods promoting robustness – including regularization, injecting random noise into the data, and adversarial training – significantly improve interpretability of DNNs, especially for smaller datasets.","",""
17,"Sercan Ö. Arik, Tomas Pfister","Attention-Based Prototypical Learning Towards Interpretable, Confident and Robust Deep Neural Networks",2019,"","","","",94,"2022-07-13 10:08:47","","","","",,,,,17,5.67,9,2,3,"We propose a new framework for prototypical learning that bases decision-making on few relevant examples that we call prototypes. Our framework utilizes an attention mechanism that relates the encoded representations to determine the prototypes. This results in a model that: (1) enables interpretability by outputting samples most relevant to the decision-making in addition to outputting the classification results; (2) allows confidence-controlled prediction by quantifying the mismatch across prototype labels; (3) permits detection of distribution mismatch; and (4) improves robustness to label noise. We demonstrate that our model is able to maintain comparable performance to baseline models while enabling all these benefits.","",""
2,"F. Hu, Jiaxin Jiang, P. Yin","Interpretable Prediction of Protein-Ligand Interaction by Convolutional Neural Network",2019,"","","","",95,"2022-07-13 10:08:47","","10.1109/BIBM47256.2019.8982989","","",,,,,2,0.67,1,3,3,"Evaluation of protein-ligand interaction is a crucial step in the process of drug discovery. Recently, several methods based on deep learning have gained impressive binary classification performance on protein-ligand binding prediction. However, lack of three-dimensional complex data still limits the accuracy and robustness of evaluation of protein-ligand binding affinity, as well as the prediction of their binding sites. In this paper, we propose a novel convolutional neural network based method for estimating the binding affinity between protein and ligand using only 1D sequence data. Even with the same amount of sample size, this model outperforms other structure-dependent traditional and machine learning based methods in terms of both binary classification and regression task. Furthermore, we use this model to identify the key amino acid residues of protein that are vital for binding interaction, which provides biological interpretation.","",""
21,"Weiqi Ji, Sili Deng","Autonomous Discovery of Unknown Reaction Pathways from Data by Chemical Reaction Neural Network",2020,"","","","",96,"2022-07-13 10:08:47","","10.1021/acs.jpca.0c09316","","",,,,,21,10.50,11,2,2,"Chemical reactions occur in energy, environmental, biological, and many other natural systems, and the inference of the reaction networks is essential to understand and design the chemical processes in engineering and life sciences. Yet, revealing the reaction pathways for complex systems and processes is still challenging because of the lack of knowledge of the involved species and reactions. Here, we present a neural network approach that autonomously discovers reaction pathways from the time-resolved species concentration data. The proposed chemical reaction neural network (CRNN), by design, satisfies the fundamental physics laws, including the law of mass action and the Arrhenius law. Consequently, the CRNN is physically interpretable such that the reaction pathways can be interpreted, and the kinetic parameters can be quantified simultaneously from the weights of the neural network. The inference of the chemical pathways is accomplished by training the CRNN with species concentration data via stochastic gradient descent. We demonstrate the successful implementations and the robustness of the approach in elucidating the chemical reaction pathways of several chemical engineering and biochemical systems. The autonomous inference by the CRNN approach precludes the need for expert knowledge in proposing candidate networks and addresses the curse of dimensionality in complex systems. The physical interpretability also makes the CRNN capable of not only fitting the data for a given system but also developing knowledge of unknown pathways that could be generalized to similar chemical systems.","",""
19,"Chao Jiang, R. Vinuesa, Ruilin Chen, Junyi Mi, Shujin Laima, Hui Li","An interpretable framework of data-driven turbulence modeling using deep neural networks",2021,"","","","",97,"2022-07-13 10:08:47","","10.1063/5.0048909","","",,,,,19,19.00,3,6,1,"Reynolds-averaged Navier–Stokes simulations represent a cost-effective option for practical engineering applications, but are facing ever-growing demands for more accurate turbulence models. Recently, emerging machine learning techniques have had a promising impact on turbulence modeling, but are still in their infancy regarding widespread industrial adoption. Toward their extensive uptake, this paper presents a universally interpretable machine learning (UIML) framework for turbulence modeling, which consists of two parallel machine learning-based modules to directly infer the structural and parametric representations of turbulence physics, respectively. At each phase of model development, data reflecting the evolution dynamics of turbulence and domain knowledge representing prior physical considerations are converted into modeling knowledge. The data- and knowledge-driven UIML is investigated with a deep residual network. The following three aspects are demonstrated in detail: (i) a compact input feature parameterizing a new turbulent timescale is introduced to prevent nonunique mappings between conventional input arguments and output Reynolds stress; (ii) a realizability limiter is developed to overcome the under-constrained state of modeled stress; and (iii) fairness and noise-insensitivity constraints are included in the training procedure. Consequently, an invariant, realizable, unbiased, and robust data-driven turbulence model is achieved. The influences of the training dataset size, activation function, and network hyperparameter on the performance are also investigated. The resulting model exhibits good generalization across two- and three-dimensional flows, and captures the effects of the Reynolds number and aspect ratio. Finally, the underlying rationale behind prediction is explored.","",""
0,"Yipeng Du, Jian Liu","IENet: a robust convolutional neural network for EEG based brain-computer interfaces",2022,"","","","",98,"2022-07-13 10:08:47","","10.1088/1741-2552/ac7257","","",,,,,0,0.00,0,2,1,"Objective. Brain-computer interfaces (BCIs) based on electroencephalogram (EEG) develop into novel application areas with more complex scenarios, which put forward higher requirements for the robustness of EEG signal processing algorithms. Deep learning can automatically extract discriminative features and potential dependencies via deep structures, demonstrating strong analytical capabilities in numerous domains such as computer vision and natural language processing. Making full use of deep learning technology to design a robust algorithm that is capable of analyzing EEG across BCI paradigms is our main work in this paper. Approach. Inspired by InceptionV4 and InceptionTime architecture, we introduce a neural network ensemble named InceptionEEG-Net (IENet), where multi-scale convolutional layer and convolution of length 1 enable model to extract rich high-dimensional features with limited parameters. In addition, we propose the average receptive field (RF) gain for convolutional neural networks (CNNs), which optimizes IENet to detect long patterns at a smaller cost. We compare with the current state-of-the-art methods across five EEG-BCI paradigms: steady-state visual evoked potentials (VEPs), epilepsy EEG, overt attention P300 VEPs, covert attention P300 visual-EPs and movement-related cortical potentials. Main results. The classification results show that the generalizability of IENet is on par with the state-of-the-art paradigm-agnostic models on test datasets. Furthermore, the feature explainability analysis of IENet illustrates its capability to extract neurophysiologically interpretable features for different BCI paradigms, ensuring the reliability of algorithm. Significance. It can be seen from our results that IENet can generalize to different BCI paradigms. And it is essential for deep CNNs to increase the RF size using average RF gain.","",""
5,"Naoya Takeishi, Alexandros Kalousis","Physics-Integrated Variational Autoencoders for Robust and Interpretable Generative Modeling",2021,"","","","",99,"2022-07-13 10:08:47","","","","",,,,,5,5.00,3,2,1,"Integrating physics models within machine learning models holds considerable promise toward learning robust models with improved interpretability and abilities to extrapolate. In this work, we focus on the integration of incomplete physics models into deep generative models. In particular, we introduce an architecture of variational autoencoders (VAEs) in which a part of the latent space is grounded by physics. A key technical challenge is to strike a balance between the incomplete physics and trainable components such as neural networks for ensuring that the physics part is used in a meaningful manner. To this end, we propose a regularized learning method that controls the effect of the trainable components and preserves the semantics of the physics-based latent variables as intended. We not only demonstrate generative performance improvements over a set of synthetic and real-world datasets, but we also show that we learn robust models that can consistently extrapolate beyond the training distribution in a meaningful manner. Moreover, we show that we can control the generative process in an interpretable manner.","",""
24,"Tianyu Kang, W. Ding, Luoyan Zhang, D. Ziemek, Kourosh Zarringhalam","A biological network-based regularized artificial neural network model for robust phenotype prediction from gene expression data",2017,"","","","",100,"2022-07-13 10:08:47","","10.1186/s12859-017-1984-2","","",,,,,24,4.80,5,5,5,"","",""
6,"Yashas B L Samaga, Shampa Raghunathan, U. D. Priyakumar","SCONES: Self-Consistent Neural Network for Protein Stability Prediction Upon Mutation.",2021,"","","","",101,"2022-07-13 10:08:47","","10.26434/CHEMRXIV.14729445.V1","","",,,,,6,6.00,2,3,1,"Engineering proteins to have desired properties by mutating amino acids at specific sites is commonplace. Such engineered proteins must be stable to function. Experimental methods used to determine stability at throughputs required to scan the protein sequence space thoroughly are laborious. To this end, many machine learning based methods have been developed to predict thermodynamic stability changes upon mutation. These methods have been evaluated for symmetric consistency by testing with hypothetical reverse mutations. In this work, we propose transitive data augmentation, evaluating transitive consistency with our new Stransitive data set, and a new machine learning based method, the first of its kind, that incorporates both symmetric and transitive properties into the architecture. Our method, called SCONES, is an interpretable neural network that predicts small relative protein stability changes for missense mutations that do not significantly alter the structure. It estimates a residue's contributions toward protein stability (ΔG) in its local structural environment, and the difference between independently predicted contributions of the reference and mutant residues is reported as ΔΔG. We show that this self-consistent machine learning architecture is immune to many common biases in data sets, relies less on data than existing methods, is robust to overfitting, and can explain a substantial portion of the variance in experimental data.","",""
0,"Preetam Prabhu Srikar Dammu, S. Chalamala, A. Singh, B. Yegnanarayana","Interpretable and Robust Face Verification",2021,"","","","",102,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,4,1,"Advances in deep learning have been instrumental in enhancing the performance of face verification systems. Despite their ability to attain high accuracy, most of these systems fail to provide interpretations of their decisions. With the increased demands in making deep learning models more interpretable, numerous post-hoc methods have been proposed to probe the workings of these systems. Yet, the quest for face verification systems that inherently provide interpretations still remains largely unexplored. Additionally, most of the existing face recognition models are highly susceptible to adversarial attacks. In this work, we propose a face verification system which addresses the issue of interpretability by employing modular neural networks. In this, representations for each individual facial parts such as nose, mouth, eyes etc. are learned separately. We also show that our method is significantly more resistant to adversarial attacks, thereby addressing another crucial weakness concerning deep learning models.","",""
33,"A. Szab'o, C. Castelnovo","Neural network wave functions and the sign problem",2020,"","","","",103,"2022-07-13 10:08:47","","10.1103/PHYSREVRESEARCH.2.033075","","",,,,,33,16.50,17,2,2,"Neural quantum states (NQS) are a promising approach to study many-body quantum physics. However, they face a major challenge when applied to lattice models: Convolutional networks struggle to converge to ground states with a nontrivial sign structure. We tackle this problem by proposing a neural network architecture with a simple, explicit, and interpretable phase ansatz, which can robustly represent such states and achieve state-of-the-art variational energies for both conventional and frustrated antiferromagnets. In the latter case, our approach uncovers low-energy states that exhibit the Marshall sign rule and are therefore inconsistent with the expected ground state. Such states are the likely cause of the obstruction for NQS-based variational Monte Carlo to access the true ground states of these systems. We discuss the implications of this observation and suggest potential strategies to overcome the problem.","",""
32,"Jiaming Shen, Zhihong Shen, Chenyan Xiong, Chi Wang, Kuansan Wang, Jiawei Han","TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network",2020,"","","","",104,"2022-07-13 10:08:47","","10.1145/3366423.3380132","","",,,,,32,16.00,5,6,2,"Taxonomies consist of machine-interpretable semantics and provide valuable knowledge for many web applications. For example, online retailers (e.g., Amazon and eBay) use taxonomies for product recommendation, and web search engines (e.g., Google and Bing) leverage taxonomies to enhance query understanding. Enormous efforts have been made on constructing taxonomies either manually or semi-automatically. However, with the fast-growing volume of web content, existing taxonomies will become outdated and fail to capture emerging knowledge. Therefore, in many applications, dynamic expansions of an existing taxonomy are in great demand. In this paper, we study how to expand an existing taxonomy by adding a set of new concepts. We propose a novel self-supervised framework, named TaxoExpan, which automatically generates a set of ⟨query concept, anchor concept⟩ pairs from the existing taxonomy as training data. Using such self-supervision data, TaxoExpan learns a model to predict whether a query concept is the direct hyponym of an anchor concept. We develop two innovative techniques in TaxoExpan: (1) a position-enhanced graph neural network that encodes the local structure of an anchor concept in the existing taxonomy, and (2) a noise-robust training objective that enables the learned model to be insensitive to the label noise in the self-supervision data. Extensive experiments on three large-scale datasets from different domains demonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy expansion.","",""
2,"Zhifang Liao, Haihui Pan, Xiaoping Fan, Yan Zhang, Li Kuang","Multiple Wavelet Convolutional Neural Network for Short-Term Load Forecasting",2020,"","","","",105,"2022-07-13 10:08:47","","10.1109/JIOT.2020.3026733","","",,,,,2,1.00,0,5,2,"Although the accuracy of load forecasting has been studied by many works, the actual deployability of a model is rarely considered. In this work, we consider the actual deployability of a model from four aspects: 1) the prediction performance of the model; 2) the robustness of the model; 3) the dependence of the model on external data; and 4) the storage size of the model. From these four aspects, we propose a multiple wavelet convolutional neural network (MWCNN) for load forecasting. On two public data sets, we verified the performance and robustness of the MWCNN. The MWCNN only uses load data, and the storage size of the model is only 497 kB, which shows that MWCNN has good deployability. In addition, our MWCNN prediction results are interpretable. The experimental results show that the MWCNN can effectively capture the periodic characteristics of load data.","",""
3,"Tom Dupré la Tour, Mi Lu, Michael Eickenberg, J. Gallant","A finer mapping of convolutional neural network layers to the visual cortex",2021,"","","","",106,"2022-07-13 10:08:47","","","","",,,,,3,3.00,1,4,1,"There is increasing interest in understanding similarities and differences between convolutional neural networks (CNNs) and the visual cortex. A common approach is to use some specific layer of a pre-trained CNN as a source of features to predict brain activity recorded during a visual task. Associating each brain region to the best predicting CNN layer reveals a gradual change over the visual cortex. However, this winner-take-all mapping is non-robust, because consecutive CNN layers are strongly correlated and have similar prediction accuracies. Moreover, this mapping is usually performed on static stimuli, which ignores the temporal component of human vision. When the mapping is performed on video stimuli, the features are extracted frame-by-frame and downsampled using an anti-aliasing low-pass filter, which removes high temporal frequencies that could be informative. To address the first issue and improve the non-robust winner-take-all approach, we propose to fit a joint model on all layers simultaneously. The model is fit with banded ridge regression, where a separate regularization hyperparameter is learned for each layer. By performing a selection over layers, this model effectively removes non-predictive or redundant layers and disentangles the contributions of each layer. We show that using a joint model increases prediction accuracy and leads to finer mappings from CNN layers to the visual cortex. To address the second issue and preserve more high frequency information, we propose to filter the features with a set of band-pass filters. We show that using the envelopes of the filtered signals as additional features further increases prediction accuracy. Introduction Convolutional neural networks (CNNs) were inspired originally by the anatomy of the brain, and they have been remarkably successful in computer vision [1, 2]. However, these networks still fail in many tasks that humans can perform easily. Therefore, there is increasing interest in understanding the similarities and differences between CNNs and the brain. To investigate this issue, a common method is to use some specific layer of a pre-trained CNN as a source of features to fit a brain encoding model [3]. With this approach, many studies have shown that early CNN layers best predict brain activity in low-level visual areas, while late layers best predict brain activity in intermediate and higher-level visual areas, with gradual changes of layer mapping over the cortical surface [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]. A similar approach has also been applied to speech [14, 15] and language tasks [16, 17]. One problem with this approach is that there are strong correlations between CNN activations from one layer to the next. This confound causes different layers to have similar predictive power in encoding models [8, 16, 17, 18]. It is thus hard to separate which part of the predictive power is specific to a layer and which part is shared with other layers. Most studies ignore this issue and select the best-predicting layer for each voxel [5, 6, 8, 9, 14, 19, 11], but this winner-take-all approach is not robust and it ignores potential complementarities between layers. Some studies use variance partitioning [20] or canonical component analysis [21] to disentangle the different layers, but these approaches cannot disentangle more than two or three layers. 3rd Workshop on Shared Visual Representations in Human and Machine Intelligence (SVRHM 2021) of the Neural Information Processing Systems (NeurIPS) conference, Virtual. To address this issue, we use banded ridge regression, which has been shown to disentangle contributions from correlated feature spaces in encoding models [22]. Specifically, we fit a predictive model using features from all layers at once, grouping the features by layers, and learning optimal regularization for each layer through cross-validation. We show empirically that this joint model performs a selection over layers, effectively removing non-predictive or redundant layers, and disentangling the contributions of each layer on each voxel. Using this joint model increases prediction accuracy, and leads to smoother cortical maps of layer mapping. A second problem of the conventional approach is that it oversimplifies the temporal aspect of visual processing. Indeed, most studies only use static image stimuli [5, 6, 7, 8, 11, 13], which entirely ignores the temporal component of human vision. Some studies use video stimuli [8, 9] and extract features frame by frame from an image-based CNN. Then, the features are downsampled to the brain imaging sampling frequency (typically 0.5 Hz), using an anti-aliasing low-pass filter [8, 9]. However, this low-pass filter is suboptimal, because it removes valuable high-frequency information contained in the CNN activations. Indeed, a video stimulus induces brain activity linked to movement, and this brain activity has been shown to be poorly predicted by low-pass filtered static features [23]. To address this issue, we first use video stimuli and extract features frame by frame from an imagebased CNN. Then, to preserve more high temporal frequency information, we filter the features with a set of band-pass filters, and extract the envelope of the filtered signals. The envelopes are then used as additional features which increase prediction accuracy of the model. Note that we specifically do not use a video-based CNN to be able to compare both approaches on the same CNN architecture. We expect further gain in prediction accuracy by using the set of band-pass filters on features extracted from a video-based CNN. These two methodological improvements pave the way for high-precision mappings between CNNs and human brains, which may help both designing and interpreting CNNs, and defining highresolution information pathways over the cortical surface. 1 Conventional approach The conventional approach for mapping CNN layers to brain regions [4, 5, 6, 7, 8, 9, 19, 11, 12, 13] follows the voxelwise encoding model framework [24, 25]. First, brain activity is recorded while subjects perceive a visual stimulus. Then, the same stimulus is presented to a pretrained CNN, activations are extracted from intermediate CNN layers and preprocessed into features (see below). Finally, a regression model is trained on each voxel to predict brain activity from the features. 1.1 Feature extraction To extract features, each image of the stimulus is first presented to a pretrained image-based CNN. Then, the activations of one convolutional or fully-connected layer are extracted (typically after ReLU and max-pooling layers). With a video stimulus, features are extracted frame by frame from an imagebased CNN, before being down-sampled to the brain imaging sampling frequency (typically 0.5 Hz). Next, a compressive nonlinearity x 7→ log(1 + x) is applied, and features are centered individually along the train set. Then, to account for the delay between the stimulus and the hemodynamic response, features are either convolved with a hemodynamic response function, or duplicated with multiple temporal delays. This process is repeated for each CNN layer. Limitations. With a video stimulus, the feature extraction process contains a down-sampling step to match the brain imaging sampling frequency (typically 0.5 Hz). This down-sampling is typically done with an anti-aliasing low-pass filter [8, 9]. However, this low-pass filter likely removes valuable information from the CNN activations. Indeed, a video stimulus induces brain activity linked to movement, and this activity has been shown to be poorly predicted by low-pass filtered features [23]. 1.2 Winner-take-all model In the conventional approach, a separate ridge regression [26] is fit to the features extracted from each layer of the CNN independently. Then, the best layer is selected for each voxel, based on cross-validated prediction accuracy. Finally, differences in terms of selected layers are analyzed across the brain. The approach thus produces a mapping from CNN layers to brain regions.","",""
21,"G. Portwood, B. Nadiga, J. Saenz, D. Livescu","Interpreting neural network models of residual scalar flux",2020,"","","","",107,"2022-07-13 10:08:47","","10.1017/jfm.2020.861","","",,,,,21,10.50,5,4,2,"Abstract We show that, in addition to providing effective and competitive closures, when analysed in terms of the dynamics and physically relevant diagnostics, artificial neural networks (ANNs) can be both interpretable and provide useful insights into the on-going task of developing and improving turbulence closures. In the context of large-eddy simulations (LES) of a passive scalar in homogeneous isotropic turbulence, exact subfilter fluxes obtained by filtering direct numerical simulations are used both to train deep ANN models as a function of filtered variables, and to optimise the coefficients of a turbulent Prandtl number LES closure. A priori analysis of the subfilter scalar variance transfer rate demonstrates that learnt ANN models outperform optimised turbulent Prandtl number closures and Clark-type gradient models. Next, a posteriori solutions are obtained with each model over several integral time scales. These experiments reveal, with single- and multi-point diagnostics, that ANN models temporally track exact resolved scalar variance with greater accuracy compared to other subfilter flux models for a given filter length scale. Finally, we interpret the artificial neural networks statistically with differential sensitivity analysis to show that the ANN models feature a dynamics reminiscent of so-called ‘mixed models’, where mixed models are understood as comprising both a structural and functional component. Besides enabling enhanced-accuracy LES of passive scalars henceforth, we anticipate this work to contribute to utilising neural network models as a tool in interpretability, robustness and model discovery.","",""
5,"Dimitrios Sakkos, Kevin D. McCay, Claire Marcroft, N. Embleton, Samiran Chattopadhyay, Edmond S. L. Ho","Identification of Abnormal Movements in Infants: A Deep Neural Network for Body Part-Based Prediction of Cerebral Palsy",2021,"","","","",108,"2022-07-13 10:08:47","","10.1109/ACCESS.2021.3093469","","",,,,,5,5.00,1,6,1,"The early diagnosis of cerebral palsy is an area which has recently seen significant multi-disciplinary research. Diagnostic tools such as the General Movements Assessment (GMA), have produced some very promising results, however these manual methods can be laborious. The prospect of automating these processes is seen as key in advancing this field of study. In our previous works, we examined the viability of using pose-based features extracted from RGB video sequences to undertake classification of infant body movements based upon the GMA. In this paper, we propose a new deep learning framework for this classification task. We also propose a visualization framework which identifies body-parts with the greatest contribution towards a classification decision. The inclusion of a visualization framework is an important step towards automation as it helps make the decisions made by the machine learning framework interpretable. We directly compare the proposed framework’s classification with several other methods from the literature using two independent datasets. Our experimental results show that the proposed method performs more consistently and more robustly than our previous pose-based techniques as well as other features from related works in this setting. We also find that our visualization framework helps provide greater interpretability, enhancing the likelihood of the adoption of these technologies within the medical domain.","",""
0,"Liang-yu Chen, Yutong Chen, Young D. Kwon, Youwen Kang, Pan Hui","IAN: interpretable attention network for churn prediction in LBSNs",2021,"","","","",109,"2022-07-13 10:08:47","","10.1145/3487351.3488328","","",,,,,0,0.00,0,5,1,"With the rise of Location-Based Social Networks (LBSNs) and their heavy reliance on User-Generated Content, it has become essential to attract and keep more users, which makes the churn prediction problem interesting. Recent research focuses on solving the task by utilizing complex neural networks. However, due to the black-box nature of those proposed deep learning algorithms, it is still a challenge for LBSN managers to interpret the prediction results and design strategies to prevent churning behavior. Therefore, in this paper, we perform the first investigation into the interpretability of the churn prediction in LBSNs. We proposed a novel attention-based deep learning network, Interpretable Attention Network (IAN), to achieve high performance while ensuring interpretability. The network is capable to process the complex temporal multivariate multidimensional user data from LBSN datasets (i.e. Yelp and Foursquare) and provides meaningful explanations of its prediction. We also utilize several visualization techniques to interpret the prediction results. By analyzing the attention output, researchers can intuitively gain insights into which features dominate the model's prediction of churning users. Finally, we expect our model to become a robust and powerful tool to help LBSN applications to understand and analyze user churning behavior and in turn remain users.","",""
77,"Yu Zhang, P. Tiňo, A. Leonardis, K. Tang","A Survey on Neural Network Interpretability",2020,"","","","",110,"2022-07-13 10:08:47","","10.1109/TETCI.2021.3100641","","",,,,,77,38.50,19,4,2,"Along with the great success of deep neural networks, there is also growing concern about their black-box nature. The interpretability issue affects people's trust on deep learning systems. It is also related to many ethical problems, e.g., algorithmic discrimination. Moreover, interpretability is a desired property for deep networks to become powerful tools in other research fields, e.g., drug discovery and genomics. In this survey, we conduct a comprehensive review of the neural network interpretability research. We first clarify the definition of interpretability as it has been used in many different contexts. Then we elaborate on the importance of interpretability and propose a novel taxonomy organized along three dimensions: type of engagement (passive vs. active interpretation approaches), the type of explanation, and the focus (from local to global interpretability). This taxonomy provides a meaningful 3D view of distribution of papers from the relevant literature as two of the dimensions are not simply categorical but allow ordinal subcategories. Finally, we summarize the existing interpretability evaluation methods and suggest possible research directions inspired by our new taxonomy.","",""
6,"Souvik Kundu, K. Sim, M. Gales","Incorporating a Generative Front-End Layer to Deep Neural Network for Noise Robust Automatic Speech Recognition",2016,"","","","",111,"2022-07-13 10:08:47","","10.21437/Interspeech.2016-760","","",,,,,6,1.00,2,3,6,"It is difficult to apply well-formulated model-based noise adaptation approaches to Deep Neural Network (DNN) due to the lack of interpretability of the model parameters. In this paper, we propose incorporating a generative front-end layer (GFL), which is parameterised by Gaussian Mixture Model (GMM), into the DNN. A GFL can be easily adapted to different noise conditions by applying the model-based Vector Taylor Series (VTS) to the underlying GMM. We show that incorporating a GFL to DNN yields 12.1% relative improvement over a baseline multi-condition DNN. We also show that the proposed system performs significantly better than the noise aware training method, where the per-utterance estimated noise parameters are appended to the acoustic features.","",""
4,"Praveenram Balachandar, K. Michmizos","A Spiking Neural Network Emulating the Structure of the Oculomotor System Requires No Learning to Control a Biomimetic Robotic Head",2020,"","","","",112,"2022-07-13 10:08:47","","10.1109/BioRob49111.2020.9224303","","",,,,,4,2.00,2,2,2,"Robotic vision introduces requirements for real-time processing of fast-varying, noisy information in a continuously changing environment. In a real-world environment, convenient assumptions, such as static camera systems and deep learning algorithms devouring high volumes of ideally slightlyvarying data are hard to survive. Leveraging on recent studies on the neural connectome associated with eye movements, we designed a neuromorphic oculomotor controller and placed it at the heart of our in-house biomimetic robotic head prototype. The controller is unique in the sense that (1) all data are encoded and processed by a spiking neural network (SNN), and (2) by mimicking the associated brain areas’ topology, the SNN is biologically interpretable and requires no training to operate. Here, we report the robot’s target tracking ability, demonstrate that its eye kinematics are similar to those reported in human eye studies and show that a biologically-constrained learning, although not required for the SNN’s function, can be used to further refine its performance. This work aligns with our ongoing effort to develop energy-efficient neuromorphic SNNs and harness their emerging intelligence to control biomimetic robots with versatility and robustness.","",""
8,"D. Valeriani, K. Simonyan","A microstructural neural network biomarker for dystonia diagnosis identified by a DystoniaNet deep learning platform",2020,"","","","",113,"2022-07-13 10:08:47","","10.1073/pnas.2009165117","","",,,,,8,4.00,4,2,2,"Significance This research identified a microstructural neural network biomarker for objective and accurate diagnosis of isolated dystonia based on the disorder pathophysiology using an advanced deep learning algorithm, DystoniaNet, and raw structural brain images of large cohorts of patients with isolated focal dystonia and healthy controls. DystoniaNet significantly outperformed shallow machine-learning pipelines and substantially exceeded the current agreement rates between clinicians, reaching an overall accuracy of 98.8% in diagnosing different forms of isolated focal dystonia. These results suggest that DystoniaNet could serve as an objective, robust, and generalizable algorithmic platform of dystonia diagnosis for enhanced clinical decision-making. Implementation of the identified biomarker for objective and accurate diagnosis of dystonia may be transformative for clinical management of this disorder. Isolated dystonia is a neurological disorder of heterogeneous pathophysiology, which causes involuntary muscle contractions leading to abnormal movements and postures. Its diagnosis is remarkably challenging due to the absence of a biomarker or gold standard diagnostic test. This leads to a low agreement between clinicians, with up to 50% of cases being misdiagnosed and diagnostic delays extending up to 10.1 y. We developed a deep learning algorithmic platform, DystoniaNet, to automatically identify and validate a microstructural neural network biomarker for dystonia diagnosis from raw structural brain MRIs of 612 subjects, including 392 patients with three different forms of isolated focal dystonia and 220 healthy controls. DystoniaNet identified clusters in corpus callosum, anterior and posterior thalamic radiations, inferior fronto-occipital fasciculus, and inferior temporal and superior orbital gyri as the biomarker components. These regions are known to contribute to abnormal interhemispheric information transfer, heteromodal sensorimotor processing, and executive control of motor commands in dystonia pathophysiology. The DystoniaNet-based biomarker showed an overall accuracy of 98.8% in diagnosing dystonia, with a referral of 3.5% of cases due to diagnostic uncertainty. The diagnostic decision by DystoniaNet was computed in 0.36 s per subject. DystoniaNet significantly outperformed shallow machine-learning algorithms in benchmark comparisons, showing nearly a 20% increase in its diagnostic performance. Importantly, the microstructural neural network biomarker and its DystoniaNet platform showed substantial improvement over the current 34% agreement on dystonia diagnosis between clinicians. The translational potential of this biomarker is in its highly accurate, interpretable, and generalizable performance for enhanced clinical decision-making.","",""
2,"Patrick McClure, D. Moraczewski, K. Lam, Adam Thomas, Francisco Pereira","Evaluating Adversarial Robustness for Deep Neural Network Interpretability using fMRI Decoding",2020,"","","","",114,"2022-07-13 10:08:47","","","","",,,,,2,1.00,0,5,2,"While deep neural networks (DNNs) are being increasingly used to make predictions from high-dimensional, complex data, they are widely seen as uninterpretable ""black boxes"", since it can be difficult to discover what input information is used to make predictions. This ability is particularly important for applications in cognitive neuroscience and neuroinformatics. A saliency map is a common approach for producing interpretable visualizations of the relative importance of input features for a prediction. However, many methods for creating these maps fail due to focusing too much on the input or being extremely sensitive to small input noise. It is also challenging to quantitatively evaluate how well saliency maps correspond to the truly relevant input information. In this paper, we develop two quantitative evaluation procedures for saliency methods, using the fact that the Human Connectome Project (HCP) dataset contains functional magnetic resonance imaging (fMRI) data from multiple tasks per subject to create ground truth saliency maps. We then introduce an adversarial training method that makes DNNs robust to small input noise, and demonstrate that it measurably improves interpretability.","",""
2,"G. Baudat, John B. Hayes","A star-test wavefront sensor using neural network analysis",2020,"","","","",115,"2022-07-13 10:08:47","","10.1117/12.2568018","","",,,,,2,1.00,1,2,2,"We describe a new, simple wavefront sensing method that uses a single measurement of a defocused star and a neural network to determine low-order wavefront components. The neural net is trained on computed diffracted star image data at 640 nm to output annular Zernike terms for an obscured circular aperture over a discrete range of all values. In the context of an actual star, the neural-net also provides the Fried’s parameter as an estimation of atmospheric turbulence. It is shown that the neural-net can produce a robust, high accuracy solution of the wavefront based on a single measurement. The method can also be used to simultaneously determine both on-axis and fielddependent wavefront performance from a single measurement of stars throughout the field. The prototype system can run at a rate of about 1 Hz with Python interpreted code, but higher speeds, up to video rates, are possible with compilation, proper hardware and optimization. This technique is particularly useful for low-order active-optics control and for optical alignment. A key advantage of this new method is that it only requires a single camera making it a simple cost-effective solution that can take advantage of an existing camera that may already be in an optical system. Results for this method are compared to high-precision interferometric data taken with a 4D Technology, PhaseCam interferometer and with an Innovations Foresight StarWave Shack Hartmann sensor from ALCOR SYSTEM under well-controlled conditions to validate performance. We also look at how the system has been implemented to use starlight for aligning multiple mirror telescopes in the presence of atmospheric seeing.","",""
0,"Amit Sahu, Noelia V'allez, Rosana Rodr'iguez-Bobada, Mohamad Alhaddad, Omar Moured, G. Neugschwandtner","Application of the Neural Network Dependability Kit in Real-World Environments",2020,"","","","",116,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,6,2,"In this paper, we provide a guideline for using the Neural Network Dependability Kit (NNDK) during the development process of NN models, and show how the algorithm is applied in two image classification use cases. The case studies demonstrate the usage of the dependability kit to obtain insights about the NN model and how they informed the development process of the neural network model. After interpreting neural networks via the different metrics available in the NNDK, the developers were able to increase the NNs' accuracy, trust the developed networks, and make them more robust. In addition, we obtained a novel application-oriented technique to provide supporting evidence for an NN's classification result to the user. In the medical image classification use case, it was used to retrieve case images from the training dataset that were similar to the current patient's image and could therefore act as a support for the NN model's decision and aid doctors in interpreting the results.","",""
1,"Adam D. Cobb, Brian Jalaian, Nathaniel D. Bastian, Stephen Russell","Robust Decision-Making in the Internet of Battlefield Things Using Bayesian Neural Networks",2021,"","","","",117,"2022-07-13 10:08:47","","10.1109/WSC52266.2021.9715532","","",,,,,1,1.00,0,4,1,"The Internet of Battlefield Things (IoBT) is a dynamically composed network of intelligent sensors and actuators that operate as a command and control, communications, computers, and intelligence complex-system with the aim to enable multi-domain operations. The use of artificial intelligence can help transform the IoBT data into actionable insight to create information and decision advantage on the battlefield. In this work, we focus on how accounting for uncertainty in IoBT systems can result in more robust and safer systems. Human trust in these systems requires the ability to understand and interpret how machines make decisions. Most real-world applications currently use deterministic machine learning techniques that cannot incorporate uncertainty. In this work, we focus on the machine learning task of classifying vehicles from their audio recordings, comparing deterministic convolutional neural networks (CNNs) with Bayesian CNNs to show that correctly estimating the uncertainty can help lead to robust decision-making in IoBT.","",""
0,"G. Henter, S. Ronanki, O. Watts, M. Wester, Zhizheng Wu, Simon King","Robust text-to-speech duration modelling with a deep neural network",2016,"","","","",118,"2022-07-13 10:08:47","","10.1121/1.4969147","","",,,,,0,0.00,0,6,6,"Accurate modeling and prediction of speech-sound durations is important for generating more natural synthetic speech. Deep neural networks (DNNs) offer powerful models, and large, found corpora of natural speech are easily acquired for training them. Unfortunately, poor quality control (e.g., transcription errors) and phenomena such as reductions and filled pauses complicate duration modelling from found speech data. To mitigate issues caused by these idiosyncrasies, we propose to incorporate methods from robust statistics into speech synthesis. Robust methods can disregard ill-fitting training-data points—errors or other outliers—to describe the typical case better. For instance, parameter estimation can be made robust by replacing maximum likelihood with a robust estimation criterion based on the density power divergence (a.k.a. the β-divergence). Alternatively, a standard approximation for output generation with mixture density networks (MDNs) can be interpreted as a robust output generation heuristic....","",""
0,"William Knauth","The Self-Simplifying Machine: Exploiting the Structure of Piecewise Linear Neural Networks to Create Interpretable Models",2020,"","","","",119,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,1,2,"Today, it is more important than ever before for users to have trust in the models they use. As Machine Learning models fall under increased regulatory scrutiny and begin to see more applications in high-stakes situations, it becomes critical to explain our models. Piecewise Linear Neural Networks (PLNN) with the ReLU activation function have quickly become extremely popular models due to many appealing properties; however, they still present many challenges in the areas of robustness and interpretation. To this end, we introduce novel methodology toward simplification and increased interpretability of Piecewise Linear Neural Networks for classification tasks. Our methods include the use of a trained, deep network to produce a well-performing, single-hidden-layer network without further stochastic training, in addition to an algorithm to reduce flat networks to a smaller, more interpretable size with minimal loss in performance. On these methods, we conduct preliminary studies of model performance, as well as a case study on Wells Fargo's Home Lending dataset, together with visual model interpretation.","",""
0,"Justin A. Goodwin, Olivia M. Brown, Victoria Helus","Fast Training of Deep Neural Networks Robust to Adversarial Perturbations",2020,"","","","",120,"2022-07-13 10:08:47","","10.1109/HPEC43674.2020.9286256","","",,,,,0,0.00,0,3,2,"Despite their promising performance, deep neural networks have shown sensitivities to perturbations of their inputs (e.g., adversarial examples) and their learned feature representations are often difficult to interpret, raising concerns about their true capability and trustworthiness. Recent work in adversarial training, a form of robust optimization in which the model is optimized against adversarial examples, demonstrates the ability to improve performance sensitivities to perturbations and yield feature representations that are more interpretable. Adversarial training, however, comes with an increased computational cost over that of standard (i.e., nonrobust) training, rendering it impractical for use in large-scale problems. Recent work suggests that a fast approximation to adversarial training shows promise for reducing training time and maintaining robustness in the presence of perturbations bounded by the infinity norm. In this work, we demonstrate that this approach extends to the Euclidean norm and preserves the human-aligned feature representations that are common for robust models. Additionally, we show that using a distributed training scheme can further reduce the time to train robust deep networks. Fast adversarial training is a promising approach that will provide increased security and explainability in machine learning applications for which robust optimization was previously thought to be impractical.","",""
327,"Nicolas Papernot, P. Mcdaniel","Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning",2018,"","","","",121,"2022-07-13 10:08:47","","","","",,,,,327,81.75,164,2,4,"Deep neural networks (DNNs) enable innovative applications of machine learning like image recognition, machine translation, or malware detection. However, deep learning is often criticized for its lack of robustness in adversarial settings (e.g., vulnerability to adversarial inputs) and general inability to rationalize its predictions. In this work, we exploit the structure of deep learning to enable new learning-based inference and decision strategies that achieve desirable properties such as robustness and interpretability. We take a first step in this direction and introduce the Deep k-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest neighbors algorithm with representations of the data learned by each layer of the DNN: a test input is compared to its neighboring training points according to the distance that separates them in the representations. We show the labels of these neighboring points afford confidence estimates for inputs outside the model's training manifold, including on malicious inputs like adversarial examples--and therein provides protections against inputs that are outside the models understanding. This is because the nearest neighbors can be used to estimate the nonconformity of, i.e., the lack of support for, a prediction in the training data. The neighbors also constitute human-interpretable explanations of predictions. We evaluate the DkNN algorithm on several datasets, and show the confidence estimates accurately identify inputs outside the model, and that the explanations provided by nearest neighbors are intuitive and useful in understanding model failures.","",""
64,"H. C. Liaw, B. Shirinzadeh, Julian Smith","Robust Neural Network Motion Tracking Control of Piezoelectric Actuation Systems for Micro/Nanomanipulation",2009,"","","","",122,"2022-07-13 10:08:47","","10.1109/TNN.2008.2004406","","",,,,,64,4.92,21,3,13,"This paper presents a robust neural network motion tracking control methodology for piezoelectric actuation systems employed in micro/nanomanipulation. This control methodology is proposed for tracking of desired motion trajectories in the presence of unknown system parameters, nonlinearities including the hysteresis effect and external disturbances in the control systems. In this paper, the related control issues are investigated, and a control methodology is established including the neural networks and a sliding control scheme. In particular, the radial basis function (RBF) neural networks are chosen for function approximations. The stability of the closed-loop system, as well as the convergence of the position and velocity tracking errors to zero, is assured by the control methodology in the presence of the aforementioned conditions. An offline learning procedure is also proposed for the improvement of the motion tracking performance. Precise tracking results of the proposed control methodology for a desired motion trajectory are demonstrated in the experimental study. With such a motion tracking capability, the proposed control methodology promises the realization of high-performance piezoelectric actuated micro/nanomanipulation systems.","",""
5,"Jan Rudy, Weiguang Ding, Daniel Jiwoong Im, Graham W. Taylor","Neural Network Regularization via Robust Weight Factorization",2014,"","","","",123,"2022-07-13 10:08:47","","","","",,,,,5,0.63,1,4,8,"Regularization is essential when training large neural networks. As deep neural networks can be mathematically interpreted as universal function approximators, they are effective at memorizing sampling noise in the training data. This results in poor generalization to unseen data. Therefore, it is no surprise that a new regularization technique, Dropout, was partially responsible for the now-ubiquitous winning entry to ImageNet 2012 by the University of Toronto. Currently, Dropout (and related methods such as DropConnect) are the most effective means of regularizing large neural networks. These amount to efficiently visiting a large number of related models at training time, while aggregating them to a single predictor at test time. The proposed FaMe model aims to apply a similar strategy, yet learns a factorization of each weight matrix such that the factors are robust to noise.","",""
11,"Ming Jin, Heng Chang, Wenwu Zhu, S. Sojoudi","Power up! Robust Graph Convolutional Network via Graph Powering",2019,"","","","",124,"2022-07-13 10:08:47","","","","",,,,,11,3.67,3,4,3,"Graph convolutional networks (GCNs) are powerful tools for graph-structured data. However, they have been recently shown to be vulnerable to topological attacks. To enhance adversarial robustness, we go beyond spectral graph theory to robust graph theory. By challenging the classical graph Laplacian, we propose a new convolution operator that is provably robust in the spectral domain and is incorporated in the GCN architecture to improve expressivity and interpretability. By extending the original graph to a sequence of graphs, we also propose a robust training paradigm that encourages transferability across graphs that span a range of spatial and spectral characteristics. The proposed approaches are demonstrated in extensive experiments to simultaneously improve performance in both benign and adversarial situations. Introduction Graph convolutional networks (GCNs) are powerful extensions of convolutional neural networks (CNN) to graphstructured data. Recently, GCNs and variants have been applied to a wide range of domains, achieving state-of-the-art performances in social networks (Kipf and Welling 2017), traffic prediction (Rahimi, Cohn, and Baldwin 2018), recommendation systems (Ying et al. 2018), applied chemistry and biology (Kearnes et al. 2016; Fout et al. 2017), and natural language processing (Atwood and Towsley 2016; Hamilton, Ying, and Leskovec 2017; Bastings et al. 2017; Marcheggiani and Titov 2017), just to name a few (Zhou et al. 2018; Wu et al. 2019). GCNs belong to a family of spectral methods that deal with spectral representations of graphs (Zhou et al. 2018; Wu et al. 2019). A fundamental ingredient of GCNs is the graph convolution operation defined by the graph Laplacian in the Fourier domain: gθ ? x := ĝθ(L)x, (1) where x ∈ R is the graph signal on the set of vertices V and ĝθ is a spectral function applied to the graph Laplacian L := D − A (where D and A are the degree matrix and *The two first authors made equal contributions. This work was conducted during Heng Chang’s visit to Professor Somayeh Sojoudi’s group at UC Berkeley. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. the adjacency matrix, respectively). Because this operation is computational intensive for large graphs and non-spatially localized (Bruna et al. 2014), early attempts relied on a parameterization with smooth coefficients (Henaff, Bruna, and LeCun 2015) or a truncated expansion in terms of of Chebyshev polynomials (Hammond, Vandergheynst, and Gribonval 2011). By further restricting the Chebyshev polynomial order by 2, the approach in (Kipf and Welling 2017) referred henceforth as the vanilla GCN pushed the state-of-the-art performance of semi-supervised learning. The network has the following layer-wise update rule: H := ψ ( AHW (l) ) , (2) where H is the l-th layer hidden state (with H := X as nodal features),W (l) is the l-th layer weight matrix, ψ is the usual point-wise activation function, and A is the convolution operator chosen to be the degree weighted Laplacian with some slight modifications (Kipf and Welling 2017). Subsequent GCN variants have different architectures, but they all share the use of the Laplacian matrix as the convolution operator (Zhou et al. 2018; Wu et al. 2019). Why Not Graph Laplacian? Undoubtedly, the Laplacian operator (and its variants, e.g., normalized/powered Laplacian) plays a central role in spectral theory, and is a natural choice for a variety of spectral algorithms such as principal component analysis, clustering and linear embeddings (Chung and Graham 1997; Belkin and Niyogi 2002). So what can be problematic? From a spatial perspective, GCNs with d layers cannot acquire nodal information beyond its d-distance neighbors; hence, it severely limits its scope of data fusion. Recent works (Lee et al. 2018; Abu-El-Haija et al. 2018, 2019; Wu et al. 2019) alleviated this issue by directly powering the graph Laplacian. From a spectral perspective, one could demand better spectral properties, given that GCN is fundamentally a particular (yet effective) approximation of the spectral convolution (1). A key desirable property for generic spectral methods is known as “spectral separation,” namely the spectrum should comprise a few dominant eigenvalues whose associated eigenvectors reveal the sought structure in the graph. A well-known prototype is the Ramanujan property, for which the second The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)","",""
0,"Paul Tylkin, Tsun-Hsuan Wang, Kyle Palko, R. Allen, H. Siu, Daniel Wrafter, T. Seyde, Alexander Amini, D. Rus","Interpretable Autonomous Flight Via Compact Visualizable Neural Circuit Policies",2022,"","","","",125,"2022-07-13 10:08:47","","10.1109/lra.2022.3146555","","",,,,,0,0.00,0,9,1,"We learn interpretable end-to-end controllers based on Neural Circuit Policies (NCPs) to enable goal reaching and dynamic obstacle avoidance in flight domains. In addition to being able to learn high-quality control, NCP networks are designed with a small number of neurons. This property allows for the learned policies to be interpreted at the neuron level and interrogated, leading to more robust understanding of why the artificial agents make the decisions that they do. We also demonstrate transfer of the learned policy to physical flight hardware by deploying a small NCP (200 KB of memory) capable of real-time inference on a Raspberry Pi Zero controlling a DJI Tello drone. Designing interpretable artificial agents is crucial for building trustworthy AIs, both as fully autonomous systems and also for parallel autonomy, where humans and AIs work on collaboratively solving problems in the same environment.","",""
0,"S. Sengupta, C. Abbey, Kaiyan Li, M. Anastasio","Investigation of adversarial robust training for establishing interpretable CNN-based numerical observers",2022,"","","","",126,"2022-07-13 10:08:47","","10.1117/12.2613220","","",,,,,0,0.00,0,4,1,"The use of convolutional neural networks (CNNs) for establishing anthropomorphic numerical observers (ANOs) is being actively explored. In these data-driven approaches, CNNs are trained in a standard supervised way with human-labeled training data; hence, the anthropomorphic component of this procedure resides only in the training labels. However, it is well-known that such traditionally trained CNNs can rely on image features that are highly specific to the training distribution and may not align with features exploited by human perception. While being able to predict human observer performance under certain specified conditions, traditionally-trained CNNs lack the interpretability and robustness that may be desired for an ANO. To address this, in this work we investigate the use of an adversarial robust training strategy for training CNN-based observers. As recently demonstrated in the computer vision literature, this training strategy can result in CNNs that exploit more human-interpretable features than would be employed by a standard CNN. Robustly trained CNNs are systematically investigated for performing a signal-known-exactly (SKE) and background-known-statistically (BKS) binary detection task. Additionally, a differential evolution-based optimization procedure is developed to establish robustly trained CNNs that achieve a specified performance, which may provide a new approach to establishing ANOs.","",""
1,"Rahul Soni, Naresh Shah, Chua Tat Seng, J. D. Moore","Adversarial TCAV - Robust and Effective Interpretation of Intermediate Layers in Neural Networks",2020,"","","","",127,"2022-07-13 10:08:47","","","","",,,,,1,0.50,0,4,2,"Interpreting neural network decisions and the information learned in intermediate layers is still a challenge due to the opaque internal state and shared non-linear interactions. Although (Kim et al, 2017) proposed to interpret intermediate layers by quantifying its ability to distinguish a user-defined concept (from random examples), the questions of robustness (variation against the choice of random examples) and effectiveness (retrieval rate of concept images) remain. We investigate these two properties and propose improvements to make concept activations reliable for practical use.  Effectiveness: If the intermediate layer has effectively learned a user-defined concept, it should be able to recall --- at the testing step --- most of the images containing the proposed concept. For instance, we observed that the recall rate of Tiger shark and Great white shark from the ImageNet dataset with ""Fins"" as a user-defined concept was only 18.35% for VGG16. To increase the effectiveness of concept learning, we propose A-CAV --- the Adversarial Concept Activation Vector --- this results in larger margins between user concepts and (negative) random examples. This approach improves the aforesaid recall to 76.83% for VGG16.  For robustness, we define it as the ability of an intermediate layer to be consistent in its recall rate (the effectiveness) for different random seeds. We observed that TCAV has a large variance in recalling a concept across different random seeds. For example, the recall of cat images (from a layer learning the concept of tail) varies from 18% to 86% with 20.85% standard deviation on VGG16. We propose a simple and scalable modification that employs a Gram-Schmidt process to sample random noise from concepts and learn an average ""concept classifier"". This approach improves the aforesaid standard deviation from 20.85% to 6.4%.","",""
4,"Shixiang Zhu, Shuang Li, Yao Xie","Interpretable Generative Neural Spatio-Temporal Point Processes",2019,"","","","",128,"2022-07-13 10:08:47","","","","",,,,,4,1.33,1,3,3,"We present a novel generative model for spatio-temporal correlated discrete event data. Despite the rapid development of one-dimensional point processes for temporal event data, the study of how to model spatial aspects of such discrete event data is scarce. Our proposed Neural Embedding Spatio-Temporal (NEST) point process is a probabilistic generative model, which captures complex spatial influence, by carefully combining statistical models with flexible neural networks with spatial information embedding. NEST also enjoys computational complexity, high-interpretability, and strong expressive capacity for complex spatio-temporal dependency. We present two computationally efficient approaches based on maximum likelihood and imitation learning, which is robust to model mismatch. Experiments based on real data show the superior performance of our method relative to the state-of-the-art.","",""
31,"Q. Song, J. Spall, Y. Soh, Jie-ke Ni","Robust Neural Network Tracking Controller Using Simultaneous Perturbation Stochastic Approximation",2008,"","","","",129,"2022-07-13 10:08:47","","10.1109/TNN.2007.912315","","",,,,,31,2.21,8,4,14,"This paper considers the design of robust neural network tracking controllers for nonlinear systems. The neural network is used in the closed-loop system to estimate the nonlinear system function. We introduce the conic sector theory to establish a robust neural control system, with guaranteed boundedness for both the input/output (I/O) signals and the weights of the neural network. The neural network is trained by the simultaneous perturbation stochastic approximation (SPSA) method instead of the standard backpropagation (BP) algorithm. The proposed neural control system guarantees closed-loop stability of the estimation system, and a good tracking performance. The performance improvement of the proposed system over existing systems can be quantified in terms of preventing weight shifts, fast convergence, and robustness against system disturbance.","",""
13,"Igor Kvasić, N. Mišković, Z. Vukic","Convolutional Neural Network Architectures for Sonar-Based Diver Detection and Tracking",2019,"","","","",130,"2022-07-13 10:08:47","","10.1109/OCEANSE.2019.8867461","","",,,,,13,4.33,4,3,3,"Autonomous underwater navigation presents a whole set of challenges to be resolved in order to become adequately accurate and reliable. That is particularly critical when human divers work in close collaboration with autonomous underwater vehicles (AUVs). In absence of global positioning signals underwater, acoustic based sensors such as LBL (long-baseline), SBL (short-baseline) and USBL (ultrashort-baseline) are commonly used for navigation and localization. In addition to these low-bandwidth and high latency technologies, cameras and sonars can provide position measurements relative to the vehicle which can be used as an aid for navigation as well as for keeping a safe working distance between the diver and the AUV. While optical cameras are highly affected by water turbidity and lighting conditions, sonar images often become hard to interpret using conventional image processing methods due to image granulation and high noise levels.This paper focuses on finding a robust and reliable sonar image processing method for detection and tracking of human divers using convolutional neural networks. Machine learning algorithms are making a huge impact in computer vision applications but are not always considered when it comes to sonar image processing. After presenting commonly used image processing techniques the paper will focus on giving an overview of state-of-the-art machine learning algorithms and explore their performance in custom sonar image dataset processing. Finally, the performance of these algorithms will be compared on a set of sonar recordings to determine their reliability and applicability in a real-time operation.","",""
0,"Shaeke Salman, S. N. Payrovnaziri, Xiuwen Liu, Zhe He","Interpretable Deep Neural Networks for Patient Mortality Prediction: A Consensus-based Approach",2019,"","","","",131,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,4,3,"Deep neural networks have achieved remarkable success in challenging tasks. However, the black-box approach of training and testing of such networks is not acceptable to critical applications. In particular, the existence of adversarial examples and their overgeneralization to irrelevant inputs makes it difficult, if not impossible, to explain decisions by commonly used neural networks. In this paper, we analyze the underlying mechanism of generalization of deep neural networks and propose an ($n$, $k$) consensus algorithm to be insensitive to adversarial examples and at the same time be able to reject irrelevant samples. Furthermore, the consensus algorithm is able to improve classification accuracy by using multiple trained deep neural networks. To handle the complexity of deep neural networks, we cluster linear approximations and use cluster means to capture feature importance. Due to weight symmetry, a small number of clusters are sufficient to produce a robust interpretation. Experimental results on a health dataset show the effectiveness of our algorithm in enhancing the prediction accuracy and interpretability of deep neural network models on one-year patient mortality prediction.","",""
10,"Sampo Kuutti, R. Bowden, Harita Joshi, Robert de Temple, Saber Fallah","Safe Deep Neural Network-Driven Autonomous Vehicles Using Software Safety Cages",2019,"","","","",132,"2022-07-13 10:08:47","","10.1007/978-3-030-33617-2_17","","",,,,,10,3.33,2,5,3,"","",""
7,"Yongbing Zhang, Yangzhe Liu, Xiu Li, Shaowei Jiang, Krishna Dixit, Xinfeng Zhang, Xiangyang Ji","PgNN: Physics-guided Neural Network for Fourier Ptychographic Microscopy",2019,"","","","",133,"2022-07-13 10:08:47","","","","",,,,,7,2.33,1,7,3,"Fourier ptychography (FP) is a newly developed computational imaging approach that achieves both high resolution and wide field of view by stitching a series of low-resolution images captured under angle-varied illumination. So far, many supervised data-driven models have been applied to solve inverse imaging problems. These models need massive amounts of data to train, and are limited by the dataset characteristics. In FP problems, generic datasets are always scarce, and the optical aberration varies greatly under different acquisition conditions. To address these dilemmas, we model the forward physical imaging process as an interpretable physics-guided neural network (PgNN), where the reconstructed image in the complex domain is considered as the learnable parameters of the neural network. Since the optimal parameters of the PgNN can be derived by minimizing the difference between the model-generated images and real captured angle-varied images corresponding to the same scene, the proposed PgNN can get rid of the problem of massive training data as in traditional supervised methods. Applying the alternate updating mechanism and the total variation regularization, PgNN can flexibly reconstruct images with improved performance. In addition, the Zernike mode is incorporated to compensate for optical aberrations to enhance the robustness of FP reconstructions. As a demonstration, we show our method can reconstruct images with smooth performance and detailed information in both simulated and experimental datasets. In particular, when validated in an extension of a high-defocus, high-exposure tissue section dataset, PgNN outperforms traditional FP methods with fewer artifacts and distinguishable structures.","",""
2,"Mingxing Xu, Wenrui Dai, Yangmei Shen, H. Xiong","MSGCNN: Multi-scale Graph Convolutional Neural Network for Point Cloud Segmentation",2019,"","","","",134,"2022-07-13 10:08:47","","10.1109/BigMM.2019.00-35","","",,,,,2,0.67,1,4,3,"Point cloud has emerged as a scalable and flexible geometric representation for 3D data. Graph convolutional neural networks (GCNNs) have shown superior performance and robustness in point cloud processing with structure-awareness and permutation invariance. However, naive graph convolution networks are limited in point cloud segmentation tasks especially in the border areas of multiple segmentation instances due to the lack of multi-scale feature extraction ability. In this paper, we propose a novel multi-scale graph convolutional neural network (MSGCNN) to allow multi-scale feature learning for fine-grained point cloud segmentation. The proposed geometrical interpretable multi-scale point cloud processing framework is able to considerately enlarge the graph filters receptive fields and exploit discriminative multi-scale structure-aware point features for the superior segmentation performance against naive graph convolution networks especially in border area. Experimental results for part segmentation task on ShapeNet datasets show that MSGCNN achieves competitive performance with state-of-the-arts. In comparison to naive graph convolution networks, MSGCNN is shown to obtain better visual quality in the border area. We further validate that our model is robust to data point missing and noise perturbation with the learned multi-scale structure-aware point features.","",""
11,"Chaithanya Kumar Mummadi, Ranjitha Subramaniam, Robin Hutmacher, J. Vitay, Volker Fischer, J. H. Metzen","Does enhanced shape bias improve neural network robustness to common corruptions?",2021,"","","","",135,"2022-07-13 10:08:47","","","","",,,,,11,11.00,2,6,1,"Convolutional neural networks (CNNs) learn to extract representations of complex features, such as object shapes and textures to solve image recognition tasks. Recent work indicates that CNNs trained on ImageNet are biased towards features that encode textures and that these alone are sufficient to generalize to unseen test data from the same distribution as the training data but often fail to generalize to out-of-distribution data. It has been shown that augmenting the training data with different image styles decreases this texture bias in favor of increased shape bias while at the same time improving robustness to common corruptions, such as noise and blur. Commonly, this is interpreted as shape bias increasing corruption robustness. However, this relationship is only hypothesized. We perform a systematic study of different ways of composing inputs based on natural images, explicit edge information, and stylization. While stylization is essential for achieving high corruption robustness, we do not find a clear correlation between shape bias and robustness. We conclude that the data augmentation caused by style-variation accounts for the improved corruption robustness and increased shape bias is only a byproduct.","",""
5,"Chengjun Xu, G. Zhu, Jin Shu","A Lightweight and Robust Lie Group-Convolutional Neural Networks Joint Representation for Remote Sensing Scene Classification",2021,"","","","",136,"2022-07-13 10:08:47","","10.1109/TGRS.2020.3048024","","",,,,,5,5.00,2,3,1,"The existing convolutional neural network (CNN) models have shown excellent performance in remote sensing scene classification. However, the structure of such models is becoming more and more complex, and the learning of low-level features is difficult to interpret. To address this problem, in this study, we introduce lie group machine learning into the CNN model, try to combine both approaches to extract more distinguishing ability and effective features, and propose a novel network model, namely, the lie group regional influence network (LGRIN). First, manifold space samples of the lie group are obtained by mapping, and then, the features of the lie group are extracted after the operations of image decomposition and integral image calculation. Second, the multidilation pooling is integrated into the CNN architecture. At the same time, the image regional influence network module is designed to guide the attention of the classification model by using the regional-level supervision of the decomposition. Finally, the fusion features are classified, and the predicted results are obtained. Our model takes full advantage of regional influence, lie group kernel function, and lie group feature learning. Moreover, our model produces satisfactory performance on three public and challenging data sets: Aerial Image Dataset (AID), UC Merced, and NWPU-RESISC45. The experimental results verify that, compared with the state-of-the-art methods, this method is more explanatory and achieves higher accuracy.","",""
94,"C. Kwan, F. Lewis, D. Dawson","Robust neural-network control of rigid-link electrically driven robots",1998,"","","","",137,"2022-07-13 10:08:47","","10.1109/72.701172","","",,,,,94,3.92,31,3,24,"A robust neural-network (NN) controller is proposed for the motion control of rigid-link electrically driven (RLED) robots. Two-layer NN's are used to approximate two very complicated nonlinear functions. The main advantage of our approach is that the NN weights are tuned on-line, with no off-line learning phase required. Most importantly, we can guarantee the uniformly ultimately bounded (UUB) stability of tracking errors and NN weights. When compared with standard adaptive robot controllers, we do not require lengthy and tedious preliminary analysis to determine a regression matrix. The controller can be regarded as a universal reusable controller because the same controller can be applied to any type of RLED robots without any modifications.","",""
0,"Lech Szymanski, B. McCane, C. Atkinson","Switched linear projections and inactive state sensitivity for deep neural network interpretability",2019,"","","","",138,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,3,3,"We introduce switched linear projections for expressing the activity of a neuron in a ReLU-based deep neural network in terms of a single linear projection in the input space. The method works by isolating the active subnetwork, a series of linear transformations, that completely determine the entire computation of the deep network for a given input instance. We also propose that for interpretability it is more instructive and meaningful to focus on the patterns that deactive the neurons in the network, which are ignored by the exisiting methods that implicitly track only the active aspect of the network's computation. We introduce a novel interpretability method for the inactive state sensitivity (Insens). Comparison against existing methods shows that Insens is more robust (in the presence of noise), more complete (in terms of patterns that affect the computation) and a very effective interpretability method for deep neural networks.","",""
0,"Mark R. P. Thomas, B. Martin, Katie A. Kowarski, B. Gaudet, S. Matwin","Interpreting the latent representations of a convolutional neural network trained on spectrograms",2019,"","","","",139,"2022-07-13 10:08:47","","10.1121/1.5137277","","",,,,,0,0.00,0,5,3,"Recent work [1,2] has shown that Convolutional Neural Networks (CNNs) trained on spectrograms of acoustic signals are capable of learning high-level latent representations for the purpose of detecting and classifying the vocalizations of endangered baleen whales. The aforementioned latent representations were used in the development of an automated system that was capable of detecting the vocalizations of blue, fin, and sei whales against non-biological and ambient noise sources to a high degree of accuracy (0.961, F-1 Score = 0.899). In this work, we conduct an exploratory analysis of the same latent representations using statistical machine learning approaches as well as by visualizing the convolutional feature maps learned by the CNN. Through this analysis we attempt to interpret what properties of a spectrogram are easily and/or most often exploited by the CNN during training in order to improve upon the state-of-the-art and develop more robust detection systems going forward. [1] M. Thomas, B. Martin, K. Kowarski, B. Gaudet, and S. Matwin, Marine Mammal Species Classification using Convolutional Neural Networks and a Novel Acoustic Representation, ECML PKDD 2019 (Springer, Cham, 2019). [2] M. Thomas, ""Towards a novel data representation for classifying acoustic signals,"" in Canadian Conference on Artificial Intelligence (Springer, Cham, 2019).","",""
1,"Maxpool, Preact","Reproducibility report: Interpretable Complex-Valued Neural Networks For Privacy Protection",2021,"","","","",140,"2022-07-13 10:08:47","","","","",,,,,1,1.00,1,2,1,"Since the code was not made publicly available we implemented our own version of the reported DNNs. Baseline DNNs were created using the default model architecture. The figures and math of the original paper were used to recreate the structure of the complex-valued DNNs, in which the model is divided into an encoder, a processing module on the cloud, and a decoder. The goal of the complex-valued DNN is to make sure that the features are rotated and obfuscated to ensure that the privacy of the data is secured. We compare the performance of the baseline and complex-valued DNNs. Then, we test the robustness of the models against privacy attacks, where potential attackers were mimicked using inversion attacks.","",""
4,"Ying Du, Yadong Liu, Xuhong Wang, Jian Fang, G. Sheng, Xiuchen Jiang","Predicting Weather-Related Failure Risk in Distribution Systems Using Bayesian Neural Network",2021,"","","","",141,"2022-07-13 10:08:47","","10.1109/TSG.2020.3019263","","",,,,,4,4.00,1,6,1,"The reliability of distribution systems is often challenged under unfavorable weather conditions, where weather-related failures occur with high probability. Predicting the number of weather-related failures in distribution systems can provide guiding information for operation and maintenance decisions, improving the risk management capability of utility companies. This article proposes a novel Bayesian Neural Network (BNN) based model to predict weather-related failures caused by wind, rain and lightning. Superior prediction performance of the BNN based model is verified by contrast experiments with other advanced prediction models under four different evaluation metrics. BNN based prediction model presents remarkable robustness, especially in the prediction of high failure levels. In addition, compared to most previous used prediction models without any prediction confidence feedback, BNN based prediction model has the capability of uncertainty estimation. The confidence interval of prediction results can be obtained, which provides sufficient information for guiding risk management of utility companies. An effective operation and maintenance guiding scheme based on the analysis of prediction uncertainty is proposed, which fully excavates the interpretability of the proposed model and enrich the application value of the model.","",""
3,"A. Piccardo, R. Cappuccio, G. Bottoni, D. Cecchin, L. Mazzella, A. Cirone, S. Righi, Martina Ugolini, P. Bianchi, P. Bertolaccini, E. Lorenzini, M. Massollo, A. Castaldi, F. Fiz, L. Strada, A. Cistaro, M. Del Sette","The role of the deep convolutional neural network as an aid to interpreting brain [18F]DOPA PET/CT in the diagnosis of Parkinson’s disease",2021,"","","","",142,"2022-07-13 10:08:47","","10.1007/s00330-021-07779-z","","",,,,,3,3.00,0,17,1,"","",""
1,"Can Udomcharoenchaikit, P. Boonkwan, P. Vateekul","Adversarial Evaluation of Robust Neural Sequential Tagging Methods for Thai Language",2020,"","","","",143,"2022-07-13 10:08:47","","10.1145/3383201","","",,,,,1,0.50,0,3,2,"Sequential tagging tasks, such as Part-Of-Speech (POS) tagging and Named-Entity Recognition, are the building blocks of many natural language processing applications. Although prior works have reported promising results in standard settings, they often underperform on non-standard text, such as microblogs and social media. In this article, we introduce an adversarial evaluation scheme for the Thai language by creating adversarial examples based on known spelling errors. Furthermore, we propose novel methods including UNK masking, condition initialization with affixation embeddings, and untied-directional self-attention mechanism to enhance robustness and interpretability of the neural networks. We conducted experiments on two Thai corpora: BEST2010 and ORCHID. Our adversarial evaluation schemes reveal that bidirectional LSTM (BiLSTM) do not perform well on adversarial examples. Our best methods match the performance of the BiLSTM baseline model and outperform it on adversarial examples.","",""
1,"Peng Lu, Yang Gao, Hao Xi, Yabin Zhang, Chao Gao, Bing Zhou, Hongpo Zhang, Liwei Chen, Xiaobo Mao","KecNet: A Light Neural Network for Arrhythmia Classification Based on Knowledge Reinforcement",2021,"","","","",144,"2022-07-13 10:08:47","","10.1155/2021/6684954","","",,,,,1,1.00,0,9,1,"Acquiring electrocardiographic (ECG) signals and performing arrhythmia classification in mobile device scenarios have the advantages of short response time, almost no network bandwidth consumption, and human resource savings. In recent years, deep neural networks have become a popular method to efficiently and accurately simulate nonlinear patterns of ECG data in a data-driven manner but require more resources. Therefore, it is crucial to design deep learning (DL) algorithms that are more suitable for resource-constrained mobile devices. In this paper, KecNet, a lightweight neural network construction scheme based on domain knowledge, is proposed to model ECG data by effectively leveraging signal analysis and medical knowledge. To evaluate the performance of KecNet, we use the Association for the Advancement of Medical Instrumentation (AAMI) protocol and the MIT-BIH arrhythmia database to classify five arrhythmia categories. The result shows that the ACC, SEN, and PRE achieve 99.31%, 99.45%, and 98.78%, respectively. In addition, it also possesses high robustness to noisy environments, low memory usage, and physical interpretability advantages. Benefiting from these advantages, KecNet can be applied in practice, especially wearable and lightweight mobile devices for arrhythmia classification.","",""
2,"S. Barland, Franccois Gustave","Convolutional neural network for self-mixing interferometric displacement sensing.",2021,"","","","",145,"2022-07-13 10:08:47","","10.1364/OE.419844","","",,,,,2,2.00,1,2,1,"Self-mixing interferometry is a well established interferometric measurement technique. In spite of the robustness and simplicity of the concept, interpreting the self-mixing signal is often complicated in practice, which is detrimental to measurement availability. Here we discuss the use of a convolutional neural network to reconstruct the displacement of a target from the self-mixing signal in a semiconductor laser. The network, once trained on periodic displacement patterns, can reconstruct arbitrarily complex displacement in different alignment conditions and setups. The approach validated here is amenable to generalization to modulated schemes or even to totally different self-mixing sensing tasks.","",""
1,"Yanghuan Xu, Dong-cheng Wang, Bo Duan, Hua-xin Yu, Hongmin Liu","Copper Strip Surface Defect Detection Model Based on Deep Convolutional Neural Network",2021,"","","","",146,"2022-07-13 10:08:47","","10.3390/app11198945","","",,,,,1,1.00,0,5,1,"Surface defect automatic detection has great significance for copper strip production. The traditional machine vision for surface defect automatic detection of copper strip needs artificial feature design, which has a long cycle, and poor ability of versatility and robustness. However, deep learning can effectively solve these problems. Therefore, based on the deep convolution neural network and the transfer learning strategy, an intelligent recognition model of surface defects of copper strip is established in this paper. Firstly, the defects were classified in accordance with the mechanism and morphology, and the surface defect dataset of copper strip was established by comprehensively adopting image acquisition and image augmentation. Then, a two-class discrimination model was established to achieve the accurate discrimination of perfect and defect images. On this basis, four CNN models were adopted for the recognition of defect images. Among these models, the EfficientNet model through transfer learning strategy had the best comprehensive performance with a recognition accuracy rate of 93.05%. Finally, the interpretability and deficiency of the model were analysed by the class activation map and confusion matrix, which point toward the direction of further optimization for future research.","",""
0,"Ethan Harris, Daniela Mihai, Jonathon S. Hare","How Convolutional Neural Network Architecture Biases Learned Opponency and Color Tuning",2021,"","","","",147,"2022-07-13 10:08:47","","10.1162/neco_a_01356","","",,,,,0,0.00,0,3,1,"Recent work suggests that changing convolutional neural network (CNN) architecture by introducing a bottleneck in the second layer can yield changes in learned function. To understand this relationship fully requires a way of quantitatively comparing trained networks. The fields of electrophysiology and psychophysics have developed a wealth of methods for characterizing visual systems that permit such comparisons. Inspired by these methods, we propose an approach to obtaining spatial and color tuning curves for convolutional neurons that can be used to classify cells in terms of their spatial and color opponency. We perform these classifications for a range of CNNs with different depths and bottleneck widths. Our key finding is that networks with a bottleneck show a strong functional organization: almost all cells in the bottleneck layer become both spatially and color opponent, and cells in the layer following the bottleneck become nonopponent. The color tuning data can further be used to form a rich understanding of how color a network encodes color. As a concrete demonstration, we show that shallower networks without a bottleneck learn a complex nonlinear color system, whereas deeper networks with tight bottlenecks learn a simple channel opponent code in the bottleneck layer. We develop a method of obtaining a hue sensitivity curve for a trained CNN that enables high-level insights that complement the low-level findings from the color tuning data. We go on to train a series of networks under different conditions to ascertain the robustness of the discussed results. Ultimately our methods and findings coalesce with prior art, strengthening our ability to interpret trained CNNs and furthering our understanding of the connection between architecture and learned representation. Trained models and code for all experiments are available at https://github.com/ecs-vlc/opponency.","",""
14,"T. Briegel, Volker Tresp","Robust Neural Network Regression for Offline and Online Learning",1999,"","","","",148,"2022-07-13 10:08:47","","","","",,,,,14,0.61,7,2,23,"We replace the commonly used Gaussian noise model in nonlinear regression by a more flexible noise model based on the Student-t- distribution. The degrees of freedom of the t-distribution can be chosen such that as special cases either the Gaussian distribution or the Cauchy distribution are realized. The latter is commonly used in robust regression. Since the t-distribution can be interpreted as being an infinite mixture of Gaussians, parameters and hyperparameters such as the degrees of freedom of the t-distribution can be learned from the data based on an EM-learning algorithm. We show that modeling using the t-distribution leads to improved predictors on real world data sets. In particular, if outliers are present, the t-distribution is superior to the Gaussian noise model. In effect, by adapting the degrees of freedom, the system can ""learn"" to distinguish between outliers and non-outliers. Especially for online learning tasks, one is interested in avoiding inappropriate weight changes due to measurement outliers to maintain stable online learning capability. We show experimentally that using the t-distribution as a noise model leads to stable online learning algorithms and outperforms state-of-the art online learning methods like the extended Kalman filter algorithm.","",""
9,"Darius Afchar, Romain Hennequin","Making Neural Networks Interpretable with Attribution: Application to Implicit Signals Prediction",2020,"","","","",149,"2022-07-13 10:08:47","","10.1145/3383313.3412253","","",,,,,9,4.50,5,2,2,"Explaining recommendations enables users to understand whether recommended items are relevant to their needs and has been shown to increase their trust in the system. More generally, if designing explainable machine learning models is key to check the sanity and robustness of a decision process and improve their efficiency, it however remains a challenge for complex architectures, especially deep neural networks that are often deemed ”black-box”. In this paper, we propose a novel formulation of interpretable deep neural networks for the attribution task. Differently to popular post-hoc methods, our approach is interpretable by design. Using masked weights, hidden features can be deeply attributed, split into several input-restricted sub-networks and trained as a boosted mixture of experts. Experimental results on synthetic data and real-world recommendation tasks demonstrate that our method enables to build models achieving close predictive performances to their non-interpretable counterparts, while providing informative attribution interpretations.","",""
356,"M. Mirman, Timon Gehr, Martin T. Vechev","Differentiable Abstract Interpretation for Provably Robust Neural Networks",2018,"","","","",150,"2022-07-13 10:08:47","","","","",,,,,356,89.00,119,3,4,"We introduce a scalable method for training robust neural networks based on abstract interpretation. We present several abstract transformers which balance efficiency with precision and show these can be used to train large neural networks that are certifiably robust to adversarial perturbations.","",""
40,"J. Hao, Youngsoon Kim, Tae-Kyung Kim, Mingon Kang","PASNet: pathway-associated sparse deep neural network for prognosis prediction from high-throughput data",2018,"","","","",151,"2022-07-13 10:08:47","","10.1186/s12859-018-2500-z","","",,,,,40,10.00,10,4,4,"","",""
44,"Minh Nguyen Nhat To, Q. Vu, B. Turkbey, P. Choyke, J. T. Kwak","Deep dense multi-path neural network for prostate segmentation in magnetic resonance imaging",2018,"","","","",152,"2022-07-13 10:08:47","","10.1007/s11548-018-1841-4","","",,,,,44,11.00,9,5,4,"","",""
5,"J. Günther, Elias Reichensdorfer, P. Pilarski, K. Diepold","Interpretable PID parameter tuning for control engineering using general dynamic neural networks: An extensive comparison",2019,"","","","",153,"2022-07-13 10:08:47","","10.1371/journal.pone.0243320","","",,,,,5,1.67,1,4,3,"Modern automation systems largely rely on closed loop control, wherein a controller interacts with a controlled process via actions, based on observations. These systems are increasingly complex, yet most deployed controllers are linear Proportional-Integral-Derivative (PID) controllers. PID controllers perform well on linear and near-linear systems but their simplicity is at odds with the robustness required to reliably control complex processes. Modern machine learning techniques offer a way to extend PID controllers beyond their linear control capabilities by using neural networks. However, such an extension comes at the cost of losing stability guarantees and controller interpretability. In this paper, we examine the utility of extending PID controllers with recurrent neural networks—–namely, General Dynamic Neural Networks (GDNN); we show that GDNN (neural) PID controllers perform well on a range of complex control systems and highlight how they can be a scalable and interpretable option for modern control systems. To do so, we provide an extensive study using four benchmark systems that represent the most common control engineering benchmarks. All control environments are evaluated with and without noise as well as with and without disturbances. The neural PID controller performs better than standard PID control in 15 of 16 tasks and better than model-based control in 13 of 16 tasks. As a second contribution, we address the lack of interpretability that prevents neural networks from being used in real-world control processes. We use bounded-input bounded-output stability analysis to evaluate the parameters suggested by the neural network, making them understandable for engineers. This combination of rigorous evaluation paired with better interpretability is an important step towards the acceptance of neural-network-based control approaches for real-world systems. It is furthermore an important step towards interpretable and safely applied artificial intelligence.","",""
3,"Artur Petrosyan, M. Sinkin, M. Lebedev, A. Ossadtchi","Decoding and interpreting cortical signals with a compact convolutional neural network",2021,"","","","",154,"2022-07-13 10:08:47","","10.1088/1741-2552/abe20e","","",,,,,3,3.00,1,4,1,"Objective. Brain–computer interfaces (BCIs) decode information from neural activity and send it to external devices. The use of Deep Learning approaches for decoding allows for automatic feature engineering within the specific decoding task. Physiologically plausible interpretation of the network parameters ensures the robustness of the learned decision rules and opens the exciting opportunity for automatic knowledge discovery. Approach. We describe a compact convolutional network-based architecture for adaptive decoding of electrocorticographic (ECoG) data into finger kinematics. We also propose a novel theoretically justified approach to interpreting the spatial and temporal weights in the architectures that combine adaptation in both space and time. The obtained spatial and frequency patterns characterizing the neuronal populations pivotal to the specific decoding task can then be interpreted by fitting appropriate spatial and dynamical models. Main results. We first tested our solution using realistic Monte-Carlo simulations. Then, when applied to the ECoG data from Berlin BCI competition IV dataset, our architecture performed comparably to the competition winners without requiring explicit feature engineering. Using the proposed approach to the network weights interpretation we could unravel the spatial and the spectral patterns of the neuronal processes underlying the successful decoding of finger kinematics from an ECoG dataset. Finally we have also applied the entire pipeline to the analysis of a 32-channel EEG motor-imagery dataset and observed physiologically plausible patterns specific to the task. Significance. We described a compact and interpretable CNN architecture derived from the basic principles and encompassing the knowledge in the field of neural electrophysiology. For the first time in the context of such multibranch architectures with factorized spatial and temporal processing we presented theoretically justified weights interpretation rules. We verified our recipes using simulations and real data and demonstrated that the proposed solution offers a good decoder and a tool for investigating motor control neural mechanisms.","",""
1,"Michael Yeung, L. Rundo, Yang Nan, E. Sala, C. Schönlieb, Guang Yang","Calibrating the Dice loss to handle neural network overconfidence for biomedical image segmentation",2021,"","","","",155,"2022-07-13 10:08:47","","","","",,,,,1,1.00,0,6,1,"The Dice similarity coefficient (DSC) is both a widely used metric and loss function for biomedical image segmentation due to its robustness to class imbalance. However, it is well known that the DSC loss is poorly calibrated, resulting in overconfident predictions that cannot be usefully interpreted in biomedical and clinical practice. Performance is often the only metric used to evaluate segmentations produced by deep neural networks, and calibration is often neglected. However, calibration is important for translation into biomedical and clinical practice, providing crucial contextual information to model predictions for interpretation by scientists and clinicians. In this study, we identify poor calibration as an emerging challenge of deep learning based biomedical image segmentation. We provide a simple yet effective extension of the DSC loss, named the DSC++ loss, that selectively modulates the penalty associated with overconfident, incorrect predictions. As a standalone loss function, the DSC++ loss achieves significantly improved calibration over the conventional DSC loss across five well-validated open-source biomedical imaging datasets. Similarly, we observe significantly improved when integrating the DSC++ loss into four DSC-based loss functions. Finally, we use softmax thresholding to illustrate that well calibrated outputs enable tailoring of precision-recall bias, an important post-processing technique to adapt the model predictions to suit the biomedical or clinical task. The DSC++ loss overcomes the major limitation of the DSC, providing a suitable loss function for training deep learning segmentation models for use in biomedical and clinical practice.","",""
619,"Mou Chen, S. Ge, B. How","Robust Adaptive Neural Network Control for a Class of Uncertain MIMO Nonlinear Systems With Input Nonlinearities",2010,"","","","",156,"2022-07-13 10:08:47","","10.1109/TNN.2010.2042611","","",,,,,619,51.58,206,3,12,"In this paper, robust adaptive neural network (NN) control is investigated for a general class of uncertain multiple-input-multiple-output (MIMO) nonlinear systems with unknown control coefficient matrices and input nonlinearities. For nonsymmetric input nonlinearities of saturation and deadzone, variable structure control (VSC) in combination with backstepping and Lyapunov synthesis is proposed for adaptive NN control design with guaranteed stability. In the proposed adaptive NN control, the usual assumption on nonsingularity of NN approximation for unknown control coefficient matrices and boundary assumption between NN approximation error and control input have been eliminated. Command filters are presented to implement physical constraints on the virtual control laws, then the tedious analytic computations of time derivatives of virtual control laws are canceled. It is proved that the proposed robust backstepping control is able to guarantee semiglobal uniform ultimate boundedness of all signals in the closed-loop system. Finally, simulation results are presented to illustrate the effectiveness of the proposed adaptive NN control.","",""
2,"A. Petrosino, Giuseppe Salvi","A Robust Neural Network Based Object Recognition System and Its SIMD Implementation",1999,"","","","",157,"2022-07-13 10:08:47","","10.1007/3-540-48311-X_135","","",,,,,2,0.09,1,2,23,"","",""
8,"Zicheng Hu, A. Tang, Jaiveer Singh, S. Bhattacharya, A. Butte","A robust and interpretable end-to-end deep learning model for cytometry data",2020,"","","","",158,"2022-07-13 10:08:47","","10.1073/pnas.2003026117","","",,,,,8,4.00,2,5,2,"Significance Cytometry technologies are able to profile immune cells at single-cell resolution. They are widely used for both clinical diagnosis and biological research. We developed a deep learning model for analyzing cytometry data. We demonstrated that the deep learning model accurately diagnoses the latent cytomegalovirus (CMV) in healthy individuals. In addition, we developed a method for interpreting the deep learning model, allowing us to identify biomarkers associated with latent CMV infection. The deep learning model is widely applicable to other cytometry data related to human diseases. Cytometry technologies are essential tools for immunology research, providing high-throughput measurements of the immune cells at the single-cell level. Existing approaches in interpreting and using cytometry measurements include manual or automated gating to identify cell subsets from the cytometry data, providing highly intuitive results but may lead to significant information loss, in that additional details in measured or correlated cell signals might be missed. In this study, we propose and test a deep convolutional neural network for analyzing cytometry data in an end-to-end fashion, allowing a direct association between raw cytometry data and the clinical outcome of interest. Using nine large cytometry by time-of-flight mass spectrometry or mass cytometry (CyTOF) studies from the open-access ImmPort database, we demonstrated that the deep convolutional neural network model can accurately diagnose the latent cytomegalovirus (CMV) in healthy individuals, even when using highly heterogeneous data from different studies. In addition, we developed a permutation-based method for interpreting the deep convolutional neural network model. We were able to identify a CD27- CD94+ CD8+ T cell population significantly associated with latent CMV infection, confirming the findings in previous studies. Finally, we provide a tutorial for creating, training, and interpreting the tailored deep learning model for cytometry data using Keras and TensorFlow (https://github.com/hzc363/DeepLearningCyTOF).","",""
5,"Shaeke Salman, S. N. Payrovnaziri, Xiuwen Liu, Pablo A Rengifo-Moreno, Zhe He","DeepConsensus: Consensus-based Interpretable Deep Neural Networks with Application to Mortality Prediction",2019,"","","","",159,"2022-07-13 10:08:47","","10.1109/IJCNN48605.2020.9206678","","",,,,,5,1.67,1,5,3,"Deep neural networks have achieved remarkable success in various challenging tasks. However, the black-box nature of such networks is not acceptable to critical applications, such as healthcare. In particular, the existence of adversarial examples and their overgeneralization to irrelevant, out-ofdistribution inputs with high confidence makes it difficult, if not impossible, to explain decisions by such networks. In this paper, we analyze the underlying mechanism of generalization of deep neural networks and propose an (n, k) consensus algorithm which is insensitive to adversarial examples and can reliably reject out- of-distribution samples. Furthermore, the consensus algorithm is able to improve classification accuracy by using multiple trained deep neural networks. To handle the complexity of deep neural networks, we cluster linear approximations of individual models and identify highly correlated clusters among different models to capture feature importance robustly, resulting in improved interpretability. Motivated by the importance of building accurate and interpretable prediction models for healthcare, our experimental results on an ICU dataset show the effectiveness of our algorithm in enhancing both the prediction accuracy and the interpretability of deep neural network models on one-year patient mortality prediction. In particular, while the proposed method maintains similar interpretability as conventional shallow models such as logistic regression, it improves the prediction accuracy significantly.","",""
8,"S. Candemir, Richard D. White, M. Demirer, Vikash Gupta, M. Bigelow, L. Prevedello, B. Erdal","Automated coronary artery atherosclerosis detection and weakly supervised localization on coronary CT angiography with a deep 3-dimensional convolutional neural network",2019,"","","","",160,"2022-07-13 10:08:47","","","","",,,,,8,2.67,1,7,3,"We propose a fully automated algorithm based on a deep learning framework enabling screening of a Coronary Computed Tomography Angiography (CCTA) examination for confident detection of the presence or absence of coronary artery atherosclerosis. The system starts with extracting the coronary arteries and their branches from CCTA datasets and representing them with multi-planar reformatted volumes; pre-processing and augmentation techniques are then applied to increase the robustness and generalization ability of the system. A 3-Dimensional Convolutional Neural Network (3D CNN) is utilized to model pathological changes (e.g., atherosclerotic plaques) in coronary vessels. The system learns the discriminatory features between vessels with and without atherosclerosis. The discriminative features at the final convolutional layer are visualized with a saliency map approach to provide visual clues related to atherosclerosis likelihood and location. We have evaluated the system on a reference dataset representing 247 patients with atherosclerosis and 246 patients free of atherosclerosis. With 5-fold cross-validation, an Accuracy = 90:9%, Positive Predictive Value = 58:8%, Sensitivity = 68:9%, Specificity of 93:6%, and Negative Predictive Value (NPV) = 96:1% are achieved at the artery/branch level with threshold 0.5. The average area under the receiver operating characteristic curve is 0.91. The system indicates a high NPV, which may be potentially useful for assisting interpreting physicians in excluding coronary atherosclerosis in patients with acute chest pain.","",""
2,"Sara Aqab, Muhammad Usman","Handwriting Recognition using Artificial Intelligence Neural Network and Image Processing",2020,"","","","",161,"2022-07-13 10:08:47","","10.14569/ijacsa.2020.0110719","","",,,,,2,1.00,1,2,2,"Due to increased usage of digital technologies in all sectors and in almost all day to day activities to store and pass information, Handwriting character recognition has become a popular subject of research. Handwriting remains relevant, but people still want to have Handwriting copies converted into electronic copies that can be communicated and stored electronically. Handwriting character recognition refers to the computer's ability to detect and interpret intelligible Handwriting input from Handwriting sources such as touch screens, photographs, paper documents, and other sources. Handwriting characters remain complex since different individuals have different handwriting styles. This paper aims to report the development of a Handwriting character recognition system that will be used to read students and lectures Handwriting notes. The development is based on an artificial neural network, which is a field of study in artificial intelligence. Different techniques and methods are used to develop a Handwriting character recognition system. However, few of them focus on neural networks. The use of neural networks for recognizing Handwriting characters is more efficient and robust compared with other computing techniques. The paper also outlines the methodology, design, and architecture of the Handwriting character recognition system and testing and results of the system development. The aim is to demonstrate the effectiveness of neural networks for Handwriting character recognition.","",""
1,"Federico Amato, Fabian Guignard, P. Jacquet, M. Kanevski","On Feature Selection Using Anisotropic General Regression Neural Network",2020,"","","","",162,"2022-07-13 10:08:47","","","","",,,,,1,0.50,0,4,2,"The presence of irrelevant features in the input dataset tends to reduce the interpretability and predictive quality of machine learning models. Therefore, the development of feature selection methods to recognize irrelevant features is a crucial topic in machine learning. Here we show how the General Regression Neural Network used with an anisotropic Gaussian Kernel can be used to perform feature selection. A number of numerical experiments are conducted using simulated data to study the robustness of the proposed methodology and its sensitivity to sample size. Finally, a comparison with four other feature selection methods is performed on several real world datasets.","",""
1,"Ethan Harris, Daniela Mihai, Jonathon S. Hare","How Convolutional Neural Network Architecture Biases Learned Opponency and Colour Tuning",2020,"","","","",163,"2022-07-13 10:08:47","","","","",,,,,1,0.50,0,3,2,"Recent work suggests that changing Convolutional Neural Network (CNN) architecture by introducing a bottleneck in the second layer can yield changes in learned function. To understand this relationship fully requires a way of quantitatively comparing trained networks. The fields of electrophysiology and psychophysics have developed a wealth of methods for characterising visual systems which permit such comparisons. Inspired by these methods, we propose an approach to obtaining spatial and colour tuning curves for convolutional neurons, which can be used to classify cells in terms of their spatial and colour opponency. We perform these classifications for a range of CNNs with different depths and bottleneck widths. Our key finding is that networks with a bottleneck show a strong functional organisation: almost all cells in the bottleneck layer become both spatially and colour opponent, cells in the layer following the bottleneck become non-opponent. The colour tuning data can further be used to form a rich understanding of how colour is encoded by a network. As a concrete demonstration, we show that shallower networks without a bottleneck learn a complex non-linear colour system, whereas deeper networks with tight bottlenecks learn a simple channel opponent code in the bottleneck layer. We further develop a method of obtaining a hue sensitivity curve for a trained CNN which enables high level insights that complement the low level findings from the colour tuning data. We go on to train a series of networks under different conditions to ascertain the robustness of the discussed results. Ultimately, our methods and findings coalesce with prior art, strengthening our ability to interpret trained CNNs and furthering our understanding of the connection between architecture and learned representation. Trained models and code for all experiments are available at https://github.com/ecs-vlc/opponency.","",""
1,"Haonan Sun, Luqi Liang, Chunlin Wang, Yi Wu, Fei Yang, M. Rong","Prediction of the Electrical Strength and Boiling Temperature of the Substitutes for Greenhouse Gas SF₆ Using Neural Network and Random Forest",2020,"","","","",164,"2022-07-13 10:08:47","","10.1109/ACCESS.2020.3004519","","",,,,,1,0.50,0,6,2,"Finding substitutes for sulfur hexafluoride (SF6), a gas with extremely high global warming potential, has been a persistent effort for years in the field of high voltage power equipment, which focuses on the evaluation of the electrical strength and boiling temperature for the practical purpose. Following up the previous proposed linear regression models, this work introduces machine learning algorithms including artificial neural network (ANN) and random forest (RF) as the potential approaches to predict the electrical strength and boiling temperature. Based on a series of descriptors derived from the molecular structure of 74 molecules, the performance of three different methods: multiple linear regression, artificial neural network and random forest are compared and assessed in terms of the sensitivity to the sample size, prediction accuracy and stability, and the interpretability of predictors. Considering the available data are limited, random forest shows superior performance with higher robustness and efficiency. The same approaches were applied to the boiling temperature and random forest produced better results as well. Besides, the variable importance ranked by RF improves understanding of the correlation between the molecular properties and electrical strength. It provides important insights to analyze the properties of the SF6 substitutes during the design and synthesis of the new eco-friendly gases in power equipment.","",""
10,"Julian Viereck, Jules Kozolinsky, Alexander Herzog, L. Righetti","Learning a Structured Neural Network Policy for a Hopping Task",2017,"","","","",165,"2022-07-13 10:08:47","","10.1109/LRA.2018.2861466","","",,,,,10,2.00,3,4,5,"In this letter, we present a method for learning a reactive policy for a simple dynamic locomotion task involving hard impact and switching contacts where we assume the contact location and contact timing to be unknown. To learn such a policy, we use optimal control to optimize a local controller for a fixed environment and contacts. We learn the contact-rich dynamics for our underactuated systems along these trajectories in a sample efficient manner. We use the optimized policies to learn the reactive policy in form of a neural network. Using a new neural network architecture, we are able to preserve more information from the local policy and make its output interpretable in the sense that its output in terms of desired trajectories, feedforward commands and gains can be interpreted. Extensive simulations demonstrate the robustness of the approach to changing environments, outperforming a model-free gradient policy based methods on the same tasks in simulation. Finally, we show that the learned policy can be robustly transferred on a real robot.","",""
0,"Jörg Wagner, Volker Fischer, Michael Herman, Sven Behnke","Functionally Modular and Interpretable Temporal Filtering for Robust Segmentation",2018,"","","","",166,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,4,4,"The performance of autonomous systems heavily relies on their ability to generate a robust representation of the environment. Deep neural networks have greatly improved vision-based perception systems but still fail in challenging situations, e.g. sensor outages or heavy weather. These failures are often introduced by data-inherent perturbations, which significantly reduce the information provided to the perception system. We propose a functionally modularized temporal filter, which stabilizes an abstract feature representation of a single-frame segmentation model using information of previous time steps. Our filter module splits the filter task into multiple less complex and more interpretable subtasks. The basic structure of the filter is inspired by a Bayes estimator consisting of a prediction and an update step. To make the prediction more transparent, we implement it using a geometric projection and estimate its parameters. This additionally enables the decomposition of the filter task into static representation filtering and low-dimensional motion filtering. Our model can cope with missing frames and is trainable in an end-to-end fashion. Using photorealistic, synthetic video data, we show the ability of the proposed architecture to overcome data-inherent perturbations. The experiments especially highlight advantages introduced by an interpretable and explicit filter module.","",""
41,"K. Islam, R. G. Raj","Real-Time (Vision-Based) Road Sign Recognition Using an Artificial Neural Network",2017,"","","","",167,"2022-07-13 10:08:47","","10.3390/s17040853","","",,,,,41,8.20,21,2,5,"Road sign recognition is a driver support function that can be used to notify and warn the driver by showing the restrictions that may be effective on the current stretch of road. Examples for such regulations are ‘traffic light ahead’ or ‘pedestrian crossing’ indications. The present investigation targets the recognition of Malaysian road and traffic signs in real-time. Real-time video is taken by a digital camera from a moving vehicle and real world road signs are then extracted using vision-only information. The system is based on two stages, one performs the detection and another one is for recognition. In the first stage, a hybrid color segmentation algorithm has been developed and tested. In the second stage, an introduced robust custom feature extraction method is used for the first time in a road sign recognition approach. Finally, a multilayer artificial neural network (ANN) has been created to recognize and interpret various road signs. It is robust because it has been tested on both standard and non-standard road signs with significant recognition accuracy. This proposed system achieved an average of 99.90% accuracy with 99.90% of sensitivity, 99.90% of specificity, 99.90% of f-measure, and 0.001 of false positive rate (FPR) with 0.3 s computational time. This low FPR can increase the system stability and dependability in real-time applications.","",""
101,"Fatemeh Fahimi, Zhuo Zhang, Wooi-Boon Goh, Tih-Shih Lee, K. Ang, Cuntai Guan","Inter-subject transfer learning with an end-to-end deep convolutional neural network for EEG-based BCI.",2019,"","","","",168,"2022-07-13 10:08:47","","10.1088/1741-2552/aaf3f6","","",,,,,101,33.67,17,6,3,"OBJECTIVE Despite the effective application of deep learning (DL) in brain-computer interface (BCI) systems, the successful execution of this technique, especially for inter-subject classification, in cognitive BCI has not been accomplished yet. In this paper, we propose a framework based on the deep convolutional neural network (CNN) to detect the attentive mental state from single-channel raw electroencephalography (EEG) data.   APPROACH We develop an end-to-end deep CNN to decode the attentional information from an EEG time series. We also explore the consequences of input representations on the performance of deep CNN by feeding three different EEG representations into the network. To ensure the practical application of the proposed framework and avoid time-consuming re-training, we perform inter-subject transfer learning techniques as a classification strategy. Eventually, to interpret the learned attentional patterns, we visualize and analyse the network perception of the attention and non-attention classes.   MAIN RESULTS The average classification accuracy is 79.26%, with only 15.83% of 120 subjects having an accuracy below 70% (a generally accepted threshold for BCI). This is while with the inter-subject approach, it is literally difficult to output high classification accuracy. This end-to-end classification framework surpasses conventional classification methods for attention detection. The visualization results demonstrate that the learned patterns from the raw data are meaningful.   SIGNIFICANCE This framework significantly improves attention detection accuracy with inter-subject classification. Moreover, this study sheds light on the research on end-to-end learning; the proposed network is capable of learning from raw data with the least amount of pre-processing, which in turn eliminates the extensive computational load of time-consuming data preparation and feature extraction.","",""
2,"G. Portwood, B. Nadiga, J. Saenz, D. Livescu","Analysis and interpretation of out-performing neural network residual flux models",2020,"","","","",169,"2022-07-13 10:08:47","","","","",,,,,2,1.00,1,4,2,"We present novel approaches for the development, evaluation and interpretation of artificial neural networks (ANNs) for subfilter closures and demonstrate their usage in the context of large-eddy simulations (LES) of a passive scalar in homogeneous isotropic turbulence. Exact subfilter fluxes obtained by filtering direct numerical simulations (DNS) are used both to train deep ANN models as a function of filtered variables, and to optimise the coefficients of common spatio-temporally local LES closures. \textit{A-priori} analysis with respect to important dynamical features such as backscatter and subfilter scalar variance transfer rate, reveals that learnt ANN models out-performs optimised, turbulent Prandtl number closure models and gradient models. Next, \textit{a-posteriori} solutions are obtained with each model over several integral timescales. These solutions are obtained by explicitly filtering DNS-resolved velocity in order to isolate sources of error to subfilter flux closure. These experiments reveal that ANN models temporally track resolved scalar variance with greater accuracy compared to other subfilter flux models for a given filter length scale. Similarly, moments of scalar two-point structure functions reveal that trained neural network models reproduce statistics of ground-truth DNS with greater fidelity compared to common algebraic closure models. Finally, we interpret the artificial neural networks statistically with differential sensitivity analysis to show that the ANN models learns dynamics reminiscent of so-called ""mixed models"", where mixed models are understood as comprising both a structural and functional component. Besides enabling enhanced-accuracy LES of passive scalars henceforth, we anticipate this work to contribute to utilising well-performing neural network models as a tool in interpretability, robustness and model discovery.","",""
25,"K. Islam, R. G. Raj, G. Mujtaba","Recognition of Traffic Sign Based on Bag-of-Words and Artificial Neural Network",2017,"","","","",170,"2022-07-13 10:08:47","","10.3390/SYM9080138","","",,,,,25,5.00,8,3,5,"The traffic sign recognition system is a support system that can be useful to give notification and warning to drivers. It may be effective for traffic conditions on the current road traffic system. A robust artificial intelligence based traffic sign recognition system can support the driver and significantly reduce driving risk and injury. It performs by recognizing and interpreting various traffic sign using vision-based information. This study aims to recognize the well-maintained, un-maintained, standard, and non-standard traffic signs using the Bag-of-Words and the Artificial Neural Network techniques. This research work employs a Bag-of-Words model on the Speeded Up Robust Features descriptors of the road traffic signs. A robust classifier Artificial Neural Network has been employed to recognize the traffic sign in its respective class. The proposed system has been trained and tested to determine the suitable neural network architecture. The experimental results showed high accuracy of classification of traffic signs including complex background images. The proposed traffic sign detection and recognition system obtained 99.00% classification accuracy with a 1.00% false positive rate. For real-time implementation and deployment, this marginal false positive rate may increase reliability and stability of the proposed system.","",""
409,"Shuai Li, W. Li, Chris Cook, Ce Zhu, Yanbo Gao","Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN",2018,"","","","",171,"2022-07-13 10:08:47","","10.1109/CVPR.2018.00572","","",,,,,409,102.25,82,5,4,"Recurrent neural networks (RNNs) have been widely used for processing sequential data. However, RNNs are commonly difficult to train due to the well-known gradient vanishing and exploding problems and hard to learn long-term patterns. Long short-term memory (LSTM) and gated recurrent unit (GRU) were developed to address these problems, but the use of hyperbolic tangent and the sigmoid action functions results in gradient decay over layers. Consequently, construction of an efficiently trainable deep network is challenging. In addition, all the neurons in an RNN layer are entangled together and their behaviour is hard to interpret. To address these problems, a new type of RNN, referred to as independently recurrent neural network (IndRNN), is proposed in this paper, where neurons in the same layer are independent of each other and they are connected across layers. We have shown that an IndRNN can be easily regulated to prevent the gradient exploding and vanishing problems while allowing the network to learn long-term dependencies. Moreover, an IndRNN can work with non-saturated activation functions such as relu (rectified linear unit) and be still trained robustly. Multiple IndRNNs can be stacked to construct a network that is deeper than the existing RNNs. Experimental results have shown that the proposed IndRNN is able to process very long sequences (over 5000 time steps), can be used to construct very deep networks (21 layers used in the experiment) and still be trained robustly. Better performances have been achieved on various tasks by using IndRNNs compared with the traditional RNN and LSTM.","",""
6,"Fengchao Xiong, Jun Zhou, Shuyin Tao, Jianfeng Lu, Y. Qian","SNMF-Net: Learning a Deep Alternating Neural Network for Hyperspectral Unmixing",2021,"","","","",172,"2022-07-13 10:08:47","","10.1109/TGRS.2021.3081177","","",,,,,6,6.00,1,5,1,"Hyperspectral unmixing is recognized as an important tool to learn the constituent materials and corresponding distribution in a scene. The physical spectral mixture model is always important to tackle this problem because of its highly ill-posed nature. In this article, we introduce a linear spectral mixture model (LMM)-based end-to-end deep neural network named SNMF-Net for hyperspectral unmixing. SNMF-Net shares an alternating architecture and benefits from both model-based methods and learning-based methods. On the one hand, SNMF-Net is of high physical interpretability as it is built by unrolling <inline-formula> <tex-math notation=""LaTeX"">$L_{p}$ </tex-math></inline-formula> sparsity constrained nonnegative matrix factorization (<inline-formula> <tex-math notation=""LaTeX"">$L_{p}$ </tex-math></inline-formula>-NMF) model belonging to LMM families. On the other hand, all the parameters and submodules of SNMF-Net can be seamlessly linked with the alternating optimization algorithm of <inline-formula> <tex-math notation=""LaTeX"">$L_{p}$ </tex-math></inline-formula>-NMF and unmixing problem. This enables us to reasonably integrate the prior knowledge on unmixing, the optimization algorithm, and the sparse representation theory into the network for robust learning, so as to improve unmixing. Experimental results on the synthetic and real-world data show the advantages of the proposed SNMF-Net over many state-of-the-art methods.","",""
879,"Tyler Martin","Interpretable Machine Learning",2019,"","","","",173,"2022-07-13 10:08:47","","","","",,,,,879,293.00,879,1,3,"Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.","",""
1,"Ji-Seon Bang, Seong-Whan Lee","Interpretable Convolutional Neural Networks for Subject-Independent Motor Imagery Classification",2021,"","","","",174,"2022-07-13 10:08:47","","10.1109/BCI53720.2022.9734822","","",,,,,1,1.00,1,2,1,"Deep learning frameworks have become increasingly popular in brain-computer interface (BCI) study thanks to their outstanding performance. However, in terms of the classification model alone, they are treated as black boxes as they do not provide any information on what led them to reach a particular decision. In other words, we cannot convince whether the neuro-physiological factor or simply noise is the factor of high performance. Because of this disadvantage, it is difficult to ensure adequate reliability compared to their high performance. In this study, we propose an explainable deep learning model aimed at classifying EEG signal which is obtained from the motor-imagery (MI) task. Layer-wise relevance propagation (LRP) was adopted on the model to interpret the reason that the model derived certain classification output. We visualized the heatmap which indicates the output of the LRP in the form of topography to certify neuro-physiological factors. Furthermore, we classified EEG in the subject-independent manner to learn robust and generalized EEG features by avoiding subject dependency. The methodology also provides the advantage of avoiding the expense of building training data for each subject. With our proposed model, we obtained generalized heatmap patterns for all subjects. As a result, we can conclude that our proposed model provides neuro-physiologically reliable interpretation.","",""
1,"Haozhe Lin, Yushun Fan, Jia Zhang, Bing Bai","MSP-RNN: Multi-Step Piecewise Recurrent Neural Network for Predicting the Tendency of Services Invocation",2022,"","","","",175,"2022-07-13 10:08:47","","10.1109/tsc.2020.2966487","","",,,,,1,1.00,0,4,1,"Driven by the widespread application of Service-Oriented Architecture (SOA), an increasing number of services and mashups have been developed and published onto the Internet in the past decades. With the number keeping on burgeoning, predicting the tendency of services invocation will provide various roles in service ecosystems with promising opportunities. However, services invocation bear three unique characteristics, which give rise to difficulties in predicting them. First, enormous services show different and complicated traits, like periodicity, nonlinearity and nonstationarity. Second, services providing similar or compensatory functions make up intricate relationship. Third, the combination dependencies between mashups and their comprising component services further amplify the difficulty. Given these factors, we have developed a tailored model Multi-Step Piecewise Recurrent Neural Network (MSP-RNN) to predict the tendency of services invocation. In MSP-RNN, Long Short Term Memory (LSTM) units are used to extract universal features. Based on these features, we have developed a piecewise regressive mechanism to make prediction discriminatingly. Besides, we have developed a multi-step prediction strategy to further enhance prediction accuracy and robustness. Extensive experiments in real-world data set with interpretable analysis show that MSP-RNN predicts the tendency of services invocation more accurately, i.e., by 3.7 percent in terms of symmetric mean absolute percentage error (SMAPE), than state-of-the-art baseline methods.","",""
46,"Xiaoxiao Li, N. Dvornek, Yuan Zhou, Juntang Zhuang, P. Ventola, J. Duncan","Graph Neural Network for Interpreting Task-fMRI Biomarkers",2019,"","","","",176,"2022-07-13 10:08:47","","10.1007/978-3-030-32254-0_54","","",,,,,46,15.33,8,6,3,"","",""
0,"Ben Qi, Liguo Zhang, Jin'gang Liang, J. Tong","Combinatorial Techniques for Fault Diagnosis in Nuclear Power Plants Based on Bayesian Neural Network and Simplified Bayesian Network-Artificial Neural Network",2022,"","","","",177,"2022-07-13 10:08:47","","10.3389/fenrg.2022.920194","","",,,,,0,0.00,0,4,1,"Knowledge-driven and data-driven methods are the two representative categories of intelligent technologies used in fault diagnosis in nuclear power plants. Knowledge-driven methods have advantages in interpretability and robustness, while data-driven methods have better performance in ease of modeling and inference efficiency. Given the complementarity of the two methods, a combination of them is a worthwhile investigation. In this work, we introduce two new techniques based on Bayesian theory (knowledge-driven) and artificial neural network (data-driven) for fault diagnosis in nuclear power plants. The first approach exploits an integrated technique, Bayesian Neural Network (BNN), which introduces Bayesian theory into the neural network to provide confidence in diagnosis. The second approach, denoted as Simplified Bayesian Network-Artificial Neural Network (SBN-ANN), adopts a hierarchical diagnosis idea, which firstly uses a simplified Bayesian network to diagnose fault types and then a neural network to diagnose the severity of faults. The two new techniques are implemented and verified with simulated faults data of a typical pressurized water reactor. Compared with single-algorithmic diagnostic approaches such as Bayesian network and neural network, the new combinatorial techniques show better performance in diagnostic precision. The results suggest the feasibility to develop the data and knowledge dual-drive technologies for fault diagnosis.","",""
12,"Diego Manzanas Lopez, Patrick Musau, Hoang-Dung Tran, Taylor T. Johnson","Verification of Closed-loop Systems with Neural Network Controllers",2019,"","","","",178,"2022-07-13 10:08:47","","10.29007/btv1","","",,,,,12,4.00,3,4,3,"This benchmark suite presents a detailed description of a series of closed-loop control systems with artificial neural network controllers. In many applications, feed-forward neural networks are heavily involved in the implementation of controllers by learning and representing control laws through several methods such as model predictive control (MPC) and reinforcement learning (RL). The type of networks that we consider in this manuscript are feed-forward neural networks consisting of multiple hidden layers with ReLU activation functions and a linear activation function in the output layer. While neural network controllers have been able to achieve desirable performance in many contexts, they also present a unique challenge in that it is difficult to provide any guarantees about the correctness of their behavior or reason about the stability a system that employs their use. Thus, from a controls perspective, it is necessary to verify them in conjunction with their corresponding plants in closed-loop. While there have been a handful of works proposed towards the verification of closed-loop systems with feed-forward neural network controllers, this area still lacks attention and a unified set of benchmark examples on which verification techniques can be evaluated and compared. Thus, to this end, we present a range of closed-loop control systems ranging from two to six state variables, and a range of controllers with sizes in the range of eleven neurons to a few hundred neurons in more complex systems. Category: Academic Difficulty: High Acknowledgement The material presented in this paper is based upon work supported by the National Science Foundation (NSF) under grant number SHF 1736323, the Air Force Office of Scientific Research (AFOSR) through contract numbers FA9550-15-1-0258, FA9550-16-10246, and FA9550-18-1-0122, and the Defense Advanced Research Projects Agency (DARPA) through contract number FA8750-18-C-0089. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of AFOSR, DARPA, or NSF G. Frehse and M. Althoff (eds.), ARCH19 (EPiC Series in Computing, vol. 61), pp. 201–210 Closed-loop Systems with Neural Network Controllers Manzanas Lopez, Musau, Tran and Johnson 1 Context and Origins. In recent years, advances in Artficial Intelligence (AI) have enabled a diverse range of technologies that are directly impacting people’s everyday lives [16]. Particularly, within this space, machine learning methods such as Deep Learning (DL) have achieved levels of accuracy and performance that are competitive or better than humans for tasks such as pattern and image recognition [12], natural language processing [7], and knowledge representation and reasoning [15,22]. Despite these achievements, there have been reservations about incorporating them into safety critical systems [11] due to their susceptibility to unexpected and errant behavior from a slight perturbation in their inputs [18]. Furthermore, neural networks are often viewed as ""black boxes"" since the underlying operation of the neuron activations is often indiscernible [22]. In light of these challenges, there has been significant work towards the creation of methods and verification tools that can formally reason about the behavior of neural networks [22]. However, the vast majority of these techniques have only been able to deal with feed-forward neural networks with piecewise-linear activation functions [4]. Additionally, the bulk of these methods have primarily considered the verification of input-output properties of neural networks in isolation [22], and there are only a handful of works that have explicitly addressed the verification of closed-loop control systems with neural network controllers [5, 8, 19–21]. One of the central challenges in verifying neural network control systems is that applying existing methodology to these systems is not straightforward [9], and a simple combination of verification tools for non-linear ordinary differential equations along with a neural network reachability tool suffers from severe overestimation errors [5]. Still, the verification of closed loop neural network systems is deeply important as they naturally arise in safety critical systems [5] such as autonomous vehicles, and complex control systems that make use of model predictive control and reinforcement learning [16]. Thus, there is a compelling need for methods and advanced software tools that can effectively deal with the complexities exhibited by these systems [5]. Inspired by a shortage of verification methods for closed-loop neural network control systems in the research literature, the central contribution of this paper is the provision of a set of executable benchmarks that have been synthesized using methods such as reinforcement learning [17], and model predictive control [14]. The problems elucidated in the paper are modeled using Simulink/Stateflow (SLSF) and are available at the following github repository1. We aim to provide a thorough problem description to which the numerous tools and approaches for non-linear systems and neural network verification present in the research community can be evaluated and compared [22]. If the research community is able to devise acceptable solutions to the aformentioned challenges they will stimulate the development of robust and intelligent systems with the potential to bring unparalleled benefits to numerous application domains. 2 Description of benchmarks. In this manuscript, we present a set of linear and non-linear closed-loop systems with continuoustime plants and feedforward neural networks controllers trained using different controls schemes such as reinforcement learning or model predictive control (MPC). A typical architecture describing the structure of these systems is displayed in Figure 2.1. All the neural networks 1https://github.com/verivital/ARCH-2019","",""
27,"Fuxun Yu, Zhuwei Qin, Chenchen Liu, Liang Zhao, Yanzhi Wang, Xiang Chen","Interpreting and Evaluating Neural Network Robustness",2019,"","","","",179,"2022-07-13 10:08:47","","10.24963/ijcai.2019/583","","",,,,,27,9.00,5,6,3,"Recently, adversarial deception becomes one of the most considerable threats to deep neural networks. However, compared to extensive research in new designs of various adversarial attacks and defenses, the neural networks' intrinsic robustness property is still lack of thorough investigation. This work aims to qualitatively interpret the adversarial attack and defense mechanisms through loss visualization, and establish a quantitative metric to evaluate the model's intrinsic robustness. The proposed robustness metric identifies the upper bound of a model's prediction divergence in the given domain and thus indicates whether the model can maintain a stable prediction. With extensive experiments, our metric demonstrates several advantages over conventional testing accuracy based robustness estimation: (1) it provides a uniformed evaluation to models with different structures and parameter scales; (2) it over-performs conventional accuracy based robustness evaluation and provides a more reliable evaluation that is invariant to different test settings; (3) it can be fast generated without considerable testing cost.","",""
0,"","On Dynamics of Interpretable Neural Models",2019,"","","","",180,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,0,3,"Neural networks have a reputation for behaving as black-boxes. To motivate their usage in real world systems their interpretability is essential. Evidently, there has been a lot of discussion in the community regarding this aspect of neural networks. While most of the recent interest has focused on providing local explanations, there has been a much lower emphasis on studying the effects of model dynamics and its impact on explanation. We address the challenges of both over-confident and under-confident predictions with interpretability using attention distribution. Our results indicate that the means of using attention distributions for interpretability are highly unstable for uncalibrated models. We also conduct a comprehensive study on the behavior of deep learning models under different random seed initializations. We try to quantify the model in-stability as a function of random seeds by investigating the effects of the induced randomness on model performance, attention mechanisms, and the robustness of the model in general. Our experiments indicate that deep learning models can behave in-consistently, providing counter-factual explanations, under the impression of different random seeds. We propose a novel technique called Aggressive Stochastic Weight Averaging (ASWA) and an extension called Norm-filtered Aggressive Stochastic Weight Averaging (NASWA) which improves the stability of model over random-seeds. With our ASWA and NASWA implementations, we are able to improve the robustness of the original model, on an average, reducing the standard deviation of the model’s performance by 72%.","",""
11,"Henry Kenlay, D. Thanou, Xiaowen Dong","Interpretable Stability Bounds for Spectral Graph Filters",2021,"","","","",181,"2022-07-13 10:08:47","","","","",,,,,11,11.00,4,3,1,"Graph-structured data arise in a variety of realworld context ranging from sensor and transportation to biological and social networks. As a ubiquitous tool to process graph-structured data, spectral graph filters have been used to solve common tasks such as denoising and anomaly detection, as well as design deep learning architectures such as graph neural networks. Despite being an important tool, there is a lack of theoretical understanding of the stability properties of spectral graph filters, which are important for designing robust machine learning models. In this paper, we study filter stability and provide a novel and interpretable upper bound on the change of filter output, where the bound is expressed in terms of the endpoint degrees of the deleted and newly added edges, as well as the spatial proximity of those edges. This upper bound allows us to reason, in terms of structural properties of the graph, when a spectral graph filter will be stable. We further perform extensive experiments to verify intuition that can be gained from the bound.","",""
0,"S. Wein, A. Schüller, Ana Maria Tom'e, W. M. Malloni, M. Greenlee, E. Lang","Forecasting Brain Activity Based on Models of Spatio-Temporal Brain Dynamics: A Comparison of Graph Neural Network Architectures",2021,"","","","",182,"2022-07-13 10:08:47","","10.1162/netn_a_00252","","",,,,,0,0.00,0,6,1,"  Comprehending the interplay between spatial and temporal characteristics of neural dynamics can contribute to our understanding of information processing in the human brain. Graph neural networks (GNNs) provide a new possibility to interpret graph structured signals like those observed in complex brain networks. In our study we compare different spatio-temporal GNN architectures and study their ability to model neural activity distributions obtained in functional MRI (fMRI) studies. We evaluate the performance of the GNN models on a variety of scenarios in MRI studies and also compare it to a VAR model, which is currently often used for directed functional connectivity analysis. We show that by learning localized functional interactions on the anatomical substrate, GNN based approaches are able to robustly scale to large network studies, even when available data are scarce. By including anatomical connectivity as the physical substrate for information propagation, such GNNs also provide a multi-modal perspective on directed connectivity analysis, offering a novel possibility to investigate the spatio-temporal dynamics in brain networks.","",""
1,"Noor D. Al-shakarchy, I. H. Ali","Abnormal head movement classification using deep neural network DNN",2019,"","","","",183,"2022-07-13 10:08:47","","10.1063/1.5123123","","",,,,,1,0.33,1,2,3,"Abnormal head movements play a crucial role in diagnoisis of varity diseases. Moreover, different studies considered with these type of information. In addition, the gestures based mainly on head movement which can be employed in many applications such as using head-nodding or shaking to feedback content-related feedback, detect and interpret the emotion, gaze orientation, focus of attention, driver assistance system and so on. In this paper, a new method proposed to detect and classify the flopping head movements as normal or abnormal based on Convolution Neural Network CNN in the term of special sense interaction and behavioral studies with this movement. The proposed system based on deep learning employing the Convolution Neural Network CNN as most promising approach to deal with lighting condition (illumination change) and distortion and noise. Normal Abnormal Head Movement Dataset (NAHM) static images dataset gathered and used in proposed system implementation. This dataset provided the various image conditions and subjects to prevent the overfitting and under fitting problem that appears with publically datasets. The proposed frame work presents robust learning ability based on accuracy and lose functions which achieved training loss: 0.0106, training accuracy: 0.9980, validation loss: 0.0968 and validation accuracy: 0.9831.Abnormal head movements play a crucial role in diagnoisis of varity diseases. Moreover, different studies considered with these type of information. In addition, the gestures based mainly on head movement which can be employed in many applications such as using head-nodding or shaking to feedback content-related feedback, detect and interpret the emotion, gaze orientation, focus of attention, driver assistance system and so on. In this paper, a new method proposed to detect and classify the flopping head movements as normal or abnormal based on Convolution Neural Network CNN in the term of special sense interaction and behavioral studies with this movement. The proposed system based on deep learning employing the Convolution Neural Network CNN as most promising approach to deal with lighting condition (illumination change) and distortion and noise. Normal Abnormal Head Movement Dataset (NAHM) static images dataset gathered and used in proposed system implementation. This dataset provided the various image...","",""
3,"S. Bersimis, Aggeliki Sgora, S. Psarakis","A robust meta‐method for interpreting the out‐of‐control signal of multivariate control charts using artificial neural networks",2021,"","","","",184,"2022-07-13 10:08:47","","10.1002/qre.2955","","",,,,,3,3.00,1,3,1,"Multivariate control charts are an effective mean to identify an out‐of‐control process in several (industrial or non‐industrial) fields, where the quality depends on many related variables. However, the main shortcoming of these charts is that they fail to indicate which measured variable or variables has or have shifted. In order to address this issue, several alternative analytical approaches that aim to diagnose the responsible variable or variables for the out‐of‐control signal and help identify aberrant variables have been proposed. However, there is no particular method that can be considered as panacea, since its performance depends on several parameters, such as the correlation among the variables, and so forth. In this paper, a meta‐method is proposed that combines the results of several well‐known analytical methods in order to identify robustly the out‐of‐control variables. The obtained results show that the proposed meta‐method achieves high performance and it is extremely robust under different scenarios of out‐of‐control processes.","",""
14,"P. V. C. Souza, L. Torres, A. J. Guimarães, Vanessa Souza Araújo","Pulsar Detection for Wavelets SODA and Regularized Fuzzy Neural Networks Based on Andneuron and Robust Activation Function",2019,"","","","",185,"2022-07-13 10:08:47","","10.1142/S0218213019500039","","",,,,,14,4.67,4,4,3,"The use of intelligent models may be slow because of the number of samples involved in the problem. The identification of pulsars (stars that emit Earth-catchable signals) involves collecting thousands of signals by professionals of astronomy and their identification may be hampered by the nature of the problem, which requires many dimensions and samples to be analyzed. This paper proposes the use of hybrid models based on concepts of regularized fuzzy neural networks that use the representativeness of input data to define the groupings that make up the neurons of the initial layers of the model. The andneurons are used to aggregate the neurons of the first layer and can create fuzzy rules. The training uses fast extreme learning machine concepts to generate the weights of neurons that use robust activation functions to perform pattern classification. To solve large-scale problems involving the nature of pulsar detection problems, the model proposes a fast and highly accurate approach to address complex issues. In the execution of the tests with the proposed model, experiments were conducted explanation in two databases of pulsars, and the results prove the viability of the fast and interpretable approach in identifying such involved stars.","",""
1,"Cedrique Rovile Njieutcheu Tassi","Bayesian Convolutional Neural Network: Robustly Quantify Uncertainty for Misclassifications Detection",2019,"","","","",186,"2022-07-13 10:08:47","","10.1007/978-3-030-37548-5_10","","",,,,,1,0.33,1,1,3,"","",""
16,"Fan Zhang, Fábio Duarte, Ruixian Ma, Dimitrios Milioris, Hui-Ching Lin, C. Ratti","Indoor Space Recognition using Deep Convolutional Neural Network: A Case Study at MIT Campus",2016,"","","","",187,"2022-07-13 10:08:47","","","","",,,,,16,2.67,3,6,6,"In this paper, we propose a robust and parsimonious approach using Deep Convolutional Neural Network (DCNN) to recognize and interpret interior space. DCNN has achieved incredible success in object and scene recognition. In this study we design and train a DCNN to classify a pre-zoning indoor space, and from a single phone photo to recognize the learned space features, with no need of additional assistive technology. We collect more than 600,000 images inside MIT campus buildings to train our DCNN model, and achieved 97.9% accuracy in validation dataset and 81.7% accuracy in test dataset based on spatial-scale fixed model. Furthermore, the recognition accuracy and spatial resolution can be potentially improved through multiscale classification model. We identify the discriminative image regions through Class Activating Mapping (CAM) technique, to observe the model's behavior in how to recognize space and interpret it in an abstract way. By evaluating the results with misclassification matrix, we investigate the visual spatial feature of interior space by looking into its visual similarity and visual distinctiveness, giving insights into interior design and human indoor perception and wayfinding research. The contribution of this paper is threefold. First, we propose a robust and parsimonious approach for indoor navigation using DCNN. Second, we demonstrate that DCNN also has a potential capability in space feature learning and recognition, even under severe appearance changes. Third, we introduce a DCNN based approach to look into the visual similarity and visual distinctiveness of interior space.","",""
17,"Yi-Shan Lin, Wen-Chuan Lee, Z. B. Celik","What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors",2020,"","","","",188,"2022-07-13 10:08:47","","10.1145/3447548.3467213","","",,,,,17,8.50,6,3,2,"EXplainable AI (XAI) methods have been proposed to interpret how a deep neural network predicts inputs through model saliency explanations that highlight the input parts deemed important to arrive at a decision for a specific target. However, it remains challenging to quantify the correctness of their interpretability as current evaluation approaches either require subjective input from humans or incur high computation cost with automated evaluation. In this paper, we propose backdoor trigger patterns--hidden malicious functionalities that cause misclassification--to automate the evaluation of saliency explanations. Our key observation is that triggers provide ground truth for inputs to evaluate whether the regions identified by an XAI method are truly relevant to its output. Since backdoor triggers are the most important features that cause deliberate misclassification, a robust XAI method should reveal their presence at inference time. We introduce three complementary metrics for the systematic evaluation of explanations that an XAI method generates. We evaluate seven state-of-the-art model-free and model-specific post-hoc methods through 36 models trojaned with specifically crafted triggers using color, shape, texture, location, and size. We found six methods that use local explanation and feature relevance fail to completely highlight trigger regions, and only a model-free approach can uncover the entire trigger region. We made our code available at https://github.com/yslin013/evalxai.","",""
405,"David Alvarez-Melis, T. Jaakkola","Towards Robust Interpretability with Self-Explaining Neural Networks",2018,"","","","",189,"2022-07-13 10:08:47","","","","",,,,,405,101.25,203,2,4,"Most recent work on interpretability of complex machine learning models has focused on estimating a posteriori explanations for previously trained models around specific predictions. Self-explaining models where interpretability plays a key role already during learning have received much less attention. We propose three desiderata for explanations in general – explicitness, faithfulness, and stability – and show that existing methods do not satisfy them. In response, we design self-explaining models in stages, progressively generalizing linear classifiers to complex yet architecturally explicit models. Faithfulness and stability are enforced via regularization specifically tailored to such models. Experimental results across various benchmark datasets show that our framework offers a promising direction for reconciling model complexity and interpretability.","",""
0,"R. Sathish, Debdoot Sheet","Unit Impulse Response as an Explainer of Redundancy in a Deep Convolutional Neural Network",2019,"","","","",190,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,2,3,"Convolutional neural networks (CNN) are generally designed with a heuristic initialization of network architecture and trained for a certain task. This often leads to overparametrization after learning and induces redundancy in the information flow paths within the network. This robustness and reliability is at the increased cost of redundant computations. Several methods have been proposed which leverage metrics that quantify the redundancy in each layer. However, layer-wise evaluation in these methods disregards the long-range redundancy which exists across depth on account of the distributed nature of the features learned by the model. In this paper, we propose (i) a mechanism to empirically demonstrate the robustness in performance of a CNN on account of redundancy across its depth, (ii) a method to identify the systemic redundancy in response of a CNN across depth using the understanding of unit impulse response, we subsequently demonstrate use of these methods to interpret redundancy in few networks as example. These techniques provide better insights into the internal dynamics of a CNN","",""
0,"Pau","Neural network signal understanding for instrumentation",2019,"","","","",191,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,1,3,"This paper reports on the use of neural signal interpretation theory and techniques for the purpose of classifying the shapes of a set of instrumentation signals, in order to calibrate devices, diagnose anomalies, generate tuning/settings, and interpret the measurement results. Neural signal understanding research is surveyed, and the selected implementation is described with its performance in terms of correct classification rates and robustness to noise. Formal results on neural net training time and sensitivity to weights are given. A theory for neural control is given using functional link nets and an explanation technique is designed to help neural signal understanding. The results of this are compared to those of a knowledge-based signal interpretation system within the context of the same specific instrument and data. Keywords-Neural understanding, calibration, signal understanding, control theory, neural control, training time, sensitivity to noise, explanation facilities, knowledge-based signal interpretation, instrumentation, analytical instrumentation.","",""
1,"Shaojie Xu, J. Vaughan, Jie Chen, Aijun Zhang, A. Sudjianto","Traversing the Local Polytopes of ReLU Neural Networks: A Unified Approach for Network Verification",2021,"","","","",192,"2022-07-13 10:08:47","","","","",,,,,1,1.00,0,5,1,"Although neural networks (NNs) with ReLU activation functions have found success in a wide range of applications, their adoption in risk-sensitive settings has been limited by the concerns on robustness and interpretability. Previous works to examine robustness and to improve interpretability partially exploited the piecewise linear function form of ReLU NNs. In this paper, we explore the unique topological structure that ReLU NNs create in the input space, identifying the adjacency among the partitioned local polytopes and developing a traversing algorithm based on this adjacency. Our polytope traversing algorithm can be adapted to verify a wide range of network properties related to robustness and interpretability, providing an unified approach to examine the network behavior. As the traversing algorithm explicitly visits all local polytopes, it returns a clear and full picture of the network behavior within the traversed region. The time and space complexity of the traversing algorithm is determined by the number of a ReLU NN’s partitioning hyperplanes passing through the traversing region.","",""
3,"Gabriel Michau, Chi-Ching Hsu, Olga Fink","Interpretable Detection of Partial Discharge in Power Lines with Deep Learning",2021,"","","","",193,"2022-07-13 10:08:47","","10.3390/s21062154","","",,,,,3,3.00,1,3,1,"Partial discharge (PD) is a common indication of faults in power systems, such as generators and cables. These PDs can eventually result in costly repairs and substantial power outages. PD detection traditionally relies on hand-crafted features and domain expertise to identify very specific pulses in the electrical current, and the performance declines in the presence of noise or of superposed pulses. In this paper, we propose a novel end-to-end framework based on convolutional neural networks. The framework has two contributions: First, it does not require any feature extraction and enables robust PD detection. Second, we devise the pulse activation map. It provides interpretability of the results for the domain experts with the identification of the pulses that led to the detection of the PDs. The performance is evaluated on a public dataset for the detection of damaged power lines. An ablation study demonstrates the benefits of each part of the proposed framework.","",""
692,"W. Samek, Alexander Binder, G. Montavon, S. Lapuschkin, K. Müller","Evaluating the Visualization of What a Deep Neural Network Has Learned",2015,"","","","",194,"2022-07-13 10:08:47","","10.1109/TNNLS.2016.2599820","","",,,,,692,98.86,138,5,7,"Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the “importance” of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.","",""
4,"Xiao Sun, B. Bahmani, Nikolaos N. Vlassis, Waiching Sun, Yanxun Xu","Data-driven discovery of interpretable causal relations for deep learning material laws with uncertainty propagation",2021,"","","","",195,"2022-07-13 10:08:47","","10.1007/s10035-021-01137-y","","",,,,,4,4.00,1,5,1,"","",""
38,"G. Lai, Zhi Liu, Yun Zhang, C. L. Chen","Adaptive Position/Attitude Tracking Control of Aerial Robot With Unknown Inertial Matrix Based on a New Robust Neural Identifier",2016,"","","","",196,"2022-07-13 10:08:47","","10.1109/TNNLS.2015.2406812","","",,,,,38,6.33,10,4,6,"This paper presents a novel adaptive controller for controlling an autonomous helicopter with unknown inertial matrix to asymptotically track the desired trajectory. To identify the unknown inertial matrix included in the attitude dynamic model, this paper proposes a new structural identifier that differs from those previously proposed in that it additionally contains a neural networks (NNs) mechanism and a robust adaptive mechanism, respectively. Using the NNs to compensate the unknown aerodynamic forces online and the robust adaptive mechanism to cancel the combination of the overlarge NNs compensation error and the external disturbances, the new robust neural identifier exhibits a better identification performance in the complex flight environment. Moreover, an optimized algorithm is included in the NNs mechanism to alleviate the burdensome online computation. By the strict Lyapunov argument, the asymptotic convergence of the inertial matrix identification error, position tracking error, and attitude tracking error to arbitrarily small neighborhood of the origin is proved. The simulation and implementation results are provided to evaluate the performance of the proposed controller.","",""
0,"Jian Jiang","MIIDL: a Python package for microbial biomarkers identification powered by interpretable deep learning",2021,"","","","",197,"2022-07-13 10:08:47","","","","",,,,,0,0.00,0,1,1,"Summary: Detecting microbial biomarkers used to predict disease phenotypes and clinical outcomes is crucial for disease early-stage screening and diagnosis. Most methods for biomarker identification are linear-based, which is very limited as biological processes are rarely fully linear. The introduction of machine learning to this field tends to bring a promising solution. However, identifying microbial biomarkers in an interpretable, datadriven and robust manner remains challenging. We present MIIDL, a Python package for the identification of microbial biomarkers based on interpretable deep learning. MIIDL innovatively applies convolutional neural networks, a variety of interpretability algorithms and plenty of pre-processing methods to provide a one-stop and robust pipeline for microbial biomarkers identification from high-dimensional and sparse data sets. Availability: Source code is available on GitHub (https://github.com/chunribu/miidl/) under the MIT license. MIIDL is operating system independent and can be installed directly via pip or conda. Contact: chunribu@mail.sdu.edu.cn","",""
0,"Sahar Iravani, T. Conrad","An Interpretable Deep Learning Approach for Biomarker Detection in LC-MS Proteomics Data",2021,"","","","",198,"2022-07-13 10:08:47","","10.1101/2021.02.19.431935","","",,,,,0,0.00,0,2,1,"Analyzing mass spectrometry-based proteomics data with deep learning (DL) approaches poses several challenges due to the high dimensionality, low sample size, and high level of noise. Additionally, DL-based workflows are often hindered to be integrated into medical settings due to the lack of interpretable explanation. We present DLearnMS, a DL biomarker detection framework, to address these challenges on proteomics instances of liquid chromatography-mass spectrometry (LC-MS) - a well-established tool for quantifying complex protein mixtures. Our DLearnMS framework learns the clinical state of LC-MS data instances using convolutional neural networks. Based on the trained neural networks, we show how biomarkers can be identified using layer-wise relevance propagation. This enables detecting discriminating regions of the data and the design of more robust networks. One of the main advantages over other established methods is that no explicit preprocessing step is needed in our DLearnMS framework. Our evaluation shows that DLearnMS outperforms conventional LC-MS biomarker detection approaches in identifying fewer false positive peaks while maintaining a comparable amount of true positives peaks. Code availability The code is available from the following GIT repository: https://github.com/SaharIravani/DlearnMS","",""
3,"A. Preece, Daniel Harborne, R. Raghavendra, Richard J. Tomsett, Dave Braines","Provisioning Robust and Interpretable AI/ML-Based Service Bundles",2018,"","","","",199,"2022-07-13 10:08:47","","10.1109/MILCOM.2018.8599838","","",,,,,3,0.75,1,5,4,"Coalition operations environments are characterised by the need to share intelligence, surveillance and reconnaissance services. Increasingly, such services are based on artificial intelligence (AI)and machine learning (ML)technologies. Two key issues in the exploitation of AI/ML services are robustness and interpretability. Employing a diverse portfolio of services can make a system robust to ‘unknown unknowns’. Interpretability - the need for services to offer explanation facilities to engender user trust - can be addressed by a variety of methods to generate either transparent or post hoc explanations according to users' requirements. This paper shows how a service-provisioning framework for coalition operations can be extended to address specific requirements for robustness and interpretability, allowing automatic selection of service bundles for intelligence, surveillance and reconnaissance tasks. The approach is demonstrated in a case study on traffic monitoring featuring a diverse set of AI/ML services based on deep neural networks and heuristic reasoning approaches.","",""
158,"A. Vemuri, M. Polycarpou","Neural-network-based robust fault diagnosis in robotic systems",1997,"","","","",200,"2022-07-13 10:08:47","","10.1109/72.641464","","",,,,,158,6.32,79,2,25,"Fault diagnosis plays an important role in the operation of modern robotic systems. A number of researchers have proposed fault diagnosis architectures for robotic manipulators using the model-based analytical redundancy approach. One of the key issues in the design of such fault diagnosis schemes is the effect of modeling uncertainties on their performance. This paper investigates the problem of fault diagnosis in rigid-link robotic manipulators with modeling uncertainties. A learning architecture with sigmoidal neural networks is used to monitor the robotic system for any off-nominal behavior due to faults. The robustness and stability properties of the fault diagnosis scheme are rigorously established. Simulation examples are presented to illustrate the ability of the neural-network-based robust fault diagnosis scheme to detect and accommodate faults in a two-link robotic manipulator.","",""
