Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
7,"J. Bayley, C. Messenger, G. Woan","Robust machine learning algorithm to search for continuous gravitational waves",2020,"","","","",1,"2022-07-13 10:05:55","","10.1103/physrevd.102.083024","","",,,,,7,3.50,2,3,2,"Many continuous gravitational wave searches are affected by instrumental spectral lines that could be confused with a continuous astrophysical signal. Several techniques have been developed to limit the effect of these lines by penalizing signals that appear in only a single detector. We have developed a general method, using a convolutional neural network, to reduce the impact of instrumental artifacts on searches that use the SOAP algorithm Bayley et al. [Phys. Rev. D 100, 023006 (2019)]. The method can identify features in corresponding frequency bands of each detector and classify these bands as containing a signal, an instrumental line, or noise. We tested the method against four different datasets: Gaussian noise with time gaps, data from the final run of Initial LIGO (S6) with signals added, the reference S6 mock data challenge dataset Walsh et al. [Phys. Rev. D 94, 124010 (2016)] and signals injected into data from the second advanced LIGO observing run (O2). Using the S6 mock data challenge dataset and at a 1% false alarm probability we showed that at 95% efficiency a fully automated SOAP search has a sensitivity corresponding to a coherent signal-to-noise ratio of 110, equivalent to a sensitivity depth of $10\text{ }\text{ }{\mathrm{Hz}}^{\ensuremath{-}1/2}$, making this automated search competitive with other searches requiring significantly more computing resources and human intervention.","",""
7,"Waqar Hussain, Muhammad Shahid Iqbal, Jie Xiang, Bin Wang, Yan Niu, Y. Gao, Xin Wang, Jie Sun, Qionghui Zhan, R. Cao, Zhou Mengni","Epileptic Seizure Detection With Permutation Fuzzy Entropy Using Robust Machine Learning Techniques",2019,"","","","",2,"2022-07-13 10:05:55","","10.1109/ACCESS.2019.2956865","","",,,,,7,2.33,1,11,3,"The automatic and accurate determination of the epileptogenic area can assist doctors in presurgical evaluation by providing higher security and quality of life. Visual inspection of electroencephalogram (EEG) signals is expensive, time-consuming and prone to errors. Several numbers of automated seizure detection frameworks were proposed to replace the traditional methods and to assist neurophysiologists in identifying epileptic seizures accurately. However, these systems lagged in achieving high performance due to the anti-noise ability of feature extraction techniques, while EEG signals are highly susceptible to noise during acquisition. The present study put forwards a new entropy index Permutation Fuzzy Entropy (PFEN), which may delineate between ictal and interictal state of epileptic seizure using different machine learning classifiers. 10-fold cross-validation has been used to avoid the over-fitting of the classification model to achieve unbiased, stable, and reliable performance. The proposed index correctly distinguishes ictal and interictal states with an average accuracy of 98.72%, sensitivity of 98.82% and a specificity of 98.63%, across 21 patients with six epileptic seizure origins. The proposed system manifests the fact that lower PFEN characterizes the EEG during seizure state than in the Interictal seizure state. The study also helps us to investigate the more profound enactment of different classifiers in term of their distance metrics, learning rate, distance, weights, multiple scales, etc. rather than the conventional methods in the literature. Compared to other state of art entropy-based feature extraction methods, PFEN showed its potential to be a promising non-linear feature for achieving high accuracy and efficiency in seizure detection. It also show’s its feasibility towards the development of a real-time EEG-based brain monitoring system for epileptic seizure detection.","",""
36,"J. Li","Principled approaches to robust machine learning and beyond",2018,"","","","",3,"2022-07-13 10:05:55","","","","",,,,,36,9.00,36,1,4,"As we apply machine learning to more and more important tasks, it becomes increasingly important that these algorithms are robust to systematic, or worse, malicious, noise. Despite considerable interest, no efficient algorithms were known to be robust to such noise in high dimensional settings for some of the most fundamental statistical tasks for over sixty years of research. In this thesis we devise two novel, but similarly inspired, algorithmic paradigms for estimation in high dimensions in the presence of a small number of adversarially added data points. Both algorithms are the first efficient algorithms which achieve (nearly) optimal error bounds for a number fundamental statistical tasks such as mean estimation and covariance estimation. The goal of this thesis is to present these two frameworks in a clean and unified manner. We show that these insights also have applications for other problems in learning theory. Specifically, we show that these algorithms can be combined with the powerful Sum-of-Squares hierarchy to yield improvements for clustering high dimensional Gaussian mixture models, the first such improvement in over fifteen years of research. Going full circle, we show that Sum-of-Squares also can be used to improve error rates for robust mean estimation. Not only are these algorithms of interest theoretically, but we demonstrate empirically that we can use these insights in practice to uncover patterns in high dimensional data that were previously masked by noise. Based on our algorithms, we give new implementations for robust PCA, new defenses for data poisoning attacks for stochastic optimization, and new defenses for watermarking attacks on deep nets. In all of these tasks, we demonstrate on both synthetic and real data sets that our performance is substantially better than the state-of-the-art, often able to detect most to all corruptions when previous methods could not reliably detect any. Thesis Supervisor: Ankur Moitra Title: Rockwell International CD Associate Professor of Mathematics","",""
3,"Justin Morris, Kazim Ergun, Behnam Khaleghi, M. Imani, Baris Aksanli, T. Simunic","HyDREA: Towards More Robust and Efficient Machine Learning Systems with Hyperdimensional Computing",2021,"","","","",4,"2022-07-13 10:05:55","","10.23919/DATE51398.2021.9474218","","",,,,,3,3.00,1,6,1,"Today's systems, especially in the age of federated learning, rely on sending all the data to the cloud, and then use complex algorithms, such as Deep Neural Networks, which require billions of parameters and many hours to train a model. In contrast, the human brain can do much of this learning effortlessly. Hyperdimensional (HD) Computing aims to mimic the behavior of the human brain by utilizing high dimensional representations. This leads to various desirable properties that other Machine Learning (ML) algorithms lack such as: robustness to noise in the system and simple, highly parallel operations. In this paper, we propose HyDREA, a HD computing system that is Robust, Efficient, and Accurate. To evaluate the feasibility of HyDREA in a federated learning environment with wireless communication noise, we utilize NS-3, a popular network simulator that models a real world environment with wireless communication noise. We found that HyDREA is 48× more robust to noise than other comparable ML algorithms. We additionally propose a Processing-in-Memory (PIM) architecture that adaptively changes the bitwidth of the model based on the signal to noise ratio (SNR) of the incoming sample to maintain the robustness of the HD model while achieving high accuracy and energy efficiency. Our results indicate that our proposed system loses less than 1% classification accuracy, even in scenarios with an SNR of 6.64. Our PIM architecture is also able to achieve 255× better energy efficiency and speed up execution time by 28× compared to the baseline PIM architecture.","",""
5,"Khalid M. Al-Gethami, M. Al-Akhras, Mohammed Alawairdhi","Empirical Evaluation of Noise Influence on Supervised Machine Learning Algorithms Using Intrusion Detection Datasets",2021,"","","","",5,"2022-07-13 10:05:55","","10.1155/2021/8836057","","",,,,,5,5.00,2,3,1,"Optimizing the detection of intrusions is becoming more crucial due to the continuously rising rates and ferocity of cyber threats and attacks. One of the popular methods to optimize the accuracy of intrusion detection systems (IDSs) is by employing machine learning (ML) techniques. However, there are many factors that affect the accuracy of the ML-based IDSs. One of these factors is noise, which can be in the form of mislabelled instances, outliers, or extreme values. Determining the extent effect of noise helps to design and build more robust ML-based IDSs. )is paper empirically examines the extent effect of noise on the accuracy of the ML-based IDSs by conducting a wide set of different experiments. )e used ML algorithms are decision tree (DT), random forest (RF), support vector machine (SVM), artificial neural networks (ANNs), and Naı̈ve Bayes (NB). In addition, the experiments are conducted on two widely used intrusion datasets, which are NSL-KDD and UNSW-NB15. Moreover, the paper also investigates the use of these ML algorithms as base classifiers with two ensembles of classifiers learning methods, which are bagging and boosting. )e detailed results and findings are illustrated and discussed in this paper.","",""
9,"K. Kunaraj, S. Maria Wenisch, S. Balaji, F. P. Mahimai Don Bosco","Impulse Noise Classification Using Machine Learning Classifier and Robust Statistical Features",2019,"","","","",6,"2022-07-13 10:05:55","","10.1007/978-3-030-37218-7_72","","",,,,,9,3.00,2,4,3,"","",""
18,"Haosheng Xu, A. Angrisano, S. Gaglione, L. Hsu","Machine learning based LOS/NLOS classifier and robust estimator for GNSS shadow matching",2020,"","","","",7,"2022-07-13 10:05:55","","10.1186/s43020-020-00016-w","","",,,,,18,9.00,5,4,2,"","",""
3,"J. Blanchet, Yang Kang, J. L. M. Olea, Viet Anh Nguyen, Xuhui Zhang","Machine Learning's Dropout Training is Distributionally Robust Optimal",2020,"","","","",8,"2022-07-13 10:05:55","","","","",,,,,3,1.50,1,5,2,"This paper shows that dropout training in Generalized Linear Models is the minimax solution of a two-player, zero-sum game where an adversarial nature corrupts a statistician's covariates using a multiplicative nonparametric errors-in-variables model. In this game---known as a Distributionally Robust Optimization problem---nature's least favorable distribution is dropout noise, where nature independently deletes entries of the covariate vector with some fixed probability $\delta$. Our decision-theoretic analysis shows that dropout training---the statistician's minimax strategy in the game---indeed provides out-of-sample expected loss guarantees for distributions that arise from multiplicative perturbations of in-sample data.  This paper also provides a novel, parallelizable, Unbiased Multi-Level Monte Carlo algorithm to speed-up the implementation of dropout training. Our algorithm has a much smaller computational cost compared to the naive implementation of dropout, provided the number of data points is much smaller than the dimension of the covariate vector.","",""
5,"Jie Zhang, Yanjiao Li, Wendong Xiao, Zhiqiang Zhang","Robust extreme learning machine for modeling with unknown noise",2020,"","","","",9,"2022-07-13 10:05:55","","10.1016/j.jfranklin.2020.06.027","","",,,,,5,2.50,1,4,2,"","",""
10,"Jiahao Ding, Xinyue Zhang, Mingsong Chen, Kaiping Xue, Chi Zhang, M. Pan","Differentially Private Robust ADMM for Distributed Machine Learning",2019,"","","","",10,"2022-07-13 10:05:55","","10.1109/BigData47090.2019.9005716","","",,,,,10,3.33,2,6,3,"To embrace the era of big data, there has been growing interest in designing distributed machine learning to exploit the collective computing power of the local computing nodes. Alternating Direction Method of Multipliers (ADMM) is one of the most popular methods. This method applies iterative local computations over local datasets at each agent and computation results exchange between the neighbors. During this iterative process, data privacy leakage arises when performing local computation over sensitive data. Although many differentially private ADMM algorithms have been proposed to deal with such privacy leakage, they still have to face many challenging issues such as low model accuracy over strict privacy constraints and requiring strong assumptions of convexity of the objective function. To address those issues, in this paper, we propose a differentially private robust ADMM algorithm (PR-ADMM) with Gaussian mechanism. We employ two kinds of noise variance decay schemes to carefully adjust the noise addition in the iterative process and utilize a threshold to eliminate the too noisy results from neighbors. We also prove that PR-ADMM satisfies dynamic zero-concentrated differential privacy (dynamic zCDP) and a total privacy loss is given by $ (\epsilon, \delta)$-differential privacy. From a theoretical point of view, we analyze the convergence rate of PR-ADMM for general convex objectives, which is $\mathcal{O}(1 /K)$ with K being the number of iterations. The performance of the proposed algorithm is evaluated on real-world datasets. The experimental results show that the proposed algorithm outperforms other differentially private ADMM based algorithms under the same total privacy loss.","",""
10,"M. Chamarczuk, M. Malinowski, Y. Nishitsuji, J. Thorbecke, E. Koivisto, S. Heinonen, Sanna Juurela, M. Mezyk, D. Draganov","Automatic 3D illumination-diagnosis method for large-N arrays: Robust data scanner and machine-learning feature provider",2019,"","","","",11,"2022-07-13 10:05:55","","10.1190/GEO2018-0504.1","","",,,,,10,3.33,1,9,3,"The main issues related to passive-source reflection imaging with seismic interferometry (SI) are inadequate acquisition parameters for sufficient spatial wavefield sampling and vulnerability of surface arrays to the dominant influence of the omnipresent surface-wave sources. Additionally, long recordings provide large data volumes that require robust and efficient processing methods. We address these problems by developing a two-step wavefield evaluation and event detection (TWEED) method of body waves in recorded ambient noise. TWEED evaluates the spatiotemporal characteristics of noise recordings by simultaneous analysis of adjacent receiver lines. We test our method on synthetic data representing transient ambient-noise sources at the surface and in the deeper subsurface. We discriminate between basic types of seismic events by using three adjacent receiver lines. Subsequently, we apply TWEED to 600 h of ambient noise acquired with an approximately 1000-receiver array deployed over an active underground mine in Eastern Finland. We develop the detection of body-wave events related to mine blasts and other routine mining activities using a representative 1 h noise panel. Using TWEED, we successfully detect 1093 body-wave events in the full data set. To increase the computational efficiency, we use slowness parameters derived from the first step of TWEED as input to a support vector machine (SVM) algorithm. Using this approach, we detect 94% of the TWEED-evaluated body-wave events indicating the possibility to limit the illumination analysis to only one step, and therefore increase the time efficiency at the price of lower detection rate. However, TWEED on a small volume of the recorded data followed by SVM on the rest of the data could be efficiently used for a quick and robust (real-time) scanning for body-wave energy in large data volumes for subsequent application of SI for retrieval of reflections.","",""
17,"Xinjiang Lu, Li Ming, Wenbo Liu, Han-Xiong Li","Probabilistic Regularized Extreme Learning Machine for Robust Modeling of Noise Data",2018,"","","","",12,"2022-07-13 10:05:55","","10.1109/TCYB.2017.2738060","","",,,,,17,4.25,4,4,4,"The extreme learning machine (ELM) has been extensively studied in the machine learning field and has been widely implemented due to its simplified algorithm and reduced computational costs. However, it is less effective for modeling data with non-Gaussian noise or data containing outliers. Here, a probabilistic regularized ELM is proposed to improve modeling performance with data containing non-Gaussian noise and/or outliers. While traditional ELM minimizes modeling error by using a worst-case scenario principle, the proposed method constructs a new objective function to minimize both mean and variance of this modeling error. Thus, the proposed method considers the modeling error distribution. A solution method is then developed for this new objective function and the proposed method is further proved to be more robust when compared with traditional ELM, even when subject to noise or outliers. Several experimental cases demonstrate that the proposed method has better modeling performance for problems with non-Gaussian noise or outliers.","",""
14,"M. Ahsan, Rahul Gomes, M. Chowdhury, K. Nygard","Enhancing Machine Learning Prediction in Cybersecurity Using Dynamic Feature Selector",2021,"","","","",13,"2022-07-13 10:05:55","","10.3390/JCP1010011","","",,,,,14,14.00,4,4,1,"Machine learning algorithms are becoming very efficient in intrusion detection systems with their real time response and adaptive learning process. A robust machine learning model can be deployed for anomaly detection by using a comprehensive dataset with multiple attack types. Nowadays datasets contain many attributes. Such high dimensionality of datasets poses a significant challenge to information extraction in terms of time and space complexity. Moreover, having so many attributes may be a hindrance towards creation of a decision boundary due to noise in the dataset. Large scale data with redundant or insignificant features increases the computational time and often decreases goodness of fit which is a critical issue in cybersecurity. In this research, we have proposed and implemented an efficient feature selection algorithm to filter insignificant variables. Our proposed Dynamic Feature Selector (DFS) uses statistical analysis and feature importance tests to reduce model complexity and improve prediction accuracy. To evaluate DFS, we conducted experiments on two datasets used for cybersecurity research namely Network Security Laboratory (NSL-KDD) and University of New South Wales (UNSW-NB15). In the meta-learning stage, four algorithms were compared namely Bidirectional Long Short-Term Memory (Bi-LSTM), Gated Recurrent Units, Random Forest and a proposed Convolutional Neural Network and Long Short-Term Memory (CNN-LSTM) for accuracy estimation. For NSL-KDD, experiments revealed an increment in accuracy from 99.54% to 99.64% while reducing feature size of one-hot encoded features from 123 to 50. In UNSW-NB15 we observed an increase in accuracy from 90.98% to 92.46% while reducing feature size from 196 to 47. The proposed approach is thus able to achieve higher accuracy while significantly lowering number of features required for processing.","",""
6,"Sanjaya Lohani, R. Glasser","Generative machine learning for robust free-space communication",2019,"","","","",14,"2022-07-13 10:05:55","","10.1038/S42005-020-00444-9","","",,,,,6,2.00,3,2,3,"","",""
19,"D. Gupta, B. B. Hazarika, M. Berlin","Robust regularized extreme learning machine with asymmetric Huber loss function",2020,"","","","",15,"2022-07-13 10:05:55","","10.1007/s00521-020-04741-w","","",,,,,19,9.50,6,3,2,"","",""
10,"Ankur Rai, H. Singh","Machine Learning-Based Robust Watermarking Technique for Medical Image Transmitted Over LTE Network",2018,"","","","",16,"2022-07-13 10:05:55","","10.1515/jisys-2017-0068","","",,,,,10,2.50,5,2,4,"Abstract This paper discusses a safe and secure watermarking technique using a machine learning algorithm. In this paper, the propagation of a watermarked image is simulated over the third-generation partnership project (3GPP)/long-term evolution (LTE) downlink physical layer. The watermark data are scrambled and a transform domain-based hybrid watermarking technique is used to embed this watermark into the transform coefficients of the host image and transmitted over the orthogonal frequency division multiplexing (OFDM) downlink physical layer. Support vector machine (SVM) is used as a classifier for the classification of non-region of interest (NROI) and region of interest (ROI) in a medical image. The result achieved in this experiment revealed that a 10−6 bit error rate (BER) value is realizable for a greater value of signal-to-noise ratio (SNR; i.e. more than 10.4 dB of SNR). The peak SNR (PSNR) of the received cover image is more than 35 dB, which is acceptable for clinical applications.","",""
11,"Zhikuan Zhao, Jack K. Fitzsimons, P. Rebentrost, V. Dunjko, J. Fitzsimons","Smooth input preparation for quantum and quantum-inspired machine learning",2018,"","","","",17,"2022-07-13 10:05:55","","10.1007/s42484-021-00045-x","","",,,,,11,2.75,2,5,4,"","",""
11,"Sarah Akers, E. Kautz, Andrea Trevino-Gavito, M. Olszta, B. Matthews, Le Wang, Yingge Du, S. Spurgeon","Rapid and flexible segmentation of electron microscopy data using few-shot machine learning",2021,"","","","",18,"2022-07-13 10:05:55","","10.1038/s41524-021-00652-z","","",,,,,11,11.00,1,8,1,"","",""
12,"Yufei Han, Xiangliang Zhang","Robust Federated Learning via Collaborative Machine Teaching",2020,"","","","",19,"2022-07-13 10:05:55","","10.1609/AAAI.V34I04.5826","","",,,,,12,6.00,6,2,2,"For federated learning systems deployed in the wild, data flaws hosted on local agents are widely witnessed. On one hand, given a large amount (e.g. over 60%) of training data are corrupted by systematic sensor noise and environmental perturbations, the performances of federated model training can be degraded significantly. On the other hand, it is prohibitively expensive for either clients or service providers to set up manual sanitary checks to verify the quality of data instances. In our study, we echo this challenge by proposing a collaborative and privacy-preserving machine teaching method. Specifically, we use a few trusted instances provided by teachers as benign examples in the teaching process. Our collaborative teaching approach seeks jointly the optimal tuning on the distributed training set, such that the model learned from the tuned training set predicts labels of the trusted items correctly. The proposed method couples the process of teaching and learning and thus produces directly a robust prediction model despite the extremely pervasive systematic data corruption. The experimental study on real benchmark data sets demonstrates the validity of our method.","",""
4,"Liang-Rui Ren, Ying-Lian Gao, Jin-Xing Liu, J. Shang, C. Zheng","Correntropy induced loss based sparse robust graph regularized extreme learning machine for cancer classification",2020,"","","","",20,"2022-07-13 10:05:55","","10.1186/s12859-020-03790-1","","",,,,,4,2.00,1,5,2,"","",""
20,"L. Pan, Caixia Cheng, U. Haberkorn, A. Dimitrakopoulou-Strauss","Machine learning-based kinetic modeling: a robust and reproducible solution for quantitative analysis of dynamic PET data.",2017,"","","","",21,"2022-07-13 10:05:55","","10.1088/1361-6560/aa6244","","",,,,,20,4.00,5,4,5,"A variety of compartment models are used for the quantitative analysis of dynamic positron emission tomography (PET) data. Traditionally, these models use an iterative fitting (IF) method to find the least squares between the measured and calculated values over time, which may encounter some problems such as the overfitting of model parameters and a lack of reproducibility, especially when handling noisy data or error data. In this paper, a machine learning (ML) based kinetic modeling method is introduced, which can fully utilize a historical reference database to build a moderate kinetic model directly dealing with noisy data but not trying to smooth the noise in the image. Also, due to the database, the presented method is capable of automatically adjusting the models using a multi-thread grid parameter searching technique. Furthermore, a candidate competition concept is proposed to combine the advantages of the ML and IF modeling methods, which could find a balance between fitting to historical data and to the unseen target curve. The machine learning based method provides a robust and reproducible solution that is user-independent for VOI-based and pixel-wise quantitative analysis of dynamic PET data.","",""
7,"M. A. Ganaie, M. Tanveer, P. Suganthan","Regularized robust fuzzy least squares twin support vector machine for class imbalance learning",2020,"","","","",22,"2022-07-13 10:05:55","","10.1109/IJCNN48605.2020.9207724","","",,,,,7,3.50,2,3,2,"Twin support vector machines (TWSVM) have been successfully applied to the classification problems. TWSVM is computationally efficient model of support vector machines (SVM). However, in real world classification problems issues of class imbalance and noise provide great challenges. Due to this, models lead to the inaccurate classification either due to higher tendency towards the majority class or due to the presence of noise. We provide an improved version of robust fuzzy least squares twin support vector machine (RFLSTSVM) known as regularized robust fuzzy least squares twin support vector machine (RRFLSTSVM) to handle the imbalance problem. The advantage of RRFLSTSVM over RFLSTSVM is that the proposed RRFLSTSVM implements the structural risk minimization principle by the introduction of regularization term in the primal formulation of the objective functions. This modification leads to the improved classification as it embodies the marrow of statistical learning theory. The proposed RRFLSTSVM doesn’t require any extra assumption as the matrices resulting in the dual are positive definite. However, RFLSTSVM is based on the assumption that the inverse of the matrices resulting in the dual always exist as the matrices are positive semi-definite. To subsidize the effects of class imbalance and noise, the data samples are assigned weights via fuzzy membership function. The fuzzy membership function incorporates the imbalance ratio knowledge and assigns appropriate weights to the data samples. Unlike TWSVM which solves a pair of quadratic programming problem (QPP), the proposed RRFLSTSVM method solves a pair of system of linear equations and hence is computationally efficient. Experimental and statistical analysis show the efficacy of the proposed RRFLSTSVM method.","",""
7,"T. Haug, C. Self, M. Kim","Large-scale quantum machine learning",2021,"","","","",23,"2022-07-13 10:05:55","","","","",,,,,7,7.00,2,3,1,"Quantum computers promise to enhance machine learning for practical applications. Quantum machine learning for real-world data has to handle extensive amounts of high-dimensional data. However, conventional methods for measuring quantum kernels are impractical for large datasets as they scale with the square of the dataset size. Here, we measure quantum kernels using randomized measurements to gain a quadratic speedup in computation time and quickly process large datasets. Further, we efficiently encode high-dimensional data into quantum computers with the number of features scaling linearly with the circuit depth. The encoding is characterized by the quantum Fisher information metric and is related to the radial basis function kernel. We demonstrate the advantages of our methods by classifying images with the IBM quantum computer. To achieve further speedups we distribute the quantum computational tasks between different quantum computers. Our approach is exceptionally robust to noise via a complementary error mitigation scheme. Using currently available quantum computers, the MNIST database can be processed within 220 hours instead of 10 years which opens up industrial applications of quantum machine learning.","",""
3,"Xinjiang Lu, Li Ming, TeTe Hu, Bin Fan","Collaborative Learning-Based Clustered Support Vector Machine for Modeling of Nonlinear Processes Subject to Noise",2020,"","","","",24,"2022-07-13 10:05:55","","10.1109/TSMC.2018.2867238","","",,,,,3,1.50,1,4,2,"The least squares support vector machine (LS-SVM) is often employed to model data with a nonlinear distribution using a divide-and-conquer strategy. However, when nonlinear data are contaminated by either noise or outliers, LS-SVM is often an ineffective approach due to a lack of robustness. In this paper, a collaborative learning-based clustered LS-SVM method is proposed for modeling of nonlinear processes that are subject to noise or outliers. First, a large-scale dataset is divided into several subsets and the data distribution of each subset is estimated. A robust LS-SVM is then developed to represent each subset using this distributional information. A global model is further constructed through integration of all submodels, whose continuity and smoothness are ensured by the development of the collaborative learning technique. As a result, the proposed method considers both the nonlinear distribution of data and the robustness of each submodel, and ensures the continuity and smoothness of the global model. Thus, it can effectively model nonlinear data that is subject to either noise or outliers. As further validation of this approach, both artificial and real cases demonstrated its effectiveness.","",""
6,"Matthew Norton, Akiko Takeda, Alexander Mafusalov","Optimistic Robust Optimization With Applications To Machine Learning",2017,"","","","",25,"2022-07-13 10:05:55","","","","",,,,,6,1.20,2,3,5,"Robust Optimization has traditionally taken a pessimistic, or worst-case viewpoint of uncertainty which is motivated by a desire to find sets of optimal policies that maintain feasibility under a variety of operating conditions. In this paper, we explore an optimistic, or best-case view of uncertainty and show that it can be a fruitful approach. We show that these techniques can be used to address a wide variety of problems. First, we apply our methods in the context of robust linear programming, providing a method for reducing conservatism in intuitive ways that encode economically realistic modeling assumptions. Second, we look at problems in machine learning and find that this approach is strongly connected to the existing literature. Specifically, we provide a new interpretation for popular sparsity inducing non-convex regularization schemes. Additionally, we show that successful approaches for dealing with outliers and noise can be interpreted as optimistic robust optimization problems. Although many of the problems resulting from our approach are non-convex, we find that DCA or DCA-like optimization approaches can be intuitive and efficient.","",""
8,"Kookjin Lee, Nathaniel Trask, P. Stinis","Machine learning structure preserving brackets for forecasting irreversible processes",2021,"","","","",26,"2022-07-13 10:05:55","","","","",,,,,8,8.00,3,3,1,"Forecasting of time-series data requires imposition of inductive biases to obtain predictive extrapolation, and recent works have imposed Hamiltonian/Lagrangian form to preserve structure for systems with reversible dynamics. In this work we present a novel parameterization of dissipative brackets from metriplectic dynamical systems appropriate for learning irreversible dynamics with unknown a priori model form. The process learns generalized Casimirs for energy and entropy guaranteed to be conserved and nondecreasing, respectively. Furthermore, for the case of added thermal noise, we guarantee exact preservation of a ﬂuctuation-dissipation theorem, ensuring thermodynamic consistency. We provide benchmarks for dissipative systems demonstrating learned dynamics are more robust and generalize better than either ""black-box"" or penalty-based approaches.","",""
4,"Jae-Gil Lee, Yuji Roh, Hwanjun Song, S. E. Whang","Machine Learning Robustness, Fairness, and their Convergence",2021,"","","","",27,"2022-07-13 10:05:55","","10.1145/3447548.3470799","","",,,,,4,4.00,1,4,1,"Responsible AI becomes critical where robustness and fairness must be satisfied together. Traditionally, the two topics have been studied by different communities for different applications. Robust training is designed for noisy or poisoned data where image data is typically considered. In comparison, fair training primarily deals with biased data where structured data is typically considered. Nevertheless, robust training and fair training are fundamentally similar in considering that both of them aim at fixing the inherent flaws of real-world data. In this tutorial, we first cover state-of-the-art robust training techniques where most of the research is on combating various label noises. In particular, we cover label noise modeling, robust training approaches, and real-world noisy data sets. Then, proceeding to the related fairness literature, we discuss pre-processing, in-processing, and post-processing unfairness mitigation techniques, depending on whether the mitigation occurs before, during, or after the model training. Finally, we cover the recent trend emerged to combine robust and fair training in two flavors: the former is to make the fair training more robust (i.e., robust fair training), and the latter is to consider robustness and fairness as two equals to incorporate them into a holistic framework. This tutorial is indeed timely and novel because the convergence of the two topics is increasingly common, but yet to be addressed in tutorials. The tutors have extensive experience publishing papers in top-tier machine learning and data mining venues and developing machine learning platforms.","",""
18,"Yohei Nishizaki, R. Horisaki, K. Kitaguchi, M. Saito, J. Tanida","Analysis of non-iterative phase retrieval based on machine learning",2020,"","","","",28,"2022-07-13 10:05:55","","10.1007/s10043-019-00574-8","","",,,,,18,9.00,4,5,2,"","",""
6,"Thomas Haubner, Andreas Brendel, Mohamed Elminshawi, Walter Kellermann","Noise-Robust Adaptation Control for Supervised Acoustic System Identification Exploiting a Noise Dictionary",2021,"","","","",29,"2022-07-13 10:05:55","","10.1109/ICASSP39728.2021.9414180","","",,,,,6,6.00,2,4,1,"We present a noise-robust adaptation control strategy for block-online supervised acoustic system identification by exploiting a noise dictionary. The proposed algorithm takes advantage of the pronounced spectral structure which characterizes many types of interfering noise signals. We model the noisy observations by a linear Gaussian Discrete Fourier Transform-domain state space model whose parameters are estimated by an online generalized Expectation-Maximization algorithm. Unlike all other state-of-the-art approaches we suggest to model the covariance matrix of the observation probability density function by a dictionary model. We propose to learn the noise dictionary from training data, which can be gathered either offline or online whenever the system is not excited, while we infer the activations continuously. The proposed algorithm represents a novel machine-learning-based approach to noise-robust adaptation control which allows for faster convergence in applications characterized by high-level and non-stationary interfering noise signals and abrupt system changes.","",""
11,"J. Hayes, E. Kerins, S. Awiphan, I. McDonald, J. Morgan, P. Chuanraksasat, S. Komonjinda, N. Sanguansak, P. Kittara","Optimizing exoplanet atmosphere retrieval using unsupervised machine-learning classification",2019,"","","","",30,"2022-07-13 10:05:55","","10.1093/mnras/staa978","","",,,,,11,3.67,1,9,3,"  One of the principal bottlenecks to atmosphere characterization in the era of all-sky surveys is the availability of fast, autonomous, and robust atmospheric retrieval methods. We present a new approach using unsupervised machine learning to generate informed priors for retrieval of exoplanetary atmosphere parameters from transmission spectra. We use principal component analysis (PCA) to efficiently compress the information content of a library of transmission spectra forward models generated using the platon package. We then apply a k-means clustering algorithm in PCA space to segregate the library into discrete classes. We show that our classifier is almost always able to instantaneously place a previously unseen spectrum into the correct class, for low-to-moderate spectral resolutions, R, in the range R = 30−300 and noise levels up to 10 per cent of the peak-to-trough spectrum amplitude. The distribution of physical parameters for all members of the class therefore provides an informed prior for standard retrieval methods such as nested sampling. We benchmark our informed-prior approach against a standard uniform-prior nested sampler, finding that our approach is up to a factor of 2 faster, with negligible reduction in accuracy. We demonstrate the application of this method to existing and near-future observatories, and show that it is suitable for real-world application. Our general approach is not specific to transmission spectroscopy and should be more widely applicable to cases that involve the repetitive fitting of trusted high-dimensional models to large data catalogues, including beyond exoplanetary science.","",""
10,"Taesik Na, Minah Lee, B. Mudassar, Priyabrata Saha, J. Ko, S. Mukhopadhyay","Mixture of Pre-processing Experts Model for Noise Robust Deep Learning on Resource Constrained Platforms",2019,"","","","",31,"2022-07-13 10:05:55","","10.1109/IJCNN.2019.8851932","","",,,,,10,3.33,2,6,3,"Deep learning on an edge device requires energy efficient operation due to ever diminishing power budget. Intentional low quality data during the data acquisition for longer battery life, and natural noise from the low cost sensor degrade the quality of target output which hinders adoption of deep learning on an edge device. To overcome these problems, we propose simple yet efficient mixture of pre-processing experts (MoPE) model to handle various image distortions including low resolution and noisy images. We also propose to use adversarially trained auto encoder as a pre-processing expert for the noisy images. We evaluate our proposed method for various machine learning tasks including object detection on MS-COCO 2014 dataset, multiple object tracking problem on MOT-Challenge dataset, and human activity classification on UCF 101 dataset. Experimental results show that the proposed method achieves better detection, tracking and activity classification accuracies under noise without sacrificing accuracies for the clean images. The overheads of our proposed MoPE are 0.67% and 0.17% in terms of memory and computation compared to the baseline object detection network.","",""
15,"Chenhao Ma, B. Zhu, Xue-qiao Xu, Weixing Wang","Machine learning surrogate models for Landau fluid closure",2019,"","","","",32,"2022-07-13 10:05:55","","10.1063/1.5129158","","",,,,,15,5.00,4,4,3,"The first result of applying the machine/deep learning technique to the fluid closure problem is presented in this paper. As a start, three different types of neural networks [multilayer perceptron (MLP), convolutional neural network (CNN), and two-layer discrete Fourier transform (DFT) network] were constructed and trained to learn the well-known Hammett–Perkins Landau fluid closure in configuration space. We find that in order to train a well-preformed network, a minimum size of the training data set is needed; MLP also requires a minimum number of neurons in the hidden layers that equals the degrees of freedom in Fourier space, despite the fact that training data are being fed into the configuration space. Out of the three models, DFT performs the best for the clean data, most likely due to the existence of the simple Fourier expression for the Hammett–Perkins closure, but it is the least robust with respect to input noise. Overall, with appropriate tuning and optimization, all three neural networks are able to accurately predict the Hammett–Perkins closure and reproduce the intrinsic nonlocal feature, suggesting a promising path to calculating more sophisticated closures with the machine/deep learning technique.","",""
7,"Eric Minor, Stian D. Howard, Adam A S Green, M. Glaser, C. Park, N. Clark","End-to-end machine learning for experimental physics: using simulated data to train a neural network for object detection in video microscopy.",2019,"","","","",33,"2022-07-13 10:05:55","","10.1039/c9sm01979k","","",,,,,7,2.33,1,6,3,"We demonstrate a method for training a convolutional neural network with simulated images for usage on real-world experimental data. Modern machine learning methods require large, robust training data sets to generate accurate predictions. Generating these large training sets requires a significant up-front time investment that is often impractical for small-scale applications. Here we demonstrate a 'full-stack' computational solution, where the training data set is generated on-the-fly using a noise injection process to produce simulated data characteristic of the experimental system. We demonstrate the power of this full-stack approach by applying it to the study of topological defect annihilation in systems of liquid crystal freely-suspended films. This specific experimental system requires accurate observations of both the spatial distribution of the defects and the total number of defects, making it an ideal system for testing the robustness of the trained network. The fully trained network was found to be comparable in accuracy to human hand-annotation, with four-orders of magnitude improvement in time efficiency.","",""
8,"M. Yahaya, Wenbo Fan, Chuanyun Fu, Xiang Li, Yue Su, Xinguo Jiang","A machine-learning method for improving crash injury severity analysis: a case study of work zone crashes in Cairo, Egypt",2020,"","","","",34,"2022-07-13 10:05:55","","10.1080/17457300.2020.1746814","","",,,,,8,4.00,1,6,2,"Abstract The quality of vehicular collision data is crucial for studying the relationship between injury severity and collision factors. Misclassified injury severity data in the crash dataset, however, may cause inaccurate parameter estimates and consequently lead to biased conclusions and poorly designed countermeasures. This is particularly true for imbalanced data where the number of samples in one class far outnumber the other. To improve the classification performance of the injury severity, the paper presents a robust noise filtering technique to deal with the mislabels in the imbalanced crash dataset using the advanced machine learning algorithms. We examine the state-of-the-art filtering algorithms, including Iterative Noise Filtering based on the Fusion of Classifiers (INFFC), Iterative Partitioning Filter (IPF), and Saturation Filter (SatF). In the case study of Cairo (Egypt), the empirical results show that: (1) the mislabels in crash data significantly influence the injury severity predictions, and (2) the proposed M-IPF filter outperforms its counterparts in terms of the effectiveness and efficiency in eliminating the mislabels in crash data. The test results demonstrate the efficacy of the M-IPF in handling the data noise and mitigating the impacts thereof.","",""
5,"Negin Majidi, E. Amid, Hossein Talebi, Manfred K. Warmuth","Exponentiated Gradient Reweighting for Robust Training Under Label Noise and Beyond",2021,"","","","",35,"2022-07-13 10:05:55","","","","",,,,,5,5.00,1,4,1,"Many learning tasks in machine learning can be viewed as taking a gradient step towards minimizing the average loss of a batch of examples in each training iteration. When noise is prevalent in the data, this uniform treatment of examples can lead to overfitting to noisy examples with larger loss values and result in poor generalization. Inspired by the expert setting in on-line learning, we present a flexible approach to learning from noisy examples. Specifically, we treat each training example as an expert and maintain a distribution over all examples. We alternate between updating the parameters of the model using gradient descent and updating the example weights using the exponentiated gradient update. Unlike other related methods, our approach handles a general class of loss functions and can be applied to a wide range of noise types and applications. We show the efficacy of our approach for multiple learning settings, namely noisy principal component analysis and a variety of noisy classification problems.","",""
4,"J. Guan, Wang Fang, M. Ying","Robustness Verification of Quantum Machine Learning",2020,"","","","",36,"2022-07-13 10:05:55","","","","",,,,,4,2.00,1,3,2,"Several important models of machine learning algorithms have been successfully generalized to the quantum world, with potential applications to data analytics in quantum physics that can be implemented on the near future quantum computers. However, noise and decoherence are two major obstacles to the practical implementation of quantum machine learning. In this work, we introduce a general framework for the robustness analysis of quantum machine learning algorithms against noise and decoherence. We argue that fidelity is the only pick of measuring the robustness. A robust bound is derived and an algorithm is developed to check whether or not a quantum machine learning algorithm is robust with respect to the training data. In particular, this algorithm can help to defense attacks and improve the accuracy as it can identify useful new training data during checking. The effectiveness of our robust bound and algorithm is confirmed by the case study of quantum phase recognition. Furthermore, this experiment demonstrates a trade-off between the accuracy of quantum machine learning algorithms and their robustness.","",""
5,"B. Limbacher, S. Schoenhuber, M. Wenclawiak, M. Kainz, A. M. Andrews, G. Strasser, J. Darmo, K. Unterrainer","Terahertz optical machine learning for object recognition",2020,"","","","",37,"2022-07-13 10:05:55","","10.1063/5.0029310","","",,,,,5,2.50,1,8,2,"We demonstrate an optical machine learning method in the terahertz domain, which allows the recognition of objects within a single measurement. As many materials are transparent in the terahertz spectral region, objects hidden within such materials can be identified. In contrast to typical object recognition methods, our method only requires a single pixel detector instead of a focal plane array. The core of the calculation is performed by a quantum cascade laser generated terahertz beam, which is spatially modulated at a near-infrared encoded silicon wafer. We show that this method is robust against displacements of the objects and noise. Additionally, the method is flexible and, due to the optically performed recognition task, inherently fast.","",""
9,"Xiaokai Liu, Rong Li, Cheng-lin Zhao, Pengbiao Wang","Robust signal recognition algorithm based on machine learning in heterogeneous networks",2016,"","","","",38,"2022-07-13 10:05:55","","10.1109/JSEE.2016.00034","","",,,,,9,1.50,2,4,6,"There are various heterogeneous networks for terminals to deliver a better quality of service. Signal system recognition and classification contribute a lot to the process. However, in low signal to noise ratio (SNR) circumstances or under time-varying multipath channels, the majority of the existing algorithms for signal recognition are already facing limitations. In this series, we present a robust signal recognition method based upon the original and latest updated version of the extreme learning machine (ELM) to help users to switch between networks. The ELM utilizes signal characteristics to distinguish systems. The superiority of this algorithm lies in the random choices of hidden nodes and in the fact that it determines the output weights analytically, which result in lower complexity. Theoretically, the algorithm tends to offer a good generalization performance at an extremely fast speed of learning. Moreover, we implement the GSM/WCDMA/LTE models in the Matlab environment by using the Simulink tools. The simulations reveal that the signals can be recognized successfully to achieve a 95% accuracy in a low SNR (0 dB) environment in the time-varying multipath Rayleigh fading channel.","",""
5,"Dongxu Cheng, Xinman Zhang, Xuebin Xu","An Improved Recognition Approach for Noisy Multispectral Palmprint by Robust L2 Sparse Representation with a Tensor-Based Extreme Learning Machine",2019,"","","","",39,"2022-07-13 10:05:55","","10.3390/s19020235","","",,,,,5,1.67,2,3,3,"For the past decades, recognition technologies of multispectral palmprint have attracted more and more attention due to their abundant spatial and spectral characteristics compared with the single spectral case. Enlightened by this, an innovative robust L2 sparse representation with tensor-based extreme learning machine (RL2SR-TELM) algorithm is put forward by using an adaptive image level fusion strategy to accomplish the multispectral palmprint recognition. Firstly, we construct a robust L2 sparse representation (RL2SR) optimization model to calculate the linear representation coefficients. To suppress the affection caused by noise contamination, we introduce a logistic function into RL2SR model to evaluate the representation residual. Secondly, we propose a novel weighted sparse and collaborative concentration index (WSCCI) to calculate the fusion weight adaptively. Finally, we put forward a TELM approach to carry out the classification task. It can deal with the high dimension data directly and reserve the image spatial information well. Extensive experiments are implemented on the benchmark multispectral palmprint database provided by PolyU. The experiment results validate that our RL2SR-TELM algorithm overmatches a number of state-of-the-art multispectral palmprint recognition algorithms both when the images are noise-free and contaminated by different noises.","",""
23,"Patrick A. K. Reinbold, Logan Kageorge, M. Schatz, R. Grigoriev","Robust learning from noisy, incomplete, high-dimensional experimental data via physically constrained symbolic regression",2021,"","","","",40,"2022-07-13 10:05:55","","10.1038/s41467-021-23479-0","","",,,,,23,23.00,6,4,1,"","",""
16,"M. Hassan, Md. Rafiul Hassan, S. Huda, V. H. C. de Albuquerque","A Robust Deep-Learning-Enabled Trust-Boundary Protection for Adversarial Industrial IoT Environment",2021,"","","","",41,"2022-07-13 10:05:55","","10.1109/JIOT.2020.3019225","","",,,,,16,16.00,4,4,1,"In recent years, trust-boundary protection has become a challenging problem in Industrial Internet of Things (IIoT) environments. Trust boundaries separate IIoT processes and data stores in different groups based on user access privilege. Points where dataflow intersects with the trust boundary are becoming entry points for attackers. Attackers use various model skewing and intelligent techniques to generate adversarial/noisy examples that are indistinguishable from natural data. Many of the existing machine-learning (ML)-based approaches attempt to circumvent this problem. However, owing to an extremely large attack surface in the IIoT network, capturing a true distribution during training is difficult. The standard generative adversarial network (GAN) commonly generates adversarial examples for training using randomly sampled noise. However, the distribution of noisy inputs of GAN largely differs from actual distribution of data in IIoT networks and shows less robustness against adversarial attacks. Therefore, in this article, we propose a downsampler-encoder-based cooperative data generator that is trained using an algorithm to ensure better capture of the actual distribution of attack models for the large IIoT attack surface. The proposed downsampler-based data generator is alternatively updated and verified during training using a deep neural network discriminator to ensure robustness. This guarantees the performance of the generator against input sets with a high noise level at time of training and testing. Various experiments are conducted on a real IIoT testbed data set. Experimental results show that the proposed approach outperforms conventional deep learning and other ML techniques in terms of robustness against adversarial/noisy examples in the IIoT environment.","",""
2,"S. Siltanen, Takanori Ide","Electrical Impedance Tomography, Enclosure Method and Machine Learning",2020,"","","","",42,"2022-07-13 10:05:55","","10.1109/MLSP49062.2020.9231717","","",,,,,2,1.00,1,2,2,"Electrical impedance tomography (EIT) is a non-destructive imaging method, where a physical body is probed with electric measurements at the boundary, and information about the internal conductivity is extracted from the data. The enclosure method of Ikehata [J. Inv. III-Posed Prob. 8(2000)] recovers the convex hull of an inclusion of unknown conductivity embedded in known background conductivity. Practical implementations of the enclosure method are based on least-squares (LS) fitting of lines to noise-robust values of the so-called indicator function. It is shown how a convolutional neural network instead of LS fitting improves the accuracy of the enclosure method significantly while retaining interpretability.","",""
78,"R. Biswas, L. Blackburn, J. Cao, R. Essick, K. Hodge, E. Katsavounidis, K. Kim, Young-Min Kim, E. Bigot, Chang-Hwan Lee, John J. Oh, S. Oh, E. Son, R. Vaulin, Xiaoge Wang, T. Ye","Application of machine learning algorithms to the study of noise artifacts in gravitational-wave data",2013,"","","","",43,"2022-07-13 10:05:55","","10.1103/PhysRevD.88.062003","","",,,,,78,8.67,8,16,9,"The sensitivity of searches for astrophysical transients in data from the Laser Interferometer Gravitational-wave Observatory (LIGO) is generally limited by the presence of transient, non-Gaussian noise artifacts, which occur at a high enough rate such that accidental coincidence across multiple detectors is non-negligible. These ``glitches'' can easily be mistaken for transient gravitational-wave signals, and their robust identification and removal will help any search for astrophysical gravitational waves. We apply machine-learning algorithms (MLAs) to the problem, using data from auxiliary channels within the LIGO detectors that monitor degrees of freedom unaffected by astrophysical signals. Noise sources may produce artifacts in these auxiliary channels as well as the gravitational-wave channel. The number of auxiliary-channel parameters describing these disturbances may also be extremely large; high dimensionality is an area where MLAs are particularly well suited. We demonstrate the feasibility and applicability of three different MLAs: artificial neural networks, support vector machines, and random forests. These classifiers identify and remove a substantial fraction of the glitches present in two different data sets: four weeks of LIGO's fourth science run and one week of LIGO's sixth science run. We observe that all three algorithms agree on which events are glitches to within 10% for the sixth-science-run data, and support this by showing that the different optimization criteria used by each classifier generate the same decision surface, based on a likelihood-ratio statistic. Furthermore, we find that all classifiers obtain similar performance to the benchmark algorithm, the ordered veto list, which is optimized to detect pairwise correlations between transients in LIGO auxiliary channels and glitches in the gravitational-wave data. This suggests that most of the useful information currently extracted from the auxiliary channels is already described by this model. Future performance gains are thus likely to involve additional sources of information, rather than improvements in the classification algorithms themselves. We discuss several plausible sources of such new information as well as the ways of propagating it through the classifiers into gravitational-wave searches.","",""
69,"Martins Ezuma, F. Erden, C. K. Anjinappa, O. Ozdemir, I. Guvenc","Micro-UAV Detection and Classification from RF Fingerprints Using Machine Learning Techniques",2019,"","","","",44,"2022-07-13 10:05:55","","10.1109/AERO.2019.8741970","","",,,,,69,23.00,14,5,3,"This paper focuses on the detection and classification of micro-unmanned aerial vehicles (UAVs)using radio frequency (RF)fingerprints of the signals transmitted from the controller to the micro-UAV. In the detection phase, raw signals are split into frames and transformed into the wavelet domain to remove the bias in the signals and reduce the size of data to be processed. A naive Bayes approach, which is based on Markov models generated separately for UAV and non-UAV classes, is used to check for the presence of a UAV in each frame. In the classification phase, unlike the traditional approaches that rely solely on time-domain signals and corresponding features, the proposed technique uses the energy transient signal. This approach is more robust to noise and can cope with different modulation techniques. First, the normalized energy trajectory is generated from the energy-time-frequency distribution of the raw control signal. Next, the start and end points of the energy transient are detected by searching for the most abrupt changes in the mean of the energy trajectory. Then, a set of statistical features is extracted from the energy transient. Significant features are selected by performing neighborhood component analysis (NCA)to keep the computational cost of the algorithm low. Finally, selected features are fed to several machine learning algorithms for classification. The algorithms are evaluated experimentally using a database containing 100 RF signals from each of 14 different UAV controllers. The signals are recorded wirelessly using a high-frequency oscilloscope. The data set is randomly partitioned into training and test sets for validation with the ratio 4:1. Ten Monte Carlo simulations are run and results are averaged to assess the performance of the methods. All the micro-UAVs are detected correctly and an average accuracy of 96.3% is achieved using the k-nearest neighbor (kNN)classification. Proposed methods are also tested for different signal-to-noise ratio (SNR)levels and results are reported.","",""
26,"A. Peel, Florian Lalande, Jean-Luc Starck, V. Pettorino, J. Merten, C. Giocoli, M. Meneghetti, M. Baldi","Distinguishing standard and modified gravity cosmologies with machine learning",2018,"","","","",45,"2022-07-13 10:05:55","","10.1103/PhysRevD.100.023508","","",,,,,26,6.50,3,8,4,"We present a convolutional neural network to identify distinct cosmological scenarios based on the weak-lensing maps they produce. Modified gravity models with massive neutrinos can mimic the standard concordance model in terms of Gaussian weak-lensing observables, limiting a deeper understanding of what causes cosmic acceleration. We demonstrate that a network trained on simulated clean convergence maps, condensed into a novel representation, can discriminate between such degenerate models with 83%-100% accuracy. Our method outperforms conventional statistics by up to 40% and is more robust to noise.","",""
14,"Hao Peng, X. Bai","Comparative evaluation of three machine learning algorithms on improving orbit prediction accuracy",2019,"","","","",46,"2022-07-13 10:05:55","","10.1007/S42064-018-0055-4","","",,,,,14,4.67,7,2,3,"","",""
14,"Chengquan Zhou, Hongbao Ye, Zhifu Xu, Jun Hu, X. Shi, Shan Hua, Jibo Yue, Guijun Yang","Estimating Maize-Leaf Coverage in Field Conditions by Applying a Machine Learning Algorithm to UAV Remote Sensing Images",2019,"","","","",47,"2022-07-13 10:05:55","","10.3390/APP9112389","","",,,,,14,4.67,2,8,3,"Leaf coverage is an indicator of plant growth rate and predicted yield, and thus it is crucial to plant-breeding research. Robust image segmentation of leaf coverage from remote-sensing images acquired by unmanned aerial vehicles (UAVs) in varying environments can be directly used for large-scale coverage estimation, and is a key component of high-throughput field phenotyping. We thus propose an image-segmentation method based on machine learning to extract relatively accurate coverage information from the orthophoto generated after preprocessing. The image analysis pipeline, including dataset augmenting, removing background, classifier training and noise reduction, generates a set of binary masks to obtain leaf coverage from the image. We compare the proposed method with three conventional methods (Hue-Saturation-Value, edge-detection-based algorithm, random forest) and a frontier deep-learning method called DeepLabv3+. The proposed method improves indicators such as Qseg, Sr, Es and mIOU by 15% to 30%. The experimental results show that this approach is less limited by radiation conditions, and that the protocol can easily be implemented for extensive sampling at low cost. As a result, with the proposed method, we recommend using red-green-blue (RGB)-based technology in addition to conventional equipment for acquiring the leaf coverage of agricultural crops.","",""
21,"Andrew L. Miller, P. Astone, S. D’Antonio, S. Frasca, G. Intini, I. La Rosa, P. Leaci, S. Mastrogiovanni, F. Muciaccia, Andonis Mitidis, C. Palomba, O. Piccinni, A. Singhal, B. Whiting, L. Rei","How effective is machine learning to detect long transient gravitational waves from neutron stars in a real search?",2019,"","","","",48,"2022-07-13 10:05:55","","10.1103/PhysRevD.100.062005","","",,,,,21,7.00,2,15,3,"We present a comprehensive study of the effectiveness of Convolution Neural Networks (CNNs) to detect long duration transient gravitational-wave signals lasting $O(hours-days)$ from isolated neutron stars. We determine that CNNs are robust towards signal morphologies that differ from the training set, and they do not require many training injections/data to guarantee good detection efficiency and low false alarm probability. In fact, we only need to train one CNN on signal/noise maps in a single 150 Hz band; afterwards, the CNN can distinguish signals/noise well in any band, though with different efficiencies and false alarm probabilities due to the non-stationary noise in LIGO/Virgo. We demonstrate that we can control the false alarm probability for the CNNs by selecting the optimal threshold on the outputs of the CNN, which appears to be frequency dependent. Finally we compare the detection efficiencies of the networks to a well-established algorithm, the Generalized FrequencyHough (GFH), which maps curves in the time/frequency plane to lines in a plane that relates to the initial frequency/spindown of the source. The networks have similar sensitivities to the GFH but are orders of magnitude faster to run and can detect signals to which the GFH is blind. Using the results of our analysis, we propose strategies to apply CNNs to a real search using LIGO/Virgo data to overcome the obstacles that we would encounter, such as a finite amount of training data. We then use our networks and strategies to run a real search for a remnant of GW170817, making this the first time ever that a machine learning method has been applied to search for a gravitational wave signal from an isolated neutron star.","",""
30,"Zhao Zhang, Weiming Jiang, Fanzhang Li, Mingbo Zhao, Bing Li, Li Zhang","Structured Latent Label Consistent Dictionary Learning for Salient Machine Faults Representation-Based Robust Classification",2017,"","","","",49,"2022-07-13 10:05:55","","10.1109/TII.2017.2653184","","",,,,,30,6.00,5,6,5,"This paper investigates the salient machine faults representation-based classification issue by dictionary learning. A novel structured latent label consistent dictionary learning (LLC-DL) model is proposed for joint discriminative salient representation and classification. Our LLC-DL deals with the tasks by solving one objective function that aims to minimize the structured reconstruction error, structured discriminative sparse-code error and classification error simultaneously. Also, LLC-DL decomposes given signals into a sparse reconstruction part over structured latent weighted discriminative dictionary, a salient feature extraction part and an error part fitting noise. Specifically, the dictionary is learnt atom by atom, where each dictionary atom is learnt with a latent vector that reduces the disturbance between interclass atoms. The structured coding coefficients are calculated via minimizing the reconstruction error and discriminative sparse code error simultaneously. The salient representations are learnt by embedding signals onto a projection and a robust linear classifier is then trained over the learned salient features directly so that features can be ensured to be optimal for classification, where robust l2 ,1-norm imposed on the classifier can make the prediction results more accurate. By including a salient feature extraction term, the classification approach of LLC-DL is very efficient, since there is no need to involve an extra time-consuming sparse reconstruction process with the well-trained dictionary for each test signal. Extensive simulations versify the effectiveness of our algorithm.","",""
11,"P. Poudel, A. Illanes, E. Ataide, N. Esmaeili, Sathish Balakrishnan, M. Friebe","Thyroid Ultrasound Texture Classification Using Autoregressive Features in Conjunction With Machine Learning Approaches",2019,"","","","",50,"2022-07-13 10:05:55","","10.1109/ACCESS.2019.2923547","","",,,,,11,3.67,2,6,3,"The thyroid is one of the largest endocrine glands in the human body, which is involved in several body mechanisms like controlling protein synthesis, use of energy sources, and controlling the body’s sensitivity to other hormones. Thyroid segmentation and volume reconstruction are hence essential to diagnose thyroid related diseases as most of these diseases involve a change in the shape and size of the thyroid over time. Classification of thyroid texture is the first step toward the segmentation of the thyroid. The classification of texture in thyroid Ultrasound (US) images is not an easy task as it suffers from low image contrast, presence of speckle noise, and non-homogeneous texture distribution inside the thyroid region. Hence, a robust algorithmic approach is required to accurately classify thyroid texture. In this paper, we propose three machine learning based approaches: Support Vector Machine; Artificial Neural Network; and Random Forest Classifier to classify thyroid texture. The computation of features for training these classifiers is based on a novel approach recently proposed by our team, where autoregressive modeling was applied on a signal version of the 2D thyroid US images to compute 30 spectral energy-based features for classifying the thyroid and non-thyroid textures. Our approach differs from the methods proposed in the literature as they use image-based features to characterize thyroid tissues. We obtained an accuracy of around 90% with all the three methods.","",""
9,"Fulu Zheng, Xing Gao, A. Eisfeld","Excitonic Wave Function Reconstruction from Near-Field Spectra Using Machine Learning Techniques.",2019,"","","","",51,"2022-07-13 10:05:55","","10.1103/PhysRevLett.123.163202","","",,,,,9,3.00,3,3,3,"A general problem in quantum mechanics is the reconstruction of eigenstate wave functions from measured data. In the case of molecular aggregates, information about excitonic eigenstates is vitally important to understand their optical and transport properties. Here we show that from spatially resolved near field spectra it is possible to reconstruct the underlying delocalized aggregate eigenfunctions. Although this high-dimensional nonlinear problem defies standard numerical or analytical approaches, we have found that it can be solved using a convolutional neural network. For both one-dimensional and two-dimensional aggregates we find that the reconstruction is robust to various types of disorder and noise.","",""
2,"M. Mohamed, H. Gotzig, R. Zöllner, Patrick Mäder","A Machine Learning Approach for Detecting Ultrasonic Echoes in Noisy Environments",2019,"","","","",52,"2022-07-13 10:05:55","","10.1109/VTCSpring.2019.8746680","","",,,,,2,0.67,1,4,3,"In this paper we present a novel approach for using industrial grade ultrasonic sensors to perform echolocation by detecting ultrasonic echoes using machine learning. We show how this methodology is robust against the influence of ultrasonic noise sources in the environment as well as undesired reflections coming from the terrain. Several noise sources and noise powers are assessed as well as different terrain types. The results are benchmarked against the state of art energy thresholding and matched filters correlation algorithms clearly showing the superiority of the machine learning based approach.","",""
5,"Congcong Hu, R. Albertani","Machine learning applied to wind turbine blades impact detection",2020,"","","","",53,"2022-07-13 10:05:55","","10.1177/0309524X19849859","","",,,,,5,2.50,3,2,2,"The significant development of wind power generation worldwide brings, together with environmental benefits, wildlife concerns, especially for volant species vulnerability to interactions with wind energy facilities. For surveying such events, an automatic system for continuous monitoring of blade collisions is critical. An onboard multi-senor system capable of providing real-time collision detection using integrated vibration sensors is developed and successfully tested. However, to detect low signal-to-noise ratio impact can be challenging; hence, an advanced impact detection method has been developed and presented in this article. A robust automated detection algorithm based on support vector machine is proposed. After a preliminary signal pre-processing, geometric features specifically selected for their sensitivity to impact signals are extracted from raw vibration signal and energy distribution graph. The predictive model is formulated by training conventional support vector machine using extracted features for impact identification. Finally, the performance of the predictive model is evaluated by accuracy, precision, and recall. Results indicate a linear regression relationship between signal-to-noise ratio and model overall performance. The proposed method is much reliable on higher signal-to-noise ratio ( SNR ≥ 6 ) , but it shows to be ineffective at lower signal-to-noise ratio ( SNR < 2 ) .","",""
42,"Bo Han, Quanming Yao, Tongliang Liu, Gang Niu, I. Tsang, J. Kwok, M. Sugiyama","A Survey of Label-noise Representation Learning: Past, Present and Future",2020,"","","","",54,"2022-07-13 10:05:55","","","","",,,,,42,21.00,6,7,2,"Classical machine learning implicitly assumes that labels of the training data are sampled from a clean distribution, which can be too restrictive for real-world scenarios. However, statistical learning-based methods may not train deep learning models robustly with these noisy labels. Therefore, it is urgent to design Label-Noise Representation Learning (LNRL) methods for robustly training deep models with noisy labels. To fully understand LNRL, we conduct a survey study. We first clarify a formal definition for LNRL from the perspective of machine learning. Then, via the lens of learning theory and empirical study, we figure out why noisy labels affect deep models' performance. Based on the theoretical guidance, we categorize different LNRL methods into three directions. Under this unified taxonomy, we provide a thorough discussion of the pros and cons of different categories. More importantly, we summarize the essential components of robust LNRL, which can spark new directions. Lastly, we propose possible research directions within LNRL, such as new datasets, instance-dependent LNRL, and adversarial LNRL. Finally, we envision potential directions beyond LNRL, such as learning with feature-noise, preference-noise, domain-noise, similarity-noise, graph-noise, and demonstration-noise.","",""
9,"T. Lu, Yingjie Guan, Yanduo Zhang, Shenming Qu, Z. Xiong","Robust and efficient face recognition via low-rank supported extreme learning machine",2018,"","","","",55,"2022-07-13 10:05:55","","10.1007/s11042-017-5475-2","","",,,,,9,2.25,2,5,4,"","",""
7,"Yulei Wu","Robust Learning-Enabled Intelligence for the Internet of Things: A Survey From the Perspectives of Noisy Data and Adversarial Examples",2021,"","","","",56,"2022-07-13 10:05:55","","10.1109/JIOT.2020.3018691","","",,,,,7,7.00,7,1,1,"The Internet of Things (IoT) has been widely adopted in a range of verticals, e.g., automation, health, energy, and manufacturing. Many of the applications in these sectors, such as self-driving cars and remote surgery, are critical and high stakes applications, calling for advanced machine learning (ML) models for data analytics. Essentially, the training and testing data that are collected by massive IoT devices may contain noise (e.g., abnormal data, incorrect labels, and incomplete information) and adversarial examples. This requires high robustness of ML models to make reliable decisions for IoT applications. The research of robust ML has received tremendous attention from both academia and industry in recent years. This article will investigate the state of the art and representative works of robust ML models that can enable high resilience and reliability of IoT intelligence. Two aspects of robustness will be focused on, i.e., when the training data of ML models contain noises and adversarial examples, which may typically happen in many real-world IoT scenarios. In addition, the reliability of both neural networks and reinforcement learning framework will be investigated. Both of these two ML paradigms have been widely used in handling data in IoT scenarios. The potential research challenges and open issues will be discussed to provide future research directions.","",""
9,"Purvi Agrawal, S. Ganapathy","Unsupervised modulation filter learning for noise-robust speech recognition.",2017,"","","","",57,"2022-07-13 10:05:55","","10.1121/1.5001926","","",,,,,9,1.80,5,2,5,"The modulation filtering approach to robust automatic speech recognition (ASR) is based on enhancing perceptually relevant regions of the modulation spectrum while suppressing the regions susceptible to noise. In this paper, a data-driven unsupervised modulation filter learning scheme is proposed using convolutional restricted Boltzmann machine. The initial filter is learned using the speech spectrogram while subsequent filters are learned using residual spectrograms. The modulation filtered spectrograms are used for ASR experiments on noisy and reverberant speech where these features provide significant improvements over other robust features. Furthermore, the application of the proposed method for semi-supervised learning is investigated.","",""
183,"M. Zevin, S. Coughlin, S. Bahaadini, E. Besler, N. Rohani, S. Allen, M. Cabero, Kevin Crowston, A. Katsaggelos, S. Larson, T. K. Lee, C. Lintott, T. Littenberg, A. Lundgren, C. Østerlund, J R Smith, L. Trouille, V. Kalogera","Gravity Spy: integrating advanced LIGO detector characterization, machine learning, and citizen science.",2016,"","","","",58,"2022-07-13 10:05:55","","10.1088/1361-6382/aa5cea","","",,,,,183,30.50,18,18,6,"With the first direct detection of gravitational waves, the advanced laser interferometer gravitational-wave observatory (LIGO) has initiated a new field of astronomy by providing an alternative means of sensing the universe. The extreme sensitivity required to make such detections is achieved through exquisite isolation of all sensitive components of LIGO from non-gravitational-wave disturbances. Nonetheless, LIGO is still susceptible to a variety of instrumental and environmental sources of noise that contaminate the data. Of particular concern are noise features known as glitches, which are transient and non-Gaussian in their nature, and occur at a high enough rate so that accidental coincidence between the two LIGO detectors is non-negligible. Glitches come in a wide range of time-frequency-amplitude morphologies, with new morphologies appearing as the detector evolves. Since they can obscure or mimic true gravitational-wave signals, a robust characterization of glitches is paramount in the effort to achieve the gravitational-wave detection rates that are predicted by the design sensitivity of LIGO. This proves a daunting task for members of the LIGO Scientific Collaboration alone due to the sheer amount of data. In this paper we describe an innovative project that combines crowdsourcing with machine learning to aid in the challenging task of categorizing all of the glitches recorded by the LIGO detectors. Through the Zooniverse platform, we engage and recruit volunteers from the public to categorize images of time-frequency representations of glitches into pre-identified morphological classes and to discover new classes that appear as the detectors evolve. In addition, machine learning algorithms are used to categorize images after being trained on human-classified examples of the morphological classes. Leveraging the strengths of both classification methods, we create a combined method with the aim of improving the efficiency and accuracy of each individual classifier. The resulting classification and characterization should help LIGO scientists to identify causes of glitches and subsequently eliminate them from the data or the detector entirely, thereby improving the rate and accuracy of gravitational-wave observations. We demonstrate these methods using a small subset of data from LIGO's first observing run.","",""
14,"M. Singla, K. K. Shukla","Robust statistics-based support vector machine and its variants: a survey",2019,"","","","",59,"2022-07-13 10:05:55","","10.1007/s00521-019-04627-6","","",,,,,14,4.67,7,2,3,"","",""
17,"Hanrui Wang, Yongshan Ding, Jiaqi Gu, Yujun Lin, D. Pan, F. Chong, Song Han","QuantumNAS: Noise-Adaptive Search for Robust Quantum Circuits",2021,"","","","",60,"2022-07-13 10:05:55","","10.1109/HPCA53966.2022.00057","","",,,,,17,17.00,2,7,1,"Quantum noise is the key challenge in Noisy Intermediate-Scale Quantum (NISQ) computers. Previous work for mitigating noise has primarily focused on gate-level or pulse-level noise-adaptive compilation. However, limited research has explored a higher level of optimization by making the quantum circuits themselves resilient to noise.In this paper, we propose QuantumNAS, a comprehensive framework for noise-adaptive co-search of the variational circuit and qubit mapping. Variational quantum circuits are a promising approach for constructing quantum neural networks for machine learning and variational ansatzes for quantum simulation. However, finding the best variational circuit and its optimal parameters is challenging due to the large design space and parameter training cost. We propose to decouple the circuit search from parameter training by introducing a novel SuperCircuit. The SuperCircuit is constructed with multiple layers of pre-defined parameterized gates (e.g., U3 and CU3) and trained by iteratively sampling and updating the parameter subsets (SubCircuits) of it. It provides an accurate estimation of SubCircuits performance trained from scratch. Then we perform an evolutionary co-search of SubCircuit and its qubit mapping. The SubCircuit performance is estimated with parameters inherited from SuperCircuit and simulated with real device noise models. Finally, we perform iterative gate pruning and finetuning to remove redundant gates in a fine-grained manner.Extensively evaluated with 12 quantum machine learning (QML) and variational quantum eigensolver (VQE) benchmarks on 14 quantum computers, QuantumNAS significantly outperforms noise-unaware search, human, random, and existing noise-adaptive qubit mapping baselines. For QML tasks, QuantumNAS is the first to demonstrate over 95% 2-class, 85% 4-class, and 32% 10-class classification accuracy on real quantum computers. It also achieves the lowest eigenvalue for VQE tasks on H2, H2O, LiH, CH4, BeH2 compared with UCCSD baselines. We also open-source the TorchQuantum library for fast training of parameterized quantum circuits to facilitate future research.","",""
4,"Jicong Fan, Chengrun Yang, Madeleine Udell","Robust Non-Linear Matrix Factorization for Dictionary Learning, Denoising, and Clustering",2020,"","","","",61,"2022-07-13 10:05:55","","10.1109/TSP.2021.3062988","","",,,,,4,2.00,1,3,2,"Low dimensional nonlinear structure abounds in datasets across computer vision and machine learning. Kernelized matrix factorization techniques have recently been proposed to learn these nonlinear structures for denoising, classification, dictionary learning, and missing data imputation, by observing that the image of the matrix in a sufficiently large feature space is low-rank. However, these nonlinear methods fail in the presence of sparse noise or outliers. In this work, we propose a new robust nonlinear factorization method called Robust Non-Linear Matrix Factorization (RNLMF). RNLMF constructs a dictionary for the data space by factoring a kernelized feature space; a noisy matrix can then be decomposed as the sum of a sparse noise matrix and a clean data matrix that lies in a low dimensional nonlinear manifold. RNLMF is robust to sparse noise and outliers and scales to matrices with thousands of rows and columns. Empirically, RNLMF achieves noticeable improvements over baseline methods in denoising and clustering.","",""
4,"A. Seghouane, Navid Shokouhi","Adaptive Learning for Robust Radial Basis Function Networks",2019,"","","","",62,"2022-07-13 10:05:55","","10.1109/TCYB.2019.2951811","","",,,,,4,1.33,2,2,3,"This article addresses the robust estimation of the output layer linear parameters in a radial basis function network (RBFN). A prominent method used to estimate the output layer parameters in an RBFN with the predetermined hidden layer parameters is the least-squares estimation, which is the maximum-likelihood (ML) solution in the specific case of the Gaussian noise. We highlight the connection between the ML estimation and minimizing the Kullback–Leibler (KL) divergence between the actual noise distribution and the assumed Gaussian noise. Based on this connection, a method is proposed using a variant of a generalized KL divergence, which is known to be more robust to outliers in the pattern recognition and machine-learning problems. The proposed approach produces a surrogate-likelihood function, which is robust in the sense that it is adaptive to a broader class of noise distributions. Several signal processing experiments are conducted using artificially generated and real-world data. It is shown that in all cases, the proposed adaptive learning algorithm outperforms the standard approaches in terms of mean-squared error (MSE). Using the relative increase in the MSE for different noise conditions, we compare the robustness of our proposed algorithm with the existing methods for robust RBFN training and show that our method results in overall improvement in terms of absolute MSE values and consistency.","",""
5,"Sheng Liu, Zhihui Zhu, Qing Qu, Chong You","Robust Training under Label Noise by Over-parameterization",2022,"","","","",63,"2022-07-13 10:05:55","","","","",,,,,5,5.00,1,4,1,"Recently, over-parameterized deep networks, with increasingly more network parameters than training samples, have dominated the performances of modern machine learning. However, when the training data is corrupted, it has been well-known that over-parameterized networks tend to overfit and do not generalize. In this work, we propose a principled approach for robust training of over-parameterized deep networks in classification tasks where a proportion of training labels are corrupted. The main idea is yet very simple: label noise is sparse and incoherent with the network learned from clean data, so we model the noise and learn to separate it from the data. Specifically, we model the label noise via another sparse over-parameterization term, and exploit implicit algorithmic regularizations to recover and separate the underlying corruptions. Remarkably, when trained using such a simplemethod in practice, we demonstrate state-of-the-art test accuracy against label noise on a variety of real datasets. Furthermore, our experimental results are corroborated by theory on simplified linear models, showing that exact separation between sparse noise and low-rank data can be achieved under incoherent conditions. The work opens many interesting directions for improving over-parameterized models by using sparse over-parameterization and implicit regularization1.","",""
20,"L. Albergante, E. Mirkes, Huidong Chen, Alexis Martin, Louis Faure, E. Barillot, L. Pinello, Alexander N Gorban, A. Zinovyev","Robust and Scalable Learning of Complex Intrinsic Dataset Geometry via ElPiGraph",2018,"","","","",64,"2022-07-13 10:05:55","","10.3390/e22030296","","",,,,,20,5.00,2,9,4,"Multidimensional datapoint clouds representing large datasets are frequently characterized by non-trivial low-dimensional geometry and topology which can be recovered by unsupervised machine learning approaches, in particular, by principal graphs. Principal graphs approximate the multivariate data by a graph injected into the data space with some constraints imposed on the node mapping. Here we present ElPiGraph, a scalable and robust method for constructing principal graphs. ElPiGraph exploits and further develops the concept of elastic energy, the topological graph grammar approach, and a gradient descent-like optimization of the graph topology. The method is able to withstand high levels of noise and is capable of approximating data point clouds via principal graph ensembles. This strategy can be used to estimate the statistical significance of complex data features and to summarize them into a single consensus principal graph. ElPiGraph deals efficiently with large datasets in various fields such as biology, where it can be used for example with single-cell transcriptomic or epigenomic datasets to infer gene expression dynamics and recover differentiation landscapes.","",""
25,"H. Yoon, Jae-Hoon Sim, M. Han","Analytic continuation via domain knowledge free machine learning",2018,"","","","",65,"2022-07-13 10:05:55","","10.1103/PhysRevB.98.245101","","",,,,,25,6.25,8,3,4,"We present a machine-learning approach to a long-standing issue in quantum many-body physics, namely, analytic continuation. This notorious ill-conditioned problem of obtaining spectral function from an imaginary time Green's function has been a focus of new method developments for past decades. Here we demonstrate the usefulness of modern machine-learning techniques including convolutional neural networks and the variants of a stochastic gradient descent optimizer. The machine-learning continuation kernel is successfully realized without any ``domain knowledge,'' which means that any physical ``prior'' is not utilized in the kernel construction and the neural networks ``learn'' the knowledge solely from ``training.'' The outstanding performance is achieved for both insulating and metallic band structure. Our machine-learning-based approach not only provides the more accurate spectrum than the conventional methods in terms of peak positions and heights, but is also more robust against the noise which is the required key feature for any continuation technique to be successful. Furthermore, its computation speed is ${10}^{4}\text{--}{10}^{5}$ times faster than the maximum entropy method.","",""
33,"R. Trinchero, P. Manfredi, I. Stievano, F. Canavero","Machine Learning for the Performance Assessment of High-Speed Links",2018,"","","","",66,"2022-07-13 10:05:55","","10.1109/TEMC.2018.2797481","","",,,,,33,8.25,8,4,4,"This paper investigates the application of support vector machine to the modeling of high-speed interconnects with largely varying and/or highly uncertain design parameters. The proposed method relies on a robust and well-established mathematical framework, yielding accurate surrogates of complex dynamical systems. An identification procedure based on the observation of a small set of system responses allows generating compact parametric relations, which can be used for design optimization and/or stochastic analysis. The feasibility and strength of the method are demonstrated based on a benchmark function and on the statistical assessment of a realistic printed circuit board interconnect, highlighting the main features and benefits of this technique over state-of-the-art solutions. Emphasis is given to the effects of the initial sample size and of input noise on the model estimation.","",""
7,"Xiaokong Miao, Meng Sun, Xiongwei Zhang, Yimin Wang","Noise-Robust Voice Conversion Using High-Quefrency Boosting via Sub-Band Cepstrum Conversion and Fusion",2019,"","","","",67,"2022-07-13 10:05:55","","10.3390/app10010151","","",,,,,7,2.33,2,4,3,"This paper presents a noise-robust voice conversion method with high-quefrency boosting via sub-band cepstrum conversion and fusion based on the bidirectional long short-term memory (BLSTM) neural networks that can convert parameters of vocal tracks of a source speaker into those of a target speaker. With the implementation of state-of-the-art machine learning methods, voice conversion has achieved good performance given abundant clean training data. However, the quality and similarity of the converted voice are significantly degraded compared to that of a natural target voice due to various factors, such as limited training data and noisy input speech from the source speaker. To address the problem of noisy input speech, an architecture of voice conversion with statistical filtering and sub-band cepstrum conversion and fusion is introduced. The impact of noises on the converted voice is reduced by the accurate reconstruction of the sub-band cepstrum and the subsequent statistical filtering. By normalizing the mean and variance of the converted cepstrum to those of the target cepstrum in the training phase, a cepstrum filter was constructed to further improve the quality of the converted voice. The experimental results showed that the proposed method significantly improved the naturalness and similarity of the converted voice compared to the baselines, even with the noisy inputs of source speakers.","",""
8,"Yufei Han, Xiangliang Zhang","Robust Federated Training via Collaborative Machine Teaching using Trusted Instances",2019,"","","","",68,"2022-07-13 10:05:55","","","","",,,,,8,2.67,4,2,3,"Federated learning performs distributed model training using local data hosted by agents. It shares only model parameter updates for iterative aggregation at the server. Although it is privacy-preserving by design, federated learning is vulnerable to noise corruption of local agents, as demonstrated in the previous study on adversarial data poisoning threat against federated learning systems. Even a single noise-corrupted agent can bias the model training. In our work, we propose a collaborative and privacy-preserving machine teaching paradigm with multiple distributed teachers, to improve robustness of the federated training process against local data corruption. We assume that each local agent (teacher) have the resources to verify a small portions of trusted instances, which may not by itself be adequate for learning. In the proposed collaborative machine teaching method, these trusted instances guide the distributed agents to jointly select a compact while informative training subset from data hosted by their own. Simultaneously, the agents learn to add changes of limited magnitudes into the selected data instances, in order to improve the testing performances of the federally trained model despite of the training data corruption. Experiments on toy and real data demonstrate that our approach can identify training set bugs effectively and suggest appropriate changes to the labels. Our algorithm is a step toward trustworthy machine learning.","",""
4,"E. Murphy, Justice Amoh, Saaid H. Arshad, R. Halter, K. Odame","Noise-robust bioimpedance approach for cardiac output measurement.",2019,"","","","",69,"2022-07-13 10:05:55","","10.1088/1361-6579/ab0d45","","",,,,,4,1.33,1,5,3,"OBJECTIVE Congestive heart failure is a problem effecting millions of Americans. A continuous, non-invasive, telemonitoring device that can accurately monitor cardiac metrics could greatly help this population, reducing unnecessary hospitalizations and cost.   APPROACH Machine Learning (ML) algorithms trained on electrical-impedance tomography (EIT) data are presented for portable cardiac monitoring. The approach was validated on a simulated thorax and a measured tank experiment. A highly detailed 4D chest model (finite element method mesh and conductivity profiles) was developed utilizing the 4D XCAT phantom to provide realistic data. The ML algorithms were trained using databases that assumed the presence of poorly contacting electrodes without any assumptions of knowing which electrodes would be bad in the experiment. The trained ML algorithms were compared to EIT evaluated with and without removing bad electrodes.   MAIN RESULTS A regression Support Vector Machine (rSVM) and a Deep Neural Network (DNN) were found to be the most accurate and robust to poorly contacting electrodes while not needing to know which electrodes were in poor contact in the simulated and measured experiments, respectively.   SIGNIFICANCE Although, the ML algorithms are not always better than EIT (with bad electrodes removed), the comparable results without needing priori knowledge of which electrodes are bad is seen as a very promising feature. An evaluation of computational costs showed that the DNN required comparable computational to the other methods while requiring less memory, which could make the DNNs an attractive algorithm for a low-power, portable system. This work represents an important validation of the method using measured data, and model development, which is needed to apply this method on real clinical data. Additionally, the developed 4D simulated thorax model could be an important tool within the EIT community.","",""
77,"Hossein Hosseini, Baicen Xiao, R. Poovendran","Google's Cloud Vision API is Not Robust to Noise",2017,"","","","",70,"2022-07-13 10:05:55","","10.1109/ICMLA.2017.0-172","","",,,,,77,15.40,26,3,5,"Google has recently introduced the Cloud Vision API for image analysis. According to the demonstration website, the API ""quickly classifies images into thousands of categories, detects individual objects and faces within images, and finds and reads printed words contained within images."" It can be also used to ""detect different types of inappropriate content from adult to violent content."" In this paper, we evaluate the robustness of Google Cloud Vision API to input perturbation. In particular, we show that by adding sufficient noise to the image, the API generates completely different outputs for the noisy image, while a human observer would perceive its original content. We show that the attack is consistently successful, by performing extensive experiments on different image types, including natural images, images containing faces and images with texts. For instance, using images from ImageNet dataset, we found that adding an average of 14.25% impulse noise is enough to deceive the API. Our findings indicate the vulnerability of the API in adversarial environments. For example, an adversary can bypass an image filtering system by adding noise to inappropriate images. We then show that when a noise filter is applied on input images, the API generates mostly the same outputs for restored images as for original images. This observation suggests that cloud vision API can readily benefit from noise filtering, without the need for updating image analysis algorithms.","",""
9,"Thomas G. Fischer, C. Krauss, A. Treichel","Machine learning for time series forecasting - a simulation study",2018,"","","","",71,"2022-07-13 10:05:55","","","","",,,,,9,2.25,3,3,4,"We present a comprehensive simulation study to assess and compare the performance of popular machine learning algorithms for time series prediction tasks. Specifically, we consider the following algorithms: multilayer perceptron (MLP), logistic regression, naive Bayes, k-nearest neighbors, decision trees, random forests, and gradient-boosting trees. These models are applied to time series from eight data generating processes (DGPs) - reflecting different linear and nonlinear dependencies (base case). Additional complexity is introduced by adding discontinuities and varying degrees of noise. Our findings reveal that advanced machine learning models are capable of approximating the optimal forecast very closely in the base case, with nonlinear models in the lead across all DGPs - particularly the MLP. By contrast, logistic regression is remarkably robust in the presence of noise, thus yielding the most favorable accuracy metrics on raw data, prior to preprocessing. When introducing adequate preprocessing techniques, such as first differencing and local outlier factor, the picture is reversed, and the MLP as well as other nonlinear techniques once again become the modeling techniques of choice.","",""
9,"Wentao Mao, Di Zhang, Siyu Tian, Jiamei Tang","Robust Detection of Bearing Early Fault Based on Deep Transfer Learning",2020,"","","","",72,"2022-07-13 10:05:55","","10.3390/electronics9020323","","",,,,,9,4.50,2,4,2,"In recent years, machine learning techniques have been proven to be a promising tool for early fault detection of rolling bearings. In many actual applications, however, bearing whole-life data are not easy to be historically accumulated, while insufficient data may result in training a detection model that is not good enough. If utilizing the available data under different working conditions to facilitate model training, the data distribution of different bearings are usually quite different, which does not meet the precondition of i n d e p e n d e n t a n d i d e n t i c a l d i s t r i b u t i o n ( i . i . d ) and tends to cause performance reduction. In addition, disturbed by the unstable noise under complex conditions, most of the current detection methods are inclined to raise false alarms, so that the reliability of detection results needs to be improved. To solve these problems, a robust detection method for bearings early fault is proposed based on deep transfer learning. The method includes offline stage and online stage. In the offline stage, by introducing a deep auto-encoder network with domain adaptation, the distribution inconsistency of normal state data among different bearings can be weakened, then the common feature representation of the normal state is obtained. With the extracted common features, a new state assessment method based on the robust deep auto-encoder network is proposed to evaluate the boundary between normal state and early fault state in the low-rank feature space. By training a support vector machine classifier, the detection model is established. In the online stage, along with the data batch arriving sequentially, the features of target bearing are extracted using the common representation learnt in the offline stage, and online detection is conducted by feeding them into the SVM model. Experimental results on IEEE PHM Challenge 2012 bearing dataset and XJTU-SY dataset show that the proposed approach outperforms several state-of-the-art detection methods in terms of detection accuracy and false alarm rate.","",""
8,"L. C. Vankadara, U. V. Luxburg","Measures of distortion for machine learning",2018,"","","","",73,"2022-07-13 10:05:55","","","","",,,,,8,2.00,4,2,4,"Given data from a general metric space, one of the standard machine learning pipelines is to first embed the data into a Euclidean space and subsequently apply out of the box machine learning algorithms to analyze the data. The quality of such an embedding is typically described in terms of a distortion measure. In this paper, we show that many of the existing distortion measures behave in an undesired way, when considered from a machine learning point of view. We investigate desirable properties of distortion measures and formally prove that most of the existing measures fail to satisfy these properties. These theoretical findings are supported by simulations, which for example demonstrate that existing distortion measures are not robust to noise or outliers and cannot serve as good indicators for classification accuracy. As an alternative, we suggest a new measure of distortion, called $\sigma$-distortion. We can show both in theory and in experiments that it satisfies all desirable properties and is a better candidate to evaluate distortion in the context of machine learning.","",""
5,"D. Mislis, S. Pyrzas, K. Alsubai","TSARDI: a Machine Learning data rejection algorithm for transiting exoplanet light curves",2018,"","","","",74,"2022-07-13 10:05:55","","10.1093/mnras/sty2361","","",,,,,5,1.25,2,3,4,"We present TSARDI, an efficient rejection algorithm designed to improve the transit detection efficiency in data collected by large scale surveys. TSARDI is based on the Machine Learning clustering algorithm DBSCAN, and its purpose is to serve as a robust and adaptable filter aiming to identify unwanted noise points left over from data detrending processes. TSARDI is an unsupervised method, which can treat each light curve individually; there is no need of previous knowledge of any other field light curves. We conduct a simulated transit search by injecting planets on real data obtained by the QES project and show that TSARDI leads to an overall transit detection efficiency increase of $\sim$11\%, compared to results obtained from the same sample, but using a standard sigma-clip algorithm. For the brighter end of our sample (host star magnitude < 12), TSARDI achieves a detection efficiency of $\sim$80\% of injected planets. While our algorithm has been developed primarily for the field of exoplanets, it is easily adaptable and extendable for use in any time series.","",""
4,"M. Goedhart, E. Kampen, S. F. Armanini, C. C. Visser, Q. Chu","Machine Learning for Flapping Wing Flight Control",2018,"","","","",75,"2022-07-13 10:05:55","","10.2514/6.2018-2135","","",,,,,4,1.00,1,5,4,"Flight control of Flapping Wing Micro Air Vehicles is challenging, because of their complex dynamics and variability due to manufacturing inconsistencies. Machine Learning algorithms can be used to tackle these challenges. A Policy Gradient algorithm is used to tune the gains of a Proportional-Integral controller using Reinforcement Learning. A novel Classification Algorithm for Machine Learning control (CAML) is presented, which uses model identification and a neural network classifier to select from several predefined gain sets. The algorithms show comparable performance when considering variability only, but the Policy Gradient algorithm is more robust to noise, disturbances, nonlinearities and flapping motion. CAML seems to be promising for problems where no single gain set is available to stabilize the entire set of variable systems.","",""
4,"Sumia Abdulhussien Razooqi Al-Obaidi, Davood Zabihzadeh, Ali Salim Rasheed, R. Monsefi","Robust Metric Learning based on the Rescaled Hinge Loss",2019,"","","","",76,"2022-07-13 10:05:55","","10.1007/s13042-020-01137-z","","",,,,,4,1.33,1,4,3,"","",""
60,"Huaxia Wang, Chun-Nam Yu","A Direct Approach to Robust Deep Learning Using Adversarial Networks",2019,"","","","",77,"2022-07-13 10:05:55","","","","",,,,,60,20.00,30,2,3,"Deep neural networks have been shown to perform well in many classical machine learning problems, especially in image classification tasks. However, researchers have found that neural networks can be easily fooled, and they are surprisingly sensitive to small perturbations imperceptible to humans. Carefully crafted input images (adversarial examples) can force a well-trained neural network to provide arbitrary outputs. Including adversarial examples during training is a popular defense mechanism against adversarial attacks. In this paper we propose a new defensive mechanism under the generative adversarial network (GAN) framework. We model the adversarial noise using a generative network, trained jointly with a classification discriminative network as a minimax game. We show empirically that our adversarial network approach works well against black box attacks, with performance on par with state-of-art methods such as ensemble adversarial training and adversarial training with projected gradient descent.","",""
26,"Xiaolin Liang, Hao Zhang, Tingting Lv, T. Gulliver","Energy detector based TOA estimation for MMW systems using machine learning",2017,"","","","",78,"2022-07-13 10:05:55","","10.1007/s11235-016-0182-2","","",,,,,26,5.20,7,4,5,"","",""
92,"Rohit Punnoose, Pankaj Ajit","Prediction of Employee Turnover in Organizations using Machine Learning Algorithms A case for Extreme Gradient Boosting",2016,"","","","",79,"2022-07-13 10:05:55","","10.14569/IJARAI.2016.050904","","",,,,,92,15.33,46,2,6,"Employee turnover has been identified as a key issue for organizations because of its adverse impact on work place productivity and long term growth strategies. To solve this problem, organizations use machine learning techniques to predict employee turnover. Accurate predictions enable organizations to take action for retention or succession planning of employees. However, the data for this modeling problem comes from HR Information Systems (HRIS); these are typically under-funded compared to the Information Systems of other domains in the organization which are directly related to its priorities. This leads to the prevalence of noise in the data that renders predictive models prone to over-fitting and hence inaccurate. This is the key challenge that is the focus of this paper, and one that has not been addressed historically. The novel contribution of this paper is to explore the application of Extreme Gradient Boosting (XGBoost) technique which is more robust because of its regularization formulation. Data from the HRIS of a global retailer is used to compare XGBoost against six historically used supervised classifiers and demonstrate its significantly higher accuracy for predicting employee turnover. In this paper, the problem of employee turnover and the key machine learning algorithms that have been used to solve it are discussed. The novel contribution of this paper is to explore the application of extreme gradient boosting (XGBoost) as an improvement on these traditional algorithms, specifically in its ability to generalize on noise-ridden data which is prevalent in this domain. This is done by using data from the HRIS of a global retailer and treating the attrition problem as a classification task and modeling it using supervised techniques. The conclusion is reached by contrasting the superior accuracy of the XGBoost classifier against other techniques and explaining the reason for its superior performance. This paper is structured as follows. Section II gives a brief overview of the employee turnover problem, the importance of solving it, and the historical work done in terms of application of machine learning techniques to solve this problem. Section III explores the 7 different supervised techniques, including XGBoost, that this paper compares. Section IV outlines the experimental design in terms of the characteristics of the dataset, pre-processing, cross-validation, and the choice of metrics for accuracy comparison. Section V showcases the results of the study and its subsequent discussion. Section VI concludes the paper by recommending the XGBoost classifier for predicting turnover.","",""
7,"Siyuan Chen, Yuquan Meng, Haichuan Tang, Yin Tian, Niao He, Chenhui Shao","Robust Deep Learning-Based Diagnosis of Mixed Faults in Rotating Machinery",2020,"","","","",80,"2022-07-13 10:05:55","","10.1109/TMECH.2020.3007441","","",,,,,7,3.50,1,6,2,"Fault diagnosis for rolling elements in rotating machinery persistently receives high research interest due to the said machinery's prevalence in a broad range of applications. State-of-the-art methods in such setups focus on effective identification of faults that usually involve a single component while rejecting noise from limited sources. This article studies the data-based diagnosis of mixed faults coming from multiple components with an emphasis on model robustness against a wide spectrum of external perturbation. A dataset is collected on a rotor and bearing system by varying the levels and types of faults in both the rotor and bearing, which results in 48 machine health conditions. A duplet classifier is developed by combining two 1-D convolutional neural networks (CNNs) that are responsible for the diagnosis of the rotor and bearing faults, respectively. Experimental results show that the proposed classifier can reliably identify the onset and nature of mixed faults. In addition, one-vs-all classifiers are built using the features generated by the developed 1-D CNNs as predictors to recognize previously unlearned fault types. The effectiveness of such classifiers is demonstrated using data collected from four new fault types. Finally, the robustness and ability to reject external perturbation of the duplet classification model are analyzed using kernel density estimation. The code for the proposed classifiers is available at https://github.com/siyuanc2/machine-fault-diag.","",""
4,"Jungang Lou, Yunliang Jiang, Qing Shen, Ruiqin Wang, Zechao Li","Probabilistic Regularized Extreme Learning for Robust Modeling of Traffic Flow Forecasting.",2020,"","","","",81,"2022-07-13 10:05:55","","10.1109/TNNLS.2020.3027822","","",,,,,4,2.00,1,5,2,"The adaptive neurofuzzy inference system (ANFIS) is a structured multioutput learning machine that has been successfully adopted in learning problems without noise or outliers. However, it does not work well for learning problems with noise or outliers. High-accuracy real-time forecasting of traffic flow is extremely difficult due to the effect of noise or outliers from complex traffic conditions. In this study, a novel probabilistic learning system, probabilistic regularized extreme learning machine combined with ANFIS (probabilistic R-ELANFIS), is proposed to capture the correlations among traffic flow data and, thereby, improve the accuracy of traffic flow forecasting. The new learning system adopts a fantastic objective function that minimizes both the mean and the variance of the model bias. The results from an experiment based on real-world traffic flow data showed that, compared with some kernel-based approaches, neural network approaches, and conventional ANFIS learning systems, the proposed probabilistic R-ELANFIS achieves competitive performance in terms of forecasting ability and generalizability.","",""
3,"D. Tamada","Review: Noise and artifact reduction for MRI using deep learning",2020,"","","","",82,"2022-07-13 10:05:55","","","","",,,,,3,1.50,3,1,2,"For several years, numerous attempts have been made to reduce noise and artifacts in MRI. Although there have been many successful methods to address these problems, practical implementation for clinical images is still challenging because of its complicated mechanism. Recently, deep learning received considerable attention, emerging as a machine learning approach in delivering robust MR image processing. The purpose here is therefore to explore further and review noise and artifact reduction using deep learning for MRI.","",""
376,"Rui Zhao, Ruqiang Yan, Jinjiang Wang, K. Mao","Learning to Monitor Machine Health with Convolutional Bi-Directional LSTM Networks",2017,"","","","",83,"2022-07-13 10:05:55","","10.3390/s17020273","","",,,,,376,75.20,94,4,5,"In modern manufacturing systems and industries, more and more research efforts have been made in developing effective machine health monitoring systems. Among various machine health monitoring approaches, data-driven methods are gaining in popularity due to the development of advanced sensing and data analytic techniques. However, considering the noise, varying length and irregular sampling behind sensory data, this kind of sequential data cannot be fed into classification and regression models directly. Therefore, previous work focuses on feature extraction/fusion methods requiring expensive human labor and high quality expert knowledge. With the development of deep learning methods in the last few years, which redefine representation learning from raw data, a deep neural network structure named Convolutional Bi-directional Long Short-Term Memory networks (CBLSTM) has been designed here to address raw sensory data. CBLSTM firstly uses CNN to extract local features that are robust and informative from the sequential input. Then, bi-directional LSTM is introduced to encode temporal information. Long Short-Term Memory networks (LSTMs) are able to capture long-term dependencies and model sequential data, and the bi-directional structure enables the capture of past and future contexts. Stacked, fully-connected layers and the linear regression layer are built on top of bi-directional LSTMs to predict the target value. Here, a real-life tool wear test is introduced, and our proposed CBLSTM is able to predict the actual tool wear based on raw sensory data. The experimental results have shown that our model is able to outperform several state-of-the-art baseline methods.","",""
17,"Qunwei Li, B. Kailkhura, R. Goldhahn, P. Ray, P. Varshney","Robust Decentralized Learning Using ADMM With Unreliable Agents",2017,"","","","",84,"2022-07-13 10:05:55","","10.1109/tsp.2022.3178655","","",,,,,17,3.40,3,5,5,"Many signal processing and machine learning problems can be formulated as consensus optimization problems which can be solved efficiently via a cooperative multi-agent system. However, the agents in the system can be unreliable due to a variety of reasons: noise, faults and attacks. Providing erroneous updates leads the optimization process in a wrong direction, and degrades the performance of distributed machine learning algorithms. This paper considers the problem of decentralized learning using ADMM in the presence of unreliable agents. First, we rigorously analyze the effect of erroneous updates (in ADMM learning iterations) on the convergence behavior of the multi-agent system. We show that the algorithm linearly converges to a neighborhood of the optimal solution under certain conditions and characterize the neighborhood size analytically. Next, we provide guidelines for network design to achieve a faster convergence to the neighborhood. We also provide conditions on the erroneous updates for exact convergence to the optimal solution. Finally, to mitigate the influence of unreliable agents, we propose ROAD, a robust variant of ADMM, and show its resilience to unreliable agents with an exact convergence to the optimum.","",""
12,"E. Kurniawan, Zhiwei Lin, Sumei Sun","Machine Learning-Based Channel Classification and Its Application to IEEE 802.11ad Communications",2017,"","","","",85,"2022-07-13 10:05:55","","10.1109/GLOCOM.2017.8254052","","",,,,,12,2.40,4,3,5,"We study the application of machine learning to channel classification for identifying whether a channel belongs to the Line of Sight (LOS) or Non-Line of Sight (NLOS) classes. The machine learning approach is able to work on multiple features, resulting in a much more accurate pattern identification and classification performance. We show that even in the absence of channel estimation, it is possible to classify the channel using the received preamble sequence with machine learning. This allows quicker classification and it is robust to channel estimation error, which is favorable in the low Signal to Noise Ratio (SNR) regime. The scheme is evaluated for IEEE 802.11ad systems, but the concept is also applicable to other wireless systems in general.","",""
6,"Ana Luiza B. P. Barros, G. Barreto","Building a Robust Extreme Learning Machine for Classification in the Presence of Outliers",2013,"","","","",86,"2022-07-13 10:05:55","","10.1007/978-3-642-40846-5_59","","",,,,,6,0.67,3,2,9,"","",""
7,"Arnau Mata Llenas, Janne Riihijärvi, M. Petrova","Performance Evaluation of Machine Learning Based Signal Classification Using Statistical and Multiscale Entropy Features",2017,"","","","",87,"2022-07-13 10:05:55","","10.1109/WCNC.2017.7925865","","",,,,,7,1.40,2,3,5,"In this paper we study the performance of machine learning based signal classification approaches in realistic wireless environments. We focus in particular on impact of interference from modulated signals and influence of realistic wireless channel conditions on classification performance. For this we use both numerical simulations as well as software defined radio based implementations. We also propose to use additional time series statistics originating from complex systems research as features for the classifier, in addition to classical second and higher order statistics previously employed. Our results show that the extended feature set results in robust classification performance in wide variety of channel conditions, and also when significant modulated interference is present in addition to Gaussian noise.","",""
3,"John P. Lalor, Hao Wu, Tsendsuren Munkhdalai, Hong Yu","An Analysis of Machine Learning Intelligence",2017,"","","","",88,"2022-07-13 10:05:55","","","","",,,,,3,0.60,1,4,5,"Deep neural networks (DNNs) have set state of the art results in many machine learning and NLP tasks. However, we do not have a strong understanding of what DNN models learn. In this paper, we examine learning in DNNs through analysis of their outputs. We compare DNN performance directly to a human population, and use characteristics of individual data points such as difficulty to see how well models perform on easy and hard examples. We investigate how training size and the incorporation of noise affect a DNN’s ability to generalize and learn. Our experiments show that unlike traditional machine learning models (e.g., Naive Bayes, Decision Trees), DNNs exhibit human-like learning properties. As they are trained with more data, they are more able to distinguish between easy and difficult items, and performance on easy items improves at a higher rate than difficult items. We find that different DNN models exhibit different strengths in learning and are robust to noise in training data.","",""
30,"R. Rastogi, Sweta Sharma, S. Chandra","Robust Parametric Twin Support Vector Machine for Pattern Classification",2018,"","","","",89,"2022-07-13 10:05:55","","10.1007/s11063-017-9633-3","","",,,,,30,7.50,10,3,4,"","",""
4,"Yanchao Li, Yongli Wang, Junlong Zhou, Xiaohui Jiang","Robust Transductive Support Vector Machine for Multi-View Classification",2018,"","","","",90,"2022-07-13 10:05:55","","10.1142/S0218126618501852","","",,,,,4,1.00,1,4,4,"Semi-Supervised Learning (SSL) aims to improve the performance of models trained with a small set of labeled data and a large collection of unlabeled data. Learning multi-view representations from different perspectives of data has proved to be very effectively for improving generalization performance. However, existing semi-supervised multi-view learning methods tend to ignore the specific difficulty of different unlabeled examples, such as the outliers and noise, leading to error-prone classification. To address this problem, this paper proposes Robust Transductive Support Vector Machine (RTSVM) that introduces the margin distribution into TSVM, which is robust to the outliers and noise. Specifically, the first-order (margin mean) and second-order statistics (margin variance) are regularized into TSVM, which try to achieve strong generalization performance. Then, we impose a global similarity constraint between distinct RTSVMs each trained from one view of the data. Moreover, our algorithm runs with fast convergence by using concave–convex procedure. Finally, we validate our proposed method on a variety of multi-view datasets, and the experimental results demonstrate that our proposed algorithm is effective. By exploring large amount of unlabeled examples and being robust to the outliers and noise among different views, the generalization performance of our method show the superiority to single-view learning and other semi-supervised multi-view learning methods.","",""
9,"Lei Luo, J. Xu, Cheng Deng, Heng Huang","Robust Metric Learning on Grassmann Manifolds with Generalization Guarantees",2019,"","","","",91,"2022-07-13 10:05:55","","10.1609/AAAI.V33I01.33014480","","",,,,,9,3.00,2,4,3,"In recent research, metric learning methods have attracted increasing interests in machine learning community and have been applied to many applications. However, the existing metric learning methods usually use a fixed L2-norm to measure the distance between pairwise data samples in the projection space, which cannot provide an effective mechanism to automatically remove the noise that exist in data samples. To address this issue, we propose a new robust formulation of metric learning. Our new model constructs a projection from higher dimensional Grassmann manifold into the one in a relative low-dimensional with more discriminative capability, where the errors between sample points are considered as an MLE (maximum likelihood estimation)-like estimator. An efficient iteratively reweighted algorithm is derived to solve the proposed metric learning model. More importantly, we establish the generalization bounds for the proposed algorithm by utilizing the techniques of U-statistics. Experiments on six benchmark datasets clearly show that the proposed method achieves consistent improvements in discrimination accuracy, in comparison to state-of-the-art methods.","",""
12,"Shuang Wei, Dongqi Yang, Wenyu Zhang, Shuai Zhang","A Novel Noise-Adapted Two-Layer Ensemble Model for Credit Scoring Based on Backflow Learning",2019,"","","","",92,"2022-07-13 10:05:55","","10.1109/ACCESS.2019.2930332","","",,,,,12,4.00,3,4,3,"Recently, the machine learning method and artificial intelligence algorithm have become increasingly important in classification problems, such as credit scoring. Building an ensemble learning model that has been proven to be typically more accurate and robust than individual classifiers, it is an important information management task of commercial banks and loan lenders. In this paper, a novel noise-adapted two-layer ensemble model for credit scoring based on backflow learning is proposed, in which five widely used base classifiers, i.e., extreme gradient boosting, gradient boosting decision tree, support vector machine, random forest, and linear discriminant analysis, are integrated. To amplify the strength and diversity of the base classifiers, a new backflow learning approach is proposed so that the base classifiers will relearn the misclassified data point. A final predictive result is obtained by fusing the prediction of all base classifiers through two-layer ensemble modeling. In addition, considering that noise data are a major problem that aggravates the accuracy of a predictive model, a new noise adaption approach based on the isolation forest algorithm is proposed to address noise data. It first calculates the outlier score of each data point to detect the noise data that are subsequently boosted in the training set to form the noise-adapted training set. Three credit datasets from the UCI machine learning repository are tested to compare the performance of the proposed model with those of other benchmark models. The experimental results prove that our proposed model outperforms other models by demonstrating satisfactory improvement in various performance measures.","",""
12,"M. Niu, Vadim N. Smelyanskyi, P. Klimov, S. Boixo, R. Barends, J. Kelly, Yu Chen, K. Arya, B. Burkett, D. Bacon, Zijun Chen, B. Chiaro, R. Collins, A. Dunsworth, B. Foxen, A. Fowler, C. Gidney, M. Giustina, R. Graff, Trent Huang, E. Jeffrey, D. Landhuis, E. Lucero, A. Megrant, J. Mutus, X. Mi, O. Naaman, M. Neeley, C. Neill, C. Quintana, P. Roushan, J. Martinis, H. Neven","Learning Non-Markovian Quantum Noise from Moiré-Enhanced Swap Spectroscopy with Deep Evolutionary Algorithm",2019,"","","","",93,"2022-07-13 10:05:55","","","","",,,,,12,4.00,1,33,3,"Two-level-system (TLS) defects in amorphous dielectrics are a major source of noise and decoherence in solid-state qubits. Gate-dependent non-Markovian errors caused by TLS-qubit coupling are detrimental to fault-tolerant quantum computation and have not been rigorously treated in the existing literature. In this work, we derive the non-Markovian dynamics between TLS and qubits during a SWAP-like two-qubit gate and the associated average gate fidelity for frequency-tunable Transmon qubits. This gate dependent error model facilitates using qubits as sensors to simultaneously learn practical imperfections in both the qubit's environment and control waveforms. We combine the-state-of-art machine learning algorithm with Moir\'{e}-enhanced swap spectroscopy to achieve robust learning using noisy experimental data. Deep neural networks are used to represent the functional map from experimental data to TLS parameters and are trained through an evolutionary algorithm. Our method achieves the highest learning efficiency and robustness against experimental imperfections to-date, representing an important step towards in-situ quantum control optimization over environmental and control defects.","",""
8,"Kai Liu, Lodewijk Brand, Hua Wang, F. Nie","Learning Robust Distance Metric with Side Information via Ratio Minimization of Orthogonally Constrained L21-Norm Distances",2019,"","","","",94,"2022-07-13 10:05:55","","10.24963/ijcai.2019/417","","",,,,,8,2.67,2,4,3,"Metric Learning, which aims at learning a distance metric for a given data set, plays an important role in measuring the distance or similarity between data objects. Due to its broad usefulness, it has attracted a lot of interest in machine learning and related areas in the past few decades. This paper proposes to learn the distance metric from the side information in the forms of must-links and cannot-links. Given the pairwise constraints, our goal is to learn a Mahalanobis distance that minimizes the ratio of the distances of the data pairs in the must-links to those in the cannot-links. Different from many existing papers that use the traditional squared L2-norm distance, we develop a robust model that is less sensitive to data noise or outliers by using the not-squared L2-norm distance. In our objective, the orthonormal constraint is enforced to avoid degenerate solutions. To solve our objective, we have derived an efficient iterative solution algorithm. We have conducted extensive experiments, which demonstrated the superiority of our method over state-of-the-art.","",""
67,"Q. Miao, Ying Cao, Ge Xia, Maoguo Gong, Jiachen Liu, Jianfeng Song","RBoost: Label Noise-Robust Boosting Algorithm Based on a Nonconvex Loss Function and the Numerically Stable Base Learners",2016,"","","","",95,"2022-07-13 10:05:55","","10.1109/TNNLS.2015.2475750","","",,,,,67,11.17,11,6,6,"AdaBoost has attracted much attention in the machine learning community because of its excellent performance in combining weak classifiers into strong classifiers. However, AdaBoost tends to overfit to the noisy data in many applications. Accordingly, improving the antinoise ability of AdaBoost plays an important role in many applications. The sensitiveness to the noisy data of AdaBoost stems from the exponential loss function, which puts unrestricted penalties to the misclassified samples with very large margins. In this paper, we propose two boosting algorithms, referred to as RBoost1 and RBoost2, which are more robust to the noisy data compared with AdaBoost. RBoost1 and RBoost2 optimize a nonconvex loss function of the classification margin. Because the penalties to the misclassified samples are restricted to an amount less than one, RBoost1 and RBoost2 do not overfocus on the samples that are always misclassified by the previous base learners. Besides the loss function, at each boosting iteration, RBoost1 and RBoost2 use numerically stable ways to compute the base learners. These two improvements contribute to the robustness of the proposed algorithms to the noisy training and testing samples. Experimental results on the synthetic Gaussian data set, the UCI data sets, and a real malware behavior data set illustrate that the proposed RBoost1 and RBoost2 algorithms perform better when the training data sets contain noisy data.","",""
3,"Huang Yi-han","Extreme learning machine on robust estimation",2012,"","","","",96,"2022-07-13 10:05:55","","","","",,,,,3,0.30,3,1,10,"Extreme learning machine(ELM) is a kind of single-hidden layer feedforword neural networks(SLFNs).Comparing with traditional neural network algorithms,it is simpler in structure,with higher learning speed,and good generalization performance.The output-weight of ELM was calculated by LSE(least square estimation) method.However,LSE lack of robustness,the result would be seriously damaged when there were outliers in the training data.In order to solve this problem,this paper derived a novel approach based on M-estimators of extreme learning machine called RBELM.Simulation results indicate that the RBELM proposed can significantly robust against data noise and outliers.","",""
5,"Chen Bai, Meiling Zhou, Junwei Min, Shipei Dang, Xianghua Yu, Peng Zhang, Tong Peng, Baoli Yao","Robust contrast-transfer-function phase retrieval via flexible deep learning networks.",2019,"","","","",97,"2022-07-13 10:05:55","","10.1364/ol.44.005141","","",,,,,5,1.67,1,8,3,"By exploiting the total variation (TV) regularization scheme and the contrast transfer function (CTF), a phase map can be retrieved from single-distance coherent diffraction images via the sparsity of the investigated object. However, the CTF-TV phase retrieval algorithm often struggles in the presence of strong noise, since it is based on the traditional compressive sensing optimization problem. Here, convolutional neural networks, a powerful tool from machine learning, are used to regularize the CTF-based phase retrieval problems and improve the recovery performance. This proposed method, the CTF-Deep phase retrieval algorithm, was tested both via simulations and experiments. The results show that it is robust to noise and fast enough for high-resolution applications, such as in optical, x-ray, or terahertz imaging.","",""
4,"Francesco Cursi, Guang-Zhong Yang","A Novel Approach for Outlier Detection and Robust Sensory Data Model Learning",2019,"","","","",98,"2022-07-13 10:05:55","","10.1109/IROS40897.2019.8967653","","",,,,,4,1.33,2,2,3,"In the past few decades machine learning and data analysis have been having a huge growth and they have been applied in many different problems in the field of robotics. Data are usually the result of sensor measurements and, as such, they might be subjected to noise and outliers. The presence of outliers has a huge impact on modelling the acquired data, resulting in inappropriate models. In this work a novel approach for outlier detection and rejection for input/output mapping in regression problems is presented. The robustness of the method is shown both through simulated data for linear and nonlinear regression, and real sensory data. Despite being validated by using artificial neural networks, the method can be generalized to any other regression method.","",""
4,"Lan-Zhe Guo, Tao Han, Yu-Feng Li","Robust Semi-supervised Representation Learning for Graph-Structured Data",2019,"","","","",99,"2022-07-13 10:05:55","","10.1007/978-3-030-16142-2_11","","",,,,,4,1.33,1,3,3,"","",""
14,"Q. Yin, J. Kaur","Can Machine Learning Benefit Bandwidth Estimation at Ultra-high Speeds?",2016,"","","","",100,"2022-07-13 10:05:55","","10.1007/978-3-319-30505-9_30","","",,,,,14,2.33,7,2,6,"","",""
3,"Francesco Cursi, Guang-Zhong Yang","A Robust Regression Approach for Robot Model Learning",2019,"","","","",101,"2022-07-13 10:05:55","","","","",,,,,3,1.00,2,2,3,"Machine learning and data analysis have been used in many robotics fields, especially for modelling. Data are usually the result of sensor measurements and, as such, they might be subjected to noise and outliers. The presence of outliers has a huge impact on modelling the acquired data, resulting in inappropriate models. In this work a novel approach for outlier detection and rejection for input/output mapping in regression problems is presented. The robustness of the method is shown both through simulated data for linear and nonlinear regression, and real sensory data. Despite being validated by using artificial neural networks, the method can be generalized to any other regression method","",""
9,"H. Ge, Weiting Sun, Mingde Zhao, Yao Yao","Stacked Denoising Extreme Learning Machine Autoencoder Based on Graph Embedding for Feature Representation",2019,"","","","",102,"2022-07-13 10:05:55","","10.1109/ACCESS.2019.2894014","","",,,,,9,3.00,2,4,3,"Extreme learning machine is characterized by less training parameters, fast training speed, and strong generalization ability. It has been applied to obtain feature representations from the complex data in the tasks of data clustering or classification. In this paper, a graph embedding-based denoising extreme learning machine autoencoder (GDELM-AE) is proposed for capturing the structure of the inputs. Specifically, in GDELM-AE, a graph embedding framework that contains an intrinsic graph and a penalty graph constructed by local Fisher discrimination analysis is integrated into the autoencoder. So, it can exploit both local structure and global structure information in extreme learning machine (ELM) spaces. Further, we propose a stacked graph embedded denoising (SGD)-ELM by stacking several GDELM-AEs. The experimental results on several benchmarks validate that GDELM-AE can obtain efficient and robust feature representation of original data; moreover, the stacked GDELM-AE can obtain high-level and noise-robust representations. The comparative results with the state-of-the-art algorithms indicate that the proposed algorithm can obtain better accuracy as well as faster training speed.","",""
88,"V. Rodriguez-Galiano, M. Chica-Rivas","Evaluation of different machine learning methods for land cover mapping of a Mediterranean area using multi-seasonal Landsat images and Digital Terrain Models",2014,"","","","",103,"2022-07-13 10:05:55","","10.1080/17538947.2012.748848","","",,,,,88,11.00,44,2,8,"Land cover monitoring using digital Earth data requires robust classification methods that allow the accurate mapping of complex land cover categories. This paper discusses the crucial issues related to the application of different up-to-date machine learning classifiers: classification trees (CT), artificial neural networks (ANN), support vector machines (SVM) and random forest (RF). The analysis of the statistical significance of the differences between the performance of these algorithms, as well as sensitivity to data set size reduction and noise were also analysed. Landsat-5 Thematic Mapper data captured in European spring and summer were used with auxiliary variables derived from a digital terrain model to classify 14 different land cover categories in south Spain. Overall, statistically similar accuracies of over 91% were obtained for ANN, SVM and RF. However, the findings of this study show differences in the accuracy of the classifiers, being RF the most accurate classifier with a very simple parameterization. SVM, followed by RF, was the most robust classifier to noise and data reduction. Significant differences in their performances were only reached for thresholds of noise and data reduction greater than 20% (noise, SVM) and 25% (noise, RF), and 80% (reduction, SVM) and 50% (reduction, RF), respectively.","",""
301,"Zechao Li, J. Liu, Jinhui Tang, Hanqing Lu","Robust Structured Subspace Learning for Data Representation",2015,"","","","",104,"2022-07-13 10:05:55","","10.1109/TPAMI.2015.2400461","","",,,,,301,43.00,75,4,7,"To uncover an appropriate latent subspace for data representation, in this paper we propose a novel Robust Structured Subspace Learning (RSSL) algorithm by integrating image understanding and feature learning into a joint learning framework. The learned subspace is adopted as an intermediate space to reduce the semantic gap between the low-level visual features and the high-level semantics. To guarantee the subspace to be compact and discriminative, the intrinsic geometric structure of data, and the local and global structural consistencies over labels are exploited simultaneously in the proposed algorithm. Besides, we adopt the `2;1-norm for the formulations of loss function and regularization respectively to make our algorithm robust to the outliers and noise. An efficient algorithm is designed to solve the proposed optimization problem. It is noted that the proposed framework is a general one which can leverage several well-known algorithms as special cases and elucidate their intrinsic relationships. To validate the effectiveness of the proposed method, extensive experiments are conducted on diversity datasets for different image understanding tasks, i.e., image tagging, clustering, and classification, and the more encouraging results are achieved compared with some state-of-the-art approaches.","",""
381,"Maximilian Nickel, Volker Tresp, H. Kriegel","Factorizing YAGO: scalable machine learning for linked data",2012,"","","","",105,"2022-07-13 10:05:55","","10.1145/2187836.2187874","","",,,,,381,38.10,127,3,10,"Vast amounts of structured information have been published in the Semantic Web's Linked Open Data (LOD) cloud and their size is still growing rapidly. Yet, access to this information via reasoning and querying is sometimes difficult, due to LOD's size, partial data inconsistencies and inherent noisiness. Machine Learning offers an alternative approach to exploiting LOD's data with the advantages that Machine Learning algorithms are typically robust to both noise and data inconsistencies and are able to efficiently utilize non-deterministic dependencies in the data. From a Machine Learning point of view, LOD is challenging due to its relational nature and its scale. Here, we present an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting of millions of entities, hundreds of relations and billions of known facts. Furthermore, we show how ontological knowledge can be incorporated in the factorization to improve learning results and how computation can be distributed across multiple nodes. We demonstrate that our approach is able to factorize the YAGO~2 core ontology and globally predict statements for this large knowledge base using a single dual-core desktop computer. Furthermore, we show experimentally that our approach achieves good results in several relational learning tasks that are relevant to Linked Data. Once a factorization has been computed, our model is able to predict efficiently, and without any additional training, the likelihood of any of the 4.3 ⋅ 1014 possible triples in the YAGO~2 core ontology.","",""
302,"N. Lane, Petko Georgiev, Lorena Qendro","DeepEar: robust smartphone audio sensing in unconstrained acoustic environments using deep learning",2015,"","","","",106,"2022-07-13 10:05:55","","10.1145/2750858.2804262","","",,,,,302,43.14,101,3,7,"Microphones are remarkably powerful sensors of human behavior and context. However, audio sensing is highly susceptible to wild fluctuations in accuracy when used in diverse acoustic environments (such as, bedrooms, vehicles, or cafes), that users encounter on a daily basis. Towards addressing this challenge, we turn to the field of deep learning; an area of machine learning that has radically changed related audio modeling domains like speech recognition. In this paper, we present DeepEar -- the first mobile audio sensing framework built from coupled Deep Neural Networks (DNNs) that simultaneously perform common audio sensing tasks. We train DeepEar with a large-scale dataset including unlabeled data from 168 place visits. The resulting learned model, involving 2.3M parameters, enables DeepEar to significantly increase inference robustness to background noise beyond conventional approaches present in mobile devices. Finally, we show DeepEar is feasible for smartphones by building a cloud-free DSP-based prototype that runs continuously, using only 6% of the smartphone's battery daily.","",""
69,"Min Du, R. Jia, D. Song","Robust Anomaly Detection and Backdoor Attack Detection Via Differential Privacy",2019,"","","","",107,"2022-07-13 10:05:55","","","","",,,,,69,23.00,23,3,3,"Outlier detection and novelty detection are two important topics for anomaly detection. Suppose the majority of a dataset are drawn from a certain distribution, outlier detection and novelty detection both aim to detect data samples that do not fit the distribution. Outliers refer to data samples within this dataset, while novelties refer to new samples. In the meantime, backdoor poisoning attacks for machine learning models are achieved through injecting poisoning samples into the training dataset, which could be regarded as ""outliers"" that are intentionally added by attackers. Differential privacy has been proposed to avoid leaking any individual's information, when aggregated analysis is performed on a given dataset. It is typically achieved by adding random noise, either directly to the input dataset, or to intermediate results of the aggregation mechanism. In this paper, we demonstrate that applying differential privacy can improve the utility of outlier detection and novelty detection, with an extension to detect poisoning samples in backdoor attacks. We first present a theoretical analysis on how differential privacy helps with the detection, and then conduct extensive experiments to validate the effectiveness of differential privacy in improving outlier detection, novelty detection, and backdoor attack detection.","",""
6,"R. Pires, D. F. S. Santos, Luis A. M. Pereira, G. Souza, A. Levada, J. Papa","A Robust Restricted Boltzmann Machine for Binary Image Denoising",2017,"","","","",108,"2022-07-13 10:05:55","","10.1109/SIBGRAPI.2017.58","","",,,,,6,1.20,1,6,5,"During the image acquisition process, some level of noise is usually added to the real data mainly due to physical limitations of the acquisition sensor, and also regarding imprecisions during the data transmission and manipulation. Therefore, the resultant image needs to be processed in order to attenuate its noise without loosing details. Machine learning approaches have been successfully used for image denoising. Among such approaches, Restricted Boltzmann Machine (RBM) is one of the most used technique for this purpose. Here, we propose to enhance the RBM performance on image denoising by adding a posterior supervision before its final denoising step. To this purpose, we propose a simple but effective approach that performs a fine-tuning in the RBM model. Experiments on public datasets corrupted by different levels of Gaussian noise support the effectiveness of the proposed approach with respect to some state-of-the-art image denoising approaches.","",""
65,"Ryan LaRose, Brian Coyle","Robust data encodings for quantum classifiers",2020,"","","","",109,"2022-07-13 10:05:55","","10.1103/PHYSREVA.102.032420","","",,,,,65,32.50,33,2,2,"Data representation is crucial for the success of machine learning models. In the context of quantum machine learning with near-term quantum computers, equally important considerations of how to efficiently input (encode) data and effectively deal with noise arise. In this work, we study data encodings for binary quantum classification and investigate their properties both with and without noise. For the common classifier we consider, we show that encodings determine the classes of learnable decision boundaries as well as the set of points which retain the same classification in the presence of noise. After defining the notion of a robust data encoding, we prove several results on robustness for different channels, discuss the existence of robust encodings, and prove an upper bound on the number of robust points in terms of fidelities between noisy and noiseless states. Numerical results for several example implementations are provided to reinforce our findings.","",""
37,"Tianwei Yu, Dean P. Jones","Improving peak detection in high-resolution LC/MS metabolomics data using preexisting knowledge and machine learning approach",2014,"","","","",110,"2022-07-13 10:05:55","","10.1093/bioinformatics/btu430","","",,,,,37,4.63,19,2,8,"MOTIVATION Peak detection is a key step in the preprocessing of untargeted metabolomics data generated from high-resolution liquid chromatography-mass spectrometry (LC/MS). The common practice is to use filters with predetermined parameters to select peaks in the LC/MS profile. This rigid approach can cause suboptimal performance when the choice of peak model and parameters do not suit the data characteristics.   RESULTS Here we present a method that learns directly from various data features of the extracted ion chromatograms (EICs) to differentiate between true peak regions from noise regions in the LC/MS profile. It utilizes the knowledge of known metabolites, as well as robust machine learning approaches. Unlike currently available methods, this new approach does not assume a parametric peak shape model and allows maximum flexibility. We demonstrate the superiority of the new approach using real data. Because matching to known metabolites entails uncertainties and cannot be considered a gold standard, we also developed a probabilistic receiver-operating characteristic (pROC) approach that can incorporate uncertainties.   AVAILABILITY AND IMPLEMENTATION The new peak detection approach is implemented as part of the apLCMS package available at http://web1.sph.emory.edu/apLCMS/ CONTACT: tyu8@emory.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.","",""
6,"J. Yousafzai, M. Ager, Z. Cvetković, Peter Sollich","Discriminative and generative machine learning approaches towards robust phoneme classification",2008,"","","","",111,"2022-07-13 10:05:55","","10.1109/ITA.2008.4601091","","",,,,,6,0.43,2,4,14,"Robustness of classification of isolated phoneme segments using discriminative and generative classifiers is investigated for the acoustic waveform and PLP speech representations. The two approaches used are support vector machines (SVMs) and mixtures of probabilistic PCA (MPPCA). While recognition in the PLP domain attains superb accuracy on clean data, it is significantly affected by mismatch between training and test noise levels. Classification in the high-dimensional acoustic waveform domain, on the other hand, is more robust in the presence of additive white Gaussian noise. We also show some results on the effects of custom-designed kernel functions for SVM classification in the acoustic waveform domain.","",""
19,"Jared Frank, U. Rebbapragada, J. Bialas, T. Oommen, T. Havens","Effect of Label Noise on the Machine-Learned Classification of Earthquake Damage",2017,"","","","",112,"2022-07-13 10:05:55","","10.3390/rs9080803","","",,,,,19,3.80,4,5,5,"Automated classification of earthquake damage in remotely-sensed imagery using machine learning techniques depends on training data, or data examples that are labeled correctly by a human expert as containing damage or not. Mislabeled training data are a major source of classifier error due to the use of imprecise digital labeling tools and crowdsourced volunteers who are not adequately trained on or invested in the task. The spatial nature of remote sensing classification leads to the consistent mislabeling of classes that occur in close proximity to rubble, which is a major byproduct of earthquake damage in urban areas. In this study, we look at how mislabeled training data, or label noise, impact the quality of rubble classifiers operating on high-resolution remotely-sensed images. We first study how label noise dependent on geospatial proximity, or geospatial label noise, compares to standard random noise. Our study shows that classifiers that are robust to random noise are more susceptible to geospatial label noise. We then compare the effects of label noise on both pixel- and object-based remote sensing classification paradigms. While object-based classifiers are known to outperform their pixel-based counterparts, this study demonstrates that they are more susceptible to geospatial label noise. We also introduce a new labeling tool to enhance precision and image coverage. This work has important implications for the Sendai framework as autonomous damage classification will ensure rapid disaster assessment and contribute to the minimization of disaster risk.","",""
10,"K. Kasper, L. Mathelin, H. Abou-Kandil","A machine learning approach for constrained sensor placement",2015,"","","","",113,"2022-07-13 10:05:55","","10.1109/ACC.2015.7172034","","",,,,,10,1.43,3,3,7,"Sensor placement is of pivotal importance in closed-loop control as measurements are key to design the control laws. In this article, a novel machine learning-based sensor placement algorithm is proposed in order to recover a high-dimensional field from a limited amount of local measurements with a linear estimator. Unlike many other methods, our algorithm does not rely on a reduced order model and achieves good results even with a small number of sensors. In many situations, sensors cannot be placed arbitrarily, either because of their geometry or because of the environment they are in. Our algorithm naturally accounts for these constraints as well as being robust to noise. Its performance is illustrated on a fluid flow example and compared to two state of the art methods, Effective Independence and FrameSense, on the recovery of the pressure field from limited noisy pressure measurements.","",""
33,"I. McLoughlin, Haomin Zhang, Zhipeng Xie, Yan Song, Wei Xiao, Huy Phan","Continuous robust sound event classification using time-frequency features and deep learning",2017,"","","","",114,"2022-07-13 10:05:55","","10.1371/journal.pone.0182309","","",,,,,33,6.60,6,6,5,"The automatic detection and recognition of sound events by computers is a requirement for a number of emerging sensing and human computer interaction technologies. Recent advances in this field have been achieved by machine learning classifiers working in conjunction with time-frequency feature representations. This combination has achieved excellent accuracy for classification of discrete sounds. The ability to recognise sounds under real-world noisy conditions, called robust sound event classification, is an especially challenging task that has attracted recent research attention. Another aspect of real-word conditions is the classification of continuous, occluded or overlapping sounds, rather than classification of short isolated sound recordings. This paper addresses the classification of noise-corrupted, occluded, overlapped, continuous sound recordings. It first proposes a standard evaluation task for such sounds based upon a common existing method for evaluating isolated sound classification. It then benchmarks several high performing isolated sound classifiers to operate with continuous sound data by incorporating an energy-based event detection front end. Results are reported for each tested system using the new task, to provide the first analysis of their performance for continuous sound event detection. In addition it proposes and evaluates a novel Bayesian-inspired front end for the segmentation and detection of continuous sound recordings prior to classification.","",""
309,"Alvaro Sanchez-Gonzalez, Jonathan Godwin, T. Pfaff, Rex Ying, J. Leskovec, P. Battaglia","Learning to Simulate Complex Physics with Graph Networks",2020,"","","","",115,"2022-07-13 10:05:55","","","","",,,,,309,154.50,52,6,2,"Here we present a machine learning framework and model implementation that can learn to simulate a wide variety of challenging physical domains, involving fluids, rigid solids, and deformable materials interacting with one another. Our framework---which we term ""Graph Network-based Simulators"" (GNS)---represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our GNS framework advances the state-of-the-art in learned physical simulation, and holds promise for solving a wide range of complex forward and inverse problems.","",""
39,"Tassadaq Hussain, S. M. Siniscalchi, Chi-Chun Lee, Syu-Siang Wang, Yu Tsao, W. Liao","Experimental Study on Extreme Learning Machine Applications for Speech Enhancement",2017,"","","","",116,"2022-07-13 10:05:55","","10.1109/ACCESS.2017.2766675","","",,,,,39,7.80,7,6,5,"In wireless telephony and audio data mining applications, it is desirable that noise suppression can be made robust against changing noise conditions and operates in real time (or faster). The learning effectiveness and speed of artificial neural networks are therefore critical factors in applications for speech enhancement tasks. To address these issues, we present an extreme learning machine (ELM) framework, aimed at the effective and fast removal of background noise from a single-channel speech signal, based on a set of randomly chosen hidden units and analytically determined output weights. Because feature learning with shallow ELM may not be effective for natural signals, such as speech, even with a large number of hidden nodes, hierarchical ELM (H-ELM) architectures are deployed by leveraging sparse auto-encoders. In this manner, we not only keep all the advantages of deep models in approximating complicated functions and maintaining strong regression capabilities, but we also overcome the cumbersome and time-consuming features of both greedy layer-wise pre-training and back-propagation (BP)-based fine tuning schemes, which are typically adopted for training deep neural architectures. The proposed ELM framework was evaluated on the Aurora–4 speech database. The Aurora–4 task provides relatively limited training data, and test speech data corrupted with both additive noise and convolutive distortions for matched and mismatched channels and signal-to-noise ratio (SNR) conditions. In addition, the task includes a subset of testing data involving noise types and SNR levels that are not seen in the training data. The experimental results indicate that when the amount of training data is limited, both ELM- and H-ELM-based speech enhancement techniques consistently outperform the conventional BP-based shallow and deep learning algorithms, in terms of standardized objective evaluations, under various testing conditions.","",""
5,"Zhuo Ren, Liming Yang","Robust Extreme Learning Machines with Different Loss Functions",2018,"","","","",117,"2022-07-13 10:05:55","","10.1007/s11063-018-9890-9","","",,,,,5,1.25,3,2,4,"","",""
4,"Fátima A. Saiz, Ismael Serrano, Iñigo Barandiaran, Jairo R. Sánchez","A Robust and Fast Deep Learning-Based Method for Defect Classification in Steel Surfaces",2018,"","","","",118,"2022-07-13 10:05:55","","10.1109/IS.2018.8710501","","",,,,,4,1.00,1,4,4,"The final product quality control is critical for any manufacturing process. In the case of steel products, there are different inspection methods that are able to classify the defects, but they usually require human intervention. In this context, a deep learning-based automatic defect classifier method for steel surfaces is proposed. The method combines some traditional Machine Learning techniques with a Convolutional Neural Network (CNN). Different experiments were carried out in order to obtain the best classifier parameter setup. To verily the robustness of the classifier some additional experiments were done, obtaining high classification rate against some sources of noise such as illumination changes or occlusions. The proposed method achieves a classification rate of 99.95% taking 0.019 seconds to classify a single image. The method is compared with seventeen related methods and outperforms them on a publicly available dataset, with six types of defects and 300 samples for each class. The source code of the proposed method is publicly available.","",""
4,"Ximing Li, Yang Wang, Zhao Zhang, Richang Hong, Zhuo Li, Meng Wang","RMoR-Aion: Robust Multioutput Regression by Simultaneously Alleviating Input and Output Noises",2020,"","","","",119,"2022-07-13 10:05:55","","10.1109/TNNLS.2020.2984635","","",,,,,4,2.00,1,6,2,"Multioutput regression, referring to simultaneously predicting multiple continuous output variables with a single model, has drawn increasing attention in the machine learning community due to its strong ability to capture the correlations among multioutput variables. The methodology of output space embedding, built upon the low-rank assumption, is now the mainstream for multioutput regression since it can effectively reduce the parameter numbers while achieving effective performance. The existing low-rank methods, however, are sensitive to the noises of both inputs and outputs, referring to the noise problem. In this article, we develop a novel multioutput regression method by simultaneously alleviating input and output noises, namely, robust multioutput regression by alleviating input and output noises (RMoR-Aion), where both the noises of the input and output are exploited by leveraging auxiliary matrices. Furthermore, we propose a prediction output manifold constraint with the correlation information regarding the output variables to further reduce the adversarial effects of the noise. Our empirical studies demonstrate the effectiveness of RMoR-Aion compared with the state-of-the-art baseline methods, and RMoR-Aion is more stable in the settings with artificial noise.","",""
20,"Shichao Pei, Lu Yu, Guoxian Yu, Xiangliang Zhang","REA: Robust Cross-lingual Entity Alignment Between Knowledge Graphs",2020,"","","","",120,"2022-07-13 10:05:55","","10.1145/3394486.3403268","","",,,,,20,10.00,5,4,2,"Cross-lingual entity alignment aims at associating semantically similar entities in knowledge graphs with different languages. It has been an essential research problem for knowledge integration and knowledge graph connection, and been studied with supervised or semi-supervised machine learning methods with the assumption of clean labeled data. However, labels from human annotations often include errors, which can largely affect the alignment results. We thus aim to formulate and explore the robust entity alignment problem, which is non-trivial, due to the deficiency of noisy labels. Our proposed method named REA (Robust Entity Alignment) consists of two components: noise detection and noise-aware entity alignment. The noise detection is designed by following the adversarial training principle. The noise-aware entity alignment is devised by leveraging graph neural network based knowledge graph encoder as the core. In order to mutually boost the performance of the two components, we propose a unified reinforced training strategy to combine them. To evaluate our REA method, we conduct extensive experiments on several real-world datasets. The experimental results demonstrate the effectiveness of our proposed method and also show that our model consistently outperforms the state-of-the-art methods with significant improvement on alignment accuracy in the noise-involved scenario.","",""
11,"Changhyeok Lee, Sanjay Mehrotra","A Distributionally-robust approach for finding support vector machine",2015,"","","","",121,"2022-07-13 10:05:55","","","","",,,,,11,1.57,6,2,7,"The classical SVM is an optimization problem minimizing the hinge losses of mis-classified samples with the regularization term. When the sample size is small or data has noise, it is possible that the classifier obtained with training data may not generalize well to population, since the samples may not accurately represent the true population distribution. We propose a distributionally-robust framework for Support Vector Machines (DR-SVMs). We build an ambiguity set for the population distribution based on samples using the Kantorovich metric. DR-SVMs search the classifier that minimizes the sum of regularization term and the hinge loss function for the worst-case population distribution among the ambiguity set. We provide semi-infinite programming formulation of the DR-SVMs and propose a cutting-plane algorithm to solve the problem. Computational results on simulated data and real data from University of California, Irvine Machine Learning Repository show that the DR-SVMs outperform the SVMs in terms of the Area Under Curve (AUC) measures on several test problems.","",""
12,"Sweta Sharma, R. Rastogi, S. Chandra","Large-Scale Twin Parametric Support Vector Machine Using Pinball Loss Function",2021,"","","","",122,"2022-07-13 10:05:55","","10.1109/TSMC.2019.2896642","","",,,,,12,12.00,4,3,1,"Traditional hinge loss function-based large-scale support vector machine (SVM) algorithms tend to perform poorly in the presence of noise, especially when the model is trained incrementally. In this paper, we propose an efficient stochastic quasi-Newton method-based twin parametric SVM using the pinball loss function (termed as SQN-PTWSVM), which is efficient and more robust to the presence of noise when compared to conventional hinge loss SVM for large-scale data scenarios. To establish the theoretical convergence of the method, a modified version of SQN-PTWSVM, termed as SQN-SPTWSVM, has also been proposed. It overcomes the poor convergence issue faced by stochastic gradient twin SVM thus resulting in a faster and reliable model. In SQN-SPTWSVM, the hyperplanes obtained are stable enough to handle noise and resampling issues that occur frequently in stochastic learning scenarios, leading to better generalization ability of the classifier. The proposed method has been extended to nonlinear scenarios as well. Moreover, batch versions of the proposed algorithms have also been introduced which significantly reduce the training time and memory requirement of SQN-PTWSVM and SQN-SPTWSVM. The experimental results on several benchmark datasets and activity recognition applications have shown that the performance of our method is better than the existing classifiers in terms of speed and accuracy.","",""
22,"T. Pereira, Kais Gadhoumi, Mitchell Ma, Xiuyun Liu, Ran Xiao, Rene Colorado, Kevin J. Keenan, K. Meisel, Xiao Hu","A Supervised Approach to Robust Photoplethysmography Quality Assessment",2020,"","","","",123,"2022-07-13 10:05:55","","10.1109/JBHI.2019.2909065","","",,,,,22,11.00,2,9,2,"Early detection of Atrial Fibrillation (AFib) is crucial to prevent stroke recurrence. New tools for monitoring cardiac rhythm are important for risk stratification and stroke prevention. As many of new approaches to long-term AFib detection are now based on photoplethysmogram (PPG) recordings from wearable devices, ensuring high PPG signal-to-noise ratios is a fundamental requirement for a robust detection of AFib episodes. Traditionally, signal quality assessment is often based on the evaluation of similarity between pulses to derive signal quality indices. There are limitations to using this approach for accurate assessment of PPG quality in the presence of arrhythmia, as in the case of AFib, mainly due to substantial changes in pulse morphology. In this paper, we first tested the performance of algorithms selected from a body of studies on PPG quality assessment using a dataset of PPG recordings from patients with AFib. We then propose machine learning approaches for PPG quality assessment in 30-s segments of PPG recording from 13 stroke patients admitted to the University of California San Francisco (UCSF) neuro intensive care unit and another dataset of 3764 patients from one of the five UCSF general intensive care units. We used data acquired from two systems, fingertip PPG (fPPG) from a bedside monitor system, and radial PPG (rPPG) measured using a wearable commercial wristband. We compared various supervised machine learning techniques including k-nearest neighbors, decisions trees, and a two-class support vector machine (SVM). SVM provided the best performance. fPPG signals were used to build the model and achieved 0.9477 accuracy when tested on the data from the fPPG exclusive to the test set, and 0.9589 accuracy when tested on the rPPG data.","",""
5,"Parashjyoti Borah, D. Gupta","Robust twin bounded support vector machines for outliers and imbalanced data",2021,"","","","",124,"2022-07-13 10:05:55","","10.1007/S10489-020-01847-5","","",,,,,5,5.00,3,2,1,"","",""
6,"Olivier Deiss, S. Biswal, Jing Jin, Haoqi Sun, M. Westover, Jimeng Sun","HAMLET: Interpretable Human And Machine co-LEarning Technique",2018,"","","","",125,"2022-07-13 10:05:55","","","","",,,,,6,1.50,1,6,4,"Efficient label acquisition processes are key to obtaining robust classifiers. However, data labeling is often challenging and subject to high levels of label noise. This can arise even when classification targets are well defined, if instances to be labeled are more difficult than the prototypes used to define the class, leading to disagreements among the expert community. Here, we enable efficient training of deep neural networks. From low-confidence labels, we iteratively improve their quality by simultaneous learning of machines and experts. We call it Human And Machine co-LEarning Technique (HAMLET). Throughout the process, experts become more consistent, while the algorithm provides them with explainable feedback for confirmation. HAMLET uses a neural embedding function and a memory module filled with diverse reference embeddings from different classes. Its output includes classification labels and highly relevant reference embeddings as explanation. We took the study of brain monitoring at intensive care unit (ICU) as an application of HAMLET on continuous electroencephalography (cEEG) data. Although cEEG monitoring yields large volumes of data, labeling costs and difficulty make it hard to build a classifier. Additionally, while experts agree on the labels of clear-cut examples of cEEG patterns, labeling many real-world cEEG data can be extremely challenging. Thus, a large minority of sequences might be mislabeled. HAMLET has shown significant performance gain against deep learning and other baselines, increasing accuracy from 7.03% to 68.75% on challenging inputs. Besides improved performance, clinical experts confirmed the interpretability of those reference embeddings in helping explaining the classification results by HAMLET.","",""
17,"Chen Dan, Yuting Wei, Pradeep Ravikumar","Sharp Statistical Guarantees for Adversarially Robust Gaussian Classification",2020,"","","","",126,"2022-07-13 10:05:55","","","","",,,,,17,8.50,6,3,2,"Adversarial robustness has become a fundamental requirement in modern machine learning applications. Yet, there has been surprisingly little statistical understanding so far. In this paper, we provide the first result of the optimal minimax guarantees for the excess risk for adversarially robust classification, under Gaussian mixture model proposed by \cite{schmidt2018adversarially}. The results are stated in terms of the Adversarial Signal-to-Noise Ratio (AdvSNR), which generalizes a similar notion for standard linear classification to the adversarial setting. For the Gaussian mixtures with AdvSNR value of $r$, we establish an excess risk lower bound of order $\Theta(e^{-(\frac{1}{8}+o(1)) r^2} \frac{d}{n})$ and design a computationally efficient estimator that achieves this optimal rate. Our results built upon minimal set of assumptions while cover a wide spectrum of adversarial perturbations including $\ell_p$ balls for any $p \ge 1$.","",""
3,"Mattes Ohlenbusch, Aike Ahrens, Christian Rollwage, Jörg Bitzer","Robust Drone Detection for Acoustic Monitoring Applications",2021,"","","","",127,"2022-07-13 10:05:55","","10.23919/Eusipco47968.2020.9287433","","",,,,,3,3.00,1,4,1,"Commercially available light-weight unmanned aerial vehicles (UAVs) present a challenge for public safety, e.g. espionage, transporting dangerous goods or devices. Therefore, countermeasures are necessary. Usually, detection of UAVs is a first step. Along many other modalities, acoustic detection seems promising. Recent publications show interesting results by using machine and deep learning methods. The acoustic detection of UAVs appears to be particularly difficult in adverse situations, such as in heavy wind noise or in the presence of construction noise. In this contribution, the typical feature set is extended to increase separation of background noise and the UAV signature noise. The decision algorithm utilized is support vector machine (SVM) classification. The classification is based on an extended training dataset labeled to support binary classification. The proposed method is evaluated in comparison to previously published algorithms, on the basis of a dataset recorded from different acoustic environments, including unknown UAV types. The results show an improvement over existing methods, especially in terms of false-positive detection rate. For a first step into real-time embedded systems a recursive feature elimination method is applied to reduce the model dimensionality. The results indicate only a slight decreases in detection performance.","",""
120,"C. Granade, C. Ferrie, N. Wiebe, D. Cory","Robust Online Hamiltonian Learning",2012,"","","","",128,"2022-07-13 10:05:55","","10.1088/1367-2630/14/10/103013","","",,,,,120,12.00,30,4,10,"In this work we combine two distinct machine learning methodologies, sequential Monte Carlo and Bayesian experimental design, and apply them to the problem of inferring the dynamical parameters of a quantum system. We design the algorithm with practicality in mind by including parameters that control trade-offs between the requirements on computational and experimental resources. The algorithm can be implemented online (during experimental data collection), avoiding the need for storage and post-processing. Most importantly, our algorithm is capable of learning Hamiltonian parameters even when the parameters change from experiment-to-experiment, and also when additional noise processes are present and unknown. The algorithm also numerically estimates the Cramer?Rao lower bound, certifying its own performance.","",""
13,"Wendyam Eric Lionel Ilboudo, Taisuke Kobayashi, Kenji Sugimoto","Robust Stochastic Gradient Descent With Student-t Distribution Based First-Order Momentum",2020,"","","","",129,"2022-07-13 10:05:55","","10.1109/TNNLS.2020.3041755","","",,,,,13,6.50,4,3,2,"Remarkable achievements by deep neural networks stand on the development of excellent stochastic gradient descent methods. Deep-learning-based machine learning algorithms, however, have to find patterns between observations and supervised signals, even though they may include some noise that hides the true relationship between them, more or less especially in the robotics domain. To perform well even with such noise, we expect them to be able to detect outliers and discard them when needed. We, therefore, propose a new stochastic gradient optimization method, whose robustness is directly built in the algorithm, using the robust student-t distribution as its core idea. We integrate our method to some of the latest stochastic gradient algorithms, and in particular, Adam, the popular optimizer, is modified through our method. The resultant algorithm, called t-Adam, along with the other stochastic gradient methods integrated with our core idea is shown to effectively outperform Adam and their original versions in terms of robustness against noise on diverse tasks, ranging from regression and classification to reinforcement learning problems.","",""
37,"Liu Yang, L. Jing, M. Ng","Robust and Non-Negative Collective Matrix Factorization for Text-to-Image Transfer Learning",2015,"","","","",130,"2022-07-13 10:05:55","","10.1109/TIP.2015.2465157","","",,,,,37,5.29,12,3,7,"Heterogeneous transfer learning has recently gained much attention as a new machine learning paradigm in which the knowledge can be transferred from source domains to target domains in different feature spaces. Existing works usually assume that source domains can provide accurate and useful knowledge to be transferred to target domains for learning. In practice, there may be noise appearing in given source (text) and target (image) domains data, and thus, the performance of transfer learning can be seriously degraded. In this paper, we propose a robust and non-negative collective matrix factorization model to handle noise in text-to-image transfer learning, and make a reliable bridge to transfer accurate and useful knowledge from the text domain to the image domain. The proposed matrix factorization model can be solved by an efficient iterative method, and the convergence of the iterative method can be shown. Extensive experiments on real data sets suggest that the proposed model is able to effectively perform transfer learning in noisy text and image domains, and it is superior to the popular existing methods for text-to-image transfer learning.","",""
28,"Zhutian Yang, Wei Qiu, Hongjian Sun, A. Nallanathan","Robust Radar Emitter Recognition Based on the Three-Dimensional Distribution Feature and Transfer Learning",2016,"","","","",131,"2022-07-13 10:05:55","","10.3390/s16030289","","",,,,,28,4.67,7,4,6,"Due to the increasing complexity of electromagnetic signals, there exists a significant challenge for radar emitter signal recognition. To address this challenge, multi-component radar emitter recognition under a complicated noise environment is studied in this paper. A novel radar emitter recognition approach based on the three-dimensional distribution feature and transfer learning is proposed. The cubic feature for the time-frequency-energy distribution is proposed to describe the intra-pulse modulation information of radar emitters. Furthermore, the feature is reconstructed by using transfer learning in order to obtain the robust feature against signal noise rate (SNR) variation. Last, but not the least, the relevance vector machine is used to classify radar emitter signals. Simulations demonstrate that the approach proposed in this paper has better performances in accuracy and robustness than existing approaches.","",""
12,"Maximilian Nickel, Volker Tresp, H. Kriegel","S calable Machine Learning for Linked Data",2012,"","","","",132,"2022-07-13 10:05:55","","","","",,,,,12,1.20,4,3,10,"Vast amounts of structured information have been published in the Semantic Web’s Linked Open Data (LOD) cloud and their size is still growing rapidly. Yet, access to this information via reasoning and querying is sometimes difficult, due to LOD’s size, partial data inconsistencies and inherent noisiness. Machine Learning offers an alternative approach to exploiting LOD’s data with the advantages that Machine Learning algorithms are typically robust to both noise and data inconsistencies and are able to efficiently utilize nondeterministic dependencies in the data. From a Machine Learning point of view, LOD is challenging due to its relational nature and its scale. Here, we present an efficient approach to relational learning on LOD data, based on the factorization of a sparse tensor that scales to data consisting of millions of entities, hundreds of relations and billions of known facts. Furthermore, we show how ontological knowledge can be incorporated in the factorization to improve learning results and how computation can be distributed across multiple nodes. We demonstrate that our approach is able to factorize the YAGO 2 core ontology and globally predict statements for this large knowledge base using a single dual-core desktop computer. Furthermore, we show experimentally that our approach achieves good results in several relational learning tasks that are relevant to Linked Data. Once a factorization has been computed, our model is able to predict efficiently, and without any additional training, the likelihood of any of the 4.3 · 10 14 possible triples in the YAGO 2 core ontology.","",""
8,"F. de-la-Calle-Silos, A. Gallardo-Antolín, Carmen Peláez-Moreno","Deep Maxout Networks Applied to Noise-Robust Speech Recognition",2014,"","","","",133,"2022-07-13 10:05:55","","10.1007/978-3-319-13623-3_12","","",,,,,8,1.00,3,3,8,"","",""
11,"Wendyam Eric Lionel Ilboudo, Taisuke Kobayashi, Kenji Sugimoto","TAdam: A Robust Stochastic Gradient Optimizer",2020,"","","","",134,"2022-07-13 10:05:55","","","","",,,,,11,5.50,4,3,2,"Machine learning algorithms aim to find patterns from observations, which may include some noise, especially in robotics domain. To perform well even with such noise, we expect them to be able to detect outliers and discard them when needed. We therefore propose a new stochastic gradient optimization method, whose robustness is directly built in the algorithm, using the robust student-t distribution as its core idea. Adam, the popular optimization method, is modified with our method and the resultant optimizer, so-called TAdam, is shown to effectively outperform Adam in terms of robustness against noise on diverse task, ranging from regression and classification to reinforcement learning problems. The implementation of our algorithm can be found at this https URL","",""
4,"Philip Harding, B. Milner","On the use of Machine Learning Methods for Speech and Voicing Classification",2012,"","","","",135,"2022-07-13 10:05:55","","","","",,,,,4,0.40,2,2,10,"This work examines the effectiveness of machine learning (ML) classifiers on the problems of voice activity detection and voicing classification. A wide range of ML classifiers are considered and include parametric, probabilistic and non-probabilistic, artificial neural networks and regression. Evaluations are carried out in both stationary and non-stationary noise types at signal-to-noise ratios down to 0dB. In comparison to conventional methods the ML methods are found to be significantly more robust with multilayer perceptrons, Gaussian mixture models and Rotation Forest giving consistently best performance.","",""
7,"Yu-Di Huang, Ying-Chang Liang, Gang Yang","A Fuzzy Support Vector Machine Algorithm for Cooperative Spectrum Sensing with Noise Uncertainty",2016,"","","","",136,"2022-07-13 10:05:55","","10.1109/GLOCOM.2016.7841503","","",,,,,7,1.17,2,3,6,"In cognitive radio networks, the performance of energy detection will be degraded significantly due to the cluster overlapping caused by noise uncertainty. To alleviate the noise uncertainty effect, a novel machine learning algorithm is proposed in this paper for cooperative spectrum sensing. The proposed algorithm incorporates fuzzy support vector machine and nonparallel hyperplane support vector machine. For membership assignment, kernel shadow c-means (KSCM) algorithm is utilized. Furthermore, the test statistics collected by the second users are arranged into a feature vector instead of being combined through weighted sum. Simulations results have shown that the proposed scheme, called NP-FSVM, is more robust to noise uncertainty than the existing methods.","",""
7,"Jing Bai, X.-y. Zhang, Ji-kang Duan","Application of Support Vector Machine with Modified Gaussian Kernel in A Noise-Robust Speech Recognition System",2008,"","","","",137,"2022-07-13 10:05:55","","10.1109/KAMW.2008.4810534","","",,,,,7,0.50,2,3,14,"To improve the generalization ability of the machine learning and solve the problem that recognition rates of the speech recognition system become worse in the noisy environment, a modified Gaussian kernel function which may pay attention to the similar degree between sample space and feature space is proposed. In this paper, used the modified Gaussian kernel support vector machine to a speech recognition system for Chinese isolated words, non-specific person and middle glossary quantity and chose the improved noise-robust MFCC parameters as the speech feature, used ""one-against-one"" method for the multi-class classification problem of SVM, and analyzed the influence of Gaussian kernel parameter gamma and error penalty parameter C on SVM generalization ability. Experiments indicate that the recognition rates of SVM which chose the best parameters and modified Gaussian kernel are much better than those of traditional HMM model and RBF network. The robustness is better too.","",""
8,"Felicia S. C. Lim, W. Kleijn, Michael Chinen, J. Skoglund","Robust Low Rate Speech Coding Based on Cloned Networks and Wavenet",2020,"","","","",138,"2022-07-13 10:05:55","","10.1109/ICASSP40776.2020.9053657","","",,,,,8,4.00,2,4,2,"Rapid advances in machine-learning based generative modeling of speech make its use in speech coding attractive. However, the current performance of such models drops rapidly with noise contamination of the input, preventing use in practical applications. We present a new speech-coding scheme that is based on features that are robust to the distortions occurring in speech-coder input signals. To this purpose, we encourage the feature encoder to provide the same independent features for each of a set of linguistically equivalent signals, obtained by adding various noises to a common clean signal. The independent features, subjected to scalar quantization, are used as a conditioning vector sequence for WaveNet. Our experiments show that a 1.8 kb/s implementation of the resulting coder provides state-of-the-art performance for clean signals, and is additionally robust to noisy input.","",""
5,"Suman Samui, I. Chakrabarti, Soumya K. Ghosh","Improving the Performance of Deep Learning Based Speech Enhancement System Using Fuzzy Restricted Boltzmann Machine",2017,"","","","",139,"2022-07-13 10:05:55","","10.1007/978-3-319-69900-4_68","","",,,,,5,1.00,2,3,5,"","",""
320,"Dong Huang, R. Cabral, F. D. L. Torre","Robust Regression",2012,"","","","",140,"2022-07-13 10:05:55","","10.1007/978-3-642-33765-9_44","","",,,,,320,32.00,107,3,10,"","",""
1641,"B. Blankertz, Ryota Tomioka, S. Lemm, M. Kawanabe, K.-R. Muller","Optimizing Spatial filters for Robust EEG Single-Trial Analysis",2008,"","","","",141,"2022-07-13 10:05:55","","10.1109/MSP.2008.4408441","","",,,,,1641,117.21,328,5,14,"Due to the volume conduction multichannel electroencephalogram (EEG) recordings give a rather blurred image of brain activity. Therefore spatial filters are extremely useful in single-trial analysis in order to improve the signal-to-noise ratio. There are powerful methods from machine learning and signal processing that permit the optimization of spatio-temporal filters for each subject in a data dependent fashion beyond the fixed filters based on the sensor geometry, e.g., Laplacians. Here we elucidate the theoretical background of the common spatial pattern (CSP) algorithm, a popular method in brain-computer interface (BCD research. Apart from reviewing several variants of the basic algorithm, we reveal tricks of the trade for achieving a powerful CSP performance, briefly elaborate on theoretical aspects of CSP, and demonstrate the application of CSP-type preprocessing in our studies of the Berlin BCI (BBCI) project.","",""
11,"Muhammad Ali Abdul Aziz, J. Niu, Xiaoke Zhao, Xuelong Li","Efficient and Robust Learning for Sustainable and Reacquisition-Enabled Hand Tracking",2016,"","","","",142,"2022-07-13 10:05:55","","10.1109/TCYB.2015.2418275","","",,,,,11,1.83,3,4,6,"The use of machine learning approaches for long-term hand tracking poses some major challenges such as attaining robustness to inconsistencies in lighting, scale and object appearances, background clutter, and total object occlusion/disappearance. To address these issues in this paper, we present a robust machine learning approach based on enhanced particle filter trackers. The inherent drawbacks associated with the particle filter approach, i.e., sample degeneration and sample impoverishment, are minimized by infusing the particle filter with the mean shift approach. Moreover, to instill our tracker with reacquisition ability, we propose a rotation invariant and efficient detection framework named beta histograms of oriented gradients. Our robust appearance model operates on the red, green, blue color histogram and our newly proposed rotation invariant noise compensated local binary patterns descriptor, which is a noise compensated, rotation invariant version of the local binary patterns descriptor. Through our experiments, we demonstrate that our proposed hand tracker performs favorably against state-of-the-art algorithms on numerous challenging video sequences of hand postures, and overcomes the largely unsolved problem of redetecting hands after they vanish and reappear into the frame.","",""
56,"Aniekan Essien, C. Giannetti","A Deep Learning Model for Smart Manufacturing Using Convolutional LSTM Neural Network Autoencoders",2020,"","","","",143,"2022-07-13 10:05:55","","10.1109/TII.2020.2967556","","",,,,,56,28.00,28,2,2,"Time-series forecasting is applied to many areas of smart factories, including machine health monitoring, predictive maintenance, and production scheduling. In smart factories, machine speed prediction can be used to dynamically adjust production processes based on different system conditions, optimize production throughput, and minimize energy consumption. However, making accurate data-driven machine speed forecasts is challenging. Given the complex nature of industrial manufacturing process data, predictive models that are robust to noise and can capture the temporal and spatial distributions of input time-series signals are prerequisites for accurate forecasting. Motivated by recent deep learning studies in smart manufacturing, in this article, we propose an end-to-end model for multistep machine speed prediction. The model comprises a deep convolutional LSTM encoder–decoder architecture. Extensive empirical analyses using real-world data obtained from a metal packaging plant in the United Kingdom demonstrate the value of the proposed method when compared with the state-of-the-art predictive models.","",""
17,"Shan Pang, Xinyi Yang, Xiaofeng Zhang","Aero Engine Component Fault Diagnosis Using Multi-Hidden-Layer Extreme Learning Machine with Optimized Structure",2016,"","","","",144,"2022-07-13 10:05:55","","10.1155/2016/1329561","","",,,,,17,2.83,6,3,6,"A new aero gas turbine engine gas path component fault diagnosis method based on multi-hidden-layer extreme learning machine with optimized structure (OM-ELM) was proposed. OM-ELM employs quantum-behaved particle swarm optimization to automatically obtain the optimal network structure according to both the root mean square error on training data set and the norm of output weights. The proposed method is applied to handwritten recognition data set and a gas turbine engine diagnostic application and is compared with basic ELM, multi-hidden-layer ELM, and two state-of-the-art deep learning algorithms: deep belief network and the stacked denoising autoencoder. Results show that, with optimized network structure, OM-ELM obtains better test accuracy in both applications and is more robust to sensor noise. Meanwhile it controls the model complexity and needs far less hidden nodes than multi-hidden-layer ELM, thus saving computer memory and making it more efficient to implement. All these advantages make our method an effective and reliable tool for engine component fault diagnosis tool.","",""
167,"Binu P. Chacko, V. Krishnan, G. Raju, P. B. Anto","Handwritten character recognition using wavelet energy and extreme learning machine",2012,"","","","",145,"2022-07-13 10:05:55","","10.1007/s13042-011-0049-5","","",,,,,167,16.70,42,4,10,"","",""
25,"Alexandre Araujo, Rafael Pinot, Benjamin Négrevergne, Laurent Meunier, Y. Chevaleyre, F. Yger, J. Atif","Robust Neural Networks using Randomized Adversarial Training",2019,"","","","",146,"2022-07-13 10:05:55","","","","",,,,,25,8.33,4,7,3,"Since the discovery of adversarial examples in machine learning, researchers have designed several techniques to train neural networks that are robust against different types of attacks (most notably ∞ and 2 based attacks). However , it has been observed that the defense mechanisms designed to protect against one type of attack often offer poor performance against the other. In this paper, we introduce Randomized Adversarial Training (RAT), a technique that is efficient both against 2 and ∞ attacks. To obtain this result, we build upon adversarial training, a technique that is efficient against ∞ attacks, and demonstrate that adding random noise at training and inference time further improves performance against 2 attacks. We then show that RAT is as efficient as adversarial training against ∞ attacks while being robust against strong 2 attacks. Our final comparative experiments demonstrate that RAT outperforms all state-of-the-art approaches against 2 and ∞ attacks.","",""
7,"Nico Lang, Nikolai Kalischek, J. Armston, K. Schindler, R. Dubayah, J. D. Wegner","Global canopy height estimation with GEDI LIDAR waveforms and Bayesian deep learning",2021,"","","","",147,"2022-07-13 10:05:55","","","","",,,,,7,7.00,1,6,1,"NASA’s Global Ecosystem Dynamics Investigation (GEDI) is a key climate mission whose goal is to advance our understanding of the role of forests in the global carbon cycle. While GEDI is the first space-based LIDAR explicitly optimized to measure vertical forest structure predictive of aboveground biomass, the accurate interpretation of this vast amount of waveform data across the broad range of observational and environmental conditions is challenging. Here, we present a novel supervised machine learning approach to interpret GEDI waveforms and regress canopy top height globally. We propose a Bayesian convolutional neural network (CNN) to avoid the explicit modelling of unknown effects, such as atmospheric noise. The model learns to extract robust features that generalize to unseen geographical regions and, in addition, yields reliable estimates of predictive uncertainty. Ultimately, the global canopy top height estimates produced by our model have an expected RMSE of 2.7 m with low bias.","",""
6,"Omobayode Fagbohungbe, L. Qian","Benchmarking Inference Performance of Deep Learning Models on Analog Devices",2020,"","","","",148,"2022-07-13 10:05:55","","10.1109/IJCNN52387.2021.9534143","","",,,,,6,3.00,3,2,2,"Analog hardware implemented deep learning models are promising for computation and energy constrained systems such as edge computing devices. However, the analog nature of the device and the many associated noise sources will cause changes to the value of the weights in the trained deep learning models deployed on such devices. In this study, systematic evaluation of the inference performance of trained popular deep learning models for image classification deployed on analog devices has been carried out, where additive white Gaussian noise has been added to the weights of the trained models during inference. It is observed that deeper models and models with more redundancy in design, such as VGG, are more robust to the noise in general. Also, it is observed that the performance is affected by the design philosophy of the model, the detailed structure of the model, the exact machine learning task, as well as the datasets.","",""
20,"Marco Avella-Medina","Privacy-Preserving Parametric Inference: A Case for Robust Statistics",2019,"","","","",149,"2022-07-13 10:05:55","","10.1080/01621459.2019.1700130","","",,,,,20,6.67,20,1,3,"Abstract Differential privacy is a cryptographically motivated approach to privacy that has become a very active field of research over the last decade in theoretical computer science and machine learning. In this paradigm, one assumes there is a trusted curator who holds the data of individuals in a database and the goal of privacy is to simultaneously protect individual data while allowing the release of global characteristics of the database. In this setting, we introduce a general framework for parametric inference with differential privacy guarantees. We first obtain differentially private estimators based on bounded influence M-estimators by leveraging their gross-error sensitivity in the calibration of a noise term added to them to ensure privacy. We then show how a similar construction can also be applied to construct differentially private test statistics analogous to the Wald, score, and likelihood ratio tests. We provide statistical guarantees for all our proposals via an asymptotic analysis. An interesting consequence of our results is to further clarify the connection between differential privacy and robust statistics. In particular, we demonstrate that differential privacy is a weaker stability requirement than infinitesimal robustness, and show that robust M-estimators can be easily randomized to guarantee both differential privacy and robustness toward the presence of contaminated data. We illustrate our results both on simulated and real data. Supplementary materials for this article are available online.","",""
38,"G. Hua, Chengjiang Long, Ming Yang, Yan Gao","Collaborative Active Learning of a Kernel Machine Ensemble for Recognition",2013,"","","","",150,"2022-07-13 10:05:55","","10.1109/ICCV.2013.153","","",,,,,38,4.22,10,4,9,"Active learning is an effective way of engaging users to interactively train models for visual recognition. The vast majority of previous works, if not all of them, focused on active learning with a single human oracle. The problem of active learning with multiple oracles in a collaborative setting has not been well explored. Moreover, most of the previous works assume that the labels provided by the human oracles are noise free, which may often be violated in reality. We present a collaborative computational model for active learning with multiple human oracles. It leads to not only an ensemble kernel machine that is robust to label noises, but also a principled label quality measure to online detect irresponsible labelers. Instead of running independent active learning processes for each individual human oracle, our model captures the inherent correlations among the labelers through shared data among them. Our simulation experiments and experiments with real crowd-sourced noisy labels demonstrated the efficacy of our model.","",""
18,"Mariusz Pelc, Yuriy Khoma, V. Khoma","ECG Signal as Robust and Reliable Biometric Marker: Datasets and Algorithms Comparison",2019,"","","","",151,"2022-07-13 10:05:55","","10.3390/s19102350","","",,,,,18,6.00,6,3,3,"In this paper, the possibility of using the ECG signal as an unequivocal biometric marker for authentication and identification purposes has been presented. Furthermore, since the ECG signal was acquired from 4 sources using different measurement equipment, electrodes positioning and number of patients as well as the duration of the ECG record acquisition, we have additionally provided an estimation of the extent of information available in the ECG record. To provide a more objective assessment of the credibility of the identification method, some selected machine learning algorithms were used in two combinations: with and without compression. The results that we have obtained confirm that the ECG signal can be acclaimed as a valid biometric marker that is very robust to hardware variations, noise and artifacts presence, that is stable over time and that is scalable across quite a solid (~100) number of users. Our experiments indicate that the most promising algorithms for ECG identification are LDA, KNN and MLP algorithms. Moreover, our results show that PCA compression, used as part of data preprocessing, does not only bring any noticeable benefits but in some cases might even reduce accuracy.","",""
78,"Bo Luo, Yannan Liu, Lingxiao Wei, Q. Xu","Towards Imperceptible and Robust Adversarial Example Attacks against Neural Networks",2018,"","","","",152,"2022-07-13 10:05:55","","10.1609/aaai.v32i1.11499","","",,,,,78,19.50,20,4,4,"    Machine learning systems based on deep neural networks, being able to produce state-of-the-art results on various perception tasks, have gained mainstream adoption in many applications. However, they are shown to be vulnerable to adversarial example attack, which generates malicious output by adding slight perturbations to the input. Previous adversarial example crafting methods, however, use simple metrics to evaluate the distances between the original examples and the adversarial ones, which could be easily detected by human eyes. In addition, these attacks are often not robust due to the inevitable noises and deviation in the physical world. In this work, we present a new adversarial example attack crafting method, which takes the human perceptual system into consideration and maximizes the noise tolerance of the crafted adversarial example. Experimental results demonstrate the efficacy of the proposed technique.   ","",""
5,"Shyamgopal Karthik, Jérôme Revaud, Chidlovskii Boris","Learning From Long-Tailed Data With Noisy Labels",2021,"","","","",153,"2022-07-13 10:05:55","","","","",,,,,5,5.00,2,3,1,"Class imbalance and noisy labels are the norm rather than the exception in many large-scale classification datasets. Nevertheless, most works in machine learning typically assume balanced and clean data. There have been some recent attempts to tackle, on one side, the problem of learning from noisy labels and, on the other side, learning from long-tailed data. Due to this separation, the proposed solutions often underperform when both assumptions are violated. In this work, we present a simple two-stage approach based on recent advances in self-supervised learning to treat both challenges simultaneously. It consists of, first, task-agnostic self-supervised pre-training, followed by task-specific finetuning using an appropriate loss. Most significantly, we find that self-supervised learning approaches are effectively able to cope with severe class imbalance. In addition, the resulting learned representations are also remarkably robust to label noise, when fine-tuned with an imbalanceand noise-resistant loss function. We validate our claims with experiments on CIFAR-10 and CIFAR-100 augmented with synthetic imbalance and noise, as well as the large-scale inherently noisy Clothing-1M dataset.","",""
3,"Shang-Wen Li, Jason Krone, Shuyan Dong, Yi Zhang, Y. Al-Onaizan","Meta Learning to Classify Intent and Slot Labels with Noisy Few Shot Examples",2020,"","","","",154,"2022-07-13 10:05:55","","10.1109/SLT48900.2021.9383489","","",,,,,3,1.50,1,5,2,"Recently deep learning has dominated many machine learning areas, including spoken language understanding (SLU). However, deep learning models are notorious for being data-hungry, and the heavily optimized models are usually sensitive to the quality of the training examples provided and the consistency between training and inference conditions. To improve the performance of SLU models on tasks with noisy and low training resources, we propose a new SLU benchmarking task: few-shot robust SLU, where SLU comprises two core problems, intent classification (IC) and slot labeling (SL). We establish the task by defining few-shot splits on three public IC/SL datasets, ATIS, SNIPS, and TOP, and adding two types of natural noises (adaptation example missing/replacing and modality mismatch) to the splits. We further propose a novel noise-robust few-shot SLU model based on prototypical networks. We show the model consistently outperforms the conventional fine-tuning baseline and another popular meta-learning method, Model-Agnostic Meta-Learning (MAML), in terms of achieving better IC accuracy and SL F1, and yielding smaller performance variation when noises are present.","",""
63,"Nicolas Gillis, S. Vavasis","On the Complexity of Robust PCA and ℓ1-norm Low-Rank Matrix Approximation",2015,"","","","",155,"2022-07-13 10:05:55","","10.1287/moor.2017.0895","","",,,,,63,9.00,32,2,7,"The low-rank matrix approximation problem with respect to the component-wise $\ell_1$-norm ($\ell_1$-LRA), which is closely related to robust principal component analysis (PCA), has become a very popular tool in data mining and machine learning. Robust PCA aims at recovering a low-rank matrix that was perturbed with sparse noise, with applications for example in foreground-background video separation. Although $\ell_1$-LRA is strongly believed to be NP-hard, there is, to the best of our knowledge, no formal proof of this fact. In this paper, we prove that $\ell_1$-LRA is NP-hard, already in the rank-one case, using a reduction from MAX CUT. Our derivations draw interesting connections between $\ell_1$-LRA and several other well-known problems, namely, robust PCA, $\ell_0$-LRA, binary matrix factorization, a particular densest bipartite subgraph problem, the computation of the cut norm of $\{-1,+1\}$ matrices, and the discrete basis problem, which we all prove to be NP-hard.","",""
23,"D. Bertsimas, Allison O'Hair","Learning Preferences Under Noise and Loss Aversion: An Optimization Approach",2013,"","","","",156,"2022-07-13 10:05:55","","10.1287/opre.2013.1209","","",,,,,23,2.56,12,2,9,"Preference learning has been a topic of research in many fields, including operations research, marketing, machine learning, and behavioral economics. In this work, we strive to combine the ideas from these different fields into a single methodology to learn preferences and make decisions. We use robust and integer optimization in an adaptive and dynamic way to determine preferences from data that are consistent with human behavior. We use integer optimization to address human inconsistency, robust optimization and conditional value at risk (CVaR) to address loss aversion, and adaptive conjoint analysis and linear optimization to frame the questions to learn preferences. The paper makes the following methodological contributions: to the robust optimization literature by proposing a method to derive uncertainty sets from adaptive questionnaires, to the marketing literature by using the analytic center of discrete sets (as opposed to polyhedra) to capture errors and inconsistencies, and to the risk modeling...","",""
13,"Andreu Sancho-Asensio, Albert Orriols-Puig, E. Golobardes","Robust on-line neural learning classifier system for data stream classification tasks",2014,"","","","",157,"2022-07-13 10:05:55","","10.1007/s00500-014-1233-9","","",,,,,13,1.63,4,3,8,"","",""
189,"Haomin Zhang, I. Mcloughlin, Yan Song","Robust sound event recognition using convolutional neural networks",2015,"","","","",158,"2022-07-13 10:05:55","","10.1109/ICASSP.2015.7178031","","",,,,,189,27.00,63,3,7,"Traditional sound event recognition methods based on informative front end features such as MFCC, with back end sequencing methods such as HMM, tend to perform poorly in the presence of interfering acoustic noise. Since noise corruption may be unavoidable in practical situations, it is important to develop more robust features and classifiers. Recent advances in this field use powerful machine learning techniques with high dimensional input features such as spectrograms or auditory image. These improve robustness largely thanks to the discriminative capabilities of the back end classifiers. We extend this further by proposing novel features derived from spectrogram energy triggering, allied with the powerful classification capabilities of a convolutional neural network (CNN). The proposed method demonstrates excellent performance under noise-corrupted conditions when compared against state-of-the-art approaches on standard evaluation tasks. To the author's knowledge this in the first application of CNN in this field.","",""
207,"I. Mcloughlin, Haomin Zhang, Zhipeng Xie, Yan Song, Wei Xiao","Robust Sound Event Classification Using Deep Neural Networks",2015,"","","","",159,"2022-07-13 10:05:55","","10.1109/TASLP.2015.2389618","","",,,,,207,29.57,41,5,7,"The automatic recognition of sound events by computers is an important aspect of emerging applications such as automated surveillance, machine hearing and auditory scene understanding. Recent advances in machine learning, as well as in computational models of the human auditory system, have contributed to advances in this increasingly popular research field. Robust sound event classification, the ability to recognise sounds under real-world noisy conditions, is an especially challenging task. Classification methods translated from the speech recognition domain, using features such as mel-frequency cepstral coefficients, have been shown to perform reasonably well for the sound event classification task, although spectrogram-based or auditory image analysis techniques reportedly achieve superior performance in noise. This paper outlines a sound event classification framework that compares auditory image front end features with spectrogram image-based front end features, using support vector machine and deep neural network classifiers. Performance is evaluated on a standard robust classification task in different levels of corrupting noise, and with several system enhancements, and shown to compare very well with current state-of-the-art classification techniques.","",""
55,"Daniel Holden","Robust solving of optical motion capture data by denoising",2018,"","","","",160,"2022-07-13 10:05:55","","10.1145/3197517.3201302","","",,,,,55,13.75,55,1,4,"Raw optical motion capture data often includes errors such as occluded markers, mislabeled markers, and high frequency noise or jitter. Typically these errors must be fixed by hand - an extremely time-consuming and tedious task. Due to this, there is a large demand for tools or techniques which can alleviate this burden. In this research we present a tool that sidesteps this problem, and produces joint transforms directly from raw marker data (a task commonly called ""solving"") in a way that is extremely robust to errors in the input data using the machine learning technique of denoising. Starting with a set of marker configurations, and a large database of skeletal motion data such as the CMU motion capture database [CMU 2013b], we synthetically reconstruct marker locations using linear blend skinning and apply a unique noise function for corrupting this marker data - randomly removing and shifting markers to dynamically produce billions of examples of poses with errors similar to those found in real motion capture data. We then train a deep denoising feed-forward neural network to learn a mapping from this corrupted marker data to the corresponding transforms of the joints. Once trained, our neural network can be used as a replacement for the solving part of the motion capture pipeline, and, as it is very robust to errors, it completely removes the need for any manual clean-up of data. Our system is accurate enough to be used in production, generally achieving precision to within a few millimeters, while additionally being extremely fast to compute with low memory requirements.","",""
7,"M. Sangiorgio","Deep Learning in Multi-step Forecasting of Chaotic Dynamics",2022,"","","","",161,"2022-07-13 10:05:55","","10.1007/978-3-030-85918-3_1","","",,,,,7,7.00,7,1,1,"","",""
9,"Guillermo Cortés, R. Carniel, M. Á. Mendoza, P. Lesage","Standardization of Noisy Volcanoseismic Waveforms as a Key Step toward Station‐Independent, Robust Automatic Recognition",2019,"","","","",162,"2022-07-13 10:05:55","","10.1785/0220180334","","",,,,,9,3.00,2,4,3,"This work addresses the automatic Volcano-Seismic Recognition (VSR) in a noisy scenario studying the robustness of a classifier based on Hidden Markov Models (HMMs). The system learns recognition models analyzing signals recorded in 1995 to automatically detect and classify noisy events of 2009. Both datasets were acquired in different locations at Deception Island and with a different type of sensor showing a variety of site effects and noises. To deal with the inherent waveform variability of this setup, we propose to reconstruct the seismograms to achieve both modeling standardization and noise reduction goals. We analyze a set of Empirical Mode Decomposition (EMD) algorithms jointly with static and dynamic reconstruction criteria in order to evaluate their impact on the robustness of the recognition process. This machine-learning focus on real-time, continuous, unsupervised VSR paradigm is able to increase by 16% the global VSR accuracy using an adaptive reconstruction compared to the scores obtained without any standardization.","",""
8,"Suhas Srinivasan, Nathan Johnson, Dmitry Korkin","A Hybrid Deep Clustering Approach for Robust Cell Type Profiling Using Single-cell RNA-seq Data",2019,"","","","",163,"2022-07-13 10:05:55","","10.1101/511626","","",,,,,8,2.67,3,3,3,"Single-cell RNA sequencing (scRNA-seq) is a recent technology that enables fine-grained discovery of cellular subtypes and specific cell states. It routinely uses machine learning methods, such as feature learning, clustering, and classification, to assist in uncovering novel information from scRNA-seq data. However, current methods are not well suited to deal with the substantial amounts of noise that is created by the experiments or the variation that occurs due to differences in the cells of the same type. Here, we develop a new hybrid approach, Deep Unsupervised Single-cell Clustering (DUSC), that integrates feature generation based on a deep learning architecture with a model-based clustering algorithm, to find a compact and informative representation of the single-cell transcriptomic data generating robust clusters. We also include a technique to estimate an efficient number of latent features in the deep learning model. Our method outperforms both classical and state-of-the-art feature learning and clustering methods, approaching the accuracy of supervised learning. The method is freely available to the community and will hopefully facilitate our understanding of the cellular atlas of living organisms as well as provide the means to improve patient diagnostics and treatment.","",""
6,"Jing Zhang, Lin Feng, Bin Wu","Local extreme learning machine: local classification model for shape feature extraction",2016,"","","","",164,"2022-07-13 10:05:55","","10.1007/s00521-015-2008-7","","",,,,,6,1.00,2,3,6,"","",""
11,"Qiao Cheng, Meiyuan Fang, Yaqian Han, Jin Huang, Yitao Duan","Breaking the Data Barrier: Towards Robust Speech Translation via Adversarial Stability Training",2019,"","","","",165,"2022-07-13 10:05:55","","","","",,,,,11,3.67,2,5,3,"In a pipeline speech translation system, automatic speech recognition (ASR) system will transmit errors in recognition to the downstream machine translation (MT) system. A standard machine translation system is usually trained on parallel corpus composed of clean text and will perform poorly on text with recognition noise, a gap well known in speech translation community. In this paper, we propose a training architecture which aims at making a neural machine translation model more robust against speech recognition errors. Our approach addresses the encoder and the decoder simultaneously using adversarial learning and data augmentation, respectively. Experimental results on IWSLT2018 speech translation task show that our approach can bridge the gap between the ASR output and the MT input, outperforms the baseline by up to 2.83 BLEU on noisy ASR output, while maintaining close performance on clean text.","",""
4,"Chengming Hu, Jun Yan, C. Wang","Robust Feature Extraction and Ensemble Classification Against Cyber-Physical Attacks in the Smart Grid",2019,"","","","",166,"2022-07-13 10:05:55","","10.1109/EPEC47565.2019.9074827","","",,,,,4,1.33,1,3,3,"Intrusion detection systems (IDS) are crucial in threats monitoring for the cyber-physical security of electrical power and energy systems in the smart grid with increasing machine-to-machine communication. However, the multi-sourced, voluminous, correlated, and often noise-contained data, which record various concurring cyber and physical events, are posing significant challenges to the accurate distinction by IDS among events of inadvertent and malignant natures. To tackle such challenges, this paper proposes a robust end-to-end framework based on Stacked Denoising Autoencoder (SDAE) and Ensemble Machine Learning to extract new noise and attack-informed feature sets from cyber-physical system data and incorporate different sources of information for reliable event classification. The proposed framework first leverages SDAE to create lower-dimensional features that allow reconstruction of a noise-free input from noise-corrupted perturbations. By combining attack and noisy inputs, we extracted new, automatically-engineered features that can preserve and present information on normal, fault, and attack events against different synthetic but realistic noises for better classification. Considering the heterogeneous nature of the inputs, which are composed of PMU measurements, system logs, and IDS alerts, we further introduced ensemble learning-based multi-classifier classification with the Extreme Gradient Boosting (XGBoost) technique to classify the samples based on the SDAE-extracted features. Normalization and oversampling were also both performed to improve the uniformity and balance of the data. On a realistic dataset of 37 sub-types of normal, fault, and attack collected from co-simulations on a hardware-in-the-loop (HIL) testbed security testbed, the results have shown that the proposed SDAE+XGBoost solution achieves over 90% classification accuracy with the SDAE features and ensemble classifiers, an effective 8% increase over the state-of-the-art.","",""
14,"Yaoqing Yang, Rekha Khanna, Yaodong Yu, A. Gholami, K. Keutzer, Joseph Gonzalez, K. Ramchandran, M. Mahoney","Boundary thickness and robustness in learning models",2020,"","","","",167,"2022-07-13 10:05:55","","","","",,,,,14,7.00,2,8,2,"Robustness of machine learning models to various adversarial and non-adversarial corruptions continues to be of interest. In this paper, we introduce the notion of the boundary thickness of a classifier, and we describe its connection with and usefulness for model robustness. Thick decision boundaries lead to improved performance, while thin decision boundaries lead to overfitting (e.g., measured by the robust generalization gap between training and testing) and lower robustness. We show that a thicker boundary helps improve robustness against adversarial examples (e.g., improving the robust test accuracy of adversarial training) as well as so-called out-of-distribution (OOD) transforms, and we show that many commonly-used regularization and data augmentation procedures can increase boundary thickness. On the theoretical side, we establish that maximizing boundary thickness during training is akin to the so-called mixup training. Using these observations, we show that noise-augmentation on mixup training further increases boundary thickness, thereby combating vulnerability to various forms of adversarial attacks and OOD transforms. We can also show that the performance improvement in several lines of recent work happens in conjunction with a thicker boundary.","",""
3,"R. Singh, Neelam Dabas, Vikash Chaudhary, Nagendra","Online Sequential Extreme Learning Machine for Watermarking",2015,"","","","",168,"2022-07-13 10:05:55","","10.1007/978-3-319-14066-7_12","","",,,,,3,0.43,1,4,7,"","",""
3,"T. Ahn, Sok-Beom Roh, Kuk-Yeon Hwang, Jihong Wang, Yong Soo Kim","Design of Fuzzy Pattern Classifier based on Extreme Learning Machine",2015,"","","","",169,"2022-07-13 10:05:55","","10.5391/JKIIS.2015.25.5.509","","",,,,,3,0.43,1,5,7,"In this paper, we introduce a new pattern classifier which is based on the learning algorithm of Extreme Learning Machine the sort of artificial neural networks and fuzzy set theory which is well known as being robust to noise. The learning algorithm used in Extreme Learning Machine is faster than the conventional artificial neural networks. The key advantage of Extreme Learning Machine is the generalization ability for regression problem and classification problem. In order to evaluate the classification ability of the proposed pattern classifier, we make experiments with several machine learning data sets.","",""
417,"Jiang Wang, Zicheng Liu, Ying Wu, Junsong Yuan","Learning Actionlet Ensemble for 3D Human Action Recognition",2014,"","","","",170,"2022-07-13 10:05:55","","10.1109/TPAMI.2013.198","","",,,,,417,52.13,104,4,8,"Human action recognition is an important yet challenging task. Human actions usually involve human-object interactions, highly articulated motions, high intra-class variations, and complicated temporal structures. The recently developed commodity depth sensors open up new possibilities of dealing with this problem by providing 3D depth data of the scene. This information not only facilitates a rather powerful human motion capturing technique, but also makes it possible to efficiently model human-object interactions and intra-class variations. In this paper, we propose to characterize the human actions with a novel actionlet ensemble model, which represents the interaction of a subset of human joints. The proposed model is robust to noise, invariant to translational and temporal misalignment, and capable of characterizing both the human motion and the human-object interactions. We evaluate the proposed approach on three challenging action recognition datasets captured by Kinect devices, a multiview action recognition dataset captured with Kinect device, and a dataset captured by a motion capture system. The experimental evaluations show that the proposed approach achieves superior performance to the state-of-the-art algorithms.","",""
12,"H. Pannu, Sahil Ahuja, Nitin Dang, Sahil Soni, A. Malhi","Deep learning based image classification for intestinal hemorrhage",2020,"","","","",171,"2022-07-13 10:05:55","","10.1007/s11042-020-08905-7","","",,,,,12,6.00,2,5,2,"","",""
19,"N. Hagita, M. Sawaki","Robust recognition of degraded machine-printed characters using complementary similarity measure and error-correction learning",1995,"","","","",172,"2022-07-13 10:05:55","","10.1117/12.205826","","",,,,,19,0.70,10,2,27,"Most conventional methods in character recognition extract geometrical features such as stroke direction, connectivity of strokes, etc., and compare them with reference patterns in a stored dictionary. Unfortunately, geometrical features are easily degraded by blurs, stains and the graphical background designs used in Japanese newspaper headlines. This noise must be removed before recognition commences, but no preprocessing method is completely accurate. This paper proposes a method for recognizing degraded characters and characters printed on graphical background designs. This method is based on the binary image feature method and uses binary images as features. A new similarity measure, called the complementary similarity measure, is used as a discriminant function. It compares the similarity and dissimilarity of binary patterns with reference dictionary patterns. Experiments are conducted using the standard character database ETL-2 which consists of machine-printed Kanji, Hiragana, Katakana, alphanumeric, an special characters. The results show that this method is much more robust against noise than the conventional geometrical feature method. It also achieves high recognition rates of over 92% for characters with textured foregrounds, over 98% for characters with textured backgrounds, over 98% for outline fonts, and over 99% for reverse contrast characters.","",""
54,"P. Wiecha, A. Lecestre, N. Mallet, G. Larrieu","Pushing the limits of optical information storage using deep learning",2018,"","","","",173,"2022-07-13 10:05:55","","10.1038/s41565-018-0346-1","","",,,,,54,13.50,14,4,4,"","",""
25,"Ethan X. Fang, Han Liu, K. Toh, Wen-Xin Zhou","Max-norm optimization for robust matrix recovery",2016,"","","","",174,"2022-07-13 10:05:55","","10.1007/s10107-017-1159-y","","",,,,,25,4.17,6,4,6,"","",""
24,"Yuning Hao, Ming Yan, B. Heath, Y. Lei, Yuying Xie","Fast and robust deconvolution of tumor infiltrating lymphocyte from expression profiles using least trimmed squares",2018,"","","","",175,"2022-07-13 10:05:55","","10.1371/journal.pcbi.1006976","","",,,,,24,6.00,5,5,4,"Gene-expression deconvolution is used to quantify different types of cells in a mixed population. It provides a highly promising solution to rapidly characterize the tumor-infiltrating immune landscape and identify cold cancers. However, a major challenge is that gene-expression data are frequently contaminated by many outliers that decrease the estimation accuracy. Thus, it is imperative to develop a robust deconvolution method that automatically decontaminates data by reliably detecting and removing outliers. We developed a new machine learning tool, Fast And Robust DEconvolution of Expression Profiles (FARDEEP), to enumerate immune cell subsets from whole tumor tissue samples. To reduce noise in the tumor gene expression datasets, FARDEEP utilizes an adaptive least trimmed square to automatically detect and remove outliers before estimating the cell compositions. We show that FARDEEP is less susceptible to outliers and returns a better estimation of coefficients than the existing methods with both numerical simulations and real datasets. FARDEEP provides the absolute quantitation of each immune cell subset in addition to relative percentages. Hence, FARDEEP represents a novel robust algorithm to complement the existing toolkit for the characterization of tissue-infiltrating immune cell landscape. The source code for FARDEEP as implemented in R is available for download at https://goo.gl/SqGKuo.","",""
8,"Nanhai Yang, Mingming Huang, Ran He, Xiukun Wang","Robust Semi-Supervised Learning Algorithm Based on Maximum Correntropy Criterion: Robust Semi-Supervised Learning Algorithm Based on Maximum Correntropy Criterion",2012,"","","","",176,"2022-07-13 10:05:55","","10.3724/SP.J.1001.2012.03977","","",,,,,8,0.80,2,4,10,"his paper analyzes the problem of sensitivity to noise in the mean square criterion of Gaussian- Laplacian regularized (GLR) algorithm. A robust semi-supervised learning algorithm based on maximum correntropy criterion (MCC), called GLR-MCC, is proposed to improve the robustness of GLR along with its convergence analysis. The half quadratic optimization technique is used to simplify the correntropy optimization problem to a standard semi-supervised problem in each iteration. Experimental results on typical machine learning data sets show that the proposed GLR-MCC can effectively improve the robustness of mislabeling noise and occlusion as compared with related semi-supervised learning algorithms.","",""
9,"S. Dhivya, J. Sangeetha, B. Sudhakar","Copy-move forgery detection using SURF feature extraction and SVM supervised learning technique",2020,"","","","",177,"2022-07-13 10:05:55","","10.1007/s00500-020-04795-x","","",,,,,9,4.50,3,3,2,"","",""
5,"Amirreza Shaeiri, Rozhin Nobahari, M. Rohban","Towards Deep Learning Models Resistant to Large Perturbations",2020,"","","","",178,"2022-07-13 10:05:55","","","","",,,,,5,2.50,2,3,2,"Adversarial robustness has proven to be a required property of machine learning algorithms. A key and often overlooked aspect of this problem is to try to make the adversarial noise magnitude as large as possible to enhance the benefits of the model robustness. We show that the well-established algorithm called ""adversarial training"" fails to train a deep neural network given a large, but reasonable, perturbation magnitude. In this paper, we propose a simple yet effective initialization of the network weights that makes learning on higher levels of noise possible. We next evaluate this idea rigorously on MNIST ($\epsilon$ up to $\approx 0.40$) and CIFAR10 ($\epsilon$ up to $\approx 32/255$) datasets assuming the $\ell_{\infty}$ attack model. Additionally, in order to establish the limits of $\epsilon$ in which the learning is feasible, we study the optimal robust classifier assuming full access to the joint data and label distribution. Then, we provide some theoretical results on the adversarial accuracy for a simple multi-dimensional Bernoulli distribution, which yields some insights on the range of feasible perturbations for the MNIST dataset.","",""
558,"R. He, Weishi Zheng, B. Hu","Maximum Correntropy Criterion for Robust Face Recognition",2011,"","","","",179,"2022-07-13 10:05:55","","10.1109/TPAMI.2010.220","","",,,,,558,50.73,186,3,11,"In this paper, we present a sparse correntropy framework for computing robust sparse representations of face images for recognition. Compared with the state-of-the-art l1norm-based sparse representation classifier (SRC), which assumes that noise also has a sparse representation, our sparse algorithm is developed based on the maximum correntropy criterion, which is much more insensitive to outliers. In order to develop a more tractable and practical approach, we in particular impose nonnegativity constraint on the variables in the maximum correntropy criterion and develop a half-quadratic optimization technique to approximately maximize the objective function in an alternating way so that the complex optimization problem is reduced to learning a sparse representation through a weighted linear least squares problem with nonnegativity constraint at each iteration. Our extensive experiments demonstrate that the proposed method is more robust and efficient in dealing with the occlusion and corruption problems in face recognition as compared to the related state-of-the-art methods. In particular, it shows that the proposed method can improve both recognition accuracy and receiver operator characteristic (ROC) curves, while the computational cost is much lower than the SRC algorithms.","",""
6,"Yuwei Sun, H. Esaki, H. Ochiai","Blockchain-Based Federated Learning Against End-Point Adversarial Data Corruption",2020,"","","","",180,"2022-07-13 10:05:55","","10.1109/ICMLA51294.2020.00119","","",,,,,6,3.00,2,3,2,"With the approach of 5G Society, more and more devices have been connected to the Internet, where information is stored, analyzed, and shared. Federated learning allows participants to train a machine learning model through sharing the parameters of it based on local training, instead of raw private data at local. In this research, we propose the implementation of the blockchain in federated learning for local parameters evaluation and global parameter aggregation, thus alleviating the influence of end-point adversarial training data. Besides, all updates of local parameters are encrypted and stored in a block of the blockchain after the consensus by the committee. We evaluate the performance of the scheme when adopting various types of corruption to the adversary’s dataset, including noise with various degrees and circle occlusion with various diameters. At last, it shows robust and resilient performance compared with the traditional federated learning, achieving a validation accuracy rate of 0.957 when adding noise with a degree of 1.0, and one of 0.944 when adopting circle occlusion with a diameter of 28 pixels for the classification.","",""
46,"Shudong Huang, Hongjun Wang, Tao Li, Tianrui Li, Zenglin Xu","Robust graph regularized nonnegative matrix factorization for clustering",2018,"","","","",181,"2022-07-13 10:05:55","","10.1007/s10618-017-0543-9","","",,,,,46,11.50,9,5,4,"","",""
45,"F. Nie, Xiaoqian Wang, Heng Huang","Multiclass Capped ℓp-Norm SVM for Robust Classifications",2017,"","","","",182,"2022-07-13 10:05:55","","10.1609/aaai.v31i1.10948","","",,,,,45,9.00,15,3,5,"    Support vector machine (SVM) model is one of most successful machine learning methods and has been successfully applied to solve numerous real-world application. Because the SVM methods use the hinge loss or squared hinge loss functions for classifications, they usually outperform other classification approaches, e.g. the least square loss function based methods. However, like most supervised learning algorithms, they learn classifiers based on the labeled data in training set without specific strategy to deal with the noise data. In many real-world applications, we often have data outliers in train set, which could misguide the classifiers learning, such that the classification performance is suboptimal. To address this problem, we proposed a novel capped Lp-norm SVM classification model by utilizing the capped `p-norm based hinge loss in the objective which can deal with both light and heavy outliers. We utilize the new formulation to naturally build the multiclass capped Lp-norm SVM. More importantly, we derive a novel optimization algorithms to efficiently minimize the capped Lp-norm based objectives, and also rigorously prove the convergence of proposed algorithms. We present experimental results showing that employing the new capped Lp-norm SVM method can consistently improve the classification performance, especially in the cases when the data noise level increases.   ","",""
67,"Dingjiang Huang, Junlong Zhou, B. Li, S. Hoi, Shuigeng Zhou","Robust Median Reversion Strategy for Online Portfolio Selection",2013,"","","","",183,"2022-07-13 10:05:55","","10.1109/TKDE.2016.2563433","","",,,,,67,7.44,13,5,9,"Online portfolio selection has attracted increasing attention from data mining and machine learning communities in recent years. An important theory in financial markets is mean reversion, which plays a critical role in some state-of-the-art portfolio selection strategies. Although existing mean reversion strategies have been shown to achieve good empirical performance on certain datasets, they seldom carefully deal with noise and outliers in the data, leading to suboptimal portfolios, and consequently yielding poor performance in practice. In this paper, we propose to exploit the reversion phenomenon by using robust <inline-formula><tex-math notation=""LaTeX""> $L_1$</tex-math><alternatives><inline-graphic xlink:type=""simple"" xlink:href=""huang-ieq1-2563433.gif""/></alternatives> </inline-formula>-median estimators, and design a novel online portfolio selection strategy named “Robust Median Reversion” (RMR), which constructs optimal portfolios based on the improved reversion estimator. We examine the performance of the proposed algorithms on various real markets with extensive experiments. Empirical results show that RMR can overcome the drawbacks of existing mean reversion algorithms and achieve significantly better results. Finally, RMR runs in linear time, and thus is suitable for large-scale real-time algorithmic trading applications.","",""
385,"K. Noda, Yuki Yamaguchi, K. Nakadai, HIroshi G. Okuno, T. Ogata","Audio-visual speech recognition using deep learning",2015,"","","","",184,"2022-07-13 10:05:55","","10.1007/s10489-014-0629-7","","",,,,,385,55.00,77,5,7,"","",""
18,"Jianping Gou, Lei Wang, Zhang Yi, Jiancheng Lv, Qirong Mao, Yunhao Yuan","A New Discriminative Collaborative Neighbor Representation Method for Robust Face Recognition",2018,"","","","",185,"2022-07-13 10:05:55","","10.1109/ACCESS.2018.2883527","","",,,,,18,4.50,3,6,4,"As the representative one of representation-based classification (RBC) methods, collaborative RBC (CRC) has drawn much attention in pattern recognition and machine learning recently. Moreover, the collaborative representation-based face recognition has been extensively studied because of the effective classification performance of CRC. CRC collaboratively represents each query sample as the linear combination of all the training samples and then classifies the query sample according to the categorical representation-based distances. However, most variants of CRC cannot fully consider the locality and discrimination of data and cannot well handle the noise data, which has negative effect on real-world classification problems, such as face recognition. In this paper, a new discriminative collaborative neighbor representation (DCNR) method for face recognition is proposed by integrating class discrimination and data locality. In the proposed method, the locality of data constrains collaborative representation of each query sample to find representative nearest samples of the query sample. Moreover, the class discrimination regularization is taken into account by employing the representation of each class for each query sample. Due to the existing noises, such as corruptions and occlusions in face recognition, we further propose robust DCNR (R-DCNR) for robust classification by using the  $\ell _{1}$ -norm representation fidelity. Extensive experiments on face databases demonstrate that the proposed methods achieve competitive classification performance, compared to the state-of-the-art representation-based classification methods.","",""
18,"S. Aigrain, H. Parviainen, S. Roberts, S. Reece, T. E. O. Astrophysics, Iac, O. Learning, E. Astrophysics","Robust, open-source removal of systematics in Kepler data",2017,"","","","",186,"2022-07-13 10:05:55","","10.1093/mnras/stx1422","","",,,,,18,3.60,2,8,5,"We present ARC2 (Astrophysically Robust Correction 2), an open-source Python-based systematics-correction pipeline to correct for the Kepler prime mission long cadence light curves. The ARC2 pipeline identifies and corrects any isolated discontinuities in the light curves, then removes trends common to many light curves. These trends are modelled using the publicly available co-trending basis vectors, within an (approximate) Bayesian framework with `shrinkage' priors to minimise the risk of over-fitting and the injection of any additional noise into the corrected light curves, while keeping any astrophysical signals intact. We show that the ARC2 pipeline's performance matches that of the standard Kepler PDC-MAP data products using standard noise metrics, and demonstrate its ability to preserve astrophysical signals using injection tests with simulated stellar rotation and planetary transit signals. Although it is not identical, the ARC2 pipeline can thus be used as an open source alternative to PDC-MAP, whenever the ability to model the impact of the systematics removal process on other kinds of signal is important.","",""
2,"Xu Zhou, Pak Lun Kevin Ding, Baoxin Li","Improving Robustness of Random Forest Under Label Noise",2019,"","","","",187,"2022-07-13 10:05:55","","10.1109/WACV.2019.00106","","",,,,,2,0.67,1,3,3,"Random forest is a well-known and widely-used machine learning model. In many applications where the training data arise from real-world sources, there may be labeling errors in the data. In spite of its superior performance, the basic model of random forest dose not consider potential label noise in learning, and thus its performance can suffer significantly in the presence of label noise. In order to solve this problem, we present a new variation of random forest - a novel learning approach that leads to an improved noise robust random forest (NRRF) model. We incorporate the noise information by introducing a global multi-class noise tolerant loss function into the training of the classic random forest model. This new loss function was found to significantly boost the performance of random forest. We evaluated the proposed NRRF by extensive experiments of classification tasks on standard machine learning/computer vision datasets like MNIST, letter and Cifar10. The proposed NRRF produced very promising results under a wide range of noise settings.","",""
57,"C. Lippitt, J. Rogan, Z. Li, J. R. Eastman, T. Jones","Mapping Selective Logging in Mixed Deciduous Forest: A Comparison of Machine Learning Algorithms",2008,"","","","",188,"2022-07-13 10:05:55","","10.14358/PERS.74.10.1201","","",,,,,57,4.07,11,5,14,"This study assesses the performance of five Machine Learning Algorithms (MLAs) in a chronically modified mixed deciduous forest in Massachusetts (USA) in terms of their ability to detect selective timber logging and to cope with deficient reference datasets. Multitemporal Landsat Enhanced Thematic Mapperplus (ETM+) imagery is used to assess the performance of three Artificial Neural Networks ‐ Multi-Layer Perceptron, ARTMAP, Self-Organizing Map, and two Classification Tree splitting algorithms: gini and entropy rules. MLA performance evaluations are based on susceptibility to reduced training set size, noise, and variations in the training set, as well as the operability/transparency of the classification process. Classification trees produced the most accurate selective logging maps (gini and entropy rule decision tree mean overall map accuracy � 94 percent and mean per-class kappa of 0.59 and 0.60, respectively). Classification trees are shown to be more robust and accurate when faced with deficient training data, regardless of splitting rule. Of the neural network algorithms, self-organizing maps were least sensitive to the introduction of noise and variations in training data. Given their robust classification capabilities and transparency of the classselection process, classification trees are preferable algorithms for mapping selective logging and have potential in other forest monitoring applications.","",""
3,"Chia-Te Liao, S. Lai","Robust kernel-based learning for image-related problems",2012,"","","","",189,"2022-07-13 10:05:55","","10.1049/IET-IPR.2010.0301","","",,,,,3,0.30,2,2,10,"Robustness is one of the most critical issues in the appearance-based learning techniques. This study develops a novel robust kernel for kernel machines, and consequently improves their robustness in resisting noise for solving the image-related learning problems. By incorporating a robust ρ-function to reduce the influence of outlier components, this kernel gives more reasonable kernel values when images are seriously corrupted. The authors incorporate the proposed kernel into different kernel-based approaches, such as support vector machine (SVM) and kernel Fisher discriminant (KFD) analysis, to validate its performance on various visual learning problems of face recognition and data visualisation. Experimental results indicate that the proposed kernel can provide the superior robustness to the classical approaches.","",""
17,"Yaochen Hu, Peng Liu, Linglong Kong, Di Niu","Learning Privately over Distributed Features: An ADMM Sharing Approach",2019,"","","","",190,"2022-07-13 10:05:55","","","","",,,,,17,5.67,4,4,3,"Distributed machine learning has been widely studied in order to handle exploding amount of data. In this paper, we study an important yet less visited distributed learning problem where features are inherently distributed or vertically partitioned among multiple parties, and sharing of raw data or model parameters among parties is prohibited due to privacy concerns. We propose an ADMM sharing framework to approach risk minimization over distributed features, where each party only needs to share a single value for each sample in the training process, thus minimizing the data leakage risk. We establish convergence and iteration complexity results for the proposed parallel ADMM algorithm under non-convex loss. We further introduce a novel differentially private ADMM sharing algorithm and bound the privacy guarantee with carefully designed noise perturbation. The experiments based on a prototype system shows that the proposed ADMM algorithms converge efficiently in a robust fashion, demonstrating advantage over gradient based methods especially for data set with high dimensional feature spaces.","",""
30,"J. Rogan, J. Franklin, D. Stow, Jennifer A. Miller, C. Woodcock, D. Roberts","Mapping landcover modifications over large areas : A comparison of machine learning algorithms",2008,"","","","",191,"2022-07-13 10:05:55","","","","",,,,,30,2.14,5,6,14,"Large area land-cover monitoring scenarios, involving large volumes of data, are becoming more prevalent in remote sensing applications. Thus, there is a pressing need for increased automation in the change mapping process. The objective of this research is to compare the performance of three machine learning algorithms (MLAs); two classification tree software routines (S-plus and C4.5) and an artificial neural network (ARTMAP), in the context of mapping land-cover modifications in northern and southern California study sites between 1990/91 and 1996. Comparisons were based on several criteria: overall accuracy, sensitivity to data set size and variation, and noise. ARTMAP produced the most accurate maps overall (∼84%), for two study areas — in southern and northern California, and was most resistant to training data deficiencies. The change map generated using ARTMAP has similar accuracies to a human-interpreted map produced by the U.S. Forest Service in the southern study area. ARTMAP appears to be robust and accurate for automated, large area change monitoring as it performed equally well across the diverse study areas with minimal human intervention in the classification process. © 2007 Elsevier Inc. All rights reserved.","",""
12,"Christopher A. Metzler, Philip Schniter, A. Veeraraghavan, Richard Baraniuk","prDeep: Robust Phase Retrieval with Flexible Deep Neural Networks",2018,"","","","",192,"2022-07-13 10:05:55","","","","",,,,,12,3.00,3,4,4,"Phase retrieval (PR) algorithms have become an important component in many modern computational imaging systems. For instance, in the context of ptychography and speckle correlation imaging PR algorithms enable imaging past the diffraction limit and through scattering media, respectively. Unfortunately, traditional PR algorithms struggle in the presence of noise. Recently PR algorithms have been developed that use priors to make themselves more robust. However, these algorithms often require unrealistic (Gaussian or coded diffraction pattern) measurement models and offer slow computation times. These drawbacks have hindered widespread adoption. In this work we use convolutional neural networks, a powerful tool from machine learning, to regularize phase retrieval problems and improve recovery performance. We test our new algorithm, prDeep, in simulation and demonstrate that it is robust to noise, can handle a variety system models, and operates fast enough for high-resolution applications.","",""
17,"Konstantinos Saitas Zarkias, N. Passalis, Avraam Tsantekidis, A. Tefas","Deep Reinforcement Learning for Financial Trading Using Price Trailing",2019,"","","","",193,"2022-07-13 10:05:55","","10.1109/ICASSP.2019.8683161","","",,,,,17,5.67,4,4,3,"Developing accurate financial analysis tools can be useful both for speculative trading, as well as for analyzing the behavior of markets and promptly responding to unstable conditions ensuring the smooth operation of the financial markets. This led to the development of various methods for analyzing and forecasting the behaviour of financial assets, ranging from traditional quantitative finance to more modern machine learning approaches. However, the volatile and unstable behavior of financial markets forbids the accurate prediction of future prices, reducing the performance of these approaches. In contrast, in this paper we propose a novel price trailing method that goes beyond traditional price forecasting by reformulating trading as a control problem, effectively overcoming the aforementioned limitations. The proposed method leads to developing robust agents that can withstand large amounts of noise, while still capturing the price trends and allowing for taking profitable decisions.","",""
10,"Harishchandra Dubey, A. Sangwan, J. Hansen","Leveraging Frequency-Dependent Kernel and DIP-Based Clustering for Robust Speech Activity Detection in Naturalistic Audio Streams",2018,"","","","",194,"2022-07-13 10:05:55","","10.1109/TASLP.2018.2848698","","",,,,,10,2.50,3,3,4,"Speech activity detection (SAD) is front-end in most speech systems, e.g., speaker verification, speech recognition etc. Supervised SAD typically leverages machine learning models trained on annotated data. For applications like zero-resource speech processing and NIST-OpenSAT-2017 public safety communications task, it might not be feasible to collect SAD annotations. SAD is challenging for naturalistic audio streams containing multiple noise-sources simultaneously. We propose a novel frequency-dependent kernel (FDK) based SAD features. FDK provides enhanced spectral decomposition from which several statistical descriptors are derived. FDK statistical descriptors are combined by principal component analysis into one-dimensional FDK-SAD features. We further proposed two decision backends: First, variable model-size Gaussian mixture model (VMGMM); and second, Hartigan dip-based robust feature clustering. While VMGMM is a model-based approach, the DipSAD is nonparametric. We used both backends for comparative evaluations in two phases: first, standalone SAD performance; and second, the effect of SAD on text-dependent speaker verification using RedDots data. The NIST-OpenSAD-2015 and NIST-OpenSAT-2017 corpora are used for standalone SAD evaluations. We establish two Center for Robust Speech Systems (CRSS) corpora namely CRSS-PLTL-II and CRSS long-duration naturalistic noise corpus. The CRSS corpora facilitate standalone SAD evaluations on naturalistic audio streams. We performed comparative studies of the proposed approaches with multiple baselines including SohnSAD, rSAD, semisupervised Gaussian mixture model, and Gammatone spectrogram features.","",""
9,"Zhi Xiao, Zhe Luo, Bo Zhong, Xin Dang","Robust and Efficient Boosting Method Using the Conditional Risk",2018,"","","","",195,"2022-07-13 10:05:55","","10.1109/TNNLS.2017.2711028","","",,,,,9,2.25,2,4,4,"Well known for its simplicity and effectiveness in classification, AdaBoost, however, suffers from overfitting when class-conditional distributions have significant overlap. Moreover, it is very sensitive to noise that appears in the labels. This paper tackles the above limitations simultaneously via optimizing a modified loss function (i.e., the conditional risk). The proposed approach has the following two advantages. First, it is able to directly take into account label uncertainty with an associated label confidence. Second, it introduces a trustworthiness measure on training samples via the Bayesian risk rule, and hence the resulting classifier tends to have finite sample performance that is superior to that of the original AdaBoost when there is a large overlap between class conditional distributions. Theoretical properties of the proposed method are investigated. Extensive experimental results using synthetic data and real-world data sets from UCI machine learning repository are provided. The empirical study shows the high competitiveness of the proposed method in predication accuracy and robustness when compared with the original AdaBoost and several existing robust AdaBoost algorithms.","",""
23,"Chong Peng, Zhao Kang, Yunhong Hu, Jie Cheng, Q. Cheng","Robust Graph Regularized Nonnegative Matrix Factorization for Clustering",2017,"","","","",196,"2022-07-13 10:05:55","","10.1145/3003730","","",,,,,23,4.60,5,5,5,"Matrix factorization is often used for data representation in many data mining and machine-learning problems. In particular, for a dataset without any negative entries, nonnegative matrix factorization (NMF) is often used to find a low-rank approximation by the product of two nonnegative matrices. With reduced dimensions, these matrices can be effectively used for many applications such as clustering. The existing methods of NMF are often afflicted with their sensitivity to outliers and noise in the data. To mitigate this drawback, in this paper, we consider integrating NMF into a robust principal component model, and design a robust formulation that effectively captures noise and outliers in the approximation while incorporating essential nonlinear structures. A set of comprehensive empirical evaluations in clustering applications demonstrates that the proposed method has strong robustness to gross errors and superior performance to current state-of-the-art methods.","",""
61,"M. Tanveer, Mohammad Asif Khan, S. Ho","Robust energy-based least squares twin support vector machines",2016,"","","","",197,"2022-07-13 10:05:55","","10.1007/s10489-015-0751-1","","",,,,,61,10.17,20,3,6,"","",""
6,"Weijian Ni, Tong Liu, Q. Zeng, Xianke Zhang, H. Duan, N. Xie","Robust Factorization Machines for Credit Default Prediction",2018,"","","","",198,"2022-07-13 10:05:55","","10.1007/978-3-319-97304-3_72","","",,,,,6,1.50,1,6,4,"","",""
58,"Gang Hu, Ke-jun Wang, Yuan Peng, Mengran Qiu, Jianfei Shi, Liangliang Liu","Deep Learning Methods for Underwater Target Feature Extraction and Recognition",2018,"","","","",199,"2022-07-13 10:05:55","","10.1155/2018/1214301","","",,,,,58,14.50,10,6,4,"The classification and recognition technology of underwater acoustic signal were always an important research content in the field of underwater acoustic signal processing. Currently, wavelet transform, Hilbert-Huang transform, and Mel frequency cepstral coefficients are used as a method of underwater acoustic signal feature extraction. In this paper, a method for feature extraction and identification of underwater noise data based on CNN and ELM is proposed. An automatic feature extraction method of underwater acoustic signals is proposed using depth convolution network. An underwater target recognition classifier is based on extreme learning machine. Although convolution neural networks can execute both feature extraction and classification, their function mainly relies on a full connection layer, which is trained by gradient descent-based; the generalization ability is limited and suboptimal, so an extreme learning machine (ELM) was used in classification stage. Firstly, CNN learns deep and robust features, followed by the removing of the fully connected layers. Then ELM fed with the CNN features is used as the classifier to conduct an excellent classification. Experiments on the actual data set of civil ships obtained 93.04% recognition rate; compared to the traditional Mel frequency cepstral coefficients and Hilbert-Huang feature, recognition rate greatly improved.","",""
7,"A. Przepiórkowski","Dealing with Small, Noisy and Imbalanced Data Machine Learning or Manual Grammars?",2008,"","","","",200,"2022-07-13 10:05:55","","","","",,,,,7,0.50,7,1,14,"Abstract. This paper deals with the task of deﬁnition extraction with the train-ing corpus suffering from the problems of small size, high noise and heavy im-balance. A previous approach, based on manually constructed shallow grammars,turns out to be hard to better even by such robust classiﬁers as SVMs, AdaBoostand simple ensembles of classiﬁers. However, a linear combination of varioussuch classiﬁers and manual grammars signiﬁcantly improves the results of thelatter. 1 Introduction Machine learning (ML) methods gave a new stimulus to the ﬁeld of Natural LanguageProcessing and are largelyresponsible forits rapid developmentsince the early 1990ies.Their success is undisputed in the areas where relatively large collections of manuallyannotated and balanced data of reasonably good quality are available; a prototypicalsuch area is part-of-speech tagging.Matters are less clear when only small amounts of noisy and heavily imbalancedtraining data are available; in such cases knowledge-intensive manual approaches maystill turn out to be more effective. One such task is deﬁnition extraction, which may beapproximated by the task of classifying sentences into those containing deﬁnitions ofterms and those not containing such deﬁnitions. Previous approaches to this task usu-ally rely on manually constructed shallow or deep grammars, perhaps with additionalﬁltering by ML methods.In this paper we deal with the task of extracting deﬁnitions from instructive texts inSlavic, as described in Przepiorkowski","",""
